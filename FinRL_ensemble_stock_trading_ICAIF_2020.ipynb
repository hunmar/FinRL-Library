{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_multiple_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "802ae0b5-d88e-46ba-8082-9eb5890f9cba"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "c437c266-2780-4c50-af8b-6868e7fdaa1f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, get_baseline, backtest_plot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-01-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLY.ME', 'YNDX.ME', 'ALRS.ME', 'AFLT.ME', 'VTBR.ME', 'GAZP.ME', 'GMKN.ME', 'IRAO.ME', 'LKOH.ME', 'MGNT.ME', 'MOEX.ME', 'NLMK.ME', 'NVTK.ME', 'ROSN.ME', 'SBER.ME', 'CHMF.ME', 'AFKS.ME', 'SNGS.ME', 'TATN.ME']\n"
     ]
    }
   ],
   "source": [
    "print(config.TOPCHIK_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (28804, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = config.START_DATE,\n",
    "                     end_date = '2021-01-19',\n",
    "                     ticker_list = config.TOPCHIK_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>11.150000</td>\n",
       "      <td>9.742252</td>\n",
       "      <td>16528100.0</td>\n",
       "      <td>AFKS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>33.430000</td>\n",
       "      <td>31.070000</td>\n",
       "      <td>28.180470</td>\n",
       "      <td>982201.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>63.950001</td>\n",
       "      <td>64.489998</td>\n",
       "      <td>58.910000</td>\n",
       "      <td>34.313335</td>\n",
       "      <td>4150300.0</td>\n",
       "      <td>ALRS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>500.149994</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>499.299988</td>\n",
       "      <td>253.118896</td>\n",
       "      <td>489850.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>133.949997</td>\n",
       "      <td>129.149994</td>\n",
       "      <td>98.987381</td>\n",
       "      <td>18223370.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close      volume  \\\n",
       "0  2015-01-05   11.170000   12.460000   11.150000    9.742252  16528100.0   \n",
       "1  2015-01-05   31.250000   33.430000   31.070000   28.180470    982201.0   \n",
       "2  2015-01-05   63.950001   64.489998   58.910000   34.313335   4150300.0   \n",
       "3  2015-01-05  500.149994  522.000000  499.299988  253.118896    489850.0   \n",
       "4  2015-01-05  129.500000  133.949997  129.149994   98.987381  18223370.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFKS.ME    0  \n",
       "1  AFLT.ME    0  \n",
       "2  ALRS.ME    0  \n",
       "3  CHMF.ME    0  \n",
       "4  GAZP.ME    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>275.720001</td>\n",
       "      <td>281.299988</td>\n",
       "      <td>272.950012</td>\n",
       "      <td>279.799988</td>\n",
       "      <td>7.096328e+07</td>\n",
       "      <td>SBER.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28800</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>35.865002</td>\n",
       "      <td>36.099998</td>\n",
       "      <td>4.088790e+07</td>\n",
       "      <td>SNGS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28801</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>532.400024</td>\n",
       "      <td>535.400024</td>\n",
       "      <td>523.099976</td>\n",
       "      <td>533.099976</td>\n",
       "      <td>4.929751e+06</td>\n",
       "      <td>TATN.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28802</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>0.039380</td>\n",
       "      <td>0.039440</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.039060</td>\n",
       "      <td>3.725212e+10</td>\n",
       "      <td>VTBR.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28803</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>5002.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>4990.000000</td>\n",
       "      <td>5034.000000</td>\n",
       "      <td>5.124640e+05</td>\n",
       "      <td>YNDX.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         open         high          low        close  \\\n",
       "28799  2021-01-18   275.720001   281.299988   272.950012   279.799988   \n",
       "28800  2021-01-18    36.580002    36.580002    35.865002    36.099998   \n",
       "28801  2021-01-18   532.400024   535.400024   523.099976   533.099976   \n",
       "28802  2021-01-18     0.039380     0.039440     0.038760     0.039060   \n",
       "28803  2021-01-18  5002.000000  5061.000000  4990.000000  5034.000000   \n",
       "\n",
       "             volume      tic  day  \n",
       "28799  7.096328e+07  SBER.ME    0  \n",
       "28800  4.088790e+07  SNGS.ME    0  \n",
       "28801  4.929751e+06  TATN.ME    0  \n",
       "28802  3.725212e+10  VTBR.ME    0  \n",
       "28803  5.124640e+05  YNDX.ME    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28804, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4hYkeaPiICHS",
    "outputId": "ce9d7463-a74c-4917-c96d-848a1e8ad493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>11.150000</td>\n",
       "      <td>9.742252</td>\n",
       "      <td>16528100.0</td>\n",
       "      <td>AFKS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>33.430000</td>\n",
       "      <td>31.070000</td>\n",
       "      <td>28.180470</td>\n",
       "      <td>982201.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>63.950001</td>\n",
       "      <td>64.489998</td>\n",
       "      <td>58.910000</td>\n",
       "      <td>34.313335</td>\n",
       "      <td>4150300.0</td>\n",
       "      <td>ALRS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>500.149994</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>499.299988</td>\n",
       "      <td>253.118896</td>\n",
       "      <td>489850.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>133.949997</td>\n",
       "      <td>129.149994</td>\n",
       "      <td>98.987381</td>\n",
       "      <td>18223370.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close      volume  \\\n",
       "0  2015-01-05   11.170000   12.460000   11.150000    9.742252  16528100.0   \n",
       "1  2015-01-05   31.250000   33.430000   31.070000   28.180470    982201.0   \n",
       "2  2015-01-05   63.950001   64.489998   58.910000   34.313335   4150300.0   \n",
       "3  2015-01-05  500.149994  522.000000  499.299988  253.118896    489850.0   \n",
       "4  2015-01-05  129.500000  133.949997  129.149994   98.987381  18223370.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFKS.ME    0  \n",
       "1  AFLT.ME    0  \n",
       "2  ALRS.ME    0  \n",
       "3  CHMF.ME    0  \n",
       "4  GAZP.ME    0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13199</th>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>ROSN.ME</td>\n",
       "      <td>337.549988</td>\n",
       "      <td>339.200012</td>\n",
       "      <td>335.149994</td>\n",
       "      <td>279.305328</td>\n",
       "      <td>2556469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1049.915789</td>\n",
       "      <td>26947.796763</td>\n",
       "      <td>21804.731753</td>\n",
       "      <td>69.729068</td>\n",
       "      <td>115.954293</td>\n",
       "      <td>32.841311</td>\n",
       "      <td>23847.606510</td>\n",
       "      <td>21876.488607</td>\n",
       "      <td>30.914545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>NLMK.ME</td>\n",
       "      <td>58.799999</td>\n",
       "      <td>59.950001</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>32.598995</td>\n",
       "      <td>4210170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146293</td>\n",
       "      <td>358.887931</td>\n",
       "      <td>337.925598</td>\n",
       "      <td>46.719838</td>\n",
       "      <td>-104.666307</td>\n",
       "      <td>13.075458</td>\n",
       "      <td>347.340010</td>\n",
       "      <td>343.497371</td>\n",
       "      <td>41.476314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8930</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>AFKS.ME</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>19.660000</td>\n",
       "      <td>19.150000</td>\n",
       "      <td>15.890116</td>\n",
       "      <td>19866300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.709738</td>\n",
       "      <td>116.697649</td>\n",
       "      <td>97.483123</td>\n",
       "      <td>57.738980</td>\n",
       "      <td>157.767455</td>\n",
       "      <td>37.755385</td>\n",
       "      <td>105.799867</td>\n",
       "      <td>109.063728</td>\n",
       "      <td>56.460869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12536</th>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>SNGS.ME</td>\n",
       "      <td>27.120001</td>\n",
       "      <td>27.545000</td>\n",
       "      <td>27.040001</td>\n",
       "      <td>24.818628</td>\n",
       "      <td>30527413.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.655809</td>\n",
       "      <td>12052.504561</td>\n",
       "      <td>11343.050419</td>\n",
       "      <td>52.450335</td>\n",
       "      <td>-46.473674</td>\n",
       "      <td>12.571679</td>\n",
       "      <td>11648.368197</td>\n",
       "      <td>11343.370622</td>\n",
       "      <td>16.583938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31530</th>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>MOEX.ME</td>\n",
       "      <td>93.050003</td>\n",
       "      <td>93.110001</td>\n",
       "      <td>91.959999</td>\n",
       "      <td>86.474365</td>\n",
       "      <td>3301960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.298822</td>\n",
       "      <td>97.709683</td>\n",
       "      <td>91.074266</td>\n",
       "      <td>55.770936</td>\n",
       "      <td>1.354053</td>\n",
       "      <td>14.552304</td>\n",
       "      <td>94.625958</td>\n",
       "      <td>94.201290</td>\n",
       "      <td>17.978371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      tic        open        high         low       close  \\\n",
       "13199  2016-11-29  ROSN.ME  337.549988  339.200012  335.149994  279.305328   \n",
       "7059   2016-01-11  NLMK.ME   58.799999   59.950001   58.500000   32.598995   \n",
       "8930   2016-04-19  AFKS.ME   19.299999   19.660000   19.150000   15.890116   \n",
       "12536  2016-10-25  SNGS.ME   27.120001   27.545000   27.040001   24.818628   \n",
       "31530  2019-07-22  MOEX.ME   93.050003   93.110001   91.959999   86.474365   \n",
       "\n",
       "           volume  day         macd       boll_ub       boll_lb     rsi_30  \\\n",
       "13199   2556469.0  1.0  1049.915789  26947.796763  21804.731753  69.729068   \n",
       "7059    4210170.0  0.0     0.146293    358.887931    337.925598  46.719838   \n",
       "8930   19866300.0  1.0     1.709738    116.697649     97.483123  57.738980   \n",
       "12536  30527413.0  1.0    75.655809  12052.504561  11343.050419  52.450335   \n",
       "31530   3301960.0  0.0    -0.298822     97.709683     91.074266  55.770936   \n",
       "\n",
       "           cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "13199  115.954293  32.841311  23847.606510  21876.488607   30.914545  \n",
       "7059  -104.666307  13.075458    347.340010    343.497371   41.476314  \n",
       "8930   157.767455  37.755385    105.799867    109.063728   56.460869  \n",
       "12536  -46.473674  12.571679  11648.368197  11343.370622   16.583938  \n",
       "31530    1.354053  14.552304     94.625958     94.201290   17.978371  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 19, State Space: 191\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 1, \n",
    "    \"initial_amount\": 50_000,\n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = config.START_DATE\n",
    "train_end = '2019-01-01'\n",
    "val_test_start = '2019-01-01'\n",
    "val_test_end = '2021-01-18'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 100_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "19.57915343598964\n",
      "turbulence_threshold:  529.7283042530553\n",
      "======Model training from:  2015-01-01 to  2019-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.903   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -2.11    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0091   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -1.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -7.25    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0997   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+05 |\n",
      "|    total_cost         | 3.79e+03 |\n",
      "|    total_reward       | 7.1e+04  |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 5107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.431    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.006    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.00283  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -7.43    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.087    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.02e+05  |\n",
      "|    total_cost         | 1.77e+03  |\n",
      "|    total_reward       | 5.17e+04  |\n",
      "|    total_reward_pct   | 103       |\n",
      "|    total_trades       | 5254      |\n",
      "| time/                 |           |\n",
      "|    fps                | 378       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 5         |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0408    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.695    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0337   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.6e+04  |\n",
      "|    total_cost         | 1.22e+03 |\n",
      "|    total_reward       | 3.6e+04  |\n",
      "|    total_reward_pct   | 72       |\n",
      "|    total_trades       | 5429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 2.82     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0104   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -6.72    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 6.76     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.97e+04 |\n",
      "|    total_cost         | 1.62e+03 |\n",
      "|    total_reward       | 2.97e+04 |\n",
      "|    total_reward_pct   | 59.4     |\n",
      "|    total_trades       | 5563     |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -4.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0.0272   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.271    |\n",
      "------------------------------------\n",
      "day: 1003, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 107142.41\n",
      "total_reward: 57142.41\n",
      "total_cost: 2304.90\n",
      "total_trades: 5593\n",
      "Sharpe: 1.062\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 2.3e+03  |\n",
      "|    total_reward       | 5.71e+04 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 5593     |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 3.27     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0.352    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -6.76    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0584   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.76e+03 |\n",
      "|    total_reward       | 5.32e+04 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 5533     |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.0962   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.442    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00429  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.523   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -12.8    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.238    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 2.01e+03 |\n",
      "|    total_reward       | 6.87e+04 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 5709     |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -0.289   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.988    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.0434   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 5.82     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0661   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 1.21e+03 |\n",
      "|    total_reward       | 5.98e+04 |\n",
      "|    total_reward_pct   | 120      |\n",
      "|    total_trades       | 5502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.434   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -1.86    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00956  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 2.85     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0291   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.17e+05  |\n",
      "|    total_cost         | 1.47e+03  |\n",
      "|    total_reward       | 6.69e+04  |\n",
      "|    total_reward_pct   | 134       |\n",
      "|    total_trades       | 5648      |\n",
      "| time/                 |           |\n",
      "|    fps                | 377       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 6.24      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.0537    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -4.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -5.98    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0376   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110606.61\n",
      "total_reward: 60606.61\n",
      "total_cost: 1355.79\n",
      "total_trades: 5324\n",
      "Sharpe: 0.994\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 1.36e+03 |\n",
      "|    total_reward       | 6.06e+04 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 5324     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.901   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 2.55     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00897  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -8.63    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0951   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 2.1e+03  |\n",
      "|    total_reward       | 6.91e+04 |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 6043     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -0.653   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.00609  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.452    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 4.37     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0303   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 1.74e+03 |\n",
      "|    total_reward       | 5.11e+04 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 6196     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0.0186   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -9.81    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.0175  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -5.36    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0424   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.24e+05  |\n",
      "|    total_cost         | 2.43e+03  |\n",
      "|    total_reward       | 7.41e+04  |\n",
      "|    total_reward_pct   | 148       |\n",
      "|    total_trades       | 6453      |\n",
      "| time/                 |           |\n",
      "|    fps                | 377       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -1.55     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.01      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | -0.0807  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.877   |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00823  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 1.9e+03  |\n",
      "|    total_reward       | 5.93e+04 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 6373     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -7.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.836    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.0081   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.109   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 4.06     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0412   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 115275.20\n",
      "total_reward: 65275.20\n",
      "total_cost: 1863.55\n",
      "total_trades: 6249\n",
      "Sharpe: 0.982\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+05 |\n",
      "|    total_cost         | 1.86e+03 |\n",
      "|    total_reward       | 6.53e+04 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 6249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -2.63    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00609  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.26e+05 |\n",
      "|    total_cost         | 1.24e+03 |\n",
      "|    total_reward       | 7.55e+04 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 6254     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 3.42     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0113   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | -0.395   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -2.44    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.021    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+05 |\n",
      "|    total_cost         | 1.69e+03 |\n",
      "|    total_reward       | 7.38e+04 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 6451     |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -3.38    |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.0117   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | -0.532   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 7.46     |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.0744   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.97e+03  |\n",
      "|    total_reward       | 5.01e+04  |\n",
      "|    total_reward_pct   | 100       |\n",
      "|    total_trades       | 6666      |\n",
      "| time/                 |           |\n",
      "|    fps                | 377       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -3.32     |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.0135    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | -0.606   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -3.67    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.43e+04 |\n",
      "|    total_cost         | 2.24e+03 |\n",
      "|    total_reward       | 4.43e+04 |\n",
      "|    total_reward_pct   | 88.5     |\n",
      "|    total_trades       | 7003     |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.715    |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.00409  |\n",
      "------------------------------------\n",
      "day: 1003, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70026.75\n",
      "total_reward: 20026.75\n",
      "total_cost: 2885.22\n",
      "total_trades: 7164\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7e+04    |\n",
      "|    total_cost         | 2.89e+03 |\n",
      "|    total_reward       | 2e+04    |\n",
      "|    total_reward_pct   | 40.1     |\n",
      "|    total_trades       | 7164     |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | -22.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.00334  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | -0.0862  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.756    |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.00645  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.38e+04  |\n",
      "|    total_cost         | 5.82e+03  |\n",
      "|    total_reward       | 3.38e+04  |\n",
      "|    total_reward_pct   | 67.6      |\n",
      "|    total_trades       | 7972      |\n",
      "| time/                 |           |\n",
      "|    fps                | 375       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -1.36     |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.00217   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | -0.235   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 3.87     |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0195   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 2.34e+03 |\n",
      "|    total_reward       | 5.89e+04 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 8233     |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00288  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | 0.319    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -6.6     |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.0365   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.99e+03 |\n",
      "|    total_reward       | 5e+04    |\n",
      "|    total_reward_pct   | 99.9     |\n",
      "|    total_trades       | 8411     |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | -1.88    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 6.23     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.0538   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 8.29     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 2.45e+03 |\n",
      "|    total_reward       | 5.6e+04  |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 8017     |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | -6.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 5.77     |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.0485   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | -0.634   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -2.79    |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 99066.17\n",
      "total_reward: 49066.17\n",
      "total_cost: 1679.94\n",
      "total_trades: 7795\n",
      "Sharpe: 0.872\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.91e+04 |\n",
      "|    total_cost         | 1.68e+03 |\n",
      "|    total_reward       | 4.91e+04 |\n",
      "|    total_reward_pct   | 98.1     |\n",
      "|    total_trades       | 7795     |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | -0.0603  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -3.81    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.0215   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.0631  |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00415  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.5e+04  |\n",
      "|    total_cost         | 2.07e+03 |\n",
      "|    total_reward       | 4.5e+04  |\n",
      "|    total_reward_pct   | 90       |\n",
      "|    total_trades       | 7973     |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 5.32     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0241   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.8    |\n",
      "|    explained_variance | -0.206   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.00698  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.47e+04 |\n",
      "|    total_cost         | 2.85e+03 |\n",
      "|    total_reward       | 4.47e+04 |\n",
      "|    total_reward_pct   | 89.5     |\n",
      "|    total_trades       | 8115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | -0.213   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.832   |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00154  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.1    |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.524   |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.0041   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.25e+04 |\n",
      "|    total_cost         | 2.73e+03 |\n",
      "|    total_reward       | 4.25e+04 |\n",
      "|    total_reward_pct   | 85       |\n",
      "|    total_trades       | 8288     |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -0.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.427    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.00187  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | -2.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -6       |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.0293   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.94e+04 |\n",
      "|    total_cost         | 4.61e+03 |\n",
      "|    total_reward       | 2.94e+04 |\n",
      "|    total_reward_pct   | 58.7     |\n",
      "|    total_trades       | 8644     |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | -0.244   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 7.73     |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.0619   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | 0.312    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 5        |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.0309   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110884.02\n",
      "total_reward: 60884.02\n",
      "total_cost: 4312.22\n",
      "total_trades: 8484\n",
      "Sharpe: 1.059\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 4.31e+03 |\n",
      "|    total_reward       | 6.09e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 8484     |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -2.99    |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.00745  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | 0.0417   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 4.45     |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.0302   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.3e+05  |\n",
      "|    total_cost         | 3.55e+03 |\n",
      "|    total_reward       | 8.02e+04 |\n",
      "|    total_reward_pct   | 160      |\n",
      "|    total_trades       | 8102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 4        |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.0234   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | 0.0134   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.266    |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.0197   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.32e+05 |\n",
      "|    total_cost         | 3.99e+03 |\n",
      "|    total_reward       | 8.22e+04 |\n",
      "|    total_reward_pct   | 164      |\n",
      "|    total_trades       | 8249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.00184  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | -0.0289  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 2.92     |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.0196   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.3e+05  |\n",
      "|    total_cost         | 4.66e+03 |\n",
      "|    total_reward       | 7.99e+04 |\n",
      "|    total_reward_pct   | 160      |\n",
      "|    total_trades       | 7990     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | -0.434   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 2.65     |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.00645  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.9    |\n",
      "|    explained_variance | 0.0903   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -8.44    |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.0645   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+05 |\n",
      "|    total_cost         | 5.17e+03 |\n",
      "|    total_reward       | 7.42e+04 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 7736     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -0.0197  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -1.39    |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.00663  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | -1.85    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 0.798    |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.00286  |\n",
      "------------------------------------\n",
      "day: 1003, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92318.74\n",
      "total_reward: 42318.74\n",
      "total_cost: 3986.54\n",
      "total_trades: 7228\n",
      "Sharpe: 0.821\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.23e+04 |\n",
      "|    total_cost         | 3.99e+03 |\n",
      "|    total_reward       | 4.23e+04 |\n",
      "|    total_reward_pct   | 84.6     |\n",
      "|    total_trades       | 7228     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | -0.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 10       |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.0781   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 0.000898 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 1.8      |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 0.00912  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 2.45e+03 |\n",
      "|    total_reward       | 5.29e+04 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 7673     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | -0.252   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -2.01    |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.00632  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | -0.00602 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -5.19    |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.036    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 2.63e+03 |\n",
      "|    total_reward       | 5.79e+04 |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 7885     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | -1.39    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.843    |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.0041   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | -0.00796 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -4.5     |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 2.55e+03 |\n",
      "|    total_reward       | 6.15e+04 |\n",
      "|    total_reward_pct   | 123      |\n",
      "|    total_trades       | 7994     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | -1.51    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -1.6     |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.00557  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | -0.207   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -2.29    |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.00386  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.51e+04 |\n",
      "|    total_cost         | 2.52e+03 |\n",
      "|    total_reward       | 4.51e+04 |\n",
      "|    total_reward_pct   | 90.2     |\n",
      "|    total_trades       | 7963     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | -2.7     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0.00779 |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.00151  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0.0307   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -3.53    |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.0181   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 79133.86\n",
      "total_reward: 29133.86\n",
      "total_cost: 3580.69\n",
      "total_trades: 8375\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.91e+04 |\n",
      "|    total_cost         | 3.58e+03 |\n",
      "|    total_reward       | 2.91e+04 |\n",
      "|    total_reward_pct   | 58.3     |\n",
      "|    total_trades       | 8375     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | -0.708   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -6.04    |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.0319   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | -0.0796  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -2.47    |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 0.00605  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.37e+04 |\n",
      "|    total_cost         | 3.68e+03 |\n",
      "|    total_reward       | 2.37e+04 |\n",
      "|    total_reward_pct   | 47.3     |\n",
      "|    total_trades       | 8412     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39      |\n",
      "|    explained_variance | -0.199   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -3.01    |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | -0.00554 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 2.85     |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.006    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.41e+04 |\n",
      "|    total_cost         | 6.05e+03 |\n",
      "|    total_reward       | 3.41e+04 |\n",
      "|    total_reward_pct   | 68.3     |\n",
      "|    total_trades       | 8923     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | -0.134   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 0.00846  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | -0.0316  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 2.47     |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.0201   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.25e+04 |\n",
      "|    total_cost         | 4.53e+03 |\n",
      "|    total_reward       | 3.25e+04 |\n",
      "|    total_reward_pct   | 65       |\n",
      "|    total_trades       | 8647     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | -0.333   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 2.41     |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.00605  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -8.86    |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.0531   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.39e+04 |\n",
      "|    total_cost         | 4e+03    |\n",
      "|    total_reward       | 3.39e+04 |\n",
      "|    total_reward_pct   | 67.8     |\n",
      "|    total_trades       | 8983     |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.0209   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 6.13     |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.0301   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -0.0161  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -21      |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 0.446    |\n",
      "------------------------------------\n",
      "day: 1003, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74813.62\n",
      "total_reward: 24813.62\n",
      "total_cost: 3561.71\n",
      "total_trades: 8824\n",
      "Sharpe: 0.605\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.48e+04 |\n",
      "|    total_cost         | 3.56e+03 |\n",
      "|    total_reward       | 2.48e+04 |\n",
      "|    total_reward_pct   | 49.6     |\n",
      "|    total_trades       | 8824     |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | -1.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -2.9     |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.00639  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.0898   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.661   |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.00123  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.43e+04 |\n",
      "|    total_cost         | 3e+03    |\n",
      "|    total_reward       | 2.43e+04 |\n",
      "|    total_reward_pct   | 48.5     |\n",
      "|    total_trades       | 9189     |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0.553    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -2.1     |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.00415  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0.00384  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -1.8     |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 0.00784  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.17e+04 |\n",
      "|    total_cost         | 1.46e+03 |\n",
      "|    total_reward       | 2.17e+04 |\n",
      "|    total_reward_pct   | 43.4     |\n",
      "|    total_trades       | 8959     |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.9    |\n",
      "|    explained_variance | -0.237   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -2.92    |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.00776  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | -0.175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.927    |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.0047   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.46e+04 |\n",
      "|    total_cost         | 1.98e+03 |\n",
      "|    total_reward       | 3.46e+04 |\n",
      "|    total_reward_pct   | 69.2     |\n",
      "|    total_trades       | 9604     |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 0.0175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -4.03    |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | -0.066   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -7.23    |\n",
      "|    std                | 2.15     |\n",
      "|    value_loss         | 0.0336   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.98e+04 |\n",
      "|    total_cost         | 2.66e+03 |\n",
      "|    total_reward       | 2.98e+04 |\n",
      "|    total_reward_pct   | 59.6     |\n",
      "|    total_trades       | 9703     |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | -0.186   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -2.15    |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.00415  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | -0.0678  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 5.04     |\n",
      "|    std                | 2.18     |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82076.85\n",
      "total_reward: 32076.85\n",
      "total_cost: 2529.02\n",
      "total_trades: 9802\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.21e+04 |\n",
      "|    total_cost         | 2.53e+03 |\n",
      "|    total_reward       | 3.21e+04 |\n",
      "|    total_reward_pct   | 64.2     |\n",
      "|    total_trades       | 9802     |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0.0906   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 2.19     |\n",
      "|    value_loss         | 0.0273   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | 0.0855   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 0.0113   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.32e+04 |\n",
      "|    total_cost         | 2.14e+03 |\n",
      "|    total_reward       | 4.32e+04 |\n",
      "|    total_reward_pct   | 86.4     |\n",
      "|    total_trades       | 9823     |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0.12     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 2.22     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.00348  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 368       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -4.36     |\n",
      "|    std                | 2.25      |\n",
      "|    value_loss         | 0.0131    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.78e+04 |\n",
      "|    total_cost         | 2.07e+03 |\n",
      "|    total_reward       | 2.78e+04 |\n",
      "|    total_reward_pct   | 55.5     |\n",
      "|    total_trades       | 10064    |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0322   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.0029   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 7.31     |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.0306   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.39e+04 |\n",
      "|    total_cost         | 2.24e+03 |\n",
      "|    total_reward       | 3.39e+04 |\n",
      "|    total_reward_pct   | 67.9     |\n",
      "|    total_trades       | 9980     |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0413   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 4.89     |\n",
      "|    std                | 2.31     |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.208   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -1.86    |\n",
      "|    std                | 2.34     |\n",
      "|    value_loss         | 0.00464  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.3e+04  |\n",
      "|    total_cost         | 3.32e+03 |\n",
      "|    total_reward       | 2.3e+04  |\n",
      "|    total_reward_pct   | 46       |\n",
      "|    total_trades       | 9775     |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 9.95e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -0.891   |\n",
      "|    std                | 2.35     |\n",
      "|    value_loss         | 0.00273  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -4.36    |\n",
      "|    std                | 2.37     |\n",
      "|    value_loss         | 0.0155   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90477.07\n",
      "total_reward: 40477.07\n",
      "total_cost: 3527.76\n",
      "total_trades: 10016\n",
      "Sharpe: 0.929\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.05e+04 |\n",
      "|    total_cost         | 3.53e+03 |\n",
      "|    total_reward       | 4.05e+04 |\n",
      "|    total_reward_pct   | 81       |\n",
      "|    total_trades       | 10016    |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.011    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -3       |\n",
      "|    std                | 2.39     |\n",
      "|    value_loss         | 0.00929  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.233    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 1.23     |\n",
      "|    std                | 2.41     |\n",
      "|    value_loss         | 0.0027   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.2e+04  |\n",
      "|    total_cost         | 2.68e+03 |\n",
      "|    total_reward       | 3.2e+04  |\n",
      "|    total_reward_pct   | 64       |\n",
      "|    total_trades       | 9715     |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -0.413   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -3.54    |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 0.0118   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -8.77    |\n",
      "|    std                | 2.47     |\n",
      "|    value_loss         | 0.0475   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.41e+04 |\n",
      "|    total_cost         | 3.04e+03 |\n",
      "|    total_reward       | 1.41e+04 |\n",
      "|    total_reward_pct   | 28.3     |\n",
      "|    total_trades       | 9781     |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 5.8      |\n",
      "|    std                | 2.49     |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 1.49     |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 0.0053   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.07e+04 |\n",
      "|    total_cost         | 1.88e+03 |\n",
      "|    total_reward       | 2.07e+04 |\n",
      "|    total_reward_pct   | 41.5     |\n",
      "|    total_trades       | 9746     |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.0665   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | -0.233   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 11.6     |\n",
      "|    std                | 2.57     |\n",
      "|    value_loss         | 0.0647   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.41e+04 |\n",
      "|    total_cost         | 2.11e+03 |\n",
      "|    total_reward       | 3.41e+04 |\n",
      "|    total_reward_pct   | 68.3     |\n",
      "|    total_trades       | 10085    |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0.0304   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -5.33    |\n",
      "|    std                | 2.58     |\n",
      "|    value_loss         | 0.0201   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "day: 1003, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 98843.54\n",
      "total_reward: 48843.54\n",
      "total_cost: 2776.86\n",
      "total_trades: 10208\n",
      "Sharpe: 1.063\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.88e+04 |\n",
      "|    total_cost         | 2.78e+03 |\n",
      "|    total_reward       | 4.88e+04 |\n",
      "|    total_reward_pct   | 97.7     |\n",
      "|    total_trades       | 10208    |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0.0968   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -3.1     |\n",
      "|    std                | 2.62     |\n",
      "|    value_loss         | 0.00928  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 9.17     |\n",
      "|    std                | 2.65     |\n",
      "|    value_loss         | 0.0431   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.5e+04   |\n",
      "|    total_cost         | 2.26e+03  |\n",
      "|    total_reward       | 3.5e+04   |\n",
      "|    total_reward_pct   | 70        |\n",
      "|    total_trades       | 9990      |\n",
      "| time/                 |           |\n",
      "|    fps                | 366       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -4.36     |\n",
      "|    std                | 2.67      |\n",
      "|    value_loss         | 0.0109    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.00802  |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.00117  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.82e+04 |\n",
      "|    total_cost         | 2.65e+03 |\n",
      "|    total_reward       | 3.82e+04 |\n",
      "|    total_reward_pct   | 76.4     |\n",
      "|    total_trades       | 10090    |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | -0.425   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.456    |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 0.00129  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | -0.129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -8.6     |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 0.0431   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.88e+04 |\n",
      "|    total_cost         | 2.87e+03 |\n",
      "|    total_reward       | 3.88e+04 |\n",
      "|    total_reward_pct   | 77.6     |\n",
      "|    total_trades       | 9787     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -4.63    |\n",
      "|    std                | 2.77     |\n",
      "|    value_loss         | 0.0206   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.3      |\n",
      "|    std                | 2.79     |\n",
      "|    value_loss         | 0.00332  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.65e+04 |\n",
      "|    total_cost         | 2.2e+03  |\n",
      "|    total_reward       | 2.65e+04 |\n",
      "|    total_reward_pct   | 52.9     |\n",
      "|    total_trades       | 9811     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0.286    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 1.45     |\n",
      "|    std                | 2.81     |\n",
      "|    value_loss         | 0.00258  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 3.99     |\n",
      "|    std                | 2.84     |\n",
      "|    value_loss         | 0.00755  |\n",
      "------------------------------------\n",
      "day: 1003, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 64316.68\n",
      "total_reward: 14316.68\n",
      "total_cost: 1901.65\n",
      "total_trades: 9488\n",
      "Sharpe: 0.414\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.43e+04 |\n",
      "|    total_cost         | 1.9e+03  |\n",
      "|    total_reward       | 1.43e+04 |\n",
      "|    total_reward_pct   | 28.6     |\n",
      "|    total_trades       | 9488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -4.37    |\n",
      "|    std                | 2.87     |\n",
      "|    value_loss         | 0.0196   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 7.27     |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.0368   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 2.61e+03 |\n",
      "|    total_reward       | 5.17e+04 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 9652     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -3.73    |\n",
      "|    std                | 2.91     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -6.01    |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 0.0165   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.69e+04 |\n",
      "|    total_cost         | 2e+03    |\n",
      "|    total_reward       | 4.69e+04 |\n",
      "|    total_reward_pct   | 93.9     |\n",
      "|    total_trades       | 9811     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -7.96    |\n",
      "|    std                | 2.95     |\n",
      "|    value_loss         | 0.0314   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 1.38     |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 0.00821  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.69e+04 |\n",
      "|    total_cost         | 1.64e+03 |\n",
      "|    total_reward       | 3.69e+04 |\n",
      "|    total_reward_pct   | 73.9     |\n",
      "|    total_trades       | 10036    |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | -0.0633  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 7.85     |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.0352   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0.048    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -8.54    |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.039    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 2.18e+03 |\n",
      "|    total_reward       | 5.39e+04 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 10079    |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | -0.696   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -0.343   |\n",
      "|    std                | 3.05     |\n",
      "|    value_loss         | 0.00144  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | -0.959   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -7.35    |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.0776   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 78148.49\n",
      "total_reward: 28148.49\n",
      "total_cost: 1921.34\n",
      "total_trades: 10123\n",
      "Sharpe: 0.603\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.81e+04 |\n",
      "|    total_cost         | 1.92e+03 |\n",
      "|    total_reward       | 2.81e+04 |\n",
      "|    total_reward_pct   | 56.3     |\n",
      "|    total_trades       | 10123    |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0.00242  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -5.43    |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.0143   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 33.4     |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.469    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.22e+05 |\n",
      "|    total_cost         | 2.35e+03 |\n",
      "|    total_reward       | 7.24e+04 |\n",
      "|    total_reward_pct   | 145      |\n",
      "|    total_trades       | 10072    |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0.619    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 5.91     |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.0155   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 5.65     |\n",
      "|    std                | 3.18     |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.65e+04 |\n",
      "|    total_cost         | 1.95e+03 |\n",
      "|    total_reward       | 4.65e+04 |\n",
      "|    total_reward_pct   | 92.9     |\n",
      "|    total_trades       | 9820     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | -0.121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 3.94     |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.00847  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 366       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | -4.27     |\n",
      "|    std                | 3.24      |\n",
      "|    value_loss         | 0.00867   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.45e+04 |\n",
      "|    total_cost         | 1.91e+03 |\n",
      "|    total_reward       | 4.45e+04 |\n",
      "|    total_reward_pct   | 89       |\n",
      "|    total_trades       | 10025    |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | 0.378    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -0.53    |\n",
      "|    std                | 3.26     |\n",
      "|    value_loss         | 0.000848 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -7.38    |\n",
      "|    std                | 3.29     |\n",
      "|    value_loss         | 0.0254   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.08e+05  |\n",
      "|    total_cost         | 2.11e+03  |\n",
      "|    total_reward       | 5.81e+04  |\n",
      "|    total_reward_pct   | 116       |\n",
      "|    total_trades       | 10112     |\n",
      "| time/                 |           |\n",
      "|    fps                | 365       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 203       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | 8.28      |\n",
      "|    std                | 3.31      |\n",
      "|    value_loss         | 0.034     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 2.91     |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.00433  |\n",
      "------------------------------------\n",
      "day: 1003, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110370.86\n",
      "total_reward: 60370.86\n",
      "total_cost: 2885.73\n",
      "total_trades: 10189\n",
      "Sharpe: 1.052\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 2.89e+03 |\n",
      "|    total_reward       | 6.04e+04 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 10189    |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 3.03     |\n",
      "|    std                | 3.37     |\n",
      "|    value_loss         | 0.00434  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 4.53     |\n",
      "|    std                | 3.39     |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 4.06e+03 |\n",
      "|    total_reward       | 6.81e+04 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 10173    |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | -0.0437  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 5.34     |\n",
      "|    std                | 3.41     |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -4.04    |\n",
      "|    std                | 3.43     |\n",
      "|    value_loss         | 0.00788  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.74e+04 |\n",
      "|    total_cost         | 2.22e+03 |\n",
      "|    total_reward       | 4.74e+04 |\n",
      "|    total_reward_pct   | 94.7     |\n",
      "|    total_trades       | 9957     |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | -0.264   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 1.16     |\n",
      "|    std                | 3.46     |\n",
      "|    value_loss         | 0.00246  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 2.19     |\n",
      "|    std                | 3.49     |\n",
      "|    value_loss         | 0.00338  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.06e+04 |\n",
      "|    total_cost         | 2.24e+03 |\n",
      "|    total_reward       | 4.06e+04 |\n",
      "|    total_reward_pct   | 81.2     |\n",
      "|    total_trades       | 10052    |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -2.82    |\n",
      "|    std                | 3.52     |\n",
      "|    value_loss         | 0.00935  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 3.83     |\n",
      "|    std                | 3.56     |\n",
      "|    value_loss         | 0.00635  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.61e+04 |\n",
      "|    total_cost         | 2.21e+03 |\n",
      "|    total_reward       | 4.61e+04 |\n",
      "|    total_reward_pct   | 92.2     |\n",
      "|    total_trades       | 10175    |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -3.84    |\n",
      "|    std                | 3.58     |\n",
      "|    value_loss         | 0.00695  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 1.92     |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 0.00203  |\n",
      "------------------------------------\n",
      "day: 1003, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95419.68\n",
      "total_reward: 45419.68\n",
      "total_cost: 2344.16\n",
      "total_trades: 10140\n",
      "Sharpe: 0.853\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.54e+04 |\n",
      "|    total_cost         | 2.34e+03 |\n",
      "|    total_reward       | 4.54e+04 |\n",
      "|    total_reward_pct   | 90.8     |\n",
      "|    total_trades       | 10140    |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 1.47     |\n",
      "|    std                | 3.64     |\n",
      "|    value_loss         | 0.00262  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 2.82     |\n",
      "|    std                | 3.68     |\n",
      "|    value_loss         | 0.00574  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.11e+05  |\n",
      "|    total_cost         | 1.95e+03  |\n",
      "|    total_reward       | 6.1e+04   |\n",
      "|    total_reward_pct   | 122       |\n",
      "|    total_trades       | 10068     |\n",
      "| time/                 |           |\n",
      "|    fps                | 364       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 223       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | 4.49      |\n",
      "|    std                | 3.7       |\n",
      "|    value_loss         | 0.00759   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    std                | 3.73     |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.17e+05 |\n",
      "|    total_cost         | 2.92e+03 |\n",
      "|    total_reward       | 6.69e+04 |\n",
      "|    total_reward_pct   | 134      |\n",
      "|    total_trades       | 9832     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -0.85    |\n",
      "|    std                | 3.75     |\n",
      "|    value_loss         | 0.00508  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -5.41    |\n",
      "|    std                | 3.78     |\n",
      "|    value_loss         | 0.0119   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 2.76e+03 |\n",
      "|    total_reward       | 6.56e+04 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 9785     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | 0.169    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 7.17     |\n",
      "|    std                | 3.81     |\n",
      "|    value_loss         | 0.0207   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -0.828   |\n",
      "|    std                | 3.85     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 2.36e+03 |\n",
      "|    total_reward       | 6.92e+04 |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 9867     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -8.51    |\n",
      "|    std                | 3.87     |\n",
      "|    value_loss         | 0.0277   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | 0.22     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    std                | 3.89     |\n",
      "|    value_loss         | 0.00117  |\n",
      "------------------------------------\n",
      "day: 1003, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 124377.69\n",
      "total_reward: 74377.69\n",
      "total_cost: 1982.40\n",
      "total_trades: 9791\n",
      "Sharpe: 1.106\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+05 |\n",
      "|    total_cost         | 1.98e+03 |\n",
      "|    total_reward       | 7.44e+04 |\n",
      "|    total_reward_pct   | 149      |\n",
      "|    total_trades       | 9791     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | 0.481    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 3.47     |\n",
      "|    std                | 3.92     |\n",
      "|    value_loss         | 0.00502  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    std                | 3.95     |\n",
      "|    value_loss         | 0.0621   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.31e+05 |\n",
      "|    total_cost         | 2.68e+03 |\n",
      "|    total_reward       | 8.07e+04 |\n",
      "|    total_reward_pct   | 161      |\n",
      "|    total_trades       | 9817     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -0.0776  |\n",
      "|    std                | 3.97     |\n",
      "|    value_loss         | 0.00127  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 8.74     |\n",
      "|    std                | 4.01     |\n",
      "|    value_loss         | 0.0317   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 2.37e+03 |\n",
      "|    total_reward       | 6.76e+04 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 10013    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 0.863    |\n",
      "|    std                | 4.04     |\n",
      "|    value_loss         | 0.00705  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 2.6      |\n",
      "|    std                | 4.07     |\n",
      "|    value_loss         | 0.00793  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 2.36e+03 |\n",
      "|    total_reward       | 6.88e+04 |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 10211    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | -3.97    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 10.2     |\n",
      "|    std                | 4.09     |\n",
      "|    value_loss         | 0.039    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0.124    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 0.00616  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 3.35e+03 |\n",
      "|    total_reward       | 5.65e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 10407    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.9    |\n",
      "|    explained_variance | 0.282    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -2.71    |\n",
      "|    std                | 4.14     |\n",
      "|    value_loss         | 0.00446  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | 0.262    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 1.58     |\n",
      "|    std                | 4.17     |\n",
      "|    value_loss         | 0.00656  |\n",
      "------------------------------------\n",
      "day: 1003, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 117729.53\n",
      "total_reward: 67729.53\n",
      "total_cost: 3641.64\n",
      "total_trades: 10844\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 3.64e+03 |\n",
      "|    total_reward       | 6.77e+04 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 10844    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | -1.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 2.07     |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 0.00407  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 363       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 3.1       |\n",
      "|    std                | 4.22      |\n",
      "|    value_loss         | 0.0118    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.26e+05 |\n",
      "|    total_cost         | 3.17e+03 |\n",
      "|    total_reward       | 7.64e+04 |\n",
      "|    total_reward_pct   | 153      |\n",
      "|    total_trades       | 10883    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 8.1      |\n",
      "|    std                | 4.25     |\n",
      "|    value_loss         | 0.0296   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 5.02     |\n",
      "|    std                | 4.28     |\n",
      "|    value_loss         | 0.0214   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.28e+05 |\n",
      "|    total_cost         | 3.47e+03 |\n",
      "|    total_reward       | 7.78e+04 |\n",
      "|    total_reward_pct   | 156      |\n",
      "|    total_trades       | 11048    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | -0.0564  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -2.25    |\n",
      "|    std                | 4.3      |\n",
      "|    value_loss         | 0.0062   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 9.02     |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.0327   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.39e+05 |\n",
      "|    total_cost         | 3.82e+03 |\n",
      "|    total_reward       | 8.93e+04 |\n",
      "|    total_reward_pct   | 179      |\n",
      "|    total_trades       | 11278    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | -0.805   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -3.4     |\n",
      "|    std                | 4.37     |\n",
      "|    value_loss         | 0.00556  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 3.77     |\n",
      "|    std                | 4.39     |\n",
      "|    value_loss         | 0.00933  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+05 |\n",
      "|    total_cost         | 3.48e+03 |\n",
      "|    total_reward       | 8.73e+04 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 11361    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.559   |\n",
      "|    std                | 4.41     |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 7.66     |\n",
      "|    std                | 4.44     |\n",
      "|    value_loss         | 0.0673   |\n",
      "------------------------------------\n",
      "day: 1003, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 141473.95\n",
      "total_reward: 91473.95\n",
      "total_cost: 3020.38\n",
      "total_trades: 11366\n",
      "Sharpe: 1.289\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.41e+05 |\n",
      "|    total_cost         | 3.02e+03 |\n",
      "|    total_reward       | 9.15e+04 |\n",
      "|    total_reward_pct   | 183      |\n",
      "|    total_trades       | 11366    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -1.4     |\n",
      "|    std                | 4.47     |\n",
      "|    value_loss         | 0.000927 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -1.26    |\n",
      "|    std                | 4.5      |\n",
      "|    value_loss         | 0.0366   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.38e+05 |\n",
      "|    total_cost         | 4.44e+03 |\n",
      "|    total_reward       | 8.75e+04 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 12040    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | -2.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    std                | 4.52     |\n",
      "|    value_loss         | 0.00283  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -5.66    |\n",
      "|    std                | 4.55     |\n",
      "|    value_loss         | 0.016    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.3e+05  |\n",
      "|    total_cost         | 4.72e+03 |\n",
      "|    total_reward       | 8.04e+04 |\n",
      "|    total_reward_pct   | 161      |\n",
      "|    total_trades       | 12003    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | -0.736   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -5.11    |\n",
      "|    std                | 4.58     |\n",
      "|    value_loss         | 0.00968  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56      |\n",
      "|    explained_variance | -0.295   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    std                | 4.62     |\n",
      "|    value_loss         | 0.0836   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.31e+05 |\n",
      "|    total_cost         | 3.81e+03 |\n",
      "|    total_reward       | 8.11e+04 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 11843    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | 0.311    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 1.86     |\n",
      "|    std                | 4.66     |\n",
      "|    value_loss         | 0.00301  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | -0.0141  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -9.18    |\n",
      "|    std                | 4.7      |\n",
      "|    value_loss         | 0.0338   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.4e+05  |\n",
      "|    total_cost         | 3.71e+03 |\n",
      "|    total_reward       | 8.98e+04 |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 12109    |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.4    |\n",
      "|    explained_variance | 0.0714   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -9.5     |\n",
      "|    std                | 4.72     |\n",
      "|    value_loss         | 0.0271   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | -1.88    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.334   |\n",
      "|    std                | 4.77     |\n",
      "|    value_loss         | 0.00513  |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-01-03 to  2019-04-04\n",
      "A2C Sharpe Ratio:  -0.030127591325073207\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.65e+04 |\n",
      "|    total_cost       | 9.18e+03 |\n",
      "|    total_reward     | 1.65e+04 |\n",
      "|    total_reward_pct | 33       |\n",
      "|    total_trades     | 5540     |\n",
      "| time/               |          |\n",
      "|    fps              | 468      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.02e+04    |\n",
      "|    total_cost           | 1.01e+04    |\n",
      "|    total_reward         | 2.02e+04    |\n",
      "|    total_reward_pct     | 40.3        |\n",
      "|    total_trades         | 5590        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 450         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008080849 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -1.76       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.0525      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 101266.79\n",
      "total_reward: 51266.79\n",
      "total_cost: 7332.02\n",
      "total_trades: 5440\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.61e+04    |\n",
      "|    total_cost           | 8.23e+03    |\n",
      "|    total_reward         | 2.61e+04    |\n",
      "|    total_reward_pct     | 52.2        |\n",
      "|    total_trades         | 5582        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015530047 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.29       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0413      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.05e+04    |\n",
      "|    total_cost           | 8.22e+03    |\n",
      "|    total_reward         | 4.05e+04    |\n",
      "|    total_reward_pct     | 81          |\n",
      "|    total_trades         | 5459        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 436         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016956557 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0593      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0371      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 71674.47\n",
      "total_reward: 21674.47\n",
      "total_cost: 7937.61\n",
      "total_trades: 5538\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.17e+04    |\n",
      "|    total_cost           | 7.94e+03    |\n",
      "|    total_reward         | 2.17e+04    |\n",
      "|    total_reward_pct     | 43.3        |\n",
      "|    total_trades         | 5538        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 435         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015625576 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0315      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.77e+04   |\n",
      "|    total_cost           | 6.75e+03   |\n",
      "|    total_reward         | 1.77e+04   |\n",
      "|    total_reward_pct     | 35.3       |\n",
      "|    total_trades         | 5546       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 432        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01834788 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.229      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.025      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+05    |\n",
      "|    total_cost           | 4.86e+03    |\n",
      "|    total_reward         | 5.44e+04    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 5682        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023338187 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0343      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89211.15\n",
      "total_reward: 39211.15\n",
      "total_cost: 5825.98\n",
      "total_trades: 5480\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.58e+04    |\n",
      "|    total_cost           | 5.8e+03     |\n",
      "|    total_reward         | 2.58e+04    |\n",
      "|    total_reward_pct     | 51.6        |\n",
      "|    total_trades         | 5534        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023336748 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0428      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.11e+04    |\n",
      "|    total_cost           | 6e+03       |\n",
      "|    total_reward         | 4.11e+04    |\n",
      "|    total_reward_pct     | 82.1        |\n",
      "|    total_trades         | 5784        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016760582 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0305      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 120\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 105243.43\n",
      "total_reward: 55243.43\n",
      "total_cost: 7379.25\n",
      "total_trades: 5727\n",
      "Sharpe: 1.176\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.05e+05    |\n",
      "|    total_cost           | 7.38e+03    |\n",
      "|    total_reward         | 5.52e+04    |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 5727        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010725363 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0439      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.84e+04    |\n",
      "|    total_cost           | 5.85e+03    |\n",
      "|    total_reward         | 3.84e+04    |\n",
      "|    total_reward_pct     | 76.8        |\n",
      "|    total_trades         | 5604        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020359699 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0425      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.12e+04   |\n",
      "|    total_cost           | 5.75e+03   |\n",
      "|    total_reward         | 4.12e+04   |\n",
      "|    total_reward_pct     | 82.4       |\n",
      "|    total_trades         | 5628       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 431        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02599851 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.304     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0253    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0321     |\n",
      "----------------------------------------\n",
      "day: 1003, episode: 125\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 88144.09\n",
      "total_reward: 38144.09\n",
      "total_cost: 5465.05\n",
      "total_trades: 5583\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.98e+04    |\n",
      "|    total_cost           | 6.42e+03    |\n",
      "|    total_reward         | 3.98e+04    |\n",
      "|    total_reward_pct     | 79.6        |\n",
      "|    total_trades         | 5555        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018031359 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0316      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.06e+04    |\n",
      "|    total_cost           | 5.86e+03    |\n",
      "|    total_reward         | 4.06e+04    |\n",
      "|    total_reward_pct     | 81.2        |\n",
      "|    total_trades         | 5678        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014833582 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0256      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 130\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95045.33\n",
      "total_reward: 45045.33\n",
      "total_cost: 5171.19\n",
      "total_trades: 5583\n",
      "Sharpe: 0.825\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.5e+04     |\n",
      "|    total_cost           | 5.17e+03    |\n",
      "|    total_reward         | 4.5e+04     |\n",
      "|    total_reward_pct     | 90.1        |\n",
      "|    total_trades         | 5583        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025057387 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0297      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.07e+04    |\n",
      "|    total_cost           | 5.91e+03    |\n",
      "|    total_reward         | 4.07e+04    |\n",
      "|    total_reward_pct     | 81.4        |\n",
      "|    total_trades         | 5594        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017737318 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0445      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+05    |\n",
      "|    total_cost           | 5.77e+03    |\n",
      "|    total_reward         | 6.21e+04    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 5789        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025678378 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.263      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0414      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 135\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 83425.59\n",
      "total_reward: 33425.59\n",
      "total_cost: 7347.33\n",
      "total_trades: 5752\n",
      "Sharpe: 0.861\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.98e+04    |\n",
      "|    total_cost           | 5.31e+03    |\n",
      "|    total_reward         | 3.98e+04    |\n",
      "|    total_reward_pct     | 79.7        |\n",
      "|    total_trades         | 5752        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019747298 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0411      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.14e+04    |\n",
      "|    total_cost           | 4.88e+03    |\n",
      "|    total_reward         | 3.14e+04    |\n",
      "|    total_reward_pct     | 62.8        |\n",
      "|    total_trades         | 5740        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017926976 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.249      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0306      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 140\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 76241.00\n",
      "total_reward: 26241.00\n",
      "total_cost: 5408.55\n",
      "total_trades: 5682\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.62e+04    |\n",
      "|    total_cost           | 5.41e+03    |\n",
      "|    total_reward         | 2.62e+04    |\n",
      "|    total_reward_pct     | 52.5        |\n",
      "|    total_trades         | 5682        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024238449 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.97e+04    |\n",
      "|    total_cost           | 5.19e+03    |\n",
      "|    total_reward         | 2.97e+04    |\n",
      "|    total_reward_pct     | 59.5        |\n",
      "|    total_trades         | 5659        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019768428 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0305      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.38e+04    |\n",
      "|    total_cost           | 4.53e+03    |\n",
      "|    total_reward         | 3.38e+04    |\n",
      "|    total_reward_pct     | 67.6        |\n",
      "|    total_trades         | 5962        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026680712 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0437      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 145\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82145.43\n",
      "total_reward: 32145.43\n",
      "total_cost: 5814.79\n",
      "total_trades: 5955\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.49e+04    |\n",
      "|    total_cost           | 4.89e+03    |\n",
      "|    total_reward         | 3.49e+04    |\n",
      "|    total_reward_pct     | 69.7        |\n",
      "|    total_trades         | 5871        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015633164 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0318      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.41e+04    |\n",
      "|    total_cost           | 5.24e+03    |\n",
      "|    total_reward         | 3.41e+04    |\n",
      "|    total_reward_pct     | 68.2        |\n",
      "|    total_trades         | 5811        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027292833 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0268      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 150\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89374.91\n",
      "total_reward: 39374.91\n",
      "total_cost: 4676.45\n",
      "total_trades: 5853\n",
      "Sharpe: 0.857\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 8.94e+04  |\n",
      "|    total_cost           | 4.68e+03  |\n",
      "|    total_reward         | 3.94e+04  |\n",
      "|    total_reward_pct     | 78.7      |\n",
      "|    total_trades         | 5853      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 430       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0312655 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.8     |\n",
      "|    explained_variance   | 0.414     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.253    |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -0.0196   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 0.0237    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.02e+05   |\n",
      "|    total_cost           | 6.27e+03   |\n",
      "|    total_reward         | 5.23e+04   |\n",
      "|    total_reward_pct     | 105        |\n",
      "|    total_trades         | 5969       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 430        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02345074 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.287     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0299     |\n",
      "----------------------------------------\n",
      "day: 1003, episode: 155\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85942.83\n",
      "total_reward: 35942.83\n",
      "total_cost: 6016.05\n",
      "total_trades: 5666\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.59e+04    |\n",
      "|    total_cost           | 6.02e+03    |\n",
      "|    total_reward         | 3.59e+04    |\n",
      "|    total_reward_pct     | 71.9        |\n",
      "|    total_trades         | 5666        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024439255 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.038       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.1e+04     |\n",
      "|    total_cost           | 6.23e+03    |\n",
      "|    total_reward         | 4.1e+04     |\n",
      "|    total_reward_pct     | 82.1        |\n",
      "|    total_trades         | 5725        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030248243 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0305      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.03e+04    |\n",
      "|    total_cost           | 5.32e+03    |\n",
      "|    total_reward         | 4.03e+04    |\n",
      "|    total_reward_pct     | 80.6        |\n",
      "|    total_trades         | 5983        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027567327 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.321      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0285      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 160\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 88886.31\n",
      "total_reward: 38886.31\n",
      "total_cost: 5436.66\n",
      "total_trades: 5854\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.17e+04   |\n",
      "|    total_cost           | 5.73e+03   |\n",
      "|    total_reward         | 4.17e+04   |\n",
      "|    total_reward_pct     | 83.4       |\n",
      "|    total_trades         | 5905       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 431        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02829757 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.51       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.287     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.027      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.68e+04   |\n",
      "|    total_cost           | 6.35e+03   |\n",
      "|    total_reward         | 4.68e+04   |\n",
      "|    total_reward_pct     | 93.5       |\n",
      "|    total_trades         | 5918       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 431        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02794285 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.278     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0289     |\n",
      "----------------------------------------\n",
      "day: 1003, episode: 165\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 102547.53\n",
      "total_reward: 52547.53\n",
      "total_cost: 5835.44\n",
      "total_trades: 5897\n",
      "Sharpe: 1.011\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.03e+05   |\n",
      "|    total_cost           | 5.84e+03   |\n",
      "|    total_reward         | 5.25e+04   |\n",
      "|    total_reward_pct     | 105        |\n",
      "|    total_trades         | 5897       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 431        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02509027 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.568      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.283     |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0267     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.01e+05   |\n",
      "|    total_cost           | 6.71e+03   |\n",
      "|    total_reward         | 5.11e+04   |\n",
      "|    total_reward_pct     | 102        |\n",
      "|    total_trades         | 5956       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 432        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03644149 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.289     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0268     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+05    |\n",
      "|    total_cost           | 6.59e+03    |\n",
      "|    total_reward         | 5.62e+04    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 5987        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029361002 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 170\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 94648.47\n",
      "total_reward: 44648.47\n",
      "total_cost: 5025.39\n",
      "total_trades: 5779\n",
      "Sharpe: 0.843\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 6.81e+03    |\n",
      "|    total_reward         | 5.35e+04    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 6043        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033318613 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.266      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0417      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.08e+05   |\n",
      "|    total_cost           | 5.02e+03   |\n",
      "|    total_reward         | 5.75e+04   |\n",
      "|    total_reward_pct     | 115        |\n",
      "|    total_trades         | 5873       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 432        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03457893 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.533      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.297     |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0324     |\n",
      "----------------------------------------\n",
      "day: 1003, episode: 175\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 112474.33\n",
      "total_reward: 62474.33\n",
      "total_cost: 7474.64\n",
      "total_trades: 5935\n",
      "Sharpe: 1.175\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+05    |\n",
      "|    total_cost           | 7.47e+03    |\n",
      "|    total_reward         | 6.25e+04    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 5935        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034422744 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0377      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.09e+05    |\n",
      "|    total_cost           | 6.44e+03    |\n",
      "|    total_reward         | 5.92e+04    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 6023        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021783289 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0355      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 5.19e+03    |\n",
      "|    total_reward         | 5.17e+04    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 5999        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028818784 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0442      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 180\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 101042.39\n",
      "total_reward: 51042.39\n",
      "total_cost: 6209.22\n",
      "total_trades: 6044\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.93e+04    |\n",
      "|    total_cost           | 5.7e+03     |\n",
      "|    total_reward         | 4.93e+04    |\n",
      "|    total_reward_pct     | 98.5        |\n",
      "|    total_trades         | 5945        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026736673 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.049       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+05    |\n",
      "|    total_cost           | 4.48e+03    |\n",
      "|    total_reward         | 7.86e+04    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 6029        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031265702 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0353      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 185\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114809.78\n",
      "total_reward: 64809.78\n",
      "total_cost: 4958.40\n",
      "total_trades: 5766\n",
      "Sharpe: 0.985\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.15e+05  |\n",
      "|    total_cost           | 4.96e+03  |\n",
      "|    total_reward         | 6.48e+04  |\n",
      "|    total_reward_pct     | 130       |\n",
      "|    total_trades         | 5766      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 432       |\n",
      "|    iterations           | 42        |\n",
      "|    time_elapsed         | 198       |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0318153 |\n",
      "|    clip_fraction        | 0.235     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0.535     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.28     |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | -0.0119   |\n",
      "|    std                  | 1.08      |\n",
      "|    value_loss           | 0.0482    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.71e+04    |\n",
      "|    total_cost           | 4.58e+03    |\n",
      "|    total_reward         | 4.71e+04    |\n",
      "|    total_reward_pct     | 94.3        |\n",
      "|    total_trades         | 5952        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025207732 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0485      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+05    |\n",
      "|    total_cost           | 4.88e+03    |\n",
      "|    total_reward         | 7.22e+04    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 5946        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013654245 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0487      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 190\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 118379.63\n",
      "total_reward: 68379.63\n",
      "total_cost: 4550.39\n",
      "total_trades: 5983\n",
      "Sharpe: 1.018\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.12e+05  |\n",
      "|    total_cost           | 5.5e+03   |\n",
      "|    total_reward         | 6.16e+04  |\n",
      "|    total_reward_pct     | 123       |\n",
      "|    total_trades         | 6097      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 433       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 212       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0324778 |\n",
      "|    clip_fraction        | 0.235     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.6     |\n",
      "|    explained_variance   | 0.477     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.285    |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | -0.0192   |\n",
      "|    std                  | 1.09      |\n",
      "|    value_loss           | 0.065     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 5.06e+03    |\n",
      "|    total_reward         | 7e+04       |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 6032        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 433         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026961315 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0591      |\n",
      "-----------------------------------------\n",
      "day: 1003, episode: 195\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 118978.70\n",
      "total_reward: 68978.70\n",
      "total_cost: 4853.33\n",
      "total_trades: 5830\n",
      "Sharpe: 1.027\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+05    |\n",
      "|    total_cost           | 4.85e+03    |\n",
      "|    total_reward         | 6.9e+04     |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 5830        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030123439 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.263      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0709      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+05    |\n",
      "|    total_cost           | 5.11e+03    |\n",
      "|    total_reward         | 7.49e+04    |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 6120        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027256992 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.265      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.055       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+05    |\n",
      "|    total_cost           | 5.08e+03    |\n",
      "|    total_reward         | 5.7e+04     |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 6138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024063349 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.272      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0471      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-01-03 to  2019-04-04\n",
      "PPO Sharpe Ratio:  0.08595900191088758\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.28e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 7.83e+04 |\n",
      "|    total_reward_pct | 157      |\n",
      "|    total_trades     | 5053     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 135      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total timesteps  | 4016     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 114      |\n",
      "|    critic_loss      | 113      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3012     |\n",
      "----------------------------------\n",
      "day: 1003, episode: 205\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85024.92\n",
      "total_reward: 35024.92\n",
      "total_cost: 94.82\n",
      "total_trades: 5966\n",
      "Sharpe: 0.893\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.07e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 5.75e+04 |\n",
      "|    total_reward_pct | 115      |\n",
      "|    total_trades     | 4669     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total timesteps  | 8032     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 88.1     |\n",
      "|    critic_loss      | 23.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7028     |\n",
      "----------------------------------\n",
      "day: 1003, episode: 210\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 107011.72\n",
      "total_reward: 57011.72\n",
      "total_cost: 94.82\n",
      "total_trades: 5066\n",
      "Sharpe: 1.044\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.24e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 7.44e+04 |\n",
      "|    total_reward_pct | 149      |\n",
      "|    total_trades     | 4616     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total timesteps  | 12048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 69.3     |\n",
      "|    critic_loss      | 9.16     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11044    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 215\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 104907.08\n",
      "total_reward: 54907.08\n",
      "total_cost: 94.82\n",
      "total_trades: 4714\n",
      "Sharpe: 1.191\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.89e+04 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 2.89e+04 |\n",
      "|    total_reward_pct | 57.8     |\n",
      "|    total_trades     | 5042     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 115      |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total timesteps  | 16064    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 54.8     |\n",
      "|    critic_loss      | 6.26     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15060    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 220\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 116429.45\n",
      "total_reward: 66429.45\n",
      "total_cost: 94.82\n",
      "total_trades: 4571\n",
      "Sharpe: 1.225\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.16e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 6.64e+04 |\n",
      "|    total_reward_pct | 133      |\n",
      "|    total_trades     | 4571     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total timesteps  | 20080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 44.2     |\n",
      "|    critic_loss      | 4.46     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19076    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.03e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 5.32e+04 |\n",
      "|    total_reward_pct | 106      |\n",
      "|    total_trades     | 3046     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total timesteps  | 24096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 35       |\n",
      "|    critic_loss      | 3.7      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 23092    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 225\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 108314.11\n",
      "total_reward: 58314.11\n",
      "total_cost: 94.82\n",
      "total_trades: 4982\n",
      "Sharpe: 1.081\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.69e+04 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 4.69e+04 |\n",
      "|    total_reward_pct | 93.8     |\n",
      "|    total_trades     | 3911     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total timesteps  | 28112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 27.9     |\n",
      "|    critic_loss      | 2.85     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27108    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 230\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 109089.05\n",
      "total_reward: 59089.05\n",
      "total_cost: 94.82\n",
      "total_trades: 3467\n",
      "Sharpe: 1.116\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.02e+05 |\n",
      "|    total_cost       | 109      |\n",
      "|    total_reward     | 5.19e+04 |\n",
      "|    total_reward_pct | 104      |\n",
      "|    total_trades     | 6060     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total timesteps  | 32128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 22.4     |\n",
      "|    critic_loss      | 1.29     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31124    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 235\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 79447.03\n",
      "total_reward: 29447.03\n",
      "total_cost: 94.82\n",
      "total_trades: 5410\n",
      "Sharpe: 0.823\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.12e+05 |\n",
      "|    total_cost       | 115      |\n",
      "|    total_reward     | 6.2e+04  |\n",
      "|    total_reward_pct | 124      |\n",
      "|    total_trades     | 6191     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total timesteps  | 36144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 17.8     |\n",
      "|    critic_loss      | 1.45     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35140    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 240\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 112513.59\n",
      "total_reward: 62513.59\n",
      "total_cost: 94.82\n",
      "total_trades: 6062\n",
      "Sharpe: 1.181\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.13e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 6.25e+04 |\n",
      "|    total_reward_pct | 125      |\n",
      "|    total_trades     | 6062     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total timesteps  | 40160    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 14       |\n",
      "|    critic_loss      | 2.29     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39156    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.18e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 6.82e+04 |\n",
      "|    total_reward_pct | 136      |\n",
      "|    total_trades     | 6029     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 385      |\n",
      "|    total timesteps  | 44176    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 11.1     |\n",
      "|    critic_loss      | 1.6      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43172    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 245\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110586.28\n",
      "total_reward: 60586.28\n",
      "total_cost: 114.90\n",
      "total_trades: 5853\n",
      "Sharpe: 1.142\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.17e+05 |\n",
      "|    total_cost       | 206      |\n",
      "|    total_reward     | 6.65e+04 |\n",
      "|    total_reward_pct | 133      |\n",
      "|    total_trades     | 6950     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 419      |\n",
      "|    total timesteps  | 48192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 8.78     |\n",
      "|    critic_loss      | 0.698    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47188    |\n",
      "----------------------------------\n",
      "day: 1003, episode: 250\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 99049.57\n",
      "total_reward: 49049.57\n",
      "total_cost: 267.68\n",
      "total_trades: 4078\n",
      "Sharpe: 1.125\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03 to  2019-04-04\n",
      "======Best Model Retraining from:  2015-01-01 to  2019-04-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_126_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.7e+04  |\n",
      "|    total_cost       | 270      |\n",
      "|    total_reward     | 2.7e+04  |\n",
      "|    total_reward_pct | 54.1     |\n",
      "|    total_trades     | 4003     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total timesteps  | 4268     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -145     |\n",
      "|    critic_loss      | 659      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3201     |\n",
      "----------------------------------\n",
      "day: 1066, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85840.96\n",
      "total_reward: 35840.96\n",
      "total_cost: 144.31\n",
      "total_trades: 3870\n",
      "Sharpe: 0.649\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.06e+04  |\n",
      "|    total_cost       | 148       |\n",
      "|    total_reward     | -1.94e+04 |\n",
      "|    total_reward_pct | -38.8     |\n",
      "|    total_trades     | 4090      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 125       |\n",
      "|    time_elapsed     | 67        |\n",
      "|    total timesteps  | 8536      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -107      |\n",
      "|    critic_loss      | 131       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7469      |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 59006.44\n",
      "total_reward: 9006.44\n",
      "total_cost: 140.96\n",
      "total_trades: 3906\n",
      "Sharpe: 0.292\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.01e+05 |\n",
      "|    total_cost       | 152      |\n",
      "|    total_reward     | 5.09e+04 |\n",
      "|    total_reward_pct | 102      |\n",
      "|    total_trades     | 4331     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total timesteps  | 12804    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -84.1    |\n",
      "|    critic_loss      | 38.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11737    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 60381.38\n",
      "total_reward: 10381.38\n",
      "total_cost: 140.95\n",
      "total_trades: 5042\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.19e+04 |\n",
      "|    total_cost       | 138      |\n",
      "|    total_reward     | 3.19e+04 |\n",
      "|    total_reward_pct | 63.7     |\n",
      "|    total_trades     | 3923     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total timesteps  | 17072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -67.4    |\n",
      "|    critic_loss      | 16.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16005    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 38943.88\n",
      "total_reward: -11056.12\n",
      "total_cost: 137.87\n",
      "total_trades: 4158\n",
      "Sharpe: -0.128\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.89e+04  |\n",
      "|    total_cost       | 138       |\n",
      "|    total_reward     | -1.11e+04 |\n",
      "|    total_reward_pct | -22.1     |\n",
      "|    total_trades     | 4158      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 181       |\n",
      "|    total timesteps  | 21340     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -53.6     |\n",
      "|    critic_loss      | 8.68      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 20273     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.03e+05 |\n",
      "|    total_cost       | 124      |\n",
      "|    total_reward     | 5.35e+04 |\n",
      "|    total_reward_pct | 107      |\n",
      "|    total_trades     | 6673     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total timesteps  | 25608    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -43.2    |\n",
      "|    critic_loss      | 5.5      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24541    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49310.57\n",
      "total_reward: -689.43\n",
      "total_cost: 110.27\n",
      "total_trades: 4587\n",
      "Sharpe: 0.090\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.12e+05 |\n",
      "|    total_cost       | 395      |\n",
      "|    total_reward     | 6.19e+04 |\n",
      "|    total_reward_pct | 124      |\n",
      "|    total_trades     | 4689     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total timesteps  | 29876    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -34.2    |\n",
      "|    critic_loss      | 3.15     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28809    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 33169.99\n",
      "total_reward: -16830.01\n",
      "total_cost: 131.16\n",
      "total_trades: 4742\n",
      "Sharpe: -0.251\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.41e+04 |\n",
      "|    total_cost       | 209      |\n",
      "|    total_reward     | 2.41e+04 |\n",
      "|    total_reward_pct | 48.2     |\n",
      "|    total_trades     | 2974     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total timesteps  | 34144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -27.3    |\n",
      "|    critic_loss      | 2.49     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33077    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 32715.29\n",
      "total_reward: -17284.71\n",
      "total_cost: 97.12\n",
      "total_trades: 4964\n",
      "Sharpe: -0.306\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.26e+04 |\n",
      "|    total_cost       | 284      |\n",
      "|    total_reward     | 2.26e+04 |\n",
      "|    total_reward_pct | 45.1     |\n",
      "|    total_trades     | 4021     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total timesteps  | 38412    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -21.8    |\n",
      "|    critic_loss      | 2.26     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37345    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 39328.63\n",
      "total_reward: -10671.37\n",
      "total_cost: 118.28\n",
      "total_trades: 6003\n",
      "Sharpe: -0.130\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.93e+04  |\n",
      "|    total_cost       | 118       |\n",
      "|    total_reward     | -1.07e+04 |\n",
      "|    total_reward_pct | -21.3     |\n",
      "|    total_trades     | 6003      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 362       |\n",
      "|    total timesteps  | 42680     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -17.5     |\n",
      "|    critic_loss      | 1.58      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 41613     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.92e+04 |\n",
      "|    total_cost       | 187      |\n",
      "|    total_reward     | 3.92e+04 |\n",
      "|    total_reward_pct | 78.4     |\n",
      "|    total_trades     | 3602     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 398      |\n",
      "|    total timesteps  | 46948    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -14.1    |\n",
      "|    critic_loss      | 1.42     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45881    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 60231.47\n",
      "total_reward: 10231.47\n",
      "total_cost: 129.84\n",
      "total_trades: 3166\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "======Trading from:  2019-04-04 to  2019-07-05\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  529.7283042530553\n",
      "======Model training from:  2015-01-01 to  2019-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -3.73    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.173   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.00504  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.062    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -3.95    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0332   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 4.58e+03 |\n",
      "|    total_reward       | 5.43e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 5317     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.0378  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00539  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.519    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.26    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00696  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 3.88e+03 |\n",
      "|    total_reward       | 6.25e+04 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 5297     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -4.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -8.98    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 366       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -4.62     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0288    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.22e+05 |\n",
      "|    total_cost         | 3.77e+03 |\n",
      "|    total_reward       | 7.21e+04 |\n",
      "|    total_reward_pct   | 144      |\n",
      "|    total_trades       | 5468     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.617   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.327    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0185   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.0666  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0121  |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00781  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.22e+05 |\n",
      "|    total_cost         | 2.45e+03 |\n",
      "|    total_reward       | 7.18e+04 |\n",
      "|    total_reward_pct   | 144      |\n",
      "|    total_trades       | 5642     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.627   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -2.47    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -2.76    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0471   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 106598.48\n",
      "total_reward: 56598.48\n",
      "total_cost: 1649.51\n",
      "total_trades: 5932\n",
      "Sharpe: 0.957\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 1.65e+03 |\n",
      "|    total_reward       | 5.66e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 5932     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.256   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -4       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0288   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -2.28    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.00719  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.68e+04 |\n",
      "|    total_cost         | 2.12e+03 |\n",
      "|    total_reward       | 4.68e+04 |\n",
      "|    total_reward_pct   | 93.5     |\n",
      "|    total_trades       | 6521     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -0.809   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.776   |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00355  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 2.59     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.26e+05 |\n",
      "|    total_cost         | 2.28e+03 |\n",
      "|    total_reward       | 7.56e+04 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 6649     |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0.0197   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00384  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0.258    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -2.37    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.00954  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00525  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.67e+04 |\n",
      "|    total_cost         | 2.26e+03 |\n",
      "|    total_reward       | 4.67e+04 |\n",
      "|    total_reward_pct   | 93.4     |\n",
      "|    total_trades       | 6874     |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 4.42     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0258   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.769   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -8.31    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0918   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 2.55e+03 |\n",
      "|    total_reward       | 5.39e+04 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 7429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -1.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 3.8      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0213   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0103   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 87470.93\n",
      "total_reward: 37470.93\n",
      "total_cost: 2311.43\n",
      "total_trades: 7046\n",
      "Sharpe: 0.790\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.75e+04 |\n",
      "|    total_cost         | 2.31e+03 |\n",
      "|    total_reward       | 3.75e+04 |\n",
      "|    total_reward_pct   | 74.9     |\n",
      "|    total_trades       | 7046     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.00111  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0122   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 8.39     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0982   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.64e+04 |\n",
      "|    total_cost         | 1.82e+03 |\n",
      "|    total_reward       | 4.64e+04 |\n",
      "|    total_reward_pct   | 92.9     |\n",
      "|    total_trades       | 6864     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0.0972   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -5.56    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0366   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.00377 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 4.51     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0384   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.64e+04 |\n",
      "|    total_cost         | 1.53e+03 |\n",
      "|    total_reward       | 4.64e+04 |\n",
      "|    total_reward_pct   | 92.9     |\n",
      "|    total_trades       | 7226     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -0.602   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.362    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.00574  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.259    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00067  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 2.13e+03 |\n",
      "|    total_reward       | 6.56e+04 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 7707     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -1.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -1.37    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.00468  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.767    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.00277  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.94e+04 |\n",
      "|    total_cost         | 2.32e+03 |\n",
      "|    total_reward       | 4.94e+04 |\n",
      "|    total_reward_pct   | 98.7     |\n",
      "|    total_trades       | 7385     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0.552    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 2.07     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00623  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -0.776   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.0155   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | -0.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 3.44     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103036.98\n",
      "total_reward: 53036.98\n",
      "total_cost: 2175.84\n",
      "total_trades: 7515\n",
      "Sharpe: 0.980\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 2.18e+03 |\n",
      "|    total_reward       | 5.3e+04  |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 7515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | 0.381    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 5.55     |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.0427   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -6.45    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.066    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 2.45e+03 |\n",
      "|    total_reward       | 6.39e+04 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 7776     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.588   |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.00269  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 364       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -4.6      |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.0239    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+04 |\n",
      "|    total_cost         | 1.83e+03 |\n",
      "|    total_reward       | 4.97e+04 |\n",
      "|    total_reward_pct   | 99.4     |\n",
      "|    total_trades       | 7514     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | -0.086   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 3.79     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.76     |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.00553  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.22e+04 |\n",
      "|    total_cost         | 2.5e+03  |\n",
      "|    total_reward       | 4.22e+04 |\n",
      "|    total_reward_pct   | 84.4     |\n",
      "|    total_trades       | 7446     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 5.07     |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.0277   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -0.0168  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 8.82     |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.0908   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 2.21e+03 |\n",
      "|    total_reward       | 5.83e+04 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 6942     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 3.41     |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | -16.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.0383   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110134.76\n",
      "total_reward: 60134.76\n",
      "total_cost: 1572.15\n",
      "total_trades: 6950\n",
      "Sharpe: 0.931\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.1e+05   |\n",
      "|    total_cost         | 1.57e+03  |\n",
      "|    total_reward       | 6.01e+04  |\n",
      "|    total_reward_pct   | 120       |\n",
      "|    total_trades       | 6950      |\n",
      "| time/                 |           |\n",
      "|    fps                | 364       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -2.58     |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.00619   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -4.22    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0213   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.27e+05 |\n",
      "|    total_cost         | 2.18e+03 |\n",
      "|    total_reward       | 7.71e+04 |\n",
      "|    total_reward_pct   | 154      |\n",
      "|    total_trades       | 7459     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | 0.401    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -2.31    |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.00642  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 3.61     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.22e+05 |\n",
      "|    total_cost         | 1.98e+03 |\n",
      "|    total_reward       | 7.2e+04  |\n",
      "|    total_reward_pct   | 144      |\n",
      "|    total_trades       | 7924     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | -2.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -2.75    |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | -0.0387  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 6.14     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.0495   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 2.83     |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.00856  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+05 |\n",
      "|    total_cost         | 2.04e+03 |\n",
      "|    total_reward       | 7.06e+04 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 7321     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | -10.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 4.31     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0254   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.163    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 1.71e+03 |\n",
      "|    total_reward       | 6.05e+04 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 7271     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | -0.617   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -2.41    |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.00516  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.506   |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00341  |\n",
      "------------------------------------\n",
      "day: 1066, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 109244.86\n",
      "total_reward: 59244.86\n",
      "total_cost: 1609.09\n",
      "total_trades: 7122\n",
      "Sharpe: 0.923\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 1.61e+03 |\n",
      "|    total_reward       | 5.92e+04 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 7122     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | -6.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -13      |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 1.5      |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.0796   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+05 |\n",
      "|    total_cost         | 1.58e+03 |\n",
      "|    total_reward       | 8.75e+04 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 7252     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | 0.553    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.438   |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00162  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 0.0652   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.324   |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.00154  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.27e+05 |\n",
      "|    total_cost         | 1.65e+03 |\n",
      "|    total_reward       | 7.7e+04  |\n",
      "|    total_reward_pct   | 154      |\n",
      "|    total_trades       | 7456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | -4.41    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00508  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 5.49     |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.0243   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 1.04e+03 |\n",
      "|    total_reward       | 5.61e+04 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 7582     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -2.23    |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.00777  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 364       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 3         |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 0.011     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 941      |\n",
      "|    total_reward       | 6.83e+04 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 7671     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -0.661   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -3.03    |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.0089   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | -0.258   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 6.31     |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.0441   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -7.02    |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.0827   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 142456.01\n",
      "total_reward: 92456.01\n",
      "total_cost: 963.41\n",
      "total_trades: 7681\n",
      "Sharpe: 1.233\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.42e+05 |\n",
      "|    total_cost         | 963      |\n",
      "|    total_reward       | 9.25e+04 |\n",
      "|    total_reward_pct   | 185      |\n",
      "|    total_trades       | 7681     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 5.07     |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0251   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | -0.0154  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.158    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 1.3e+03  |\n",
      "|    total_reward       | 6.12e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 7736     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 4.89     |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.0229   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 7.72     |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.0655   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 1.08e+03 |\n",
      "|    total_reward       | 6.86e+04 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 7826     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -4.36    |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | 0.332    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -3.17    |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.0192   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.35e+05 |\n",
      "|    total_cost         | 720      |\n",
      "|    total_reward       | 8.52e+04 |\n",
      "|    total_reward_pct   | 170      |\n",
      "|    total_trades       | 7929     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | -1.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 5.54     |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.0274   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | -0.332   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 7.25     |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.0612   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.32e+04 |\n",
      "|    total_cost         | 1.26e+03 |\n",
      "|    total_reward       | 4.32e+04 |\n",
      "|    total_reward_pct   | 86.5     |\n",
      "|    total_trades       | 7866     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -4.5     |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | -0.0664  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 14.4     |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "day: 1066, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113812.43\n",
      "total_reward: 63812.43\n",
      "total_cost: 1553.84\n",
      "total_trades: 8027\n",
      "Sharpe: 1.020\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 1.55e+03 |\n",
      "|    total_reward       | 6.38e+04 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 8027     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | -7.9     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -3.38    |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 6.23     |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.0296   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 1.86e+03 |\n",
      "|    total_reward       | 6.87e+04 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 8219     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | -1.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.813    |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.00237  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | -0.0493  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 3.35     |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.0163   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 5.39e+04 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 8395     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | -0.667   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -12.8    |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | -0.424   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -5.68    |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.0278   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 5.87     |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.0361   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.27e+05 |\n",
      "|    total_cost         | 958      |\n",
      "|    total_reward       | 7.7e+04  |\n",
      "|    total_reward_pct   | 154      |\n",
      "|    total_trades       | 8231     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.602    |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.00059  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -3.19    |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 0.0236   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.31e+05 |\n",
      "|    total_cost         | 990      |\n",
      "|    total_reward       | 8.13e+04 |\n",
      "|    total_reward_pct   | 163      |\n",
      "|    total_trades       | 8544     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | -7.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 9.15     |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.0705   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | -0.0684  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 5.01     |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.0399   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 127852.11\n",
      "total_reward: 77852.11\n",
      "total_cost: 1075.92\n",
      "total_trades: 8807\n",
      "Sharpe: 1.115\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.28e+05  |\n",
      "|    total_cost         | 1.08e+03  |\n",
      "|    total_reward       | 7.79e+04  |\n",
      "|    total_reward_pct   | 156       |\n",
      "|    total_trades       | 8807      |\n",
      "| time/                 |           |\n",
      "|    fps                | 363       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.4     |\n",
      "|    explained_variance | -6.68e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 2.37      |\n",
      "|    std                | 1.92      |\n",
      "|    value_loss         | 0.00487   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | 0.0056   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -3.56    |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.46e+05 |\n",
      "|    total_cost         | 1.21e+03 |\n",
      "|    total_reward       | 9.6e+04  |\n",
      "|    total_reward_pct   | 192      |\n",
      "|    total_trades       | 8868     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | -0.0406  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.00158  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | 0.45     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 5.57     |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.0284   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+05 |\n",
      "|    total_cost         | 1.12e+03 |\n",
      "|    total_reward       | 6.47e+04 |\n",
      "|    total_reward_pct   | 129      |\n",
      "|    total_trades       | 8827     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | -0.0193  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -10.1    |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 0.0793   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -0.0105  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -4.01    |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.0112   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 962      |\n",
      "|    total_reward       | 6.95e+04 |\n",
      "|    total_reward_pct   | 139      |\n",
      "|    total_trades       | 9195     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | -2.87    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 0.00165  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -6.41    |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.0281   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.25e+05 |\n",
      "|    total_cost         | 1.03e+03 |\n",
      "|    total_reward       | 7.54e+04 |\n",
      "|    total_reward_pct   | 151      |\n",
      "|    total_trades       | 9181     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.5    |\n",
      "|    explained_variance | 0.0228   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -5.96    |\n",
      "|    std                | 2.04     |\n",
      "|    value_loss         | 0.0273   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | -0.759   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.0612   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 363       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -2.29     |\n",
      "|    std                | 2.07      |\n",
      "|    value_loss         | 0.0129    |\n",
      "-------------------------------------\n",
      "day: 1066, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 120366.28\n",
      "total_reward: 70366.28\n",
      "total_cost: 1292.51\n",
      "total_trades: 9076\n",
      "Sharpe: 1.063\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 7.04e+04 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 9076     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | -235     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -23      |\n",
      "|    std                | 2.1      |\n",
      "|    value_loss         | 0.474    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | 0.0175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -12.3    |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 1.65e+03 |\n",
      "|    total_reward       | 5.86e+04 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 9190     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0.174    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -1.39    |\n",
      "|    std                | 2.14     |\n",
      "|    value_loss         | 0.00822  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 1.62e+03 |\n",
      "|    total_reward       | 6.12e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 9097     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -1.26    |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.00911  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 363       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -0.616    |\n",
      "|    std                | 2.19      |\n",
      "|    value_loss         | 0.00819   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1e+03    |\n",
      "|    total_reward       | 5.26e+04 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 8912     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 2.91     |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.00653  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.163    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 1.49e+03 |\n",
      "|    total_reward       | 6.58e+04 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 8885     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.00717  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | -0.831   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 6.43     |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 0.0263   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 104660.58\n",
      "total_reward: 54660.58\n",
      "total_cost: 1556.15\n",
      "total_trades: 9001\n",
      "Sharpe: 0.983\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 1.56e+03 |\n",
      "|    total_reward       | 5.47e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 9001     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.527    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 2.17     |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.00603  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 0.92     |\n",
      "|    std                | 2.28     |\n",
      "|    value_loss         | 0.00338  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 1.5e+03  |\n",
      "|    total_reward       | 6.79e+04 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 9223     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 0.00414  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 362       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | 0.956     |\n",
      "|    std                | 2.32      |\n",
      "|    value_loss         | 0.00343   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 5.66e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 9516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -1.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 0.54     |\n",
      "|    std                | 2.34     |\n",
      "|    value_loss         | 0.0014   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.00844  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -1.82    |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.0044   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 362       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -3.06     |\n",
      "|    std                | 2.37      |\n",
      "|    value_loss         | 0.0103    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.08e+04 |\n",
      "|    total_cost         | 1.14e+03 |\n",
      "|    total_reward       | 4.08e+04 |\n",
      "|    total_reward_pct   | 81.5     |\n",
      "|    total_trades       | 9312     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 4.02     |\n",
      "|    std                | 2.4      |\n",
      "|    value_loss         | 0.013    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 362       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -3.16     |\n",
      "|    std                | 2.42      |\n",
      "|    value_loss         | 0.0171    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.48e+04 |\n",
      "|    total_cost         | 1.03e+03 |\n",
      "|    total_reward       | 3.48e+04 |\n",
      "|    total_reward_pct   | 69.7     |\n",
      "|    total_trades       | 9339     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 0.0266   |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 0.00433  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -0.072   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -0.617   |\n",
      "|    std                | 2.47     |\n",
      "|    value_loss         | 0.0089   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 101661.58\n",
      "total_reward: 51661.58\n",
      "total_cost: 1047.06\n",
      "total_trades: 9501\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 1.05e+03 |\n",
      "|    total_reward       | 5.17e+04 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 9501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 1.9      |\n",
      "|    std                | 2.49     |\n",
      "|    value_loss         | 0.00411  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 0.0745   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 1.28e+03 |\n",
      "|    total_reward       | 6.23e+04 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 9763     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | -4.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    std                | 2.52     |\n",
      "|    value_loss         | 0.0258   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -0.385   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -1.44    |\n",
      "|    std                | 2.55     |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.7e+04  |\n",
      "|    total_cost         | 1.07e+03 |\n",
      "|    total_reward       | 4.7e+04  |\n",
      "|    total_reward_pct   | 94       |\n",
      "|    total_trades       | 9728     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.000999 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 5.5      |\n",
      "|    std                | 2.59     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+04  |\n",
      "|    total_cost         | 972      |\n",
      "|    total_reward       | 4.1e+04  |\n",
      "|    total_reward_pct   | 82       |\n",
      "|    total_trades       | 9786     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0.128    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -2.23    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.00334  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.479   |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 1.36e+03 |\n",
      "|    total_reward       | 6.2e+04  |\n",
      "|    total_reward_pct   | 124      |\n",
      "|    total_trades       | 9775     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0.068    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -9.7     |\n",
      "|    std                | 2.64     |\n",
      "|    value_loss         | 0.0454   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | -0.0562  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -2.07    |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 0.0235   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.262    |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.000947 |\n",
      "------------------------------------\n",
      "day: 1066, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82237.63\n",
      "total_reward: 32237.63\n",
      "total_cost: 1101.77\n",
      "total_trades: 9443\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.22e+04 |\n",
      "|    total_cost         | 1.1e+03  |\n",
      "|    total_reward       | 3.22e+04 |\n",
      "|    total_reward_pct   | 64.5     |\n",
      "|    total_trades       | 9443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | -0.272   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 8.16     |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 0.0367   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -12.7    |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.0787   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.33e+03 |\n",
      "|    total_reward       | 5.31e+04 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 9456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 1.63     |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 0.00319  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -8.34    |\n",
      "|    std                | 2.77     |\n",
      "|    value_loss         | 0.0362   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.95e+04  |\n",
      "|    total_cost         | 1.46e+03  |\n",
      "|    total_reward       | 4.95e+04  |\n",
      "|    total_reward_pct   | 99        |\n",
      "|    total_trades       | 9871      |\n",
      "| time/                 |           |\n",
      "|    fps                | 362       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | 4.96      |\n",
      "|    std                | 2.79      |\n",
      "|    value_loss         | 0.0137    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0.0293   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 13.8     |\n",
      "|    std                | 2.8      |\n",
      "|    value_loss         | 0.104    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 1.43e+03 |\n",
      "|    total_reward       | 6.05e+04 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 10031    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | -0.0304  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -2.59    |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.00694  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | -0.0151  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -7.22    |\n",
      "|    std                | 2.85     |\n",
      "|    value_loss         | 0.0276   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.85e+04 |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 4.85e+04 |\n",
      "|    total_reward_pct   | 97.1     |\n",
      "|    total_trades       | 10392    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 0.645    |\n",
      "|    std                | 2.87     |\n",
      "|    value_loss         | 0.000738 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -5.52    |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "day: 1066, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 111040.84\n",
      "total_reward: 61040.84\n",
      "total_cost: 1728.34\n",
      "total_trades: 10566\n",
      "Sharpe: 1.037\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 1.73e+03 |\n",
      "|    total_reward       | 6.1e+04  |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 10566    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | -0.365   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 0.915    |\n",
      "|    std                | 2.91     |\n",
      "|    value_loss         | 0.00201  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -0.395   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -2.88    |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.00453  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.5e+04  |\n",
      "|    total_cost         | 1.11e+03 |\n",
      "|    total_reward       | 3.5e+04  |\n",
      "|    total_reward_pct   | 69.9     |\n",
      "|    total_trades       | 10350    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | -0.0376  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 8.88     |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 0.0413   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -13.3    |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 1.31e+03 |\n",
      "|    total_reward       | 5.14e+04 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 10192    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | -1.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 3        |\n",
      "|    value_loss         | 0.00286  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | -0.155   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -8.74    |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.0471   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 1.89     |\n",
      "|    std                | 3.05     |\n",
      "|    value_loss         | 0.0144   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.75e+04 |\n",
      "|    total_cost         | 1.01e+03 |\n",
      "|    total_reward       | 4.75e+04 |\n",
      "|    total_reward_pct   | 95.1     |\n",
      "|    total_trades       | 10157    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 3.07     |\n",
      "|    value_loss         | 0.00253  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 21.7     |\n",
      "|    std                | 3.09     |\n",
      "|    value_loss         | 0.211    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.74e+04 |\n",
      "|    total_cost         | 1.24e+03 |\n",
      "|    total_reward       | 4.74e+04 |\n",
      "|    total_reward_pct   | 94.7     |\n",
      "|    total_trades       | 10337    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0.0873   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 2.7      |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.00585  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.00409  |\n",
      "------------------------------------\n",
      "day: 1066, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 102656.74\n",
      "total_reward: 52656.74\n",
      "total_cost: 1403.80\n",
      "total_trades: 10506\n",
      "Sharpe: 0.950\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.4e+03  |\n",
      "|    total_reward       | 5.27e+04 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 10506    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -6.18    |\n",
      "|    std                | 3.15     |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 0.658    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 2.66     |\n",
      "|    std                | 3.19     |\n",
      "|    value_loss         | 0.00377  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.32e+04 |\n",
      "|    total_cost         | 1.36e+03 |\n",
      "|    total_reward       | 4.32e+04 |\n",
      "|    total_reward_pct   | 86.3     |\n",
      "|    total_trades       | 10372    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -2.51    |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.00318  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 361       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 211       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 0.303     |\n",
      "|    std                | 3.25      |\n",
      "|    value_loss         | 0.00305   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.37e+04 |\n",
      "|    total_cost         | 1.16e+03 |\n",
      "|    total_reward       | 4.37e+04 |\n",
      "|    total_reward_pct   | 87.5     |\n",
      "|    total_trades       | 10437    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 2.91     |\n",
      "|    std                | 3.27     |\n",
      "|    value_loss         | 0.00409  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.425   |\n",
      "|    std                | 3.29     |\n",
      "|    value_loss         | 0.00663  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.15e+04  |\n",
      "|    total_cost         | 1.11e+03  |\n",
      "|    total_reward       | 4.15e+04  |\n",
      "|    total_reward_pct   | 83        |\n",
      "|    total_trades       | 10452     |\n",
      "| time/                 |           |\n",
      "|    fps                | 361       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 4.37      |\n",
      "|    std                | 3.32      |\n",
      "|    value_loss         | 0.0093    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | -0.239   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -3.39    |\n",
      "|    std                | 3.35     |\n",
      "|    value_loss         | 0.0055   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.04e+04  |\n",
      "|    total_cost         | 1.1e+03   |\n",
      "|    total_reward       | 4.04e+04  |\n",
      "|    total_reward_pct   | 80.7      |\n",
      "|    total_trades       | 10479     |\n",
      "| time/                 |           |\n",
      "|    fps                | 361       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | -0.751    |\n",
      "|    std                | 3.37      |\n",
      "|    value_loss         | 0.0045    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -5.66    |\n",
      "|    std                | 3.4      |\n",
      "|    value_loss         | 0.0215   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.3    |\n",
      "|    explained_variance | 0.00674  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 1.77     |\n",
      "|    std                | 3.43     |\n",
      "|    value_loss         | 0.00464  |\n",
      "------------------------------------\n",
      "day: 1066, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95749.91\n",
      "total_reward: 45749.91\n",
      "total_cost: 1334.84\n",
      "total_trades: 10593\n",
      "Sharpe: 0.844\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.57e+04 |\n",
      "|    total_cost         | 1.33e+03 |\n",
      "|    total_reward       | 4.57e+04 |\n",
      "|    total_reward_pct   | 91.5     |\n",
      "|    total_trades       | 10593    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 0.0869   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 3.46     |\n",
      "|    value_loss         | 0.00572  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -16.9    |\n",
      "|    std                | 3.48     |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 1.45e+03 |\n",
      "|    total_reward       | 5.4e+04  |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 10802    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | -1.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 4.87     |\n",
      "|    std                | 3.5      |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 6.79     |\n",
      "|    std                | 3.53     |\n",
      "|    value_loss         | 0.0222   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 5.37e+04 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 10782    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -7.98    |\n",
      "|    std                | 3.55     |\n",
      "|    value_loss         | 0.0444   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | -0.373   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -8.09    |\n",
      "|    std                | 3.58     |\n",
      "|    value_loss         | 0.0331   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.71e+04 |\n",
      "|    total_cost         | 1.31e+03 |\n",
      "|    total_reward       | 3.71e+04 |\n",
      "|    total_reward_pct   | 74.3     |\n",
      "|    total_trades       | 10723    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | -0.132   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 7.34     |\n",
      "|    std                | 3.6      |\n",
      "|    value_loss         | 0.034    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 0.0318   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 7.68     |\n",
      "|    std                | 3.63     |\n",
      "|    value_loss         | 0.0307   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.94e+04 |\n",
      "|    total_cost         | 1.27e+03 |\n",
      "|    total_reward       | 4.94e+04 |\n",
      "|    total_reward_pct   | 98.8     |\n",
      "|    total_trades       | 10621    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -0.665   |\n",
      "|    std                | 3.66     |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 1.98     |\n",
      "|    std                | 3.69     |\n",
      "|    value_loss         | 0.00462  |\n",
      "------------------------------------\n",
      "day: 1066, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 75764.83\n",
      "total_reward: 25764.83\n",
      "total_cost: 1401.70\n",
      "total_trades: 10629\n",
      "Sharpe: 0.537\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.58e+04  |\n",
      "|    total_cost         | 1.4e+03   |\n",
      "|    total_reward       | 2.58e+04  |\n",
      "|    total_reward_pct   | 51.5      |\n",
      "|    total_trades       | 10629     |\n",
      "| time/                 |           |\n",
      "|    fps                | 361       |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 236       |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | -2.06     |\n",
      "|    std                | 3.73      |\n",
      "|    value_loss         | 0.00234   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -1.65    |\n",
      "|    std                | 3.75     |\n",
      "|    value_loss         | 0.00135  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.08e+04 |\n",
      "|    total_cost         | 1.32e+03 |\n",
      "|    total_reward       | 4.08e+04 |\n",
      "|    total_reward_pct   | 81.6     |\n",
      "|    total_trades       | 10974    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -8.79    |\n",
      "|    std                | 3.78     |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -0.00671 |\n",
      "|    std                | 3.81     |\n",
      "|    value_loss         | 0.00255  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.47e+04 |\n",
      "|    total_cost         | 1.33e+03 |\n",
      "|    total_reward       | 3.47e+04 |\n",
      "|    total_reward_pct   | 69.4     |\n",
      "|    total_trades       | 10972    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -20.2    |\n",
      "|    std                | 3.84     |\n",
      "|    value_loss         | 0.161    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 7.54     |\n",
      "|    std                | 3.87     |\n",
      "|    value_loss         | 0.0266   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -3.89    |\n",
      "|    std                | 3.9      |\n",
      "|    value_loss         | 0.00905  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.37e+04 |\n",
      "|    total_cost         | 1.56e+03 |\n",
      "|    total_reward       | 3.37e+04 |\n",
      "|    total_reward_pct   | 67.4     |\n",
      "|    total_trades       | 11157    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -11.6    |\n",
      "|    std                | 3.94     |\n",
      "|    value_loss         | 0.0525   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 361       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 4.27      |\n",
      "|    std                | 3.97      |\n",
      "|    value_loss         | 0.00726   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.64e+04 |\n",
      "|    total_cost         | 1.5e+03  |\n",
      "|    total_reward       | 3.64e+04 |\n",
      "|    total_reward_pct   | 72.9     |\n",
      "|    total_trades       | 11317    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 3.96     |\n",
      "|    std                | 4        |\n",
      "|    value_loss         | 0.0321   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0.0252   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -1.9     |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 0.00198  |\n",
      "------------------------------------\n",
      "day: 1066, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92013.77\n",
      "total_reward: 42013.77\n",
      "total_cost: 1435.52\n",
      "total_trades: 11259\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.2e+04  |\n",
      "|    total_cost         | 1.44e+03 |\n",
      "|    total_reward       | 4.2e+04  |\n",
      "|    total_reward_pct   | 84       |\n",
      "|    total_trades       | 11259    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 5.46     |\n",
      "|    std                | 4.07     |\n",
      "|    value_loss         | 0.0104   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -2.5     |\n",
      "|    std                | 4.1      |\n",
      "|    value_loss         | 0.00384  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 1.35e+03 |\n",
      "|    total_reward       | 5.17e+04 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 11177    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -10.7    |\n",
      "|    std                | 4.14     |\n",
      "|    value_loss         | 0.0442   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -4.76    |\n",
      "|    std                | 4.17     |\n",
      "|    value_loss         | 0.0112   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.33e+04 |\n",
      "|    total_cost         | 1.03e+03 |\n",
      "|    total_reward       | 3.33e+04 |\n",
      "|    total_reward_pct   | 66.7     |\n",
      "|    total_trades       | 11194    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 0.00886  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 2.31     |\n",
      "|    std                | 4.23     |\n",
      "|    value_loss         | 0.00192  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.45e+04 |\n",
      "|    total_cost         | 1.39e+03 |\n",
      "|    total_reward       | 4.45e+04 |\n",
      "|    total_reward_pct   | 89       |\n",
      "|    total_trades       | 11604    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -6.56    |\n",
      "|    std                | 4.26     |\n",
      "|    value_loss         | 0.0174   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -4.11    |\n",
      "|    std                | 4.29     |\n",
      "|    value_loss         | 0.00673  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.47e+04 |\n",
      "|    total_cost         | 1.5e+03  |\n",
      "|    total_reward       | 4.47e+04 |\n",
      "|    total_reward_pct   | 89.5     |\n",
      "|    total_trades       | 11632    |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | -0.283   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -4.66    |\n",
      "|    std                | 4.32     |\n",
      "|    value_loss         | 0.0158   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -7.78    |\n",
      "|    std                | 4.36     |\n",
      "|    value_loss         | 0.0248   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    std                | 4.39     |\n",
      "|    value_loss         | 0.0717   |\n",
      "------------------------------------\n",
      "day: 1066, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 81955.76\n",
      "total_reward: 31955.76\n",
      "total_cost: 1475.09\n",
      "total_trades: 11475\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.2e+04  |\n",
      "|    total_cost         | 1.48e+03 |\n",
      "|    total_reward       | 3.2e+04  |\n",
      "|    total_reward_pct   | 63.9     |\n",
      "|    total_trades       | 11475    |\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 0.26     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 12.8     |\n",
      "|    std                | 4.42     |\n",
      "|    value_loss         | 0.0576   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.3    |\n",
      "|    explained_variance | 0.126    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 16.6     |\n",
      "|    std                | 4.45     |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.88e+04 |\n",
      "|    total_cost         | 1.75e+03 |\n",
      "|    total_reward       | 3.88e+04 |\n",
      "|    total_reward_pct   | 77.5     |\n",
      "|    total_trades       | 11532    |\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 26.2     |\n",
      "|    std                | 4.48     |\n",
      "|    value_loss         | 0.226    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    std                | 4.53     |\n",
      "|    value_loss         | 0.0189   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.4e+04  |\n",
      "|    total_cost         | 1.72e+03 |\n",
      "|    total_reward       | 3.4e+04  |\n",
      "|    total_reward_pct   | 68.1     |\n",
      "|    total_trades       | 11490    |\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.8    |\n",
      "|    explained_variance | -0.00492 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    std                | 4.56     |\n",
      "|    value_loss         | 0.0861   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 360       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 274       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 15.1      |\n",
      "|    std                | 4.6       |\n",
      "|    value_loss         | 0.0917    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.92e+04  |\n",
      "|    total_cost         | 1.62e+03  |\n",
      "|    total_reward       | 2.92e+04  |\n",
      "|    total_reward_pct   | 58.4      |\n",
      "|    total_trades       | 11458     |\n",
      "| time/                 |           |\n",
      "|    fps                | 360       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 275       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    std                | 4.64      |\n",
      "|    value_loss         | 0.0811    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 11.1     |\n",
      "|    std                | 4.69     |\n",
      "|    value_loss         | 0.0448   |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-04-04 to  2019-07-05\n",
      "A2C Sharpe Ratio:  0.2620761787093857\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_1\n",
      "day: 1066, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 75905.63\n",
      "total_reward: 25905.63\n",
      "total_cost: 10688.70\n",
      "total_trades: 5854\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.59e+04 |\n",
      "|    total_cost       | 1.07e+04 |\n",
      "|    total_reward     | 2.59e+04 |\n",
      "|    total_reward_pct | 51.8     |\n",
      "|    total_trades     | 5854     |\n",
      "| time/               |          |\n",
      "|    fps              | 451      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.54e+04   |\n",
      "|    total_cost           | 9.2e+03    |\n",
      "|    total_reward         | 4.54e+04   |\n",
      "|    total_reward_pct     | 90.9       |\n",
      "|    total_trades         | 5972       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 429        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02120844 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | -0.899     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.284     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0747     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.09e+04    |\n",
      "|    total_cost           | 9.39e+03    |\n",
      "|    total_reward         | 1.09e+04    |\n",
      "|    total_reward_pct     | 21.8        |\n",
      "|    total_trades         | 6001        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014797037 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.04        |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 91229.12\n",
      "total_reward: 41229.12\n",
      "total_cost: 9583.15\n",
      "total_trades: 6097\n",
      "Sharpe: 0.909\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.31e+04     |\n",
      "|    total_cost           | 1.02e+04     |\n",
      "|    total_reward         | 2.31e+04     |\n",
      "|    total_reward_pct     | 46.2         |\n",
      "|    total_trades         | 6018         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150425015 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.1        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.306       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0231      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0285       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.1e+04     |\n",
      "|    total_cost           | 8.5e+03     |\n",
      "|    total_reward         | 3.1e+04     |\n",
      "|    total_reward_pct     | 61.9        |\n",
      "|    total_trades         | 5997        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019041061 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90226.33\n",
      "total_reward: 40226.33\n",
      "total_cost: 6165.96\n",
      "total_trades: 5914\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.02e+04    |\n",
      "|    total_cost           | 6.17e+03    |\n",
      "|    total_reward         | 4.02e+04    |\n",
      "|    total_reward_pct     | 80.5        |\n",
      "|    total_trades         | 5914        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015770692 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0384      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.02e+04   |\n",
      "|    total_cost           | 8.4e+03    |\n",
      "|    total_reward         | 2.02e+04   |\n",
      "|    total_reward_pct     | 40.5       |\n",
      "|    total_trades         | 6091       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 418        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01792863 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.216      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.265     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0245    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0269     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.02e+04    |\n",
      "|    total_cost           | 8.18e+03    |\n",
      "|    total_reward         | 3.02e+04    |\n",
      "|    total_reward_pct     | 60.3        |\n",
      "|    total_trades         | 5932        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026030537 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.02        |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 76933.99\n",
      "total_reward: 26933.99\n",
      "total_cost: 8818.53\n",
      "total_trades: 6097\n",
      "Sharpe: 0.653\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.65e+04    |\n",
      "|    total_cost           | 8.07e+03    |\n",
      "|    total_reward         | 2.65e+04    |\n",
      "|    total_reward_pct     | 52.9        |\n",
      "|    total_trades         | 6043        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007863108 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 7.31e+03    |\n",
      "|    total_reward         | 5.23e+04    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 5975        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026980992 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0222      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 105262.77\n",
      "total_reward: 55262.77\n",
      "total_cost: 8490.69\n",
      "total_trades: 6266\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.05e+05    |\n",
      "|    total_cost           | 8.49e+03    |\n",
      "|    total_reward         | 5.53e+04    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 6266        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023633353 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0236      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.44e+04    |\n",
      "|    total_cost           | 7.21e+03    |\n",
      "|    total_reward         | 2.44e+04    |\n",
      "|    total_reward_pct     | 48.8        |\n",
      "|    total_trades         | 6114        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014241371 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0256      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 6.01e+03    |\n",
      "|    total_reward         | 5.33e+04    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 6025        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017114151 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0234      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 120\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92850.87\n",
      "total_reward: 42850.87\n",
      "total_cost: 6320.85\n",
      "total_trades: 5968\n",
      "Sharpe: 0.863\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.29e+04    |\n",
      "|    total_cost           | 6.32e+03    |\n",
      "|    total_reward         | 4.29e+04    |\n",
      "|    total_reward_pct     | 85.7        |\n",
      "|    total_trades         | 5968        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022586681 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0271      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.41e+04   |\n",
      "|    total_cost           | 7.47e+03   |\n",
      "|    total_reward         | 2.41e+04   |\n",
      "|    total_reward_pct     | 48.2       |\n",
      "|    total_trades         | 6108       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 416        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01656209 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.561      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.3       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0227    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0246     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.7e+04     |\n",
      "|    total_cost           | 7.1e+03     |\n",
      "|    total_reward         | 4.7e+04     |\n",
      "|    total_reward_pct     | 94          |\n",
      "|    total_trades         | 6090        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032011166 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.265      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0397      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 125\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95542.67\n",
      "total_reward: 45542.67\n",
      "total_cost: 7671.90\n",
      "total_trades: 6121\n",
      "Sharpe: 0.978\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.08e+04    |\n",
      "|    total_cost           | 5.14e+03    |\n",
      "|    total_reward         | 4.08e+04    |\n",
      "|    total_reward_pct     | 81.6        |\n",
      "|    total_trades         | 5995        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020754287 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0302      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.97e+04    |\n",
      "|    total_cost           | 6.21e+03    |\n",
      "|    total_reward         | 4.97e+04    |\n",
      "|    total_reward_pct     | 99.3        |\n",
      "|    total_trades         | 5986        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021546122 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0327      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 130\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 102120.17\n",
      "total_reward: 52120.17\n",
      "total_cost: 4849.68\n",
      "total_trades: 6005\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 4.85e+03    |\n",
      "|    total_reward         | 5.21e+04    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 6005        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026217587 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0256      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 5.89e+03    |\n",
      "|    total_reward         | 5.07e+04    |\n",
      "|    total_reward_pct     | 101         |\n",
      "|    total_trades         | 6241        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035309486 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0379      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+05    |\n",
      "|    total_cost           | 6.12e+03    |\n",
      "|    total_reward         | 7.87e+04    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 6139        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025197089 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0283      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 135\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 111615.57\n",
      "total_reward: 61615.57\n",
      "total_cost: 5214.27\n",
      "total_trades: 6167\n",
      "Sharpe: 1.055\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.52e+04   |\n",
      "|    total_cost           | 6e+03      |\n",
      "|    total_reward         | 4.52e+04   |\n",
      "|    total_reward_pct     | 90.4       |\n",
      "|    total_trades         | 6230       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 416        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03374833 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.512      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.267     |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0384     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+05    |\n",
      "|    total_cost           | 5.54e+03    |\n",
      "|    total_reward         | 5.65e+04    |\n",
      "|    total_reward_pct     | 113         |\n",
      "|    total_trades         | 6110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030735008 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 140\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 119759.56\n",
      "total_reward: 69759.56\n",
      "total_cost: 5483.17\n",
      "total_trades: 6225\n",
      "Sharpe: 1.103\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 5.48e+03    |\n",
      "|    total_reward         | 6.98e+04    |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 6225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020597864 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+05    |\n",
      "|    total_cost           | 5.26e+03    |\n",
      "|    total_reward         | 6.18e+04    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 6174        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022520002 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0472      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.09e+05    |\n",
      "|    total_cost           | 5.09e+03    |\n",
      "|    total_reward         | 5.87e+04    |\n",
      "|    total_reward_pct     | 117         |\n",
      "|    total_trades         | 6217        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025088474 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0405      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 145\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114196.75\n",
      "total_reward: 64196.75\n",
      "total_cost: 4306.79\n",
      "total_trades: 6040\n",
      "Sharpe: 1.110\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+05    |\n",
      "|    total_cost           | 4.31e+03    |\n",
      "|    total_reward         | 6.42e+04    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 6040        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020187505 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.315      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0359      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.05e+05   |\n",
      "|    total_cost           | 4.5e+03    |\n",
      "|    total_reward         | 5.48e+04   |\n",
      "|    total_reward_pct     | 110        |\n",
      "|    total_trades         | 6336       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 417        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03263328 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.284     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0382     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+05    |\n",
      "|    total_cost           | 5.12e+03    |\n",
      "|    total_reward         | 6.38e+04    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 6207        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023201833 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0381      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 150\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110015.11\n",
      "total_reward: 60015.11\n",
      "total_cost: 4137.90\n",
      "total_trades: 6252\n",
      "Sharpe: 1.145\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.46e+04   |\n",
      "|    total_cost           | 3.61e+03   |\n",
      "|    total_reward         | 4.46e+04   |\n",
      "|    total_reward_pct     | 89.3       |\n",
      "|    total_trades         | 6352       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 417        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02588347 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.27      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0355     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.11e+04    |\n",
      "|    total_cost           | 3.53e+03    |\n",
      "|    total_reward         | 4.11e+04    |\n",
      "|    total_reward_pct     | 82.2        |\n",
      "|    total_trades         | 6286        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028652787 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.036       |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 155\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 84376.89\n",
      "total_reward: 34376.89\n",
      "total_cost: 3473.49\n",
      "total_trades: 6179\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.44e+04    |\n",
      "|    total_cost           | 3.47e+03    |\n",
      "|    total_reward         | 3.44e+04    |\n",
      "|    total_reward_pct     | 68.8        |\n",
      "|    total_trades         | 6179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029088348 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0322      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.68e+04    |\n",
      "|    total_cost           | 3.58e+03    |\n",
      "|    total_reward         | 4.68e+04    |\n",
      "|    total_reward_pct     | 93.6        |\n",
      "|    total_trades         | 6280        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027525816 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0397      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 3.31e+03    |\n",
      "|    total_reward         | 5.06e+04    |\n",
      "|    total_reward_pct     | 101         |\n",
      "|    total_trades         | 6282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026502363 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0323      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 160\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89993.81\n",
      "total_reward: 39993.81\n",
      "total_cost: 3317.17\n",
      "total_trades: 6232\n",
      "Sharpe: 0.805\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.02e+05   |\n",
      "|    total_cost           | 4.09e+03   |\n",
      "|    total_reward         | 5.15e+04   |\n",
      "|    total_reward_pct     | 103        |\n",
      "|    total_trades         | 6249       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 417        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 171        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02938033 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.268     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0372     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 3.7e+03     |\n",
      "|    total_reward         | 5.28e+04    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 6291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021072315 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0463      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 165\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 108402.32\n",
      "total_reward: 58402.32\n",
      "total_cost: 3972.37\n",
      "total_trades: 6352\n",
      "Sharpe: 1.144\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.08e+05    |\n",
      "|    total_cost           | 3.97e+03    |\n",
      "|    total_reward         | 5.84e+04    |\n",
      "|    total_reward_pct     | 117         |\n",
      "|    total_trades         | 6352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030060396 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.254      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.58e+04   |\n",
      "|    total_cost           | 3.78e+03   |\n",
      "|    total_reward         | 4.58e+04   |\n",
      "|    total_reward_pct     | 91.7       |\n",
      "|    total_trades         | 6356       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 417        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03522613 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.617      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.262     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0072    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0392     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 3.9e+03     |\n",
      "|    total_reward         | 5.25e+04    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 6282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028158143 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0407      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 170\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103039.63\n",
      "total_reward: 53039.63\n",
      "total_cost: 4665.66\n",
      "total_trades: 6467\n",
      "Sharpe: 1.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 4.67e+03    |\n",
      "|    total_reward         | 5.3e+04     |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 6467        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025898188 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0351      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 3.24e+03    |\n",
      "|    total_reward         | 6.59e+04    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 6465        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022832628 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0373      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+05    |\n",
      "|    total_cost           | 4.24e+03    |\n",
      "|    total_reward         | 7.21e+04    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 6435        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027116042 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0411      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 175\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92983.82\n",
      "total_reward: 42983.82\n",
      "total_cost: 3857.60\n",
      "total_trades: 6567\n",
      "Sharpe: 0.889\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.46e+04    |\n",
      "|    total_cost           | 3.51e+03    |\n",
      "|    total_reward         | 4.46e+04    |\n",
      "|    total_reward_pct     | 89.3        |\n",
      "|    total_trades         | 6522        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029510023 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0441      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 3.57e+03    |\n",
      "|    total_reward         | 6.06e+04    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 6599        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027481709 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0354      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 180\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 109957.37\n",
      "total_reward: 59957.37\n",
      "total_cost: 4842.53\n",
      "total_trades: 6745\n",
      "Sharpe: 1.110\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.1e+05     |\n",
      "|    total_cost           | 4.84e+03    |\n",
      "|    total_reward         | 6e+04       |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 6745        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021661097 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0441      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.04e+04    |\n",
      "|    total_cost           | 4.14e+03    |\n",
      "|    total_reward         | 3.04e+04    |\n",
      "|    total_reward_pct     | 60.8        |\n",
      "|    total_trades         | 6696        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017901653 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0422      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.53e+04    |\n",
      "|    total_cost           | 3.21e+03    |\n",
      "|    total_reward         | 3.53e+04    |\n",
      "|    total_reward_pct     | 70.6        |\n",
      "|    total_trades         | 6482        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020608578 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0405      |\n",
      "-----------------------------------------\n",
      "day: 1066, episode: 185\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92295.58\n",
      "total_reward: 42295.58\n",
      "total_cost: 3115.94\n",
      "total_trades: 6465\n",
      "Sharpe: 0.870\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 4.12e+03    |\n",
      "|    total_reward         | 5.15e+04    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 6751        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027607933 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0444      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.95e+04    |\n",
      "|    total_cost           | 3.07e+03    |\n",
      "|    total_reward         | 3.95e+04    |\n",
      "|    total_reward_pct     | 79          |\n",
      "|    total_trades         | 6657        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014590041 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0459      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-04-04 to  2019-07-05\n",
      "PPO Sharpe Ratio:  0.27484104581471336\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
      "day: 1066, episode: 190\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 23810.64\n",
      "total_reward: -26189.36\n",
      "total_cost: 195.66\n",
      "total_trades: 3161\n",
      "Sharpe: -0.538\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.57e+04  |\n",
      "|    total_cost       | 185       |\n",
      "|    total_reward     | -4.29e+03 |\n",
      "|    total_reward_pct | -8.58     |\n",
      "|    total_trades     | 4651      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 145       |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total timesteps  | 4268      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 9.42      |\n",
      "|    critic_loss      | 78.5      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 3201      |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 195\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 37262.10\n",
      "total_reward: -12737.90\n",
      "total_cost: 189.37\n",
      "total_trades: 5083\n",
      "Sharpe: -0.162\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.53e+04  |\n",
      "|    total_cost       | 152       |\n",
      "|    total_reward     | -2.47e+04 |\n",
      "|    total_reward_pct | -49.4     |\n",
      "|    total_trades     | 4692      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 65        |\n",
      "|    total timesteps  | 8536      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 3.01      |\n",
      "|    critic_loss      | 17.4      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7469      |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 200\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74654.98\n",
      "total_reward: 24654.98\n",
      "total_cost: 153.76\n",
      "total_trades: 4461\n",
      "Sharpe: 0.601\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.05e+04 |\n",
      "|    total_cost       | 263      |\n",
      "|    total_reward     | 4.05e+04 |\n",
      "|    total_reward_pct | 80.9     |\n",
      "|    total_trades     | 4149     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 127      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total timesteps  | 12804    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.9      |\n",
      "|    critic_loss      | 6.53     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11737    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 205\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 36645.00\n",
      "total_reward: -13355.00\n",
      "total_cost: 115.87\n",
      "total_trades: 5119\n",
      "Sharpe: -0.186\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.66e+04  |\n",
      "|    total_cost       | 116       |\n",
      "|    total_reward     | -1.34e+04 |\n",
      "|    total_reward_pct | -26.7     |\n",
      "|    total_trades     | 5119      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 136       |\n",
      "|    total timesteps  | 17072     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 1.58      |\n",
      "|    critic_loss      | 4.12      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16005     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.52e+04  |\n",
      "|    total_cost       | 191       |\n",
      "|    total_reward     | -4.82e+03 |\n",
      "|    total_reward_pct | -9.64     |\n",
      "|    total_trades     | 3448      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 172       |\n",
      "|    total timesteps  | 21340     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 1.12      |\n",
      "|    critic_loss      | 2.3       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 20273     |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 210\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 72124.01\n",
      "total_reward: 22124.01\n",
      "total_cost: 247.37\n",
      "total_trades: 4795\n",
      "Sharpe: 0.526\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.91e+04 |\n",
      "|    total_cost       | 270      |\n",
      "|    total_reward     | 2.91e+04 |\n",
      "|    total_reward_pct | 58.1     |\n",
      "|    total_trades     | 6026     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 122      |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total timesteps  | 25608    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.892    |\n",
      "|    critic_loss      | 2.66     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24541    |\n",
      "----------------------------------\n",
      "day: 1066, episode: 215\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 44182.45\n",
      "total_reward: -5817.55\n",
      "total_cost: 119.82\n",
      "total_trades: 3053\n",
      "Sharpe: -0.004\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.05e+04  |\n",
      "|    total_cost       | 99.8      |\n",
      "|    total_reward     | -9.52e+03 |\n",
      "|    total_reward_pct | -19       |\n",
      "|    total_trades     | 5543      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 121       |\n",
      "|    time_elapsed     | 245       |\n",
      "|    total timesteps  | 29876     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.666     |\n",
      "|    critic_loss      | 1.16      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28809     |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 220\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 36969.44\n",
      "total_reward: -13030.56\n",
      "total_cost: 94.82\n",
      "total_trades: 4010\n",
      "Sharpe: -0.142\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.84e+04  |\n",
      "|    total_cost       | 102       |\n",
      "|    total_reward     | -1.16e+04 |\n",
      "|    total_reward_pct | -23.3     |\n",
      "|    total_trades     | 5758      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 121       |\n",
      "|    time_elapsed     | 281       |\n",
      "|    total timesteps  | 34144     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.401     |\n",
      "|    critic_loss      | 1.14      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 33077     |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 225\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47887.83\n",
      "total_reward: -2112.17\n",
      "total_cost: 107.61\n",
      "total_trades: 4583\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.79e+04  |\n",
      "|    total_cost       | 108       |\n",
      "|    total_reward     | -2.11e+03 |\n",
      "|    total_reward_pct | -4.22     |\n",
      "|    total_trades     | 4583      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 120       |\n",
      "|    time_elapsed     | 318       |\n",
      "|    total timesteps  | 38412     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.217     |\n",
      "|    critic_loss      | 0.92      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37345     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.85e+04  |\n",
      "|    total_cost       | 99.9      |\n",
      "|    total_reward     | -1.15e+04 |\n",
      "|    total_reward_pct | -22.9     |\n",
      "|    total_trades     | 4922      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 356       |\n",
      "|    total timesteps  | 42680     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.0718    |\n",
      "|    critic_loss      | 1.18      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 41613     |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 230\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 61714.34\n",
      "total_reward: 11714.34\n",
      "total_cost: 97.58\n",
      "total_trades: 3228\n",
      "Sharpe: 0.347\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.33e+04  |\n",
      "|    total_cost       | 110       |\n",
      "|    total_reward     | -1.67e+04 |\n",
      "|    total_reward_pct | -33.4     |\n",
      "|    total_trades     | 3011      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 393       |\n",
      "|    total timesteps  | 46948     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -0.0758   |\n",
      "|    critic_loss      | 0.432     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 45881     |\n",
      "-----------------------------------\n",
      "day: 1066, episode: 235\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 46467.82\n",
      "total_reward: -3532.18\n",
      "total_cost: 100.35\n",
      "total_trades: 3583\n",
      "Sharpe: 0.038\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-04 to  2019-07-05\n",
      "======Best Model Retraining from:  2015-01-01 to  2019-07-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_189_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.17e+05 |\n",
      "|    total_cost       | 118      |\n",
      "|    total_reward     | 6.68e+04 |\n",
      "|    total_reward_pct | 134      |\n",
      "|    total_trades     | 5075     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total timesteps  | 4520     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -25.6    |\n",
      "|    critic_loss      | 8.69     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3390     |\n",
      "----------------------------------\n",
      "day: 1129, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 53013.80\n",
      "total_reward: 3013.80\n",
      "total_cost: 156.68\n",
      "total_trades: 6040\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.49e+04  |\n",
      "|    total_cost       | 101       |\n",
      "|    total_reward     | -5.11e+03 |\n",
      "|    total_reward_pct | -10.2     |\n",
      "|    total_trades     | 3654      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 127       |\n",
      "|    time_elapsed     | 70        |\n",
      "|    total timesteps  | 9040      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -22       |\n",
      "|    critic_loss      | 3.65      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7910      |\n",
      "-----------------------------------\n",
      "day: 1129, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 38318.53\n",
      "total_reward: -11681.47\n",
      "total_cost: 97.72\n",
      "total_trades: 7600\n",
      "Sharpe: -0.094\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.19e+04 |\n",
      "|    total_cost       | 148      |\n",
      "|    total_reward     | 1.19e+04 |\n",
      "|    total_reward_pct | 23.8     |\n",
      "|    total_trades     | 6725     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total timesteps  | 13560    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -17.9    |\n",
      "|    critic_loss      | 1.8      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 12430    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 53119.40\n",
      "total_reward: 3119.40\n",
      "total_cost: 110.45\n",
      "total_trades: 7939\n",
      "Sharpe: 0.178\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.15e+05 |\n",
      "|    total_cost       | 146      |\n",
      "|    total_reward     | 6.45e+04 |\n",
      "|    total_reward_pct | 129      |\n",
      "|    total_trades     | 6295     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total timesteps  | 18080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -14.3    |\n",
      "|    critic_loss      | 0.788    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16950    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 56268.84\n",
      "total_reward: 6268.84\n",
      "total_cost: 148.67\n",
      "total_trades: 7208\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.63e+04 |\n",
      "|    total_cost       | 149      |\n",
      "|    total_reward     | 6.27e+03 |\n",
      "|    total_reward_pct | 12.5     |\n",
      "|    total_trades     | 7208     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total timesteps  | 22600    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -11.5    |\n",
      "|    critic_loss      | 1.33     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 21470    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.24e+05 |\n",
      "|    total_cost       | 115      |\n",
      "|    total_reward     | 7.43e+04 |\n",
      "|    total_reward_pct | 149      |\n",
      "|    total_trades     | 6341     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total timesteps  | 27120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -9.14    |\n",
      "|    critic_loss      | 1.4      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25990    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 51595.01\n",
      "total_reward: 1595.01\n",
      "total_cost: 148.09\n",
      "total_trades: 4686\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.87e+04  |\n",
      "|    total_cost       | 124       |\n",
      "|    total_reward     | -1.34e+03 |\n",
      "|    total_reward_pct | -2.68     |\n",
      "|    total_trades     | 5927      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 267       |\n",
      "|    total timesteps  | 31640     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -7.33     |\n",
      "|    critic_loss      | 0.427     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 30510     |\n",
      "-----------------------------------\n",
      "day: 1129, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 68370.80\n",
      "total_reward: 18370.80\n",
      "total_cost: 132.76\n",
      "total_trades: 8090\n",
      "Sharpe: 0.467\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.28e+05 |\n",
      "|    total_cost       | 150      |\n",
      "|    total_reward     | 7.81e+04 |\n",
      "|    total_reward_pct | 156      |\n",
      "|    total_trades     | 5999     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total timesteps  | 36160    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.92    |\n",
      "|    critic_loss      | 0.854    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35030    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 37924.55\n",
      "total_reward: -12075.45\n",
      "total_cost: 105.53\n",
      "total_trades: 6306\n",
      "Sharpe: -0.103\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.15e+04  |\n",
      "|    total_cost       | 96.3      |\n",
      "|    total_reward     | -8.46e+03 |\n",
      "|    total_reward_pct | -16.9     |\n",
      "|    total_trades     | 5932      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 345       |\n",
      "|    total timesteps  | 40680     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -4.78     |\n",
      "|    critic_loss      | 1.54      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 39550     |\n",
      "-----------------------------------\n",
      "day: 1129, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 136492.54\n",
      "total_reward: 86492.54\n",
      "total_cost: 232.86\n",
      "total_trades: 6179\n",
      "Sharpe: 1.278\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.36e+05 |\n",
      "|    total_cost       | 233      |\n",
      "|    total_reward     | 8.65e+04 |\n",
      "|    total_reward_pct | 173      |\n",
      "|    total_trades     | 6179     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 384      |\n",
      "|    total timesteps  | 45200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -4       |\n",
      "|    critic_loss      | 0.706    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44070    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.68e+04  |\n",
      "|    total_cost       | 114       |\n",
      "|    total_reward     | -1.32e+04 |\n",
      "|    total_reward_pct | -26.4     |\n",
      "|    total_trades     | 5294      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 424       |\n",
      "|    total timesteps  | 49720     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -3.27     |\n",
      "|    critic_loss      | 0.884     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 48590     |\n",
      "-----------------------------------\n",
      "day: 1129, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 55505.94\n",
      "total_reward: 5505.94\n",
      "total_cost: 176.44\n",
      "total_trades: 7159\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "======Trading from:  2019-07-05 to  2019-10-02\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  529.7283042530553\n",
      "======Model training from:  2015-01-01 to  2019-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -2.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -2.81    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0192   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 358       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | -0.000731 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 0.124     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.000274  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 4.51e+03 |\n",
      "|    total_reward       | 5.76e+04 |\n",
      "|    total_reward_pct   | 115      |\n",
      "|    total_trades       | 6355     |\n",
      "| time/                 |          |\n",
      "|    fps                | 358      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.988    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00553  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 358      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00365  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.64e+04 |\n",
      "|    total_cost         | 3.15e+03 |\n",
      "|    total_reward       | 3.64e+04 |\n",
      "|    total_reward_pct   | 72.9     |\n",
      "|    total_trades       | 6313     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.346   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -4.66    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0515   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.88    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -6.53    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0688   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.83e+04 |\n",
      "|    total_cost         | 3.01e+03 |\n",
      "|    total_reward       | 3.83e+04 |\n",
      "|    total_reward_pct   | 76.7     |\n",
      "|    total_trades       | 6338     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -2.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -1.71    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -0.0576  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00878  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0.212    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 7.04     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.072    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.67e+04 |\n",
      "|    total_cost         | 2.23e+03 |\n",
      "|    total_reward       | 4.67e+04 |\n",
      "|    total_reward_pct   | 93.4     |\n",
      "|    total_trades       | 6475     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -8.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 5.37     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0431   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -1.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 101158.40\n",
      "total_reward: 51158.40\n",
      "total_cost: 3100.80\n",
      "total_trades: 6863\n",
      "Sharpe: 1.008\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 3.1e+03  |\n",
      "|    total_reward       | 5.12e+04 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 6863     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -7.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 1.84     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00717  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -0.554    |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.00304   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.54e+04 |\n",
      "|    total_cost         | 2.02e+03 |\n",
      "|    total_reward       | 4.54e+04 |\n",
      "|    total_reward_pct   | 90.8     |\n",
      "|    total_trades       | 6853     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -1.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.182   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.00217  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -3.33    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 1.77     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00666  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.61e+04 |\n",
      "|    total_cost         | 1.93e+03 |\n",
      "|    total_reward       | 3.61e+04 |\n",
      "|    total_reward_pct   | 72.1     |\n",
      "|    total_trades       | 7083     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.0297   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 3.9      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0235   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -0.512    |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.00226   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -0.0653  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.419   |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.000594 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.66e+04 |\n",
      "|    total_cost         | 1.81e+03 |\n",
      "|    total_reward       | 2.66e+04 |\n",
      "|    total_reward_pct   | 53.1     |\n",
      "|    total_trades       | 7505     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -3.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 3.61     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0262   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.504    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -9.72    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 2.17e+03 |\n",
      "|    total_reward       | 5.93e+04 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 7807     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -0.0589  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00787  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0.0505   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "day: 1129, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 107319.70\n",
      "total_reward: 57319.70\n",
      "total_cost: 2460.77\n",
      "total_trades: 8036\n",
      "Sharpe: 1.111\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 2.46e+03 |\n",
      "|    total_reward       | 5.73e+04 |\n",
      "|    total_reward_pct   | 115      |\n",
      "|    total_trades       | 8036     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0.161    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 2.08     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.00504  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | -0.529   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.493    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00121  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 1.75e+03 |\n",
      "|    total_reward       | 5.2e+04  |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 7826     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -1.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -3.07    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.0108   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0.266    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 1.45     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.00478  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.219   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 4.57     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0229   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 2.24e+03 |\n",
      "|    total_reward       | 6.15e+04 |\n",
      "|    total_reward_pct   | 123      |\n",
      "|    total_trades       | 8182     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -2.45    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00983  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | 0.51     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 3.37     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0138   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.35e+04 |\n",
      "|    total_cost         | 1.57e+03 |\n",
      "|    total_reward       | 3.35e+04 |\n",
      "|    total_reward_pct   | 67       |\n",
      "|    total_trades       | 8513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.661   |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.00157  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | 0.0377   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 1.65     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 1.64e+03 |\n",
      "|    total_reward       | 6.09e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 9005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | 0.346    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.852   |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.00217  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.0062   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 104678.89\n",
      "total_reward: 54678.89\n",
      "total_cost: 1527.76\n",
      "total_trades: 8686\n",
      "Sharpe: 1.002\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 1.53e+03 |\n",
      "|    total_reward       | 5.47e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 8686     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | 0.271    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -3.91    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0286   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | -0.0616  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -7.14    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.056    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | -0.0272  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 1.67     |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.0036   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 1.45e+03 |\n",
      "|    total_reward       | 5.83e+04 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 9270     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -6.34    |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0435   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 5.54     |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.0321   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.05e+05  |\n",
      "|    total_cost         | 1.12e+03  |\n",
      "|    total_reward       | 5.52e+04  |\n",
      "|    total_reward_pct   | 110       |\n",
      "|    total_trades       | 8976      |\n",
      "| time/                 |           |\n",
      "|    fps                | 357       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -2.4      |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.00618   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -0.657   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 2.04     |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 1.42e+03 |\n",
      "|    total_reward       | 6.89e+04 |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 8886     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | 0.0375   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.77    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00162  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | -0.313   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -3.41    |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 1.11e+03 |\n",
      "|    total_reward       | 5.2e+04  |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 9029     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | -0.0369  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 4.51     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.0434   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0.0807   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -5.4     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.0337   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | 0.374    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 6.71     |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.0582   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 102901.45\n",
      "total_reward: 52901.45\n",
      "total_cost: 1266.31\n",
      "total_trades: 8582\n",
      "Sharpe: 0.981\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.27e+03 |\n",
      "|    total_reward       | 5.29e+04 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 8582     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | -0.0154  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.104    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.00369  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 3.28     |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 1.52e+03 |\n",
      "|    total_reward       | 6.33e+04 |\n",
      "|    total_reward_pct   | 127      |\n",
      "|    total_trades       | 8734     |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -0.975   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 3.39     |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.0186   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -1.5     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.00867  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+05 |\n",
      "|    total_cost         | 1.37e+03 |\n",
      "|    total_reward       | 7.09e+04 |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 8575     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.8    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.125   |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.00187  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 1.18      |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 0.0209    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.44e+05 |\n",
      "|    total_cost         | 1.56e+03 |\n",
      "|    total_reward       | 9.35e+04 |\n",
      "|    total_reward_pct   | 187      |\n",
      "|    total_trades       | 8743     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | -19      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 2.33     |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.00589  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | 0.146    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -1.68    |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | -0.0109  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 7.95     |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.0575   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.28e+05 |\n",
      "|    total_cost         | 1.57e+03 |\n",
      "|    total_reward       | 7.8e+04  |\n",
      "|    total_reward_pct   | 156      |\n",
      "|    total_trades       | 8885     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 5.84     |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.0319   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -0.0165  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.0118   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 130163.58\n",
      "total_reward: 80163.58\n",
      "total_cost: 1251.33\n",
      "total_trades: 9588\n",
      "Sharpe: 1.216\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.3e+05  |\n",
      "|    total_cost         | 1.25e+03 |\n",
      "|    total_reward       | 8.02e+04 |\n",
      "|    total_reward_pct   | 160      |\n",
      "|    total_trades       | 9588     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | -0.0868  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -1.71    |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | -3.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.0616  |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.00651  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.21e+04 |\n",
      "|    total_cost         | 863      |\n",
      "|    total_reward       | 2.21e+04 |\n",
      "|    total_reward_pct   | 44.2     |\n",
      "|    total_trades       | 9243     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | -2.83    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -2.11    |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.00504  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -0.649   |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.0043   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.00156  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.79e+04  |\n",
      "|    total_cost         | 448       |\n",
      "|    total_reward       | -1.21e+04 |\n",
      "|    total_reward_pct   | -24.2     |\n",
      "|    total_trades       | 9179      |\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 6.2       |\n",
      "|    std                | 1.68      |\n",
      "|    value_loss         | 0.0372    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -6.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 4.27     |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.98e+04 |\n",
      "|    total_cost         | 764      |\n",
      "|    total_reward       | 9.8e+03  |\n",
      "|    total_reward_pct   | 19.6     |\n",
      "|    total_trades       | 9311     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | -0.353   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 6.98     |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.0415   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | -1.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0.58    |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.00141  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.64e+04 |\n",
      "|    total_cost         | 744      |\n",
      "|    total_reward       | 1.64e+04 |\n",
      "|    total_reward_pct   | 32.8     |\n",
      "|    total_trades       | 9540     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 3.01     |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.0237   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 0.438    |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 39087.20\n",
      "total_reward: -10912.80\n",
      "total_cost: 704.12\n",
      "total_trades: 9652\n",
      "Sharpe: -0.113\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.91e+04  |\n",
      "|    total_cost         | 704       |\n",
      "|    total_reward       | -1.09e+04 |\n",
      "|    total_reward_pct   | -21.8     |\n",
      "|    total_trades       | 9652      |\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -1.21     |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 0.00153   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 2.63     |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.00856  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -2.36    |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 972      |\n",
      "|    total_reward       | 5.89e+04 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 9941     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | -0.359   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 6.4      |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.0343   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0.00118  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 6.57     |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.0441   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.59e+04 |\n",
      "|    total_cost         | 945      |\n",
      "|    total_reward       | 4.59e+04 |\n",
      "|    total_reward_pct   | 91.7     |\n",
      "|    total_trades       | 9865     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -6.27    |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.0328   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.134    |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 0.00647  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.14e+04 |\n",
      "|    total_cost         | 875      |\n",
      "|    total_reward       | 4.14e+04 |\n",
      "|    total_reward_pct   | 82.8     |\n",
      "|    total_trades       | 9562     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.489    |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.00187  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | -0.459   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 4.6      |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.33e+04 |\n",
      "|    total_cost         | 944      |\n",
      "|    total_reward       | 4.33e+04 |\n",
      "|    total_reward_pct   | 86.6     |\n",
      "|    total_trades       | 9567     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | 0.164    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -2.6     |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.00805  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -6.65    |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.0265   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | -2.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 5.32     |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.0223   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 107376.87\n",
      "total_reward: 57376.87\n",
      "total_cost: 942.78\n",
      "total_trades: 9787\n",
      "Sharpe: 1.007\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.07e+05  |\n",
      "|    total_cost         | 943       |\n",
      "|    total_reward       | 5.74e+04  |\n",
      "|    total_reward_pct   | 115       |\n",
      "|    total_trades       | 9787      |\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -2.14     |\n",
      "|    std                | 1.98      |\n",
      "|    value_loss         | 0.00692   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -0.0549  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -1.87    |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 0.00539  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.62e+04 |\n",
      "|    total_cost         | 805      |\n",
      "|    total_reward       | 2.62e+04 |\n",
      "|    total_reward_pct   | 52.4     |\n",
      "|    total_trades       | 9723     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.845    |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.00288  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 1.83     |\n",
      "|    std                | 2.04     |\n",
      "|    value_loss         | 0.00272  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.56e+04 |\n",
      "|    total_cost         | 930      |\n",
      "|    total_reward       | 4.56e+04 |\n",
      "|    total_reward_pct   | 91.2     |\n",
      "|    total_trades       | 9690     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 7.03e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.00138  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.407   |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 0.00614  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.09e+04 |\n",
      "|    total_cost         | 838      |\n",
      "|    total_reward       | 3.09e+04 |\n",
      "|    total_reward_pct   | 61.7     |\n",
      "|    total_trades       | 9804     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | -0.048   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.0406   |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.00256  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 5.59     |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.0323   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -3.47    |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.0067   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 853      |\n",
      "|    total_reward       | 5.2e+04  |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 9964     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -5.71    |\n",
      "|    std                | 2.15     |\n",
      "|    value_loss         | 0.0444   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -3.74    |\n",
      "|    std                | 2.16     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "day: 1129, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89169.59\n",
      "total_reward: 39169.59\n",
      "total_cost: 795.00\n",
      "total_trades: 9811\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.92e+04 |\n",
      "|    total_cost         | 795      |\n",
      "|    total_reward       | 3.92e+04 |\n",
      "|    total_reward_pct   | 78.3     |\n",
      "|    total_trades       | 9811     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 2.49     |\n",
      "|    std                | 2.19     |\n",
      "|    value_loss         | 0.0193   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | 0.0233   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.505   |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 0.00166  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 818      |\n",
      "|    total_reward       | 5.18e+04 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 9986     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | -0.662   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.00432  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    std                | 2.24     |\n",
      "|    value_loss         | 0.00124  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 818      |\n",
      "|    total_reward       | 6.63e+04 |\n",
      "|    total_reward_pct   | 133      |\n",
      "|    total_trades       | 9979     |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -1.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -4.89    |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.0138   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -4.74    |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.029    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.542   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    std                | 2.31     |\n",
      "|    value_loss         | 0.00627  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.92e+04  |\n",
      "|    total_cost         | 702       |\n",
      "|    total_reward       | 3.92e+04  |\n",
      "|    total_reward_pct   | 78.5      |\n",
      "|    total_trades       | 10298     |\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 0.0821    |\n",
      "|    std                | 2.33      |\n",
      "|    value_loss         | 0.00176   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -3.2     |\n",
      "|    std                | 2.35     |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.45e+04  |\n",
      "|    total_cost         | 828       |\n",
      "|    total_reward       | 4.45e+04  |\n",
      "|    total_reward_pct   | 89        |\n",
      "|    total_trades       | 10203     |\n",
      "| time/                 |           |\n",
      "|    fps                | 354       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -0.203    |\n",
      "|    std                | 2.37      |\n",
      "|    value_loss         | 0.00738   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -0.0349  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -0.381   |\n",
      "|    std                | 2.39     |\n",
      "|    value_loss         | 0.0111   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 99716.85\n",
      "total_reward: 49716.85\n",
      "total_cost: 772.39\n",
      "total_trades: 10289\n",
      "Sharpe: 0.883\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+04 |\n",
      "|    total_cost         | 772      |\n",
      "|    total_reward       | 4.97e+04 |\n",
      "|    total_reward_pct   | 99.4     |\n",
      "|    total_trades       | 10289    |\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.592    |\n",
      "|    std                | 2.41     |\n",
      "|    value_loss         | 0.00168  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.353   |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.00319  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.53e+04 |\n",
      "|    total_cost         | 621      |\n",
      "|    total_reward       | 2.53e+04 |\n",
      "|    total_reward_pct   | 50.5     |\n",
      "|    total_trades       | 10447    |\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0.363    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -3.02    |\n",
      "|    std                | 2.46     |\n",
      "|    value_loss         | 0.00646  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 354       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | -0.875    |\n",
      "|    std                | 2.48      |\n",
      "|    value_loss         | 0.00433   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -3.86    |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.00809  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.61e+04  |\n",
      "|    total_cost         | 689       |\n",
      "|    total_reward       | 2.61e+04  |\n",
      "|    total_reward_pct   | 52.2      |\n",
      "|    total_trades       | 10389     |\n",
      "| time/                 |           |\n",
      "|    fps                | 354       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -10.1     |\n",
      "|    std                | 2.53      |\n",
      "|    value_loss         | 0.0565    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -5.5     |\n",
      "|    std                | 2.55     |\n",
      "|    value_loss         | 0.0249   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.13e+04 |\n",
      "|    total_cost         | 832      |\n",
      "|    total_reward       | 4.13e+04 |\n",
      "|    total_reward_pct   | 82.5     |\n",
      "|    total_trades       | 10506    |\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -7.83    |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.0289   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 16.2     |\n",
      "|    std                | 2.59     |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 915      |\n",
      "|    total_reward       | 5.02e+04 |\n",
      "|    total_reward_pct   | 100      |\n",
      "|    total_trades       | 10727    |\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0.168    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -5.98    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 9.21     |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 0.0454   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 109603.96\n",
      "total_reward: 59603.96\n",
      "total_cost: 985.28\n",
      "total_trades: 10616\n",
      "Sharpe: 0.990\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.1e+05   |\n",
      "|    total_cost         | 985       |\n",
      "|    total_reward       | 5.96e+04  |\n",
      "|    total_reward_pct   | 119       |\n",
      "|    total_trades       | 10616     |\n",
      "| time/                 |           |\n",
      "|    fps                | 353       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 4.79      |\n",
      "|    std                | 2.65      |\n",
      "|    value_loss         | 0.0202    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | -0.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -3.45    |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 0.00874  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.855   |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.000659 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 905      |\n",
      "|    total_reward       | 5.68e+04 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 10454    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0.0372   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 2.05     |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.00866  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0.132    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -4.81    |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 0.0111   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.12e+04 |\n",
      "|    total_cost         | 823      |\n",
      "|    total_reward       | 4.12e+04 |\n",
      "|    total_reward_pct   | 82.4     |\n",
      "|    total_trades       | 10236    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | -0.168   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    std                | 2.77     |\n",
      "|    value_loss         | 0.00378  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | -0.0751  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    std                | 2.79     |\n",
      "|    value_loss         | 0.0873   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.07e+04 |\n",
      "|    total_cost         | 686      |\n",
      "|    total_reward       | 3.07e+04 |\n",
      "|    total_reward_pct   | 61.3     |\n",
      "|    total_trades       | 10472    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | -0.0859  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 5.22     |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -8.6     |\n",
      "|    std                | 2.84     |\n",
      "|    value_loss         | 0.0455   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 6.46     |\n",
      "|    std                | 2.86     |\n",
      "|    value_loss         | 0.0268   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 952      |\n",
      "|    total_reward       | 6.9e+04  |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 10683    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0.332    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.0024   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -1.1     |\n",
      "|    std                | 2.91     |\n",
      "|    value_loss         | 0.00368  |\n",
      "------------------------------------\n",
      "day: 1129, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 100716.21\n",
      "total_reward: 50716.21\n",
      "total_cost: 822.30\n",
      "total_trades: 10395\n",
      "Sharpe: 0.904\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 822      |\n",
      "|    total_reward       | 5.07e+04 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 10395    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -0.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.971    |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.00228  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -3       |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 0.00588  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.73e+04 |\n",
      "|    total_cost         | 705      |\n",
      "|    total_reward       | 4.73e+04 |\n",
      "|    total_reward_pct   | 94.6     |\n",
      "|    total_trades       | 10144    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -2.47    |\n",
      "|    std                | 2.99     |\n",
      "|    value_loss         | 0.0029   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -6.38    |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.0358   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.94e+04 |\n",
      "|    total_cost         | 685      |\n",
      "|    total_reward       | 2.94e+04 |\n",
      "|    total_reward_pct   | 58.8     |\n",
      "|    total_trades       | 10485    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 4.65     |\n",
      "|    std                | 3.05     |\n",
      "|    value_loss         | 0.0105   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -1.19    |\n",
      "|    std                | 3.07     |\n",
      "|    value_loss         | 0.00206  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    std                | 3.1      |\n",
      "|    value_loss         | 0.000174 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.28e+04 |\n",
      "|    total_cost         | 581      |\n",
      "|    total_reward       | 1.28e+04 |\n",
      "|    total_reward_pct   | 25.7     |\n",
      "|    total_trades       | 10456    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | -9.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 3.79     |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.0314   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -5.47    |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.7e+04  |\n",
      "|    total_cost         | 721      |\n",
      "|    total_reward       | 1.7e+04  |\n",
      "|    total_reward_pct   | 34.1     |\n",
      "|    total_trades       | 10787    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 0.415    |\n",
      "|    std                | 3.19     |\n",
      "|    value_loss         | 0.000805 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | -0.248   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.0851   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 59015.71\n",
      "total_reward: 9015.71\n",
      "total_cost: 711.81\n",
      "total_trades: 10594\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.9e+04  |\n",
      "|    total_cost         | 712      |\n",
      "|    total_reward       | 9.02e+03 |\n",
      "|    total_reward_pct   | 18       |\n",
      "|    total_trades       | 10594    |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 3.24     |\n",
      "|    value_loss         | 0.00642  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 353       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 0.192     |\n",
      "|    std                | 3.26      |\n",
      "|    value_loss         | 0.0014    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+04  |\n",
      "|    total_cost         | 847      |\n",
      "|    total_reward       | 4.1e+04  |\n",
      "|    total_reward_pct   | 82       |\n",
      "|    total_trades       | 10590    |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -5.13    |\n",
      "|    std                | 3.29     |\n",
      "|    value_loss         | 0.0109   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 3.67      |\n",
      "|    std                | 3.32      |\n",
      "|    value_loss         | 0.00698   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 3.28     |\n",
      "|    std                | 3.36     |\n",
      "|    value_loss         | 0.0055   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.46e+04 |\n",
      "|    total_cost         | 702      |\n",
      "|    total_reward       | 1.46e+04 |\n",
      "|    total_reward_pct   | 29.2     |\n",
      "|    total_trades       | 10660    |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -6.62    |\n",
      "|    std                | 3.38     |\n",
      "|    value_loss         | 0.0413   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 2.43     |\n",
      "|    std                | 3.41     |\n",
      "|    value_loss         | 0.00855  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.73e+04 |\n",
      "|    total_cost         | 896      |\n",
      "|    total_reward       | 3.73e+04 |\n",
      "|    total_reward_pct   | 74.6     |\n",
      "|    total_trades       | 10828    |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -2.25    |\n",
      "|    std                | 3.45     |\n",
      "|    value_loss         | 0.00516  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.6    |\n",
      "|    explained_variance | 0.0141   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.139   |\n",
      "|    std                | 3.48     |\n",
      "|    value_loss         | 0.000234 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.94e+04  |\n",
      "|    total_cost         | 496       |\n",
      "|    total_reward       | -1.06e+04 |\n",
      "|    total_reward_pct   | -21.2     |\n",
      "|    total_trades       | 10625     |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 205       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.8     |\n",
      "|    explained_variance | -0.00065  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -2.08     |\n",
      "|    std                | 3.52      |\n",
      "|    value_loss         | 0.00534   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 3.59      |\n",
      "|    std                | 3.55      |\n",
      "|    value_loss         | 0.00798   |\n",
      "-------------------------------------\n",
      "day: 1129, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 51787.81\n",
      "total_reward: 1787.81\n",
      "total_cost: 593.10\n",
      "total_trades: 10844\n",
      "Sharpe: 0.144\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.18e+04 |\n",
      "|    total_cost         | 593      |\n",
      "|    total_reward       | 1.79e+03 |\n",
      "|    total_reward_pct   | 3.58     |\n",
      "|    total_trades       | 10844    |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -9.43    |\n",
      "|    std                | 3.58     |\n",
      "|    value_loss         | 0.0442   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -5.8     |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 0.0247   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -1.25    |\n",
      "|    std                | 3.65     |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.51e+04  |\n",
      "|    total_cost         | 926       |\n",
      "|    total_reward       | 2.51e+04  |\n",
      "|    total_reward_pct   | 50.2      |\n",
      "|    total_trades       | 10911     |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -2.91     |\n",
      "|    std                | 3.68      |\n",
      "|    value_loss         | 0.00477   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 0.73     |\n",
      "|    std                | 3.71     |\n",
      "|    value_loss         | 0.00392  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.96e+04 |\n",
      "|    total_cost         | 912      |\n",
      "|    total_reward       | 1.96e+04 |\n",
      "|    total_reward_pct   | 39.2     |\n",
      "|    total_trades       | 10925    |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 3.75     |\n",
      "|    std                | 3.75     |\n",
      "|    value_loss         | 0.016    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -7.52    |\n",
      "|    std                | 3.79     |\n",
      "|    value_loss         | 0.0227   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.33e+04 |\n",
      "|    total_cost         | 690      |\n",
      "|    total_reward       | 1.33e+04 |\n",
      "|    total_reward_pct   | 26.6     |\n",
      "|    total_trades       | 10967    |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | -0.0446  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.892   |\n",
      "|    std                | 3.82     |\n",
      "|    value_loss         | 0.000543 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -3.06    |\n",
      "|    std                | 3.84     |\n",
      "|    value_loss         | 0.0119   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.82e+04 |\n",
      "|    total_cost         | 846      |\n",
      "|    total_reward       | 8.24e+03 |\n",
      "|    total_reward_pct   | 16.5     |\n",
      "|    total_trades       | 11062    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 10.4     |\n",
      "|    std                | 3.87     |\n",
      "|    value_loss         | 0.0611   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 4.75     |\n",
      "|    std                | 3.9      |\n",
      "|    value_loss         | 0.0111   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -8.82    |\n",
      "|    std                | 3.94     |\n",
      "|    value_loss         | 0.0293   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 60820.95\n",
      "total_reward: 10820.95\n",
      "total_cost: 932.32\n",
      "total_trades: 11008\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.08e+04  |\n",
      "|    total_cost         | 932       |\n",
      "|    total_reward       | 1.08e+04  |\n",
      "|    total_reward_pct   | 21.6      |\n",
      "|    total_trades       | 11008     |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 3.75      |\n",
      "|    std                | 3.97      |\n",
      "|    value_loss         | 0.00981   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.00234  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.86e+04 |\n",
      "|    total_cost         | 1.19e+03 |\n",
      "|    total_reward       | 2.86e+04 |\n",
      "|    total_reward_pct   | 57.2     |\n",
      "|    total_trades       | 11344    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 0.338    |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 0.00783  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -5.79     |\n",
      "|    std                | 4.06      |\n",
      "|    value_loss         | 0.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.25e+04 |\n",
      "|    total_cost         | 1.08e+03 |\n",
      "|    total_reward       | 1.25e+04 |\n",
      "|    total_reward_pct   | 25.1     |\n",
      "|    total_trades       | 11562    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | -0.0155  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.347   |\n",
      "|    std                | 4.09     |\n",
      "|    value_loss         | 0.00115  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 4.73      |\n",
      "|    std                | 4.12      |\n",
      "|    value_loss         | 0.029     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.07e+04 |\n",
      "|    total_cost         | 1.06e+03 |\n",
      "|    total_reward       | 2.07e+04 |\n",
      "|    total_reward_pct   | 41.3     |\n",
      "|    total_trades       | 11728    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.578    |\n",
      "|    std                | 4.16     |\n",
      "|    value_loss         | 0.0188   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -9.25    |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 0.0336   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | -5.92    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 5.81     |\n",
      "|    std                | 4.23     |\n",
      "|    value_loss         | 0.0202   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.2e+04  |\n",
      "|    total_cost         | 1.04e+03 |\n",
      "|    total_reward       | 3.2e+04  |\n",
      "|    total_reward_pct   | 64       |\n",
      "|    total_trades       | 11632    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | -0.0404  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 8.61     |\n",
      "|    std                | 4.27     |\n",
      "|    value_loss         | 0.0296   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.6    |\n",
      "|    explained_variance | -0.168   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.633    |\n",
      "|    std                | 4.3      |\n",
      "|    value_loss         | 0.000527 |\n",
      "------------------------------------\n",
      "day: 1129, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 75031.51\n",
      "total_reward: 25031.51\n",
      "total_cost: 1176.20\n",
      "total_trades: 11705\n",
      "Sharpe: 0.508\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.5e+04  |\n",
      "|    total_cost         | 1.18e+03 |\n",
      "|    total_reward       | 2.5e+04  |\n",
      "|    total_reward_pct   | 50.1     |\n",
      "|    total_trades       | 11705    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 9.44     |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.0411   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 1.67     |\n",
      "|    std                | 4.36     |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.68e+04 |\n",
      "|    total_cost         | 1.45e+03 |\n",
      "|    total_reward       | 4.68e+04 |\n",
      "|    total_reward_pct   | 93.5     |\n",
      "|    total_trades       | 11838    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -1.9     |\n",
      "|    std                | 4.4      |\n",
      "|    value_loss         | 0.00147  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 4.43     |\n",
      "|    value_loss         | 0.0852   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 3.85     |\n",
      "|    std                | 4.47     |\n",
      "|    value_loss         | 0.00783  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.3e+04  |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 2.3e+04  |\n",
      "|    total_reward_pct   | 46       |\n",
      "|    total_trades       | 11718    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 28.1     |\n",
      "|    std                | 4.5      |\n",
      "|    value_loss         | 0.259    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | -6.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -5.62    |\n",
      "|    std                | 4.54     |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.7e+04  |\n",
      "|    total_cost         | 1.28e+03 |\n",
      "|    total_reward       | 3.7e+04  |\n",
      "|    total_reward_pct   | 74       |\n",
      "|    total_trades       | 11516    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 14.5     |\n",
      "|    std                | 4.58     |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 10.1     |\n",
      "|    std                | 4.6      |\n",
      "|    value_loss         | 0.0589   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.35e+04  |\n",
      "|    total_cost         | 1.4e+03   |\n",
      "|    total_reward       | 4.35e+04  |\n",
      "|    total_reward_pct   | 86.9      |\n",
      "|    total_trades       | 11772     |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 254       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | -6.1      |\n",
      "|    std                | 4.64      |\n",
      "|    value_loss         | 0.0171    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 2.39     |\n",
      "|    std                | 4.68     |\n",
      "|    value_loss         | 0.00495  |\n",
      "------------------------------------\n",
      "day: 1129, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97292.97\n",
      "total_reward: 47292.97\n",
      "total_cost: 1498.72\n",
      "total_trades: 12072\n",
      "Sharpe: 0.813\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.73e+04 |\n",
      "|    total_cost         | 1.5e+03  |\n",
      "|    total_reward       | 4.73e+04 |\n",
      "|    total_reward_pct   | 94.6     |\n",
      "|    total_trades       | 12072    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.4    |\n",
      "|    explained_variance | 0.000512 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -0.999   |\n",
      "|    std                | 4.71     |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 6.67     |\n",
      "|    std                | 4.75     |\n",
      "|    value_loss         | 0.0199   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -1.54    |\n",
      "|    std                | 4.78     |\n",
      "|    value_loss         | 0.0062   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.89e+04 |\n",
      "|    total_cost         | 1.36e+03 |\n",
      "|    total_reward       | 3.89e+04 |\n",
      "|    total_reward_pct   | 77.7     |\n",
      "|    total_trades       | 12216    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.8    |\n",
      "|    explained_variance | 0.0317   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.397   |\n",
      "|    std                | 4.82     |\n",
      "|    value_loss         | 0.0272   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 263       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 22.2      |\n",
      "|    std                | 4.85      |\n",
      "|    value_loss         | 0.178     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.57e+03 |\n",
      "|    total_reward       | 5.3e+04  |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 12236    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.1    |\n",
      "|    explained_variance | -0.767   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -9.55    |\n",
      "|    std                | 4.9      |\n",
      "|    value_loss         | 0.0425   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 1.7      |\n",
      "|    std                | 4.92     |\n",
      "|    value_loss         | 0.0189   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 1.64e+03 |\n",
      "|    total_reward       | 5.1e+04  |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 12469    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 0.294    |\n",
      "|    std                | 4.96     |\n",
      "|    value_loss         | 0.00161  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 3.18     |\n",
      "|    std                | 4.99     |\n",
      "|    value_loss         | 0.00401  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.71e+04 |\n",
      "|    total_cost         | 1.52e+03 |\n",
      "|    total_reward       | 4.71e+04 |\n",
      "|    total_reward_pct   | 94.3     |\n",
      "|    total_trades       | 12650    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.6    |\n",
      "|    explained_variance | 0.0348   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 5.02     |\n",
      "|    value_loss         | 0.00787  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -5.91    |\n",
      "|    std                | 5.07     |\n",
      "|    value_loss         | 0.0192   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 7.92     |\n",
      "|    std                | 5.1      |\n",
      "|    value_loss         | 0.0232   |\n",
      "------------------------------------\n",
      "day: 1129, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 87306.64\n",
      "total_reward: 37306.64\n",
      "total_cost: 1337.53\n",
      "total_trades: 12616\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.73e+04  |\n",
      "|    total_cost         | 1.34e+03  |\n",
      "|    total_reward       | 3.73e+04  |\n",
      "|    total_reward_pct   | 74.6      |\n",
      "|    total_trades       | 12616     |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 274       |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | 0.703     |\n",
      "|    std                | 5.15      |\n",
      "|    value_loss         | 0.00844   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.2    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    std                | 5.19     |\n",
      "|    value_loss         | 0.0547   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 1.47e+03 |\n",
      "|    total_reward       | 5.17e+04 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 12963    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 3.12     |\n",
      "|    std                | 5.23     |\n",
      "|    value_loss         | 0.00668  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.4    |\n",
      "|    explained_variance | 0.72     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 4.05     |\n",
      "|    std                | 5.26     |\n",
      "|    value_loss         | 0.00478  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+04 |\n",
      "|    total_cost         | 1.55e+03 |\n",
      "|    total_reward       | 4.99e+04 |\n",
      "|    total_reward_pct   | 99.7     |\n",
      "|    total_trades       | 13112    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.6    |\n",
      "|    explained_variance | -0.455   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 3.39     |\n",
      "|    std                | 5.3      |\n",
      "|    value_loss         | 0.00475  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -5.28    |\n",
      "|    std                | 5.35     |\n",
      "|    value_loss         | 0.0229   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.36e+04 |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 2.36e+04 |\n",
      "|    total_reward_pct   | 47.3     |\n",
      "|    total_trades       | 13050    |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 0.703    |\n",
      "|    std                | 5.39     |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59      |\n",
      "|    explained_variance | -0.00149 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 6.05     |\n",
      "|    std                | 5.41     |\n",
      "|    value_loss         | 0.0294   |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-07-05 to  2019-10-02\n",
      "A2C Sharpe Ratio:  -0.06912181089677594\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_1\n",
      "day: 1129, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70334.46\n",
      "total_reward: 20334.46\n",
      "total_cost: 11406.15\n",
      "total_trades: 6249\n",
      "Sharpe: 0.544\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.03e+04 |\n",
      "|    total_cost       | 1.14e+04 |\n",
      "|    total_reward     | 2.03e+04 |\n",
      "|    total_reward_pct | 40.7     |\n",
      "|    total_trades     | 6249     |\n",
      "| time/               |          |\n",
      "|    fps              | 452      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.05e+04    |\n",
      "|    total_cost           | 8.21e+03    |\n",
      "|    total_reward         | 2.05e+04    |\n",
      "|    total_reward_pct     | 40.9        |\n",
      "|    total_trades         | 6161        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010187573 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0682      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.79e+04    |\n",
      "|    total_cost           | 9.74e+03    |\n",
      "|    total_reward         | 4.79e+04    |\n",
      "|    total_reward_pct     | 95.7        |\n",
      "|    total_trades         | 6199        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 426         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017983116 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0314      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90370.39\n",
      "total_reward: 40370.39\n",
      "total_cost: 9941.41\n",
      "total_trades: 6293\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.97e+04    |\n",
      "|    total_cost           | 1.19e+04    |\n",
      "|    total_reward         | 2.97e+04    |\n",
      "|    total_reward_pct     | 59.5        |\n",
      "|    total_trades         | 6356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023129763 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.0221     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0271      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.12e+04    |\n",
      "|    total_cost           | 1.02e+04    |\n",
      "|    total_reward         | 3.12e+04    |\n",
      "|    total_reward_pct     | 62.4        |\n",
      "|    total_trades         | 6290        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021222284 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.021       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.41e+04    |\n",
      "|    total_cost           | 1.15e+04    |\n",
      "|    total_reward         | 3.41e+04    |\n",
      "|    total_reward_pct     | 68.2        |\n",
      "|    total_trades         | 6302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016831107 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0216      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 81543.81\n",
      "total_reward: 31543.81\n",
      "total_cost: 8350.91\n",
      "total_trades: 6110\n",
      "Sharpe: 0.678\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.08e+04    |\n",
      "|    total_cost           | 9.04e+03    |\n",
      "|    total_reward         | 4.08e+04    |\n",
      "|    total_reward_pct     | 81.5        |\n",
      "|    total_trades         | 6320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 422         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018098578 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.77e+04   |\n",
      "|    total_cost           | 7.54e+03   |\n",
      "|    total_reward         | 4.77e+04   |\n",
      "|    total_reward_pct     | 95.5       |\n",
      "|    total_trades         | 6239       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 422        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01509113 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.291     |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0268    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n",
      "day: 1129, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95411.12\n",
      "total_reward: 45411.12\n",
      "total_cost: 7816.07\n",
      "total_trades: 6258\n",
      "Sharpe: 0.938\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.54e+04    |\n",
      "|    total_cost           | 7.82e+03    |\n",
      "|    total_reward         | 4.54e+04    |\n",
      "|    total_reward_pct     | 90.8        |\n",
      "|    total_trades         | 6258        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 420         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021985011 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0199      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 1.02e+04    |\n",
      "|    total_reward         | 5.16e+04    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 6427        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018480964 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0284      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 8.66e+03    |\n",
      "|    total_reward         | 5.09e+04    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 6356        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020796914 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 101267.23\n",
      "total_reward: 51267.23\n",
      "total_cost: 6386.63\n",
      "total_trades: 6227\n",
      "Sharpe: 0.979\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 6.39e+03    |\n",
      "|    total_reward         | 5.13e+04    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 6227        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014934124 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0369      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.15e+05   |\n",
      "|    total_cost           | 5.14e+03   |\n",
      "|    total_reward         | 6.5e+04    |\n",
      "|    total_reward_pct     | 130        |\n",
      "|    total_trades         | 6160       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 415        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02241234 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.481      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.31      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0303     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 6.5e+03     |\n",
      "|    total_reward         | 6.13e+04    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 6089        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 414         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018463844 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0404      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 125938.60\n",
      "total_reward: 75938.60\n",
      "total_cost: 7486.37\n",
      "total_trades: 6269\n",
      "Sharpe: 1.037\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 7.3e+03     |\n",
      "|    total_reward         | 6.12e+04    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 6311        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 414         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029183924 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0554      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+05    |\n",
      "|    total_cost           | 4.99e+03    |\n",
      "|    total_reward         | 5.58e+04    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 5951        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016432166 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.237      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0626      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+05    |\n",
      "|    total_cost           | 7.39e+03    |\n",
      "|    total_reward         | 5.75e+04    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 6271        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021070559 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.07        |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 120\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 121493.93\n",
      "total_reward: 71493.93\n",
      "total_cost: 6773.66\n",
      "total_trades: 6312\n",
      "Sharpe: 1.015\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+05    |\n",
      "|    total_cost           | 7.62e+03    |\n",
      "|    total_reward         | 6.23e+04    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 6384        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023333766 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 6.29e+03    |\n",
      "|    total_reward         | 6.11e+04    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 6368        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017825648 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0535      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 125\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 105830.99\n",
      "total_reward: 55830.99\n",
      "total_cost: 6058.74\n",
      "total_trades: 6335\n",
      "Sharpe: 0.861\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+05    |\n",
      "|    total_cost           | 6.06e+03    |\n",
      "|    total_reward         | 5.58e+04    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 6335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020735856 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0632      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+05    |\n",
      "|    total_cost           | 5.65e+03    |\n",
      "|    total_reward         | 6.42e+04    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 6281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018462751 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.247      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0628      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.24e+05   |\n",
      "|    total_cost           | 6.54e+03   |\n",
      "|    total_reward         | 7.43e+04   |\n",
      "|    total_reward_pct     | 149        |\n",
      "|    total_trades         | 6354       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 412        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 109        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01818515 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.517      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.294     |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0578     |\n",
      "----------------------------------------\n",
      "day: 1129, episode: 130\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 139786.96\n",
      "total_reward: 89786.96\n",
      "total_cost: 7659.90\n",
      "total_trades: 6535\n",
      "Sharpe: 1.217\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.4e+05     |\n",
      "|    total_cost           | 7.66e+03    |\n",
      "|    total_reward         | 8.98e+04    |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 6535        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022735208 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.265      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0654      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 5.34e+03    |\n",
      "|    total_reward         | 6.8e+04     |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 6295        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030437084 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0562      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.88e+04   |\n",
      "|    total_cost           | 7.22e+03   |\n",
      "|    total_reward         | 4.88e+04   |\n",
      "|    total_reward_pct     | 97.6       |\n",
      "|    total_trades         | 6513       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 411        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03054212 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.501      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.272     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0582     |\n",
      "----------------------------------------\n",
      "day: 1129, episode: 135\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113801.91\n",
      "total_reward: 63801.91\n",
      "total_cost: 7325.65\n",
      "total_trades: 6428\n",
      "Sharpe: 0.995\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.18e+05     |\n",
      "|    total_cost           | 6e+03        |\n",
      "|    total_reward         | 6.75e+04     |\n",
      "|    total_reward_pct     | 135          |\n",
      "|    total_trades         | 6481         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 411          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151760215 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.8        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.298       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0395       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+05    |\n",
      "|    total_cost           | 7.22e+03    |\n",
      "|    total_reward         | 6.69e+04    |\n",
      "|    total_reward_pct     | 134         |\n",
      "|    total_trades         | 6452        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017968273 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.252      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0438      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 6.95e+03    |\n",
      "|    total_reward         | 5.19e+04    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 6402        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016321085 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0315      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 140\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114551.52\n",
      "total_reward: 64551.52\n",
      "total_cost: 6599.29\n",
      "total_trades: 6502\n",
      "Sharpe: 1.107\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.07e+05   |\n",
      "|    total_cost           | 7.17e+03   |\n",
      "|    total_reward         | 5.74e+04   |\n",
      "|    total_reward_pct     | 115        |\n",
      "|    total_trades         | 6406       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 410        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02024651 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.267     |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0355     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.23e+05    |\n",
      "|    total_cost           | 7.5e+03     |\n",
      "|    total_reward         | 7.25e+04    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 6628        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027762167 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0341      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 145\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 107466.24\n",
      "total_reward: 57466.24\n",
      "total_cost: 8390.34\n",
      "total_trades: 6615\n",
      "Sharpe: 1.042\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+05    |\n",
      "|    total_cost           | 8.39e+03    |\n",
      "|    total_reward         | 5.75e+04    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 6615        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025890518 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.042       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.59e+04   |\n",
      "|    total_cost           | 6.43e+03   |\n",
      "|    total_reward         | 4.59e+04   |\n",
      "|    total_reward_pct     | 91.8       |\n",
      "|    total_trades         | 6485       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 410        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03515582 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.275     |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0315     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+05    |\n",
      "|    total_cost           | 7.25e+03    |\n",
      "|    total_reward         | 7.54e+04    |\n",
      "|    total_reward_pct     | 151         |\n",
      "|    total_trades         | 6652        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030864237 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0293      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 150\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 117513.28\n",
      "total_reward: 67513.28\n",
      "total_cost: 7956.37\n",
      "total_trades: 6731\n",
      "Sharpe: 1.194\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 7.96e+03    |\n",
      "|    total_reward         | 6.75e+04    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 6731        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027064208 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0324      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.27e+05    |\n",
      "|    total_cost           | 6.64e+03    |\n",
      "|    total_reward         | 7.67e+04    |\n",
      "|    total_reward_pct     | 153         |\n",
      "|    total_trades         | 6578        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025093826 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 7.36e+03    |\n",
      "|    total_reward         | 6.29e+04    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 6665        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024996517 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0431      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 155\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113918.96\n",
      "total_reward: 63918.96\n",
      "total_cost: 5772.12\n",
      "total_trades: 6613\n",
      "Sharpe: 1.043\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+05    |\n",
      "|    total_cost           | 1.06e+04    |\n",
      "|    total_reward         | 7.24e+04    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 6749        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029910896 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0384      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+05    |\n",
      "|    total_cost           | 8.03e+03    |\n",
      "|    total_reward         | 6.73e+04    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 6797        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019455157 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0415      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+05    |\n",
      "|    total_cost           | 6.01e+03    |\n",
      "|    total_reward         | 6.67e+04    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 6711        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025688656 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0349      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 160\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 86407.22\n",
      "total_reward: 36407.22\n",
      "total_cost: 4976.24\n",
      "total_trades: 6487\n",
      "Sharpe: 0.751\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.21e+05   |\n",
      "|    total_cost           | 6.96e+03   |\n",
      "|    total_reward         | 7.07e+04   |\n",
      "|    total_reward_pct     | 141        |\n",
      "|    total_trades         | 6852       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 409        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02240587 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.293     |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0354     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.1e+05     |\n",
      "|    total_cost           | 6.93e+03    |\n",
      "|    total_reward         | 6.04e+04    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 6637        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022906926 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0334      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 165\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 124796.20\n",
      "total_reward: 74796.20\n",
      "total_cost: 6441.90\n",
      "total_trades: 6670\n",
      "Sharpe: 1.264\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+05    |\n",
      "|    total_cost           | 6.44e+03    |\n",
      "|    total_reward         | 7.48e+04    |\n",
      "|    total_reward_pct     | 150         |\n",
      "|    total_trades         | 6670        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016256314 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0358      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.1e+05    |\n",
      "|    total_cost           | 7.55e+03   |\n",
      "|    total_reward         | 6.01e+04   |\n",
      "|    total_reward_pct     | 120        |\n",
      "|    total_trades         | 6799       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 409        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03682569 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.5      |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.294     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0402     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+05    |\n",
      "|    total_cost           | 5.85e+03    |\n",
      "|    total_reward         | 7.06e+04    |\n",
      "|    total_reward_pct     | 141         |\n",
      "|    total_trades         | 6952        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034945913 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0422      |\n",
      "-----------------------------------------\n",
      "day: 1129, episode: 170\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 122668.08\n",
      "total_reward: 72668.08\n",
      "total_cost: 5827.65\n",
      "total_trades: 6975\n",
      "Sharpe: 1.246\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.23e+05   |\n",
      "|    total_cost           | 5.83e+03   |\n",
      "|    total_reward         | 7.27e+04   |\n",
      "|    total_reward_pct     | 145        |\n",
      "|    total_trades         | 6975       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 409        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03378316 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.6      |\n",
      "|    explained_variance   | 0.626      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.292     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.0362     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.15e+05     |\n",
      "|    total_cost           | 5.96e+03     |\n",
      "|    total_reward         | 6.53e+04     |\n",
      "|    total_reward_pct     | 131          |\n",
      "|    total_trades         | 6824         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 229          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155274365 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -28.7        |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.308       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0195      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.0347       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| environment/            |          |\n",
      "|    portfolio_value      | 1.22e+05 |\n",
      "|    total_cost           | 7.26e+03 |\n",
      "|    total_reward         | 7.23e+04 |\n",
      "|    total_reward_pct     | 145      |\n",
      "|    total_trades         | 7100     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 409      |\n",
      "|    iterations           | 47       |\n",
      "|    time_elapsed         | 234      |\n",
      "|    total_timesteps      | 96256    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.04073  |\n",
      "|    clip_fraction        | 0.247    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.8    |\n",
      "|    explained_variance   | 0.622    |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | -0.287   |\n",
      "|    n_updates            | 460      |\n",
      "|    policy_gradient_loss | -0.00847 |\n",
      "|    std                  | 1.1      |\n",
      "|    value_loss           | 0.0348   |\n",
      "--------------------------------------\n",
      "day: 1129, episode: 175\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 116571.46\n",
      "total_reward: 66571.46\n",
      "total_cost: 5686.54\n",
      "total_trades: 7061\n",
      "Sharpe: 1.049\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.17e+05   |\n",
      "|    total_cost           | 5.69e+03   |\n",
      "|    total_reward         | 6.66e+04   |\n",
      "|    total_reward_pct     | 133        |\n",
      "|    total_trades         | 7061       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 409        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02506026 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.8      |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.302     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.0504     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+05    |\n",
      "|    total_cost           | 5.57e+03    |\n",
      "|    total_reward         | 7.1e+04     |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 6943        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030108105 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.236      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0518      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-07-05 to  2019-10-02\n",
      "PPO Sharpe Ratio:  -0.043008740059878356\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
      "day: 1129, episode: 180\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 102002.12\n",
      "total_reward: 52002.12\n",
      "total_cost: 145.21\n",
      "total_trades: 4157\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.88e+04 |\n",
      "|    total_cost       | 136      |\n",
      "|    total_reward     | 1.88e+04 |\n",
      "|    total_reward_pct | 37.5     |\n",
      "|    total_trades     | 4192     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 146      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total timesteps  | 4520     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 153      |\n",
      "|    critic_loss      | 816      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3390     |\n",
      "----------------------------------\n",
      "day: 1129, episode: 185\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 45923.16\n",
      "total_reward: -4076.84\n",
      "total_cost: 96.84\n",
      "total_trades: 6352\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.66e+04  |\n",
      "|    total_cost       | 94.8      |\n",
      "|    total_reward     | -3.44e+03 |\n",
      "|    total_reward_pct | -6.89     |\n",
      "|    total_trades     | 6641      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 68        |\n",
      "|    total timesteps  | 9040      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 116       |\n",
      "|    critic_loss      | 140       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7910      |\n",
      "-----------------------------------\n",
      "day: 1129, episode: 190\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 51771.40\n",
      "total_reward: 1771.40\n",
      "total_cost: 97.40\n",
      "total_trades: 3833\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.18e+04 |\n",
      "|    total_cost       | 97.4     |\n",
      "|    total_reward     | 1.77e+03 |\n",
      "|    total_reward_pct | 3.54     |\n",
      "|    total_trades     | 3833     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 126      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total timesteps  | 13560    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 91.5     |\n",
      "|    critic_loss      | 36.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 12430    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.05e+04 |\n",
      "|    total_cost       | 110      |\n",
      "|    total_reward     | 3.05e+04 |\n",
      "|    total_reward_pct | 61       |\n",
      "|    total_trades     | 4548     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total timesteps  | 18080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 71.6     |\n",
      "|    critic_loss      | 17       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16950    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 195\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 123640.04\n",
      "total_reward: 73640.04\n",
      "total_cost: 155.00\n",
      "total_trades: 4737\n",
      "Sharpe: 1.062\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.11e+05 |\n",
      "|    total_cost       | 158      |\n",
      "|    total_reward     | 6.12e+04 |\n",
      "|    total_reward_pct | 122      |\n",
      "|    total_trades     | 6350     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total timesteps  | 22600    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 55.9     |\n",
      "|    critic_loss      | 9.18     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 21470    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 200\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 52993.81\n",
      "total_reward: 2993.81\n",
      "total_cost: 98.16\n",
      "total_trades: 5782\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.55e+04 |\n",
      "|    total_cost       | 139      |\n",
      "|    total_reward     | 3.55e+04 |\n",
      "|    total_reward_pct | 71       |\n",
      "|    total_trades     | 6091     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total timesteps  | 27120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 43.6     |\n",
      "|    critic_loss      | 5.11     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25990    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 205\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 65880.48\n",
      "total_reward: 15880.48\n",
      "total_cost: 145.68\n",
      "total_trades: 5333\n",
      "Sharpe: 0.410\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.15e+04 |\n",
      "|    total_cost       | 127      |\n",
      "|    total_reward     | 2.15e+04 |\n",
      "|    total_reward_pct | 43.1     |\n",
      "|    total_trades     | 4746     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total timesteps  | 31640    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 33.7     |\n",
      "|    critic_loss      | 3.5      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 30510    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 210\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 66203.58\n",
      "total_reward: 16203.58\n",
      "total_cost: 145.27\n",
      "total_trades: 5223\n",
      "Sharpe: 0.442\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.62e+04 |\n",
      "|    total_cost       | 145      |\n",
      "|    total_reward     | 1.62e+04 |\n",
      "|    total_reward_pct | 32.4     |\n",
      "|    total_trades     | 5223     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total timesteps  | 36160    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 26       |\n",
      "|    critic_loss      | 2.06     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35030    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.99e+04 |\n",
      "|    total_cost       | 151      |\n",
      "|    total_reward     | 9.88e+03 |\n",
      "|    total_reward_pct | 19.8     |\n",
      "|    total_trades     | 4983     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total timesteps  | 40680    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 20.1     |\n",
      "|    critic_loss      | 2.33     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39550    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 215\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 54064.75\n",
      "total_reward: 4064.75\n",
      "total_cost: 138.43\n",
      "total_trades: 3613\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.07e+05 |\n",
      "|    total_cost       | 295      |\n",
      "|    total_reward     | 5.69e+04 |\n",
      "|    total_reward_pct | 114      |\n",
      "|    total_trades     | 5784     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 377      |\n",
      "|    total timesteps  | 45200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 15.4     |\n",
      "|    critic_loss      | 2.02     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44070    |\n",
      "----------------------------------\n",
      "day: 1129, episode: 220\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 67276.26\n",
      "total_reward: 17276.26\n",
      "total_cost: 140.66\n",
      "total_trades: 4848\n",
      "Sharpe: 0.425\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.56e+04 |\n",
      "|    total_cost       | 243      |\n",
      "|    total_reward     | 4.56e+04 |\n",
      "|    total_reward_pct | 91.3     |\n",
      "|    total_trades     | 5831     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 416      |\n",
      "|    total timesteps  | 49720    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 11.8     |\n",
      "|    critic_loss      | 1.65     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 48590    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-07-05 to  2019-10-02\n",
      "======Best Model Retraining from:  2015-01-01 to  2019-10-02\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_252_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.1e+05  |\n",
      "|    total_cost       | 107      |\n",
      "|    total_reward     | 6.01e+04 |\n",
      "|    total_reward_pct | 120      |\n",
      "|    total_trades     | 5694     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total timesteps  | 4772     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 150      |\n",
      "|    critic_loss      | 330      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3579     |\n",
      "----------------------------------\n",
      "day: 1192, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 64763.28\n",
      "total_reward: 14763.28\n",
      "total_cost: 96.51\n",
      "total_trades: 5671\n",
      "Sharpe: 0.368\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.21e+05 |\n",
      "|    total_cost       | 102      |\n",
      "|    total_reward     | 7.15e+04 |\n",
      "|    total_reward_pct | 143      |\n",
      "|    total_trades     | 5261     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total timesteps  | 9544     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 114      |\n",
      "|    critic_loss      | 57.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8351     |\n",
      "----------------------------------\n",
      "day: 1192, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 63711.02\n",
      "total_reward: 13711.02\n",
      "total_cost: 96.11\n",
      "total_trades: 7407\n",
      "Sharpe: 0.349\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.62e+04 |\n",
      "|    total_cost       | 100      |\n",
      "|    total_reward     | 1.62e+04 |\n",
      "|    total_reward_pct | 32.3     |\n",
      "|    total_trades     | 5114     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total timesteps  | 14316    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 87.8     |\n",
      "|    critic_loss      | 16.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13123    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50429.21\n",
      "total_reward: 429.21\n",
      "total_cost: 101.70\n",
      "total_trades: 7800\n",
      "Sharpe: 0.112\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.9e+04  |\n",
      "|    total_cost       | 96.2     |\n",
      "|    total_reward     | 8.95e+03 |\n",
      "|    total_reward_pct | 17.9     |\n",
      "|    total_trades     | 7017     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total timesteps  | 19088    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 68       |\n",
      "|    critic_loss      | 9.4      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17895    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 80731.84\n",
      "total_reward: 30731.84\n",
      "total_cost: 108.47\n",
      "total_trades: 4952\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.07e+04 |\n",
      "|    total_cost       | 108      |\n",
      "|    total_reward     | 3.07e+04 |\n",
      "|    total_reward_pct | 61.5     |\n",
      "|    total_trades     | 4952     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total timesteps  | 23860    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 52.4     |\n",
      "|    critic_loss      | 5.85     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 22667    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 100      |\n",
      "|    total_reward     | 5e+04    |\n",
      "|    total_reward_pct | 99.9     |\n",
      "|    total_trades     | 3573     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total timesteps  | 28632    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 40.2     |\n",
      "|    critic_loss      | 3.71     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27439    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 67852.68\n",
      "total_reward: 17852.68\n",
      "total_cost: 135.78\n",
      "total_trades: 6317\n",
      "Sharpe: 0.417\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.04e+05 |\n",
      "|    total_cost       | 190      |\n",
      "|    total_reward     | 5.36e+04 |\n",
      "|    total_reward_pct | 107      |\n",
      "|    total_trades     | 6310     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total timesteps  | 33404    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 30.8     |\n",
      "|    critic_loss      | 2.49     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32211    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 75123.65\n",
      "total_reward: 25123.65\n",
      "total_cost: 121.46\n",
      "total_trades: 5170\n",
      "Sharpe: 0.500\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.45e+04  |\n",
      "|    total_cost       | 100       |\n",
      "|    total_reward     | -5.48e+03 |\n",
      "|    total_reward_pct | -11       |\n",
      "|    total_trades     | 3393      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 322       |\n",
      "|    total timesteps  | 38176     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 23.5      |\n",
      "|    critic_loss      | 2.78      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 36983     |\n",
      "-----------------------------------\n",
      "day: 1192, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 88740.06\n",
      "total_reward: 38740.06\n",
      "total_cost: 99.62\n",
      "total_trades: 6908\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.69e+04  |\n",
      "|    total_cost       | 111       |\n",
      "|    total_reward     | -3.05e+03 |\n",
      "|    total_reward_pct | -6.11     |\n",
      "|    total_trades     | 7296      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 363       |\n",
      "|    total timesteps  | 42948     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 17.9      |\n",
      "|    critic_loss      | 1.7       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 41755     |\n",
      "-----------------------------------\n",
      "day: 1192, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70116.84\n",
      "total_reward: 20116.84\n",
      "total_cost: 107.19\n",
      "total_trades: 6321\n",
      "Sharpe: 0.452\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.01e+04 |\n",
      "|    total_cost       | 107      |\n",
      "|    total_reward     | 2.01e+04 |\n",
      "|    total_reward_pct | 40.2     |\n",
      "|    total_trades     | 6321     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 404      |\n",
      "|    total timesteps  | 47720    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 13.6     |\n",
      "|    critic_loss      | 1.08     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46527    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-10-02 to  2020-01-03\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  529.7283042530553\n",
      "======Model training from:  2015-01-01 to  2019-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 350      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.899    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -3.68    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -3.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0501  |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.000791 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.28e+04 |\n",
      "|    total_cost         | 2.07e+03 |\n",
      "|    total_reward       | 4.28e+04 |\n",
      "|    total_reward_pct   | 85.6     |\n",
      "|    total_trades       | 6157     |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.0358   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0056   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 349      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.924   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 3.09     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 1.75e+03 |\n",
      "|    total_reward       | 6.6e+04  |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 6584     |\n",
      "| time/                 |          |\n",
      "|    fps                | 348      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.403   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00214  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 348      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0.269    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00217  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -1.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -4.02    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0257   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.08e+04 |\n",
      "|    total_cost         | 1.14e+03 |\n",
      "|    total_reward       | 3.08e+04 |\n",
      "|    total_reward_pct   | 61.6     |\n",
      "|    total_trades       | 6287     |\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -3.14    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.547   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0056   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.25e+04  |\n",
      "|    total_cost         | 1.56e+03  |\n",
      "|    total_reward       | 4.25e+04  |\n",
      "|    total_reward_pct   | 84.9      |\n",
      "|    total_trades       | 6457      |\n",
      "| time/                 |           |\n",
      "|    fps                | 347       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 1.89      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.0099    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -3.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.375    |\n",
      "------------------------------------\n",
      "day: 1192, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 91452.50\n",
      "total_reward: 41452.50\n",
      "total_cost: 1407.00\n",
      "total_trades: 6797\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.15e+04 |\n",
      "|    total_cost         | 1.41e+03 |\n",
      "|    total_reward       | 4.15e+04 |\n",
      "|    total_reward_pct   | 82.9     |\n",
      "|    total_trades       | 6797     |\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.191    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -1.94    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.012    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 347       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -3.67     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0304    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -1.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 3.99     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0468   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.52e+04 |\n",
      "|    total_cost         | 912      |\n",
      "|    total_reward       | 1.52e+04 |\n",
      "|    total_reward_pct   | 30.3     |\n",
      "|    total_trades       | 6355     |\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0.208    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 1.36     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.00329 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.458   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0148   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.78e+04 |\n",
      "|    total_cost         | 1.07e+03 |\n",
      "|    total_reward       | 3.78e+04 |\n",
      "|    total_reward_pct   | 75.7     |\n",
      "|    total_trades       | 6566     |\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.319   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 2.48     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0144   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -3.43    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0141   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0.0455   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 3.36     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0168   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.17e+04 |\n",
      "|    total_cost         | 1.23e+03 |\n",
      "|    total_reward       | 3.17e+04 |\n",
      "|    total_reward_pct   | 63.3     |\n",
      "|    total_trades       | 6561     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.0825   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -1.8     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.00774  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.245   |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00817  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.69e+04 |\n",
      "|    total_cost         | 1.18e+03 |\n",
      "|    total_reward       | 3.69e+04 |\n",
      "|    total_reward_pct   | 73.8     |\n",
      "|    total_trades       | 6206     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | -0.819   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -8.95    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0.5      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 7.91     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0645   |\n",
      "------------------------------------\n",
      "day: 1192, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 61179.05\n",
      "total_reward: 11179.05\n",
      "total_cost: 1011.88\n",
      "total_trades: 6454\n",
      "Sharpe: 0.304\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.12e+04 |\n",
      "|    total_cost         | 1.01e+03 |\n",
      "|    total_reward       | 1.12e+04 |\n",
      "|    total_reward_pct   | 22.4     |\n",
      "|    total_trades       | 6454     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | -11.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -5.28    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.0359   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0.0255   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.95     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.0133   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 2.19     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00976  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.44e+04 |\n",
      "|    total_cost         | 1.38e+03 |\n",
      "|    total_reward       | 2.44e+04 |\n",
      "|    total_reward_pct   | 48.7     |\n",
      "|    total_trades       | 6710     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0.682    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 3.75     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0178   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -0.393   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.219    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00276  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.6e+04  |\n",
      "|    total_cost         | 3.18e+03 |\n",
      "|    total_reward       | 3.6e+04  |\n",
      "|    total_reward_pct   | 72       |\n",
      "|    total_trades       | 7348     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -0.0147  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -1.63    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00518  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 346       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 2.21      |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.00571   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.00305  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.31e+04 |\n",
      "|    total_cost         | 2.83e+03 |\n",
      "|    total_reward       | 1.31e+04 |\n",
      "|    total_reward_pct   | 26.2     |\n",
      "|    total_trades       | 7501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | -0.248   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 3.71     |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -0.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.705    |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.00239  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.32e+04 |\n",
      "|    total_cost         | 3.36e+03 |\n",
      "|    total_reward       | 4.32e+04 |\n",
      "|    total_reward_pct   | 86.5     |\n",
      "|    total_trades       | 7163     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | -11.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.00609  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | -0.684   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -1.83    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "day: 1192, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70290.08\n",
      "total_reward: 20290.08\n",
      "total_cost: 3389.34\n",
      "total_trades: 7126\n",
      "Sharpe: 0.452\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.03e+04 |\n",
      "|    total_cost         | 3.39e+03 |\n",
      "|    total_reward       | 2.03e+04 |\n",
      "|    total_reward_pct   | 40.6     |\n",
      "|    total_trades       | 7126     |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | -1.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.174    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.00441  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -0.504   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -4.55    |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -3.31    |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0131   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 5.66e+03 |\n",
      "|    total_reward       | 5.16e+04 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 7096     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.133   |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.0018   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.1    |\n",
      "|    explained_variance | -0.147   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -3.01    |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.74e+04 |\n",
      "|    total_cost         | 3.79e+03 |\n",
      "|    total_reward       | 1.74e+04 |\n",
      "|    total_reward_pct   | 34.8     |\n",
      "|    total_trades       | 7129     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -0.294   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00115  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | -1.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -2.7     |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.6e+04  |\n",
      "|    total_cost         | 3.65e+03 |\n",
      "|    total_reward       | 3.6e+04  |\n",
      "|    total_reward_pct   | 72       |\n",
      "|    total_trades       | 7421     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | -0.252   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -3.94    |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | -0.0385  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 3.24     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.0394   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0.000227 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -2.33    |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.00966  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.12e+04 |\n",
      "|    total_cost         | 4.56e+03 |\n",
      "|    total_reward       | 4.12e+04 |\n",
      "|    total_reward_pct   | 82.4     |\n",
      "|    total_trades       | 7660     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | -0.0786  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.81     |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.00722  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | 0.0689   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 7.69     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0985   |\n",
      "------------------------------------\n",
      "day: 1192, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 102508.90\n",
      "total_reward: 52508.90\n",
      "total_cost: 2378.94\n",
      "total_trades: 7041\n",
      "Sharpe: 0.818\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 2.38e+03 |\n",
      "|    total_reward       | 5.25e+04 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 7041     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | -0.362   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.0269  |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.000925 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | 0.0247   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.129   |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00617  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -5.89    |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0246   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.54e+04  |\n",
      "|    total_cost         | 1.29e+03  |\n",
      "|    total_reward       | 2.54e+04  |\n",
      "|    total_reward_pct   | 50.8      |\n",
      "|    total_trades       | 7728      |\n",
      "| time/                 |           |\n",
      "|    fps                | 346       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -3.28     |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 0.0139    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | -0.0799  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.486    |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.00213  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.13e+04 |\n",
      "|    total_cost         | 909      |\n",
      "|    total_reward       | 4.13e+04 |\n",
      "|    total_reward_pct   | 82.6     |\n",
      "|    total_trades       | 7098     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 4.1      |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.019    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -0.797   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -2.35    |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.9e+04  |\n",
      "|    total_cost         | 2.26e+03 |\n",
      "|    total_reward       | 2.9e+04  |\n",
      "|    total_reward_pct   | 58       |\n",
      "|    total_trades       | 7758     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | -0.0103  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -2.87    |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.00629  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | 0.671    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -3.43    |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | -0.0436  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.005    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.34e+04 |\n",
      "|    total_cost         | 2.69e+03 |\n",
      "|    total_reward       | 3.36e+03 |\n",
      "|    total_reward_pct   | 6.71     |\n",
      "|    total_trades       | 8215     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | -0.0158  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 7.42     |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.0458   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 2.25     |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "day: 1192, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 87428.75\n",
      "total_reward: 37428.75\n",
      "total_cost: 1781.19\n",
      "total_trades: 8599\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.74e+04 |\n",
      "|    total_cost         | 1.78e+03 |\n",
      "|    total_reward       | 3.74e+04 |\n",
      "|    total_reward_pct   | 74.9     |\n",
      "|    total_trades       | 8599     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | 0.216    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.00295  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 346       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 2.59      |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 0.00572   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.00424  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.51e+04 |\n",
      "|    total_cost         | 1.42e+03 |\n",
      "|    total_reward       | 1.51e+04 |\n",
      "|    total_reward_pct   | 30.1     |\n",
      "|    total_trades       | 9576     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | -0.456   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -3.41    |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -0.308   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -3.4     |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.0206   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.96e+04 |\n",
      "|    total_cost         | 1.2e+03  |\n",
      "|    total_reward       | 1.96e+04 |\n",
      "|    total_reward_pct   | 39.2     |\n",
      "|    total_trades       | 9801     |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 1.5      |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.00649  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | 0.437    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 0.257    |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.000664 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.79e+04 |\n",
      "|    total_cost         | 1.65e+03 |\n",
      "|    total_reward       | 3.79e+04 |\n",
      "|    total_reward_pct   | 75.8     |\n",
      "|    total_trades       | 10375    |\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -3.58    |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 346       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 1.95      |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 0.00351   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | -0.083   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -3.69    |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.0113   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.64e+04 |\n",
      "|    total_cost         | 1.18e+03 |\n",
      "|    total_reward       | 1.64e+04 |\n",
      "|    total_reward_pct   | 32.8     |\n",
      "|    total_trades       | 10055    |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 17.6     |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.213    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 1.45     |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n",
      "day: 1192, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95678.81\n",
      "total_reward: 45678.81\n",
      "total_cost: 1330.26\n",
      "total_trades: 9830\n",
      "Sharpe: 0.773\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.57e+04 |\n",
      "|    total_cost         | 1.33e+03 |\n",
      "|    total_reward       | 4.57e+04 |\n",
      "|    total_reward_pct   | 91.4     |\n",
      "|    total_trades       | 9830     |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | -0.181   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 8.87     |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.0538   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -2.89    |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.00676  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.83e+04 |\n",
      "|    total_cost         | 1.17e+03 |\n",
      "|    total_reward       | 1.83e+04 |\n",
      "|    total_reward_pct   | 36.6     |\n",
      "|    total_trades       | 9749     |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | -0.0434  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 10.2     |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.0718   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | -0.108   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -3.01    |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 0.00949  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.00442  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.67e+04 |\n",
      "|    total_cost         | 1.32e+03 |\n",
      "|    total_reward       | 2.67e+04 |\n",
      "|    total_reward_pct   | 53.5     |\n",
      "|    total_trades       | 9785     |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | 0.427    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 3.99     |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -4.98    |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 0.0572   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 1.74e+03 |\n",
      "|    total_reward       | 5.46e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 9771     |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -3.67    |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.00993  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 2.18     |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.00615  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 2.73     |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 0.00537  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.73e+04 |\n",
      "|    total_cost         | 1.31e+03 |\n",
      "|    total_reward       | 3.73e+04 |\n",
      "|    total_reward_pct   | 74.6     |\n",
      "|    total_trades       | 10138    |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -2.51    |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.00999  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.852    |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 0.000868 |\n",
      "------------------------------------\n",
      "day: 1192, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 112457.07\n",
      "total_reward: 62457.07\n",
      "total_cost: 1670.94\n",
      "total_trades: 10437\n",
      "Sharpe: 0.883\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 1.67e+03 |\n",
      "|    total_reward       | 6.25e+04 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 10437    |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.0807   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 4.7      |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0.000133 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 3.08     |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.00717  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.92e+04 |\n",
      "|    total_cost         | 1.27e+03 |\n",
      "|    total_reward       | 9.22e+03 |\n",
      "|    total_reward_pct   | 18.4     |\n",
      "|    total_trades       | 10285    |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | 0.0086   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -7.16    |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 0.0461   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0.0153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -23.8    |\n",
      "|    std                | 2.08     |\n",
      "|    value_loss         | 0.338    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | 0.00212  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 3.8      |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 1.76e+03 |\n",
      "|    total_reward       | 6.09e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 10440    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | -0.21    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 9.19     |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.0491   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | -1.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 8.8      |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.0485   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.21e+05  |\n",
      "|    total_cost         | 1.73e+03  |\n",
      "|    total_reward       | 7.12e+04  |\n",
      "|    total_reward_pct   | 142       |\n",
      "|    total_trades       | 10295     |\n",
      "| time/                 |           |\n",
      "|    fps                | 344       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -2.53     |\n",
      "|    std                | 2.14      |\n",
      "|    value_loss         | 0.0108    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 344       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -4.08     |\n",
      "|    std                | 2.16      |\n",
      "|    value_loss         | 0.0129    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    std                | 2.18     |\n",
      "|    value_loss         | 0.00185  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.02e+04 |\n",
      "|    total_cost         | 1.67e+03 |\n",
      "|    total_reward       | 4.02e+04 |\n",
      "|    total_reward_pct   | 80.4     |\n",
      "|    total_trades       | 10587    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0.114    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -7.23    |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.0392   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | -0.204   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -9.75    |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 0.0875   |\n",
      "------------------------------------\n",
      "day: 1192, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114114.05\n",
      "total_reward: 64114.05\n",
      "total_cost: 1608.99\n",
      "total_trades: 10441\n",
      "Sharpe: 0.865\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 1.61e+03 |\n",
      "|    total_reward       | 6.41e+04 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 10441    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0.231    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -8.23    |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.045    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | 0.0131   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -4.72    |\n",
      "|    std                | 2.24     |\n",
      "|    value_loss         | 0.0195   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 1.35e+03 |\n",
      "|    total_reward       | 6.26e+04 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 10229    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0.0148   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -3.64    |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.00981  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.655   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 16.2     |\n",
      "|    std                | 2.28     |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0654   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.853   |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 0.000954 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.77e+04 |\n",
      "|    total_cost         | 925      |\n",
      "|    total_reward       | 2.77e+04 |\n",
      "|    total_reward_pct   | 55.4     |\n",
      "|    total_trades       | 9983     |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0617  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 2.38     |\n",
      "|    std                | 2.32     |\n",
      "|    value_loss         | 0.00529  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 0.0609   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+05 |\n",
      "|    total_cost         | 1.55e+03 |\n",
      "|    total_reward       | 7.12e+04 |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 10044    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 9.58     |\n",
      "|    std                | 2.35     |\n",
      "|    value_loss         | 0.0578   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -9.78    |\n",
      "|    std                | 2.37     |\n",
      "|    value_loss         | 0.0612   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 1.36e+03 |\n",
      "|    total_reward       | 6.76e+04 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 10060    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0.427    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -10      |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 2.4      |\n",
      "|    value_loss         | 0.00515  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 8.59     |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.039    |\n",
      "------------------------------------\n",
      "day: 1192, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103074.25\n",
      "total_reward: 53074.25\n",
      "total_cost: 1696.26\n",
      "total_trades: 10301\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.7e+03  |\n",
      "|    total_reward       | 5.31e+04 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 10301    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -1.63    |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 0.00365  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 344       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -8.52     |\n",
      "|    std                | 2.46      |\n",
      "|    value_loss         | 0.0522    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.42e+04 |\n",
      "|    total_cost         | 1.73e+03 |\n",
      "|    total_reward       | 4.42e+04 |\n",
      "|    total_reward_pct   | 88.4     |\n",
      "|    total_trades       | 10504    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -4.9     |\n",
      "|    std                | 2.48     |\n",
      "|    value_loss         | 0.0161   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.228    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | -0.283   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 4.53     |\n",
      "|    std                | 2.52     |\n",
      "|    value_loss         | 0.0129   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+05 |\n",
      "|    total_cost         | 2.17e+03 |\n",
      "|    total_reward       | 7.12e+04 |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 10890    |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.0663   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -5.52    |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.027    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.23e+05 |\n",
      "|    total_cost         | 1.79e+03 |\n",
      "|    total_reward       | 7.26e+04 |\n",
      "|    total_reward_pct   | 145      |\n",
      "|    total_trades       | 10934    |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | -0.0585  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -1.68    |\n",
      "|    std                | 2.57     |\n",
      "|    value_loss         | 0.00414  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -7.27    |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 0.0267   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.6e+04  |\n",
      "|    total_cost         | 1.45e+03 |\n",
      "|    total_reward       | 4.6e+04  |\n",
      "|    total_reward_pct   | 91.9     |\n",
      "|    total_trades       | 10467    |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0.0102   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 0.546    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.00377  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0.0935   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -5.55    |\n",
      "|    std                | 2.64     |\n",
      "|    value_loss         | 0.0168   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | -0.388   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -3.2     |\n",
      "|    std                | 2.66     |\n",
      "|    value_loss         | 0.00928  |\n",
      "------------------------------------\n",
      "day: 1192, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 104344.54\n",
      "total_reward: 54344.54\n",
      "total_cost: 1609.50\n",
      "total_trades: 10300\n",
      "Sharpe: 0.818\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 1.61e+03 |\n",
      "|    total_reward       | 5.43e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 10300    |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0.0921   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.00146  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0.0154   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -8.68    |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 0.0583   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.81e+04 |\n",
      "|    total_cost         | 1.92e+03 |\n",
      "|    total_reward       | 4.81e+04 |\n",
      "|    total_reward_pct   | 96.1     |\n",
      "|    total_trades       | 10596    |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | -0.00702 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.919    |\n",
      "|    std                | 2.73     |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -1.98     |\n",
      "|    std                | 2.76      |\n",
      "|    value_loss         | 0.00234   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0.018    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -4.12    |\n",
      "|    std                | 2.78     |\n",
      "|    value_loss         | 0.0253   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.79e+04  |\n",
      "|    total_cost         | 1.8e+03   |\n",
      "|    total_reward       | 3.79e+04  |\n",
      "|    total_reward_pct   | 75.8      |\n",
      "|    total_trades       | 10983     |\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 181       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    std                | 2.81      |\n",
      "|    value_loss         | 0.0178    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | -0.113   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.896   |\n",
      "|    std                | 2.83     |\n",
      "|    value_loss         | 0.00647  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.75e+04 |\n",
      "|    total_cost         | 1.64e+03 |\n",
      "|    total_reward       | 4.75e+04 |\n",
      "|    total_reward_pct   | 95       |\n",
      "|    total_trades       | 10550    |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 2.85     |\n",
      "|    value_loss         | 0.0659   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | -0.00134 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.0738   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.98e+04 |\n",
      "|    total_cost         | 1.16e+03 |\n",
      "|    total_reward       | 3.98e+04 |\n",
      "|    total_reward_pct   | 79.5     |\n",
      "|    total_trades       | 10073    |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | -0.15    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.0642   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -5.25    |\n",
      "|    std                | 2.92     |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 11.7      |\n",
      "|    std                | 2.94      |\n",
      "|    value_loss         | 0.0817    |\n",
      "-------------------------------------\n",
      "day: 1192, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 98675.57\n",
      "total_reward: 48675.57\n",
      "total_cost: 1193.49\n",
      "total_trades: 9756\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.87e+04 |\n",
      "|    total_cost         | 1.19e+03 |\n",
      "|    total_reward       | 4.87e+04 |\n",
      "|    total_reward_pct   | 97.4     |\n",
      "|    total_trades       | 9756     |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | -0.0594  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 1.25     |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 0.0229   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | -0.243   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 12       |\n",
      "|    std                | 2.99     |\n",
      "|    value_loss         | 0.0775   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.77e+04 |\n",
      "|    total_cost         | 1.54e+03 |\n",
      "|    total_reward       | 4.77e+04 |\n",
      "|    total_reward_pct   | 95.4     |\n",
      "|    total_trades       | 9786     |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0.0996   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -1.11    |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.00175  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 1.7      |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.00308  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | -1.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    std                | 3.04     |\n",
      "|    value_loss         | 0.083    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 1.62e+03 |\n",
      "|    total_reward       | 5.47e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 9817     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -5.05    |\n",
      "|    std                | 3.07     |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -6.34    |\n",
      "|    std                | 3.09     |\n",
      "|    value_loss         | 0.0261   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.34e+04 |\n",
      "|    total_cost         | 2.18e+03 |\n",
      "|    total_reward       | 4.34e+04 |\n",
      "|    total_reward_pct   | 86.8     |\n",
      "|    total_trades       | 10557    |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 6.47     |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.0217   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.0826  |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.00412  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+04  |\n",
      "|    total_cost         | 1.56e+03 |\n",
      "|    total_reward       | 4.1e+04  |\n",
      "|    total_reward_pct   | 81.9     |\n",
      "|    total_trades       | 9755     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.7    |\n",
      "|    explained_variance | 0.352    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -1.76    |\n",
      "|    std                | 3.15     |\n",
      "|    value_loss         | 0.0023   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 3.98     |\n",
      "|    std                | 3.18     |\n",
      "|    value_loss         | 0.00988  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0.161   |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.00915  |\n",
      "------------------------------------\n",
      "day: 1192, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103616.99\n",
      "total_reward: 53616.99\n",
      "total_cost: 1800.81\n",
      "total_trades: 9494\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 1.8e+03  |\n",
      "|    total_reward       | 5.36e+04 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 9494     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -3.81    |\n",
      "|    std                | 3.23     |\n",
      "|    value_loss         | 0.00658  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 3.46     |\n",
      "|    std                | 3.25     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.85e+04 |\n",
      "|    total_cost         | 1.33e+03 |\n",
      "|    total_reward       | 4.85e+04 |\n",
      "|    total_reward_pct   | 97       |\n",
      "|    total_trades       | 9109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 3.27     |\n",
      "|    value_loss         | 0.0686   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | -2.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -4.48    |\n",
      "|    std                | 3.3      |\n",
      "|    value_loss         | 0.0454   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.37e+03 |\n",
      "|    total_reward       | 5.29e+04 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 9350     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 0.0797   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -3.36    |\n",
      "|    std                | 3.33     |\n",
      "|    value_loss         | 0.0129   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -5.82     |\n",
      "|    std                | 3.35      |\n",
      "|    value_loss         | 0.0208    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -9.96     |\n",
      "|    std                | 3.37      |\n",
      "|    value_loss         | 0.0601    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 1.19e+03 |\n",
      "|    total_reward       | 5.62e+04 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 9041     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | -0.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -6.32    |\n",
      "|    std                | 3.39     |\n",
      "|    value_loss         | 0.0231   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 3.41     |\n",
      "|    value_loss         | 0.0601   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.35e+04 |\n",
      "|    total_cost         | 1.05e+03 |\n",
      "|    total_reward       | 4.35e+04 |\n",
      "|    total_reward_pct   | 87.1     |\n",
      "|    total_trades       | 9021     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.3    |\n",
      "|    explained_variance | -0.0544  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 2.69     |\n",
      "|    std                | 3.43     |\n",
      "|    value_loss         | 0.00687  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -1.5     |\n",
      "|    std                | 3.46     |\n",
      "|    value_loss         | 0.00502  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 3.72     |\n",
      "|    std                | 3.49     |\n",
      "|    value_loss         | 0.00679  |\n",
      "------------------------------------\n",
      "day: 1192, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 94656.74\n",
      "total_reward: 44656.74\n",
      "total_cost: 951.46\n",
      "total_trades: 8914\n",
      "Sharpe: 0.627\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.47e+04 |\n",
      "|    total_cost         | 951      |\n",
      "|    total_reward       | 4.47e+04 |\n",
      "|    total_reward_pct   | 89.3     |\n",
      "|    total_trades       | 8914     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | -0.0622  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 0.12     |\n",
      "|    std                | 3.52     |\n",
      "|    value_loss         | 0.0181   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.182   |\n",
      "|    std                | 3.54     |\n",
      "|    value_loss         | 0.018    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.32e+04 |\n",
      "|    total_cost         | 1.16e+03 |\n",
      "|    total_reward       | 4.32e+04 |\n",
      "|    total_reward_pct   | 86.3     |\n",
      "|    total_trades       | 8812     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | -0.00246 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -7.71    |\n",
      "|    std                | 3.57     |\n",
      "|    value_loss         | 0.0786   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 232       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 8.93      |\n",
      "|    std                | 3.6       |\n",
      "|    value_loss         | 0.0522    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.63e+04 |\n",
      "|    total_cost         | 1.02e+03 |\n",
      "|    total_reward       | 4.63e+04 |\n",
      "|    total_reward_pct   | 92.6     |\n",
      "|    total_trades       | 9270     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 0.000148 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 0.337    |\n",
      "|    std                | 3.63     |\n",
      "|    value_loss         | 0.00174  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.58    |\n",
      "|    std                | 3.66     |\n",
      "|    value_loss         | 0.000916 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -0.748   |\n",
      "|    std                | 3.69     |\n",
      "|    value_loss         | 0.00124  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.27e+04  |\n",
      "|    total_cost         | 1.25e+03  |\n",
      "|    total_reward       | 4.27e+04  |\n",
      "|    total_reward_pct   | 85.4      |\n",
      "|    total_trades       | 9461      |\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | 5         |\n",
      "|    std                | 3.72      |\n",
      "|    value_loss         | 0.0398    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -9.24    |\n",
      "|    std                | 3.75     |\n",
      "|    value_loss         | 0.0406   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.52e+04 |\n",
      "|    total_cost         | 1.5e+03  |\n",
      "|    total_reward       | 4.52e+04 |\n",
      "|    total_reward_pct   | 90.5     |\n",
      "|    total_trades       | 9583     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 5.66     |\n",
      "|    std                | 3.78     |\n",
      "|    value_loss         | 0.039    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.138    |\n",
      "|    std                | 3.81     |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -4.83    |\n",
      "|    std                | 3.83     |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "day: 1192, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 112853.99\n",
      "total_reward: 62853.99\n",
      "total_cost: 1754.63\n",
      "total_trades: 10140\n",
      "Sharpe: 0.752\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 1.75e+03 |\n",
      "|    total_reward       | 6.29e+04 |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 10140    |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 15.2     |\n",
      "|    std                | 3.85     |\n",
      "|    value_loss         | 0.0983   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | -0.0338  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 7.8      |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 0.0312   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 1.48e+03 |\n",
      "|    total_reward       | 5.43e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 9948     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 3.95     |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.00938  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | -0.00237 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -20.9    |\n",
      "|    std                | 3.93     |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.08e+05  |\n",
      "|    total_cost         | 1.55e+03  |\n",
      "|    total_reward       | 5.76e+04  |\n",
      "|    total_reward_pct   | 115       |\n",
      "|    total_trades       | 10025     |\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 251       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -0.851    |\n",
      "|    std                | 3.95      |\n",
      "|    value_loss         | 0.00183   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -3.66    |\n",
      "|    std                | 3.98     |\n",
      "|    value_loss         | 0.00944  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 5.42     |\n",
      "|    std                | 4.01     |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 1.78e+03 |\n",
      "|    total_reward       | 5.97e+04 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 10229    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -2.61    |\n",
      "|    std                | 4.05     |\n",
      "|    value_loss         | 0.00492  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.6    |\n",
      "|    explained_variance | 0.0939   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -4.32    |\n",
      "|    std                | 4.07     |\n",
      "|    value_loss         | 0.0188   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.37e+04 |\n",
      "|    total_cost         | 1.95e+03 |\n",
      "|    total_reward       | 4.37e+04 |\n",
      "|    total_reward_pct   | 87.4     |\n",
      "|    total_trades       | 10879    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.809    |\n",
      "|    std                | 4.1      |\n",
      "|    value_loss         | 0.00226  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 341       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | -0.168    |\n",
      "|    std                | 4.14      |\n",
      "|    value_loss         | 0.0122    |\n",
      "-------------------------------------\n",
      "day: 1192, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 106513.98\n",
      "total_reward: 56513.98\n",
      "total_cost: 2462.30\n",
      "total_trades: 11699\n",
      "Sharpe: 0.797\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 2.46e+03 |\n",
      "|    total_reward       | 5.65e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 11699    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -4.83    |\n",
      "|    std                | 4.17     |\n",
      "|    value_loss         | 0.0191   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    std                | 4.21     |\n",
      "|    value_loss         | 0.0663   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -2.07    |\n",
      "|    std                | 4.24     |\n",
      "|    value_loss         | 0.00662  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.69e+04  |\n",
      "|    total_cost         | 2.53e+03  |\n",
      "|    total_reward       | 3.69e+04  |\n",
      "|    total_reward_pct   | 73.7      |\n",
      "|    total_trades       | 11640     |\n",
      "| time/                 |           |\n",
      "|    fps                | 341       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 3.73      |\n",
      "|    std                | 4.28      |\n",
      "|    value_loss         | 0.0127    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | -0.0066  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 7.02     |\n",
      "|    std                | 4.33     |\n",
      "|    value_loss         | 0.0284   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.43e+04 |\n",
      "|    total_cost         | 2.31e+03 |\n",
      "|    total_reward       | 3.43e+04 |\n",
      "|    total_reward_pct   | 68.6     |\n",
      "|    total_trades       | 11355    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.754   |\n",
      "|    std                | 4.36     |\n",
      "|    value_loss         | 0.000968 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 13.2     |\n",
      "|    std                | 4.39     |\n",
      "|    value_loss         | 0.0772   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -2.8     |\n",
      "|    std                | 4.42     |\n",
      "|    value_loss         | 0.00439  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.6e+04  |\n",
      "|    total_cost         | 1.98e+03 |\n",
      "|    total_reward       | 4.6e+04  |\n",
      "|    total_reward_pct   | 92       |\n",
      "|    total_trades       | 11204    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    std                | 4.46     |\n",
      "|    value_loss         | 0.00235  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    std                | 4.5      |\n",
      "|    value_loss         | 0.181    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.01e+04 |\n",
      "|    total_cost         | 2.07e+03 |\n",
      "|    total_reward       | 3.01e+04 |\n",
      "|    total_reward_pct   | 60.3     |\n",
      "|    total_trades       | 11207    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | 0.00494  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.35    |\n",
      "|    std                | 4.54     |\n",
      "|    value_loss         | 0.00324  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.8    |\n",
      "|    explained_variance | -0.347   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -5.58    |\n",
      "|    std                | 4.57     |\n",
      "|    value_loss         | 0.012    |\n",
      "------------------------------------\n",
      "day: 1192, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 94441.41\n",
      "total_reward: 44441.41\n",
      "total_cost: 2468.91\n",
      "total_trades: 11324\n",
      "Sharpe: 0.678\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.44e+04  |\n",
      "|    total_cost         | 2.47e+03  |\n",
      "|    total_reward       | 4.44e+04  |\n",
      "|    total_reward_pct   | 88.9      |\n",
      "|    total_trades       | 11324     |\n",
      "| time/                 |           |\n",
      "|    fps                | 341       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | -2.7      |\n",
      "|    std                | 4.6       |\n",
      "|    value_loss         | 0.00253   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | -1.45    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -4.32    |\n",
      "|    std                | 4.64     |\n",
      "|    value_loss         | 0.00759  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | -0.149   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    std                | 4.67     |\n",
      "|    value_loss         | 0.00189  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 2.91e+03 |\n",
      "|    total_reward       | 5.16e+04 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 11820    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -4.27    |\n",
      "|    std                | 4.69     |\n",
      "|    value_loss         | 0.0325   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 7.57     |\n",
      "|    std                | 4.73     |\n",
      "|    value_loss         | 0.0202   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 3.76e+03 |\n",
      "|    total_reward       | 5.05e+04 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 12205    |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.848   |\n",
      "|    std                | 4.77     |\n",
      "|    value_loss         | 0.00125  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 3.24     |\n",
      "|    std                | 4.82     |\n",
      "|    value_loss         | 0.00444  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | 0.0329   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.609    |\n",
      "|    std                | 4.86     |\n",
      "|    value_loss         | 0.000197 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.72e+04  |\n",
      "|    total_cost         | 2.79e+03  |\n",
      "|    total_reward       | 2.72e+04  |\n",
      "|    total_reward_pct   | 54.4      |\n",
      "|    total_trades       | 12189     |\n",
      "| time/                 |           |\n",
      "|    fps                | 341       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 291       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 1.26      |\n",
      "|    std                | 4.9       |\n",
      "|    value_loss         | 0.00618   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | -0.00363 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -12.7    |\n",
      "|    std                | 4.94     |\n",
      "|    value_loss         | 0.0622   |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-10-02 to  2020-01-03\n",
      "A2C Sharpe Ratio:  0.4607228256468772\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_1\n",
      "day: 1192, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 84860.42\n",
      "total_reward: 34860.42\n",
      "total_cost: 12296.09\n",
      "total_trades: 6639\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.49e+04 |\n",
      "|    total_cost       | 1.23e+04 |\n",
      "|    total_reward     | 3.49e+04 |\n",
      "|    total_reward_pct | 69.7     |\n",
      "|    total_trades     | 6639     |\n",
      "| time/               |          |\n",
      "|    fps              | 416      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.93e+04    |\n",
      "|    total_cost           | 9.18e+03    |\n",
      "|    total_reward         | 3.93e+04    |\n",
      "|    total_reward_pct     | 78.5        |\n",
      "|    total_trades         | 6777        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 406         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021180343 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.238      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.255      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.27e+04    |\n",
      "|    total_cost           | 1.1e+04     |\n",
      "|    total_reward         | 2.27e+04    |\n",
      "|    total_reward_pct     | 45.3        |\n",
      "|    total_trades         | 6774        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015593422 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.048       |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 106130.41\n",
      "total_reward: 56130.41\n",
      "total_cost: 10692.87\n",
      "total_trades: 6956\n",
      "Sharpe: 0.993\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+05    |\n",
      "|    total_cost           | 1.07e+04    |\n",
      "|    total_reward         | 5.61e+04    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 6956        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018712448 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0346      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.84e+04    |\n",
      "|    total_cost           | 7.71e+03    |\n",
      "|    total_reward         | 3.84e+04    |\n",
      "|    total_reward_pct     | 76.8        |\n",
      "|    total_trades         | 6616        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019141966 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0343      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 8.41e+03    |\n",
      "|    total_reward         | 5.28e+04    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 6814        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018286224 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0269      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 130738.98\n",
      "total_reward: 80738.98\n",
      "total_cost: 8429.33\n",
      "total_trades: 6889\n",
      "Sharpe: 1.092\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.49e+04     |\n",
      "|    total_cost           | 1.12e+04     |\n",
      "|    total_reward         | 3.49e+04     |\n",
      "|    total_reward_pct     | 69.8         |\n",
      "|    total_trades         | 6855         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120725725 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.284       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0203      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0322       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.38e+05   |\n",
      "|    total_cost           | 8.98e+03   |\n",
      "|    total_reward         | 8.81e+04   |\n",
      "|    total_reward_pct     | 176        |\n",
      "|    total_trades         | 6968       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 401        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01971474 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.3       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0328     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.09e+05   |\n",
      "|    total_cost           | 9.15e+03   |\n",
      "|    total_reward         | 5.89e+04   |\n",
      "|    total_reward_pct     | 118        |\n",
      "|    total_trades         | 6899       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 401        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01892345 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.463      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.31      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0405     |\n",
      "----------------------------------------\n",
      "day: 1192, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 99331.28\n",
      "total_reward: 49331.28\n",
      "total_cost: 7017.51\n",
      "total_trades: 6781\n",
      "Sharpe: 0.875\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.18e+04   |\n",
      "|    total_cost           | 6.18e+03   |\n",
      "|    total_reward         | 3.18e+04   |\n",
      "|    total_reward_pct     | 63.7       |\n",
      "|    total_trades         | 6837       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 400        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01561509 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.276     |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0326     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+05    |\n",
      "|    total_cost           | 7.96e+03    |\n",
      "|    total_reward         | 7.59e+04    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 6842        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019044043 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.3e+05     |\n",
      "|    total_cost           | 7.25e+03    |\n",
      "|    total_reward         | 8.02e+04    |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 6920        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028192725 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.033       |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 122203.96\n",
      "total_reward: 72203.96\n",
      "total_cost: 8978.18\n",
      "total_trades: 7058\n",
      "Sharpe: 1.218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.27e+05    |\n",
      "|    total_cost           | 5.46e+03    |\n",
      "|    total_reward         | 7.69e+04    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 6876        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021877326 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0358      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+05    |\n",
      "|    total_cost           | 6.18e+03    |\n",
      "|    total_reward         | 7.18e+04    |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 6878        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023266219 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0374      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.27e+05   |\n",
      "|    total_cost           | 6.88e+03   |\n",
      "|    total_reward         | 7.71e+04   |\n",
      "|    total_reward_pct     | 154        |\n",
      "|    total_trades         | 6835       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 401        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01748114 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.279     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0564     |\n",
      "----------------------------------------\n",
      "day: 1192, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 133574.72\n",
      "total_reward: 83574.72\n",
      "total_cost: 5437.16\n",
      "total_trades: 6775\n",
      "Sharpe: 1.211\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 5.62e+03    |\n",
      "|    total_reward         | 5.1e+04     |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 6958        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018333603 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.034       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+05    |\n",
      "|    total_cost           | 7.75e+03    |\n",
      "|    total_reward         | 7.6e+04     |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 7163        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017622836 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0442      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 6.78e+03    |\n",
      "|    total_reward         | 6.81e+04    |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 6943        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018019127 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0417      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 118808.55\n",
      "total_reward: 68808.55\n",
      "total_cost: 6771.00\n",
      "total_trades: 7305\n",
      "Sharpe: 1.055\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 6.84e+03    |\n",
      "|    total_reward         | 6.27e+04    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 7109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026864976 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+05    |\n",
      "|    total_cost           | 6.5e+03     |\n",
      "|    total_reward         | 7.1e+04     |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 7210        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026279012 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0333      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 120\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 133788.00\n",
      "total_reward: 83788.00\n",
      "total_cost: 5977.93\n",
      "total_trades: 6900\n",
      "Sharpe: 1.150\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+05    |\n",
      "|    total_cost           | 5.98e+03    |\n",
      "|    total_reward         | 8.38e+04    |\n",
      "|    total_reward_pct     | 168         |\n",
      "|    total_trades         | 6900        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027966969 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0376      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.17e+05   |\n",
      "|    total_cost           | 6.11e+03   |\n",
      "|    total_reward         | 6.67e+04   |\n",
      "|    total_reward_pct     | 133        |\n",
      "|    total_trades         | 7132       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 398        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03212855 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.658      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.298     |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0355     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 6.99e+03    |\n",
      "|    total_reward         | 5.18e+04    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 7088        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032373644 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0335      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 125\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97780.18\n",
      "total_reward: 47780.18\n",
      "total_cost: 5666.56\n",
      "total_trades: 7113\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.78e+04   |\n",
      "|    total_cost           | 5.67e+03   |\n",
      "|    total_reward         | 4.78e+04   |\n",
      "|    total_reward_pct     | 95.6       |\n",
      "|    total_trades         | 7113       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 398        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01811011 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.64       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.289     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.023     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0347     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.3e+05     |\n",
      "|    total_cost           | 6.43e+03    |\n",
      "|    total_reward         | 8.02e+04    |\n",
      "|    total_reward_pct     | 160         |\n",
      "|    total_trades         | 7235        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026778903 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.256      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0367      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.27e+05    |\n",
      "|    total_cost           | 6.69e+03    |\n",
      "|    total_reward         | 7.71e+04    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 7266        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025145426 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0461      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 130\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 108017.38\n",
      "total_reward: 58017.38\n",
      "total_cost: 7276.31\n",
      "total_trades: 7136\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.08e+05    |\n",
      "|    total_cost           | 7.28e+03    |\n",
      "|    total_reward         | 5.8e+04     |\n",
      "|    total_reward_pct     | 116         |\n",
      "|    total_trades         | 7136        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016649906 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0574      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.6e+05     |\n",
      "|    total_cost           | 7.51e+03    |\n",
      "|    total_reward         | 1.1e+05     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 7216        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021151656 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.052       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.24e+05    |\n",
      "|    total_cost           | 7.51e+03    |\n",
      "|    total_reward         | 7.38e+04    |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 7176        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035770763 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.253      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0846      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 135\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 133609.13\n",
      "total_reward: 83609.13\n",
      "total_cost: 7567.76\n",
      "total_trades: 7273\n",
      "Sharpe: 0.999\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+05    |\n",
      "|    total_cost           | 7.57e+03    |\n",
      "|    total_reward         | 8.36e+04    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 7273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028824518 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.257      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0543      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 8.01e+03    |\n",
      "|    total_reward         | 7.01e+04    |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 7418        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025874957 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0756      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.31e+05    |\n",
      "|    total_cost           | 6.49e+03    |\n",
      "|    total_reward         | 8.09e+04    |\n",
      "|    total_reward_pct     | 162         |\n",
      "|    total_trades         | 7219        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020432357 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0769      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 140\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 112693.57\n",
      "total_reward: 62693.57\n",
      "total_cost: 7608.77\n",
      "total_trades: 7365\n",
      "Sharpe: 1.005\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 7.61e+03    |\n",
      "|    total_reward         | 6.27e+04    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 7365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025208946 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.239      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.27e+05    |\n",
      "|    total_cost           | 7.3e+03     |\n",
      "|    total_reward         | 7.68e+04    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 7317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024299148 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0555      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.29e+05  |\n",
      "|    total_cost           | 6.43e+03  |\n",
      "|    total_reward         | 7.94e+04  |\n",
      "|    total_reward_pct     | 159       |\n",
      "|    total_trades         | 7313      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 397       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 180       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0339074 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.2     |\n",
      "|    explained_variance   | 0.594     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.271    |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.014    |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 0.0516    |\n",
      "---------------------------------------\n",
      "day: 1192, episode: 145\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 116518.99\n",
      "total_reward: 66518.99\n",
      "total_cost: 5760.47\n",
      "total_trades: 7223\n",
      "Sharpe: 0.972\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.17e+05   |\n",
      "|    total_cost           | 5.76e+03   |\n",
      "|    total_reward         | 6.65e+04   |\n",
      "|    total_reward_pct     | 133        |\n",
      "|    total_trades         | 7223       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 397        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 185        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03449911 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.607      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0207    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0576     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+05    |\n",
      "|    total_cost           | 5.57e+03    |\n",
      "|    total_reward         | 7.25e+04    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 7249        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029606868 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0481      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.46e+05    |\n",
      "|    total_cost           | 6.77e+03    |\n",
      "|    total_reward         | 9.59e+04    |\n",
      "|    total_reward_pct     | 192         |\n",
      "|    total_trades         | 7486        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031695176 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.042       |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 150\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 134425.78\n",
      "total_reward: 84425.78\n",
      "total_cost: 6912.60\n",
      "total_trades: 7416\n",
      "Sharpe: 1.045\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.34e+05  |\n",
      "|    total_cost           | 6.91e+03  |\n",
      "|    total_reward         | 8.44e+04  |\n",
      "|    total_reward_pct     | 169       |\n",
      "|    total_trades         | 7416      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 398       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 200       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0269914 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.3     |\n",
      "|    explained_variance   | 0.584     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.284    |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -0.0172   |\n",
      "|    std                  | 1.08      |\n",
      "|    value_loss           | 0.0561    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+05    |\n",
      "|    total_cost           | 5.2e+03     |\n",
      "|    total_reward         | 5.58e+04    |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 7247        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032097142 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0677      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.33e+05    |\n",
      "|    total_cost           | 5.28e+03    |\n",
      "|    total_reward         | 8.26e+04    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 7383        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021931326 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.046       |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 155\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 118422.45\n",
      "total_reward: 68422.45\n",
      "total_cost: 5126.03\n",
      "total_trades: 7341\n",
      "Sharpe: 0.880\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.05e+05    |\n",
      "|    total_cost           | 4.44e+03    |\n",
      "|    total_reward         | 5.48e+04    |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 7358        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019257585 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0535      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.44e+05    |\n",
      "|    total_cost           | 5.7e+03     |\n",
      "|    total_reward         | 9.44e+04    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 7462        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031219075 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.266      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0471      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 5.63e+03    |\n",
      "|    total_reward         | 6.07e+04    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 7508        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030159853 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 160\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113000.27\n",
      "total_reward: 63000.27\n",
      "total_cost: 5035.32\n",
      "total_trades: 7460\n",
      "Sharpe: 0.862\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+05    |\n",
      "|    total_cost           | 5.23e+03    |\n",
      "|    total_reward         | 7.12e+04    |\n",
      "|    total_reward_pct     | 142         |\n",
      "|    total_trades         | 7393        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033614844 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0572      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.36e+05    |\n",
      "|    total_cost           | 5.73e+03    |\n",
      "|    total_reward         | 8.64e+04    |\n",
      "|    total_reward_pct     | 173         |\n",
      "|    total_trades         | 7515        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027873697 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0487      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 4.85e+03    |\n",
      "|    total_reward         | 6.84e+04    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 7378        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027480425 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0539      |\n",
      "-----------------------------------------\n",
      "day: 1192, episode: 165\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 127804.38\n",
      "total_reward: 77804.38\n",
      "total_cost: 5876.71\n",
      "total_trades: 7467\n",
      "Sharpe: 1.055\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.3e+05    |\n",
      "|    total_cost           | 5.61e+03   |\n",
      "|    total_reward         | 8.01e+04   |\n",
      "|    total_reward_pct     | 160        |\n",
      "|    total_trades         | 7411       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 398        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02444436 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.7      |\n",
      "|    explained_variance   | 0.662      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.281     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 0.0457     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.17e+05   |\n",
      "|    total_cost           | 4.98e+03   |\n",
      "|    total_reward         | 6.72e+04   |\n",
      "|    total_reward_pct     | 134        |\n",
      "|    total_trades         | 7462       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 398        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 251        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03567189 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.8      |\n",
      "|    explained_variance   | 0.593      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.271     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 0.0689     |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2019-10-02 to  2020-01-03\n",
      "PPO Sharpe Ratio:  0.48931446546557955\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
      "day: 1192, episode: 170\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 125001.62\n",
      "total_reward: 75001.62\n",
      "total_cost: 534.63\n",
      "total_trades: 3501\n",
      "Sharpe: 1.177\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.08e+05 |\n",
      "|    total_cost       | 135      |\n",
      "|    total_reward     | 5.82e+04 |\n",
      "|    total_reward_pct | 116      |\n",
      "|    total_trades     | 4350     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total timesteps  | 4772     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -87.3    |\n",
      "|    critic_loss      | 224      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3579     |\n",
      "----------------------------------\n",
      "day: 1192, episode: 175\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 115795.12\n",
      "total_reward: 65795.12\n",
      "total_cost: 155.57\n",
      "total_trades: 5889\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.16e+05 |\n",
      "|    total_cost       | 146      |\n",
      "|    total_reward     | 6.61e+04 |\n",
      "|    total_reward_pct | 132      |\n",
      "|    total_trades     | 3660     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total timesteps  | 9544     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -65.1    |\n",
      "|    critic_loss      | 45.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8351     |\n",
      "----------------------------------\n",
      "day: 1192, episode: 180\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 117282.02\n",
      "total_reward: 67282.02\n",
      "total_cost: 171.32\n",
      "total_trades: 5073\n",
      "Sharpe: 0.968\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.3e+05  |\n",
      "|    total_cost       | 125      |\n",
      "|    total_reward     | 7.97e+04 |\n",
      "|    total_reward_pct | 159      |\n",
      "|    total_trades     | 7331     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total timesteps  | 14316    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -50.9    |\n",
      "|    critic_loss      | 18.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13123    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 185\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 104904.16\n",
      "total_reward: 54904.16\n",
      "total_cost: 168.58\n",
      "total_trades: 4417\n",
      "Sharpe: 0.752\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.05e+05 |\n",
      "|    total_cost       | 169      |\n",
      "|    total_reward     | 5.49e+04 |\n",
      "|    total_reward_pct | 110      |\n",
      "|    total_trades     | 4417     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total timesteps  | 19088    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -40      |\n",
      "|    critic_loss      | 10.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17895    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.48e+05 |\n",
      "|    total_cost       | 214      |\n",
      "|    total_reward     | 9.82e+04 |\n",
      "|    total_reward_pct | 196      |\n",
      "|    total_trades     | 5707     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total timesteps  | 23860    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -31.5    |\n",
      "|    critic_loss      | 5.01     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 22667    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 190\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 153111.20\n",
      "total_reward: 103111.20\n",
      "total_cost: 193.44\n",
      "total_trades: 3402\n",
      "Sharpe: 1.262\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.37e+05 |\n",
      "|    total_cost       | 374      |\n",
      "|    total_reward     | 8.66e+04 |\n",
      "|    total_reward_pct | 173      |\n",
      "|    total_trades     | 5701     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total timesteps  | 28632    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -25      |\n",
      "|    critic_loss      | 3.62     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27439    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 195\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 117773.17\n",
      "total_reward: 67773.17\n",
      "total_cost: 264.81\n",
      "total_trades: 8588\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.44e+05 |\n",
      "|    total_cost       | 349      |\n",
      "|    total_reward     | 9.42e+04 |\n",
      "|    total_reward_pct | 188      |\n",
      "|    total_trades     | 4767     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total timesteps  | 33404    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -19.8    |\n",
      "|    critic_loss      | 2.08     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32211    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 200\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 116031.39\n",
      "total_reward: 66031.39\n",
      "total_cost: 436.85\n",
      "total_trades: 4479\n",
      "Sharpe: 0.989\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.38e+05 |\n",
      "|    total_cost       | 241      |\n",
      "|    total_reward     | 8.77e+04 |\n",
      "|    total_reward_pct | 175      |\n",
      "|    total_trades     | 5152     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total timesteps  | 38176    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -15.7    |\n",
      "|    critic_loss      | 1.98     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 36983    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 205\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 143644.97\n",
      "total_reward: 93644.97\n",
      "total_cost: 281.56\n",
      "total_trades: 4163\n",
      "Sharpe: 1.275\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.44e+05 |\n",
      "|    total_cost       | 282      |\n",
      "|    total_reward     | 9.36e+04 |\n",
      "|    total_reward_pct | 187      |\n",
      "|    total_trades     | 4163     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total timesteps  | 42948    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -12.5    |\n",
      "|    critic_loss      | 1.78     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41755    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.29e+05 |\n",
      "|    total_cost       | 280      |\n",
      "|    total_reward     | 7.91e+04 |\n",
      "|    total_reward_pct | 158      |\n",
      "|    total_trades     | 6308     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 405      |\n",
      "|    total timesteps  | 47720    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -9.9     |\n",
      "|    critic_loss      | 1.96     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46527    |\n",
      "----------------------------------\n",
      "day: 1192, episode: 210\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114154.89\n",
      "total_reward: 64154.89\n",
      "total_cost: 265.20\n",
      "total_trades: 4384\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-02 to  2020-01-03\n",
      "======Best Model Retraining from:  2015-01-01 to  2020-01-03\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_315_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.96e+04 |\n",
      "|    total_cost       | 1.09e+04 |\n",
      "|    total_reward     | 3.96e+04 |\n",
      "|    total_reward_pct | 79.2     |\n",
      "|    total_trades     | 7035     |\n",
      "| time/               |          |\n",
      "|    fps              | 414      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.05e+04   |\n",
      "|    total_cost           | 1.29e+04   |\n",
      "|    total_reward         | 3.05e+04   |\n",
      "|    total_reward_pct     | 61         |\n",
      "|    total_trades         | 7200       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 400        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01590568 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | -0.298     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.274     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0659     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.89e+04    |\n",
      "|    total_cost           | 1.18e+04    |\n",
      "|    total_reward         | 2.89e+04    |\n",
      "|    total_reward_pct     | 57.8        |\n",
      "|    total_trades         | 7031        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023451095 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.0625     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.034       |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 100495.71\n",
      "total_reward: 50495.71\n",
      "total_cost: 9306.73\n",
      "total_trades: 7009\n",
      "Sharpe: 0.922\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.87e+04    |\n",
      "|    total_cost           | 1.21e+04    |\n",
      "|    total_reward         | 1.87e+04    |\n",
      "|    total_reward_pct     | 37.3        |\n",
      "|    total_trades         | 6985        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023615688 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0333      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.65e+04    |\n",
      "|    total_cost           | 1.19e+04    |\n",
      "|    total_reward         | 2.65e+04    |\n",
      "|    total_reward_pct     | 52.9        |\n",
      "|    total_trades         | 7125        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024674093 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0215      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 1.18e+04    |\n",
      "|    total_reward         | 5.17e+04    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 7074        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010915604 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.00758    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.326      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0178      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 93818.83\n",
      "total_reward: 43818.83\n",
      "total_cost: 10298.42\n",
      "total_trades: 7047\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 1.19e+04    |\n",
      "|    total_reward         | 5.2e+04     |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 7164        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019306004 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.55e+04    |\n",
      "|    total_cost           | 9.38e+03    |\n",
      "|    total_reward         | 3.55e+04    |\n",
      "|    total_reward_pct     | 71          |\n",
      "|    total_trades         | 6926        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020628933 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0317      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 9.42e+03    |\n",
      "|    total_reward         | 6.07e+04    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 7140        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 386         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028065948 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0248      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 100606.99\n",
      "total_reward: 50606.99\n",
      "total_cost: 11291.81\n",
      "total_trades: 7082\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 9.87e+03    |\n",
      "|    total_reward         | 6.76e+04    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 7194        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 385         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019951789 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0263      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.57e+04    |\n",
      "|    total_cost           | 1.06e+04    |\n",
      "|    total_reward         | 3.57e+04    |\n",
      "|    total_reward_pct     | 71.3        |\n",
      "|    total_trades         | 7155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029803386 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0303      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.57e+04    |\n",
      "|    total_cost           | 8.22e+03    |\n",
      "|    total_reward         | 2.57e+04    |\n",
      "|    total_reward_pct     | 51.4        |\n",
      "|    total_trades         | 7144        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020670472 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0342      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90519.21\n",
      "total_reward: 40519.21\n",
      "total_cost: 10483.88\n",
      "total_trades: 7363\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.16e+04    |\n",
      "|    total_cost           | 9.72e+03    |\n",
      "|    total_reward         | 3.16e+04    |\n",
      "|    total_reward_pct     | 63.2        |\n",
      "|    total_trades         | 7178        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017095912 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.1e+05     |\n",
      "|    total_cost           | 1.15e+04    |\n",
      "|    total_reward         | 5.98e+04    |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 7294        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017481998 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 9.56e+03    |\n",
      "|    total_reward         | 6.11e+04    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 7305        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030996822 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0303      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 100660.49\n",
      "total_reward: 50660.49\n",
      "total_cost: 10669.46\n",
      "total_trades: 7408\n",
      "Sharpe: 0.927\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.38e+04    |\n",
      "|    total_cost           | 8.35e+03    |\n",
      "|    total_reward         | 1.38e+04    |\n",
      "|    total_reward_pct     | 27.7        |\n",
      "|    total_trades         | 6842        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020593768 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0341      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.66e+04    |\n",
      "|    total_cost           | 1.08e+04    |\n",
      "|    total_reward         | 3.66e+04    |\n",
      "|    total_reward_pct     | 73.2        |\n",
      "|    total_trades         | 7100        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028073363 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0217      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.94e+04    |\n",
      "|    total_cost           | 1.02e+04    |\n",
      "|    total_reward         | 4.94e+04    |\n",
      "|    total_reward_pct     | 98.7        |\n",
      "|    total_trades         | 7253        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019997519 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 65466.65\n",
      "total_reward: 15466.65\n",
      "total_cost: 8351.70\n",
      "total_trades: 7176\n",
      "Sharpe: 0.379\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.55e+04    |\n",
      "|    total_cost           | 8.35e+03    |\n",
      "|    total_reward         | 1.55e+04    |\n",
      "|    total_reward_pct     | 30.9        |\n",
      "|    total_trades         | 7176        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024702232 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0407      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.92e+04    |\n",
      "|    total_cost           | 1.11e+04    |\n",
      "|    total_reward         | 4.92e+04    |\n",
      "|    total_reward_pct     | 98.4        |\n",
      "|    total_trades         | 7380        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015268848 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 1.05e+04    |\n",
      "|    total_reward         | 6.76e+04    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 7400        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023380153 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0293      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85521.20\n",
      "total_reward: 35521.20\n",
      "total_cost: 10058.85\n",
      "total_trades: 7353\n",
      "Sharpe: 0.763\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.55e+04    |\n",
      "|    total_cost           | 1.01e+04    |\n",
      "|    total_reward         | 3.55e+04    |\n",
      "|    total_reward_pct     | 71          |\n",
      "|    total_trades         | 7353        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029025245 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.269      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0324      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.07e+05   |\n",
      "|    total_cost           | 8.76e+03   |\n",
      "|    total_reward         | 5.71e+04   |\n",
      "|    total_reward_pct     | 114        |\n",
      "|    total_trades         | 7350       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 382        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04229743 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.266     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0235     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 8.57e+03    |\n",
      "|    total_reward         | 6.3e+04     |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 7372        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016400335 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0297      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 96368.38\n",
      "total_reward: 46368.38\n",
      "total_cost: 8747.00\n",
      "total_trades: 7340\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.64e+04    |\n",
      "|    total_cost           | 8.75e+03    |\n",
      "|    total_reward         | 4.64e+04    |\n",
      "|    total_reward_pct     | 92.7        |\n",
      "|    total_trades         | 7340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030062016 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.41e+04    |\n",
      "|    total_cost           | 6.91e+03    |\n",
      "|    total_reward         | 1.41e+04    |\n",
      "|    total_reward_pct     | 28.1        |\n",
      "|    total_trades         | 7302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031450443 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.035       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.88e+04    |\n",
      "|    total_cost           | 7.41e+03    |\n",
      "|    total_reward         | 4.88e+04    |\n",
      "|    total_reward_pct     | 97.6        |\n",
      "|    total_trades         | 7241        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 381         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030416533 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0207      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114139.54\n",
      "total_reward: 64139.54\n",
      "total_cost: 8938.06\n",
      "total_trades: 7425\n",
      "Sharpe: 1.138\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+05    |\n",
      "|    total_cost           | 8.94e+03    |\n",
      "|    total_reward         | 6.41e+04    |\n",
      "|    total_reward_pct     | 128         |\n",
      "|    total_trades         | 7425        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 381         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038110115 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+05    |\n",
      "|    total_cost           | 7.46e+03    |\n",
      "|    total_reward         | 5.74e+04    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 7292        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 381         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031112198 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0272      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+05    |\n",
      "|    total_cost           | 8.79e+03    |\n",
      "|    total_reward         | 5.43e+04    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 7365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 381         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026471827 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74976.46\n",
      "total_reward: 24976.46\n",
      "total_cost: 5512.02\n",
      "total_trades: 7082\n",
      "Sharpe: 0.492\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.5e+04    |\n",
      "|    total_cost           | 5.51e+03   |\n",
      "|    total_reward         | 2.5e+04    |\n",
      "|    total_reward_pct     | 50         |\n",
      "|    total_trades         | 7082       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 382        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03388591 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.281     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0212    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.031      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.1e+05     |\n",
      "|    total_cost           | 7.26e+03    |\n",
      "|    total_reward         | 6.03e+04    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 7467        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027740614 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.24e+05    |\n",
      "|    total_cost           | 8.87e+03    |\n",
      "|    total_reward         | 7.4e+04     |\n",
      "|    total_reward_pct     | 148         |\n",
      "|    total_trades         | 7445        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028386433 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0326      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 79123.51\n",
      "total_reward: 29123.51\n",
      "total_cost: 7443.57\n",
      "total_trades: 7338\n",
      "Sharpe: 0.537\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.91e+04    |\n",
      "|    total_cost           | 7.44e+03    |\n",
      "|    total_reward         | 2.91e+04    |\n",
      "|    total_reward_pct     | 58.2        |\n",
      "|    total_trades         | 7338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030194543 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.028       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.76e+04    |\n",
      "|    total_cost           | 7.7e+03     |\n",
      "|    total_reward         | 4.76e+04    |\n",
      "|    total_reward_pct     | 95.2        |\n",
      "|    total_trades         | 7381        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031560794 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.022       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.29e+05   |\n",
      "|    total_cost           | 8.21e+03   |\n",
      "|    total_reward         | 7.92e+04   |\n",
      "|    total_reward_pct     | 158        |\n",
      "|    total_trades         | 7516       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 383        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03187722 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.291     |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0295     |\n",
      "----------------------------------------\n",
      "day: 1255, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 116212.06\n",
      "total_reward: 66212.06\n",
      "total_cost: 7497.57\n",
      "total_trades: 7482\n",
      "Sharpe: 0.995\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.16e+05  |\n",
      "|    total_cost           | 7.5e+03   |\n",
      "|    total_reward         | 6.62e+04  |\n",
      "|    total_reward_pct     | 132       |\n",
      "|    total_trades         | 7482      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 383       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 197       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0353683 |\n",
      "|    clip_fraction        | 0.256     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28       |\n",
      "|    explained_variance   | 0.522     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.286    |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -0.0198   |\n",
      "|    std                  | 1.06      |\n",
      "|    value_loss           | 0.0365    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.4e+05     |\n",
      "|    total_cost           | 8.93e+03    |\n",
      "|    total_reward         | 8.98e+04    |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 7512        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031440884 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0373      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.2e+05    |\n",
      "|    total_cost           | 8.01e+03   |\n",
      "|    total_reward         | 7.02e+04   |\n",
      "|    total_reward_pct     | 140        |\n",
      "|    total_trades         | 7269       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 383        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 208        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02488616 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.309     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0409     |\n",
      "----------------------------------------\n",
      "day: 1255, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90719.43\n",
      "total_reward: 40719.43\n",
      "total_cost: 6622.00\n",
      "total_trades: 7155\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.07e+04    |\n",
      "|    total_cost           | 6.62e+03    |\n",
      "|    total_reward         | 4.07e+04    |\n",
      "|    total_reward_pct     | 81.4        |\n",
      "|    total_trades         | 7155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024172131 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0475      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+05    |\n",
      "|    total_cost           | 7.67e+03    |\n",
      "|    total_reward         | 7.2e+04     |\n",
      "|    total_reward_pct     | 144         |\n",
      "|    total_trades         | 7438        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017185468 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0377      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.96e+04    |\n",
      "|    total_cost           | 6.69e+03    |\n",
      "|    total_reward         | 2.96e+04    |\n",
      "|    total_reward_pct     | 59.2        |\n",
      "|    total_trades         | 7204        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026291678 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0555      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 106836.43\n",
      "total_reward: 56836.43\n",
      "total_cost: 7036.42\n",
      "total_trades: 7387\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+05    |\n",
      "|    total_cost           | 7.04e+03    |\n",
      "|    total_reward         | 5.68e+04    |\n",
      "|    total_reward_pct     | 114         |\n",
      "|    total_trades         | 7387        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034700014 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.272      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0309      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.44e+05    |\n",
      "|    total_cost           | 8.75e+03    |\n",
      "|    total_reward         | 9.42e+04    |\n",
      "|    total_reward_pct     | 188         |\n",
      "|    total_trades         | 7541        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033009276 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0542      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.09e+05   |\n",
      "|    total_cost           | 6.32e+03   |\n",
      "|    total_reward         | 5.93e+04   |\n",
      "|    total_reward_pct     | 119        |\n",
      "|    total_trades         | 7280       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 384        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02709874 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.494      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.284     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0405     |\n",
      "----------------------------------------\n",
      "day: 1255, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113521.06\n",
      "total_reward: 63521.06\n",
      "total_cost: 7909.98\n",
      "total_trades: 7317\n",
      "Sharpe: 0.866\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+05    |\n",
      "|    total_cost           | 7.91e+03    |\n",
      "|    total_reward         | 6.35e+04    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 7317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023257673 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0513      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 6.95e+03    |\n",
      "|    total_reward         | 6.59e+04    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 7343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026212666 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0518      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.06e+05   |\n",
      "|    total_cost           | 6.94e+03   |\n",
      "|    total_reward         | 5.58e+04   |\n",
      "|    total_reward_pct     | 112        |\n",
      "|    total_trades         | 7513       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 384        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03473087 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.282     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0537     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.21e+04   |\n",
      "|    total_cost           | 7.24e+03   |\n",
      "|    total_reward         | 4.21e+04   |\n",
      "|    total_reward_pct     | 84.2       |\n",
      "|    total_trades         | 7507       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 384        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 260        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02975389 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.5      |\n",
      "|    explained_variance   | 0.527      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.289     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0484     |\n",
      "----------------------------------------\n",
      "======Trading from:  2020-01-03 to  2020-04-06\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  529.7283042530553\n",
      "======Model training from:  2015-01-01 to  2020-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -107     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -4.67    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 2.3      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0082   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.87e+04 |\n",
      "|    total_cost         | 2.76e+03 |\n",
      "|    total_reward       | 2.87e+04 |\n",
      "|    total_reward_pct   | 57.4     |\n",
      "|    total_trades       | 5627     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0.706    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 7.47     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.066    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 340       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | -2.55e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 3.73      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.0283    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.457   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 7.42     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0801   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.77e+04 |\n",
      "|    total_cost         | 1.72e+03 |\n",
      "|    total_reward       | 4.77e+04 |\n",
      "|    total_reward_pct   | 95.4     |\n",
      "|    total_trades       | 5417     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -6.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 4.49     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0797   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.464    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -4.65    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 2.24e+03 |\n",
      "|    total_reward       | 6.05e+04 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 5222     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 1.29e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 2.73     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0124   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 3.76     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0301   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0.53     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -1.54    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00488  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.46e+04 |\n",
      "|    total_cost         | 1.28e+03 |\n",
      "|    total_reward       | 3.46e+04 |\n",
      "|    total_reward_pct   | 69.2     |\n",
      "|    total_trades       | 5340     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.759   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -7.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 7.09     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0531   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 93472.78\n",
      "total_reward: 43472.78\n",
      "total_cost: 1364.91\n",
      "total_trades: 5577\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.35e+04 |\n",
      "|    total_cost         | 1.36e+03 |\n",
      "|    total_reward       | 4.35e+04 |\n",
      "|    total_reward_pct   | 86.9     |\n",
      "|    total_trades       | 5577     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00427  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -13.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -1.84    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -0.579   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 3.71     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0309   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.66e+04 |\n",
      "|    total_cost         | 1.57e+03 |\n",
      "|    total_reward       | 2.66e+04 |\n",
      "|    total_reward_pct   | 53.1     |\n",
      "|    total_trades       | 5538     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 5.94     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.047    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.0348   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -5.84    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0478   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.17e+04 |\n",
      "|    total_cost         | 1.3e+03  |\n",
      "|    total_reward       | 1.17e+04 |\n",
      "|    total_reward_pct   | 23.4     |\n",
      "|    total_trades       | 5855     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -0.0317  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.366    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.000729 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.0313  |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.000389 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.418    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 4.17     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0207   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.53e+04 |\n",
      "|    total_cost         | 1.07e+03 |\n",
      "|    total_reward       | 3.53e+04 |\n",
      "|    total_reward_pct   | 70.6     |\n",
      "|    total_trades       | 5507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00162  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.861   |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.00272  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.32e+04 |\n",
      "|    total_cost         | 947      |\n",
      "|    total_reward       | 2.32e+04 |\n",
      "|    total_reward_pct   | 46.3     |\n",
      "|    total_trades       | 5855     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0.203    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.7      |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.901    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -1.51    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.0025   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 2.45e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -2.52    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.00967  |\n",
      "------------------------------------\n",
      "day: 1255, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82669.79\n",
      "total_reward: 32669.79\n",
      "total_cost: 1124.98\n",
      "total_trades: 6288\n",
      "Sharpe: 0.559\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.27e+04 |\n",
      "|    total_cost         | 1.12e+03 |\n",
      "|    total_reward       | 3.27e+04 |\n",
      "|    total_reward_pct   | 65.3     |\n",
      "|    total_trades       | 6288     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -5.62    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0589   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 2.8      |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0163   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.67e+04 |\n",
      "|    total_cost         | 784      |\n",
      "|    total_reward       | 4.67e+04 |\n",
      "|    total_reward_pct   | 93.4     |\n",
      "|    total_trades       | 6336     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0.543    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -3.28    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0112   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | 0.051    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.0122   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | -0.0246  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.472    |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.00695  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.84e+04 |\n",
      "|    total_cost         | 762      |\n",
      "|    total_reward       | 3.84e+04 |\n",
      "|    total_reward_pct   | 76.7     |\n",
      "|    total_trades       | 5896     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -12      |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.165    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -4.16    |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.0255   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 838      |\n",
      "|    total_reward       | 5.79e+04 |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 5658     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.364    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.00106  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -4.05    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 21.6     |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.411    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 975      |\n",
      "|    total_reward       | 6.19e+04 |\n",
      "|    total_reward_pct   | 124      |\n",
      "|    total_trades       | 6538     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -3.46    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 4.88     |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0237   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 106462.83\n",
      "total_reward: 56462.83\n",
      "total_cost: 645.32\n",
      "total_trades: 7190\n",
      "Sharpe: 0.797\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 645      |\n",
      "|    total_reward       | 5.65e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 7190     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | -0.77    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 4.26     |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.0194   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.852    |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.00456  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 4.73     |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0323   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.16e+04 |\n",
      "|    total_cost         | 540      |\n",
      "|    total_reward       | 3.16e+04 |\n",
      "|    total_reward_pct   | 63.1     |\n",
      "|    total_trades       | 7588     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | -44.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -20.7    |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.407    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | 0.00157  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.00675  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 665      |\n",
      "|    total_reward       | 5.9e+04  |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 7893     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | 0.131    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 5.87     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.0279   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0.253    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 4.06     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.0189   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | -17.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 1.45     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.00676  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 719      |\n",
      "|    total_reward       | 6.28e+04 |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 8324     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | 0.295    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -4.87    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.0357   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | 0.486    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -2.28    |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.00493  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 714      |\n",
      "|    total_reward       | 5.65e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 7900     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | 0.138    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 1.94     |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00511  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | -0.0224  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 5.95     |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.0401   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | 0.436    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 4.71     |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.0291   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 105639.59\n",
      "total_reward: 55639.59\n",
      "total_cost: 750.91\n",
      "total_trades: 7832\n",
      "Sharpe: 0.858\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 751      |\n",
      "|    total_reward       | 5.56e+04 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 7832     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 8.33     |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.066    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 3.09     |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00856  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 803      |\n",
      "|    total_reward       | 5.69e+04 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 8356     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | -0.187   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -1.82    |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.00491  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 6.84     |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.0494   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -2.8     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 5.44     |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.0265   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.76e+04 |\n",
      "|    total_cost         | 592      |\n",
      "|    total_reward       | 4.76e+04 |\n",
      "|    total_reward_pct   | 95.3     |\n",
      "|    total_trades       | 8633     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | 0.0604   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 6.52     |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.0404   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.5      |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.00444  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+05 |\n",
      "|    total_cost         | 776      |\n",
      "|    total_reward       | 7.14e+04 |\n",
      "|    total_reward_pct   | 143      |\n",
      "|    total_trades       | 9028     |\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -1.5     |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.00163  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.98     |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.00563  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | -0.307   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 4.85     |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.1e+04  |\n",
      "|    total_cost         | 511      |\n",
      "|    total_reward       | 3.1e+04  |\n",
      "|    total_reward_pct   | 62       |\n",
      "|    total_trades       | 9740     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 1.25     |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.877   |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.00291  |\n",
      "------------------------------------\n",
      "day: 1255, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 72566.07\n",
      "total_reward: 22566.07\n",
      "total_cost: 434.12\n",
      "total_trades: 9220\n",
      "Sharpe: 0.445\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.26e+04 |\n",
      "|    total_cost         | 434      |\n",
      "|    total_reward       | 2.26e+04 |\n",
      "|    total_reward_pct   | 45.1     |\n",
      "|    total_trades       | 9220     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.125    |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 2.5      |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.0129   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 1.99     |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 0.0044   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.17e+05 |\n",
      "|    total_cost         | 608      |\n",
      "|    total_reward       | 6.71e+04 |\n",
      "|    total_reward_pct   | 134      |\n",
      "|    total_trades       | 9649     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 12.2     |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -6.11    |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.0296   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 641      |\n",
      "|    total_reward       | 5.88e+04 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 9952     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.00574  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 4.32     |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.0291   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 338       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 2.14      |\n",
      "|    std                | 1.82      |\n",
      "|    value_loss         | 0.00545   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 503      |\n",
      "|    total_reward       | 6.61e+04 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 9623     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | -2.5e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.0533  |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.00225  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 5.14     |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.0466   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 652      |\n",
      "|    total_reward       | 6.76e+04 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 9957     |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | -0.035   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 2.98     |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.00782  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -9.21    |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.0687   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 6.38     |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.0275   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 139656.88\n",
      "total_reward: 89656.88\n",
      "total_cost: 622.69\n",
      "total_trades: 10427\n",
      "Sharpe: 1.241\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.4e+05  |\n",
      "|    total_cost         | 623      |\n",
      "|    total_reward       | 8.97e+04 |\n",
      "|    total_reward_pct   | 179      |\n",
      "|    total_trades       | 10427    |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.506   |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.00127  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | -0.736   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.3e+05  |\n",
      "|    total_cost         | 870      |\n",
      "|    total_reward       | 8.05e+04 |\n",
      "|    total_reward_pct   | 161      |\n",
      "|    total_trades       | 10444    |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | -0.00849 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 2.37     |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.00538  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | -31.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -3.3     |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.0232   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.00354  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.06e+04  |\n",
      "|    total_cost         | 630       |\n",
      "|    total_reward       | 3.06e+04  |\n",
      "|    total_reward_pct   | 61.3      |\n",
      "|    total_trades       | 10699     |\n",
      "| time/                 |           |\n",
      "|    fps                | 337       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -0.773    |\n",
      "|    std                | 2.01      |\n",
      "|    value_loss         | 0.000673  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | -0.904   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.0324   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.36e+05 |\n",
      "|    total_cost         | 1.09e+03 |\n",
      "|    total_reward       | 8.62e+04 |\n",
      "|    total_reward_pct   | 172      |\n",
      "|    total_trades       | 10866    |\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | -0.304   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -4.49    |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.0191   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | -0.397   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -14      |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.297    |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 0.00196  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.35e+04 |\n",
      "|    total_cost         | 605      |\n",
      "|    total_reward       | 4.35e+04 |\n",
      "|    total_reward_pct   | 87.1     |\n",
      "|    total_trades       | 10927    |\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.632    |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.00254  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | -0.863   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -9.25    |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.0536   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 144923.52\n",
      "total_reward: 94923.52\n",
      "total_cost: 1125.57\n",
      "total_trades: 11402\n",
      "Sharpe: 1.283\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.45e+05 |\n",
      "|    total_cost         | 1.13e+03 |\n",
      "|    total_reward       | 9.49e+04 |\n",
      "|    total_reward_pct   | 190      |\n",
      "|    total_trades       | 11402    |\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | -24.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -9.76    |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.0805   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -1.08    |\n",
      "|    std                | 2.14     |\n",
      "|    value_loss         | 0.00817  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | -0.328   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 2.15     |\n",
      "|    value_loss         | 0.0831   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.38e+05 |\n",
      "|    total_cost         | 1e+03    |\n",
      "|    total_reward       | 8.84e+04 |\n",
      "|    total_reward_pct   | 177      |\n",
      "|    total_trades       | 11182    |\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -3.21    |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.00697  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -7.83    |\n",
      "|    std                | 2.19     |\n",
      "|    value_loss         | 0.0353   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.25e+05 |\n",
      "|    total_cost         | 840      |\n",
      "|    total_reward       | 7.47e+04 |\n",
      "|    total_reward_pct   | 149      |\n",
      "|    total_trades       | 11414    |\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | -6.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 6.11     |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.0364   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 3.92     |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.0108   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 5.98     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.0247   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 873      |\n",
      "|    total_reward       | 5.39e+04 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 11198    |\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 5.95     |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.0242   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0323  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 2.39     |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.00405  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 1.02e+03 |\n",
      "|    total_reward       | 5.73e+04 |\n",
      "|    total_reward_pct   | 115      |\n",
      "|    total_trades       | 11411    |\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -37      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -5.65    |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.0489   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0017   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 2.12     |\n",
      "|    std                | 2.31     |\n",
      "|    value_loss         | 0.013    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 6.51     |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 99501.83\n",
      "total_reward: 49501.83\n",
      "total_cost: 1029.55\n",
      "total_trades: 11756\n",
      "Sharpe: 0.853\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.95e+04 |\n",
      "|    total_cost         | 1.03e+03 |\n",
      "|    total_reward       | 4.95e+04 |\n",
      "|    total_reward_pct   | 99       |\n",
      "|    total_trades       | 11756    |\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0233  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -5.9     |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.0209   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.0809   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.8e+04  |\n",
      "|    total_cost         | 946      |\n",
      "|    total_reward       | 4.8e+04  |\n",
      "|    total_reward_pct   | 95.9     |\n",
      "|    total_trades       | 12309    |\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 2.38     |\n",
      "|    std                | 2.4      |\n",
      "|    value_loss         | 0.0039   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0.00111  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.00557  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.884    |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 0.00595  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 926      |\n",
      "|    total_reward       | 6.96e+04 |\n",
      "|    total_reward_pct   | 139      |\n",
      "|    total_trades       | 12552    |\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -0.055   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.148   |\n",
      "|    std                | 2.47     |\n",
      "|    value_loss         | 0.00577  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 3.08     |\n",
      "|    std                | 2.49     |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 6.76     |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.0251   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.8e+04  |\n",
      "|    total_cost         | 945      |\n",
      "|    total_reward       | 4.8e+04  |\n",
      "|    total_reward_pct   | 96       |\n",
      "|    total_trades       | 12672    |\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | -0.00899 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 6.87     |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.0308   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -6.86    |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.0323   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.7e+04  |\n",
      "|    total_cost         | 735      |\n",
      "|    total_reward       | 2.7e+04  |\n",
      "|    total_reward_pct   | 54.1     |\n",
      "|    total_trades       | 12314    |\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -2.91    |\n",
      "|    std                | 2.59     |\n",
      "|    value_loss         | 0.00752  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -3.18    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.0082   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 336       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -2.41     |\n",
      "|    std                | 2.63      |\n",
      "|    value_loss         | 0.00312   |\n",
      "-------------------------------------\n",
      "day: 1255, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110264.65\n",
      "total_reward: 60264.65\n",
      "total_cost: 950.69\n",
      "total_trades: 12574\n",
      "Sharpe: 1.006\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 951      |\n",
      "|    total_reward       | 6.03e+04 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 12574    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | -0.0943  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 7.3      |\n",
      "|    std                | 2.65     |\n",
      "|    value_loss         | 0.0302   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | -0.102   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -4.33    |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.0262   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 1e+03    |\n",
      "|    total_reward       | 6.18e+04 |\n",
      "|    total_reward_pct   | 124      |\n",
      "|    total_trades       | 12652    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0.0142   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 7.54     |\n",
      "|    std                | 2.7      |\n",
      "|    value_loss         | 0.0305   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | -0.082   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 3.08     |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 2.13     |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 0.00746  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 1.43e+03 |\n",
      "|    total_reward       | 5.98e+04 |\n",
      "|    total_reward_pct   | 120      |\n",
      "|    total_trades       | 12652    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 2.76     |\n",
      "|    value_loss         | 0.0715   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | -0.00135 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 13.7     |\n",
      "|    std                | 2.78     |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 1.37e+03 |\n",
      "|    total_reward       | 5.85e+04 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 12524    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0.0945   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -3.29    |\n",
      "|    std                | 2.8      |\n",
      "|    value_loss         | 0.00565  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -1.48    |\n",
      "|    std                | 2.83     |\n",
      "|    value_loss         | 0.00253  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 2.69      |\n",
      "|    std                | 2.85      |\n",
      "|    value_loss         | 0.00924   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 1.34e+03 |\n",
      "|    total_reward       | 5.26e+04 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 12474    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 6.31     |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | -0.394   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 8.14     |\n",
      "|    std                | 2.9      |\n",
      "|    value_loss         | 0.0326   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 78360.82\n",
      "total_reward: 28360.82\n",
      "total_cost: 850.72\n",
      "total_trades: 12926\n",
      "Sharpe: 0.495\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.84e+04 |\n",
      "|    total_cost         | 851      |\n",
      "|    total_reward       | 2.84e+04 |\n",
      "|    total_reward_pct   | 56.7     |\n",
      "|    total_trades       | 12926    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 2.58     |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 0.00379  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 0.0035   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -9.12     |\n",
      "|    std                | 2.98      |\n",
      "|    value_loss         | 0.0416    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.55e+04 |\n",
      "|    total_cost         | 1.03e+03 |\n",
      "|    total_reward       | 3.55e+04 |\n",
      "|    total_reward_pct   | 71       |\n",
      "|    total_trades       | 13027    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -5.19    |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.0104   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -2.98    |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.00801  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.24e+04 |\n",
      "|    total_cost         | 1.2e+03  |\n",
      "|    total_reward       | 4.24e+04 |\n",
      "|    total_reward_pct   | 84.7     |\n",
      "|    total_trades       | 12919    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -5.53    |\n",
      "|    std                | 3.05     |\n",
      "|    value_loss         | 0.0196   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | -0.0149  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 3.06     |\n",
      "|    value_loss         | 0.0802   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -6.15    |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.0266   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 1.42e+03 |\n",
      "|    total_reward       | 5.57e+04 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 13063    |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -2.56    |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.0098   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -3.43    |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.0248   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 1.39e+03 |\n",
      "|    total_reward       | 6.34e+04 |\n",
      "|    total_reward_pct   | 127      |\n",
      "|    total_trades       | 13521    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 5.59     |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 9.21     |\n",
      "|    std                | 3.19     |\n",
      "|    value_loss         | 0.0746   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0.123    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -2.99    |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.00596  |\n",
      "------------------------------------\n",
      "day: 1255, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 109977.89\n",
      "total_reward: 59977.89\n",
      "total_cost: 1251.17\n",
      "total_trades: 14117\n",
      "Sharpe: 0.927\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+05  |\n",
      "|    total_cost         | 1.25e+03 |\n",
      "|    total_reward       | 6e+04    |\n",
      "|    total_reward_pct   | 120      |\n",
      "|    total_trades       | 14117    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    std                | 3.24     |\n",
      "|    value_loss         | 0.00703  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -3.2     |\n",
      "|    std                | 3.27     |\n",
      "|    value_loss         | 0.0187   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.78e+04  |\n",
      "|    total_cost         | 875       |\n",
      "|    total_reward       | 2.78e+04  |\n",
      "|    total_reward_pct   | 55.5      |\n",
      "|    total_trades       | 13886     |\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 0.235     |\n",
      "|    std                | 3.29      |\n",
      "|    value_loss         | 0.0022    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 1.84     |\n",
      "|    std                | 3.31     |\n",
      "|    value_loss         | 0.00324  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0.43    |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.00158  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 1e+03    |\n",
      "|    total_reward       | 5.19e+04 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 14252    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | -0.148   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 2.79     |\n",
      "|    std                | 3.36     |\n",
      "|    value_loss         | 0.006    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -9.87    |\n",
      "|    std                | 3.39     |\n",
      "|    value_loss         | 0.0563   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 1.17e+03 |\n",
      "|    total_reward       | 5.63e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 14346    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.721    |\n",
      "|    std                | 3.41     |\n",
      "|    value_loss         | 0.00086  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 3.51      |\n",
      "|    std                | 3.44      |\n",
      "|    value_loss         | 0.013     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 3.47     |\n",
      "|    value_loss         | 0.00298  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.87e+04 |\n",
      "|    total_cost         | 1.09e+03 |\n",
      "|    total_reward       | 3.87e+04 |\n",
      "|    total_reward_pct   | 77.4     |\n",
      "|    total_trades       | 14054    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 13.3     |\n",
      "|    std                | 3.5      |\n",
      "|    value_loss         | 0.067    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.9    |\n",
      "|    explained_variance | -0.157   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -2.82    |\n",
      "|    std                | 3.53     |\n",
      "|    value_loss         | 0.0233   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85339.52\n",
      "total_reward: 35339.52\n",
      "total_cost: 1303.97\n",
      "total_trades: 14148\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.53e+04  |\n",
      "|    total_cost         | 1.3e+03   |\n",
      "|    total_reward       | 3.53e+04  |\n",
      "|    total_reward_pct   | 70.7      |\n",
      "|    total_trades       | 14148     |\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -2.27     |\n",
      "|    std                | 3.56      |\n",
      "|    value_loss         | 0.00221   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 5.32     |\n",
      "|    std                | 3.58     |\n",
      "|    value_loss         | 0.043    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | -0.734   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -4.97    |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.91e+04 |\n",
      "|    total_cost         | 1.59e+03 |\n",
      "|    total_reward       | 4.91e+04 |\n",
      "|    total_reward_pct   | 98.1     |\n",
      "|    total_trades       | 14127    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 10.2     |\n",
      "|    std                | 3.64     |\n",
      "|    value_loss         | 0.043    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 4.67     |\n",
      "|    std                | 3.67     |\n",
      "|    value_loss         | 0.00954  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 1.52e+03 |\n",
      "|    total_reward       | 5.22e+04 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 14220    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.7    |\n",
      "|    explained_variance | -0.0578  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 3.69     |\n",
      "|    value_loss         | 0.00293  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    std                | 3.72     |\n",
      "|    value_loss         | 0.00613  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 236       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52       |\n",
      "|    explained_variance | -9.18e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | 3.78      |\n",
      "|    std                | 3.75      |\n",
      "|    value_loss         | 0.00626   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 2.1e+03  |\n",
      "|    total_reward       | 6.32e+04 |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 13967    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 0.142    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -1.43    |\n",
      "|    std                | 3.78     |\n",
      "|    value_loss         | 0.00721  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0.0371   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 2.33     |\n",
      "|    std                | 3.8      |\n",
      "|    value_loss         | 0.0216   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 1.93e+03 |\n",
      "|    total_reward       | 5.47e+04 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 14245    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | -0.689   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.838   |\n",
      "|    std                | 3.83     |\n",
      "|    value_loss         | 0.00106  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -4.52    |\n",
      "|    std                | 3.86     |\n",
      "|    value_loss         | 0.0102   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 10.2     |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 0.0502   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 120416.32\n",
      "total_reward: 70416.32\n",
      "total_cost: 2162.38\n",
      "total_trades: 14416\n",
      "Sharpe: 1.015\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 2.16e+03 |\n",
      "|    total_reward       | 7.04e+04 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 14416    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 8.83     |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.0361   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 6.03     |\n",
      "|    std                | 3.95     |\n",
      "|    value_loss         | 0.0222   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.79e+04 |\n",
      "|    total_cost         | 1.78e+03 |\n",
      "|    total_reward       | 3.79e+04 |\n",
      "|    total_reward_pct   | 75.9     |\n",
      "|    total_trades       | 14249    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -1.61    |\n",
      "|    std                | 3.98     |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -5.48    |\n",
      "|    std                | 4.01     |\n",
      "|    value_loss         | 0.0105   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 5.16     |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 0.0111   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.22e+05  |\n",
      "|    total_cost         | 2.42e+03  |\n",
      "|    total_reward       | 7.24e+04  |\n",
      "|    total_reward_pct   | 145       |\n",
      "|    total_trades       | 14585     |\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 252       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | -1.59     |\n",
      "|    std                | 4.07      |\n",
      "|    value_loss         | 0.00164   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.196   |\n",
      "|    std                | 4.1      |\n",
      "|    value_loss         | 0.00273  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.49e+04 |\n",
      "|    total_cost         | 1.9e+03  |\n",
      "|    total_reward       | 4.49e+04 |\n",
      "|    total_reward_pct   | 89.8     |\n",
      "|    total_trades       | 14284    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0.957    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -5.18    |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 0.00964  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 7.55     |\n",
      "|    std                | 4.17     |\n",
      "|    value_loss         | 0.023    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | -2.3     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 0.826    |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 0.00378  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 2.47e+03 |\n",
      "|    total_reward       | 6.12e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 14420    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -2.2     |\n",
      "|    std                | 4.24     |\n",
      "|    value_loss         | 0.00526  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | -3.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 4.28     |\n",
      "|    value_loss         | 0.00399  |\n",
      "------------------------------------\n",
      "day: 1255, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89379.81\n",
      "total_reward: 39379.81\n",
      "total_cost: 2151.34\n",
      "total_trades: 14175\n",
      "Sharpe: 0.627\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.94e+04 |\n",
      "|    total_cost         | 2.15e+03 |\n",
      "|    total_reward       | 3.94e+04 |\n",
      "|    total_reward_pct   | 78.8     |\n",
      "|    total_trades       | 14175    |\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -4       |\n",
      "|    std                | 4.3      |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -3.51    |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.0166   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -6.89    |\n",
      "|    std                | 4.38     |\n",
      "|    value_loss         | 0.0203   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 3.45e+03 |\n",
      "|    total_reward       | 6.41e+04 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 14516    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -8.76    |\n",
      "|    std                | 4.42     |\n",
      "|    value_loss         | 0.0307   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.3    |\n",
      "|    explained_variance | -0.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -23.6    |\n",
      "|    std                | 4.46     |\n",
      "|    value_loss         | 0.247    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.82e+04 |\n",
      "|    total_cost         | 2.63e+03 |\n",
      "|    total_reward       | 2.82e+04 |\n",
      "|    total_reward_pct   | 56.3     |\n",
      "|    total_trades       | 13830    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | -0.0753  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 2.64     |\n",
      "|    std                | 4.49     |\n",
      "|    value_loss         | 0.00763  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | -1.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -3.86    |\n",
      "|    std                | 4.53     |\n",
      "|    value_loss         | 0.00837  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | -0.817   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 3.22     |\n",
      "|    std                | 4.56     |\n",
      "|    value_loss         | 0.00956  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.11e+04 |\n",
      "|    total_cost         | 3e+03    |\n",
      "|    total_reward       | 4.11e+04 |\n",
      "|    total_reward_pct   | 82.3     |\n",
      "|    total_trades       | 13767    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -3.85    |\n",
      "|    std                | 4.6      |\n",
      "|    value_loss         | 0.00551  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 333       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 276       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -0.232    |\n",
      "|    std                | 4.64      |\n",
      "|    value_loss         | 0.00145   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.68e+04 |\n",
      "|    total_cost         | 2.37e+03 |\n",
      "|    total_reward       | 2.68e+04 |\n",
      "|    total_reward_pct   | 53.6     |\n",
      "|    total_trades       | 13596    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | -3.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 6.28     |\n",
      "|    std                | 4.67     |\n",
      "|    value_loss         | 0.0151   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 4.72     |\n",
      "|    value_loss         | 0.0507   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.5    |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 4.75     |\n",
      "|    value_loss         | 0.0046   |\n",
      "------------------------------------\n",
      "day: 1255, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103811.23\n",
      "total_reward: 53811.23\n",
      "total_cost: 5322.51\n",
      "total_trades: 13811\n",
      "Sharpe: 0.885\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 5.32e+03 |\n",
      "|    total_reward       | 5.38e+04 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 13811    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.7    |\n",
      "|    explained_variance | -0.329   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 2.45     |\n",
      "|    std                | 4.78     |\n",
      "|    value_loss         | 0.00839  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 10.4     |\n",
      "|    std                | 4.83     |\n",
      "|    value_loss         | 0.0404   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.98e+04 |\n",
      "|    total_cost         | 3.93e+03 |\n",
      "|    total_reward       | 2.98e+04 |\n",
      "|    total_reward_pct   | 59.6     |\n",
      "|    total_trades       | 13776    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | -0.0555  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.256   |\n",
      "|    std                | 4.87     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | 0.0879   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -4.87    |\n",
      "|    std                | 4.92     |\n",
      "|    value_loss         | 0.00897  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | -0.253   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 3.76     |\n",
      "|    std                | 4.96     |\n",
      "|    value_loss         | 0.00696  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.59e+04 |\n",
      "|    total_cost         | 9.85e+03 |\n",
      "|    total_reward       | 4.59e+04 |\n",
      "|    total_reward_pct   | 91.8     |\n",
      "|    total_trades       | 14907    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 0.418    |\n",
      "|    std                | 5        |\n",
      "|    value_loss         | 0.00345  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 333       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 291       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -2.72     |\n",
      "|    std                | 5.05      |\n",
      "|    value_loss         | 0.00287   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.81e+04 |\n",
      "|    total_cost         | 1.01e+04 |\n",
      "|    total_reward       | 1.81e+04 |\n",
      "|    total_reward_pct   | 36.1     |\n",
      "|    total_trades       | 15010    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.9    |\n",
      "|    explained_variance | -0.085   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 7.8      |\n",
      "|    std                | 5.1      |\n",
      "|    value_loss         | 0.0261   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -2.99    |\n",
      "|    std                | 5.15     |\n",
      "|    value_loss         | 0.00315  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -3.63    |\n",
      "|    std                | 5.21     |\n",
      "|    value_loss         | 0.00455  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.86e+04 |\n",
      "|    total_cost         | 9.2e+03  |\n",
      "|    total_reward       | 1.86e+04 |\n",
      "|    total_reward_pct   | 37.1     |\n",
      "|    total_trades       | 15321    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.5    |\n",
      "|    explained_variance | -5.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    std                | 5.26     |\n",
      "|    value_loss         | 0.00237  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -4.88    |\n",
      "|    std                | 5.32     |\n",
      "|    value_loss         | 0.0071   |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-01-03 to  2020-04-06\n",
      "A2C Sharpe Ratio:  -0.1331071111693907\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.07e+04 |\n",
      "|    total_cost       | 1.08e+04 |\n",
      "|    total_reward     | 2.07e+04 |\n",
      "|    total_reward_pct | 41.5     |\n",
      "|    total_trades     | 6993     |\n",
      "| time/               |          |\n",
      "|    fps              | 423      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.23e+04    |\n",
      "|    total_cost           | 1.06e+04    |\n",
      "|    total_reward         | 3.23e+04    |\n",
      "|    total_reward_pct     | 64.6        |\n",
      "|    total_trades         | 6983        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012362321 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -1.18       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0616      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.39e+04    |\n",
      "|    total_cost           | 1.29e+04    |\n",
      "|    total_reward         | 4.39e+04    |\n",
      "|    total_reward_pct     | 87.9        |\n",
      "|    total_trades         | 7005        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015204409 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.311      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0268      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 84087.06\n",
      "total_reward: 34087.06\n",
      "total_cost: 10733.87\n",
      "total_trades: 7049\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 1.09e+04    |\n",
      "|    total_reward         | 5.27e+04    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 7190        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014736651 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0257      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.66e+04    |\n",
      "|    total_cost           | 1.09e+04    |\n",
      "|    total_reward         | 4.66e+04    |\n",
      "|    total_reward_pct     | 93.1        |\n",
      "|    total_trades         | 7058        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015932795 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 1.02e+04    |\n",
      "|    total_reward         | 7.01e+04    |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 7194        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016563319 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0206      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97153.81\n",
      "total_reward: 47153.81\n",
      "total_cost: 8680.73\n",
      "total_trades: 6957\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+05    |\n",
      "|    total_cost           | 9.96e+03    |\n",
      "|    total_reward         | 6.2e+04     |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 7152        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021301743 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0209      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.66e+04    |\n",
      "|    total_cost           | 1.02e+04    |\n",
      "|    total_reward         | 3.66e+04    |\n",
      "|    total_reward_pct     | 73.2        |\n",
      "|    total_trades         | 7087        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018357804 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0294      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.9e+04     |\n",
      "|    total_cost           | 1.11e+04    |\n",
      "|    total_reward         | 4.9e+04     |\n",
      "|    total_reward_pct     | 98          |\n",
      "|    total_trades         | 7163        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015296188 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.315      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 133481.57\n",
      "total_reward: 83481.57\n",
      "total_cost: 10370.94\n",
      "total_trades: 7028\n",
      "Sharpe: 1.269\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+05    |\n",
      "|    total_cost           | 9.93e+03    |\n",
      "|    total_reward         | 7.24e+04    |\n",
      "|    total_reward_pct     | 145         |\n",
      "|    total_trades         | 7148        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022289224 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.027       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 9.59e+03    |\n",
      "|    total_reward         | 5.33e+04    |\n",
      "|    total_reward_pct     | 107         |\n",
      "|    total_trades         | 7101        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017778922 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0318      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.47e+04    |\n",
      "|    total_cost           | 6.12e+03    |\n",
      "|    total_reward         | 4.47e+04    |\n",
      "|    total_reward_pct     | 89.4        |\n",
      "|    total_trades         | 6989        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020482428 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.261      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0325      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 84061.31\n",
      "total_reward: 34061.31\n",
      "total_cost: 7462.53\n",
      "total_trades: 6980\n",
      "Sharpe: 0.648\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.4e+04    |\n",
      "|    total_cost           | 7.64e+03   |\n",
      "|    total_reward         | 2.4e+04    |\n",
      "|    total_reward_pct     | 48.1       |\n",
      "|    total_trades         | 6906       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 395        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01775398 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0384     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 9.27e+03    |\n",
      "|    total_reward         | 5.15e+04    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 7179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024280354 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.22e+05     |\n",
      "|    total_cost           | 1.03e+04     |\n",
      "|    total_reward         | 7.21e+04     |\n",
      "|    total_reward_pct     | 144          |\n",
      "|    total_trades         | 7415         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 394          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142639475 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.5        |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.278       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0297       |\n",
      "------------------------------------------\n",
      "day: 1255, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90383.87\n",
      "total_reward: 40383.87\n",
      "total_cost: 9266.79\n",
      "total_trades: 7125\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.08e+04   |\n",
      "|    total_cost           | 1.02e+04   |\n",
      "|    total_reward         | 4.08e+04   |\n",
      "|    total_reward_pct     | 81.6       |\n",
      "|    total_trades         | 7193       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 394        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02749177 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.297     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0327     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.67e+04    |\n",
      "|    total_cost           | 1e+04       |\n",
      "|    total_reward         | 4.67e+04    |\n",
      "|    total_reward_pct     | 93.3        |\n",
      "|    total_trades         | 7342        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021136023 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0267      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.03e+04    |\n",
      "|    total_cost           | 1.05e+04    |\n",
      "|    total_reward         | 2.03e+04    |\n",
      "|    total_reward_pct     | 40.6        |\n",
      "|    total_trades         | 7299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012359465 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0247      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 64845.06\n",
      "total_reward: 14845.06\n",
      "total_cost: 5771.55\n",
      "total_trades: 6920\n",
      "Sharpe: 0.359\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.48e+04    |\n",
      "|    total_cost           | 5.77e+03    |\n",
      "|    total_reward         | 1.48e+04    |\n",
      "|    total_reward_pct     | 29.7        |\n",
      "|    total_trades         | 6920        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024375118 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0181      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.83e+04   |\n",
      "|    total_cost           | 1.2e+04    |\n",
      "|    total_reward         | 4.83e+04   |\n",
      "|    total_reward_pct     | 96.6       |\n",
      "|    total_trades         | 7303       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 393        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02839232 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0186     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| environment/            |          |\n",
      "|    portfolio_value      | 8.33e+04 |\n",
      "|    total_cost           | 8.95e+03 |\n",
      "|    total_reward         | 3.33e+04 |\n",
      "|    total_reward_pct     | 66.6     |\n",
      "|    total_trades         | 7284     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 392      |\n",
      "|    iterations           | 21       |\n",
      "|    time_elapsed         | 109      |\n",
      "|    total_timesteps      | 43008    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.023208 |\n",
      "|    clip_fraction        | 0.238    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -27.6    |\n",
      "|    explained_variance   | 0.391    |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | -0.271   |\n",
      "|    n_updates            | 200      |\n",
      "|    policy_gradient_loss | -0.0192  |\n",
      "|    std                  | 1.04     |\n",
      "|    value_loss           | 0.0252   |\n",
      "--------------------------------------\n",
      "day: 1255, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 104100.44\n",
      "total_reward: 54100.44\n",
      "total_cost: 9620.47\n",
      "total_trades: 7191\n",
      "Sharpe: 0.932\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+05    |\n",
      "|    total_cost           | 9.62e+03    |\n",
      "|    total_reward         | 5.41e+04    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 7191        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029987404 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 9.24e+03    |\n",
      "|    total_reward         | 5.18e+04    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 7166        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026427146 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0321      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.25e+04   |\n",
      "|    total_cost           | 8.37e+03   |\n",
      "|    total_reward         | 4.25e+04   |\n",
      "|    total_reward_pct     | 85         |\n",
      "|    total_trades         | 7210       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 391        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 125        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01494776 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0284     |\n",
      "----------------------------------------\n",
      "day: 1255, episode: 120\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 78131.63\n",
      "total_reward: 28131.63\n",
      "total_cost: 6223.71\n",
      "total_trades: 7028\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.81e+04    |\n",
      "|    total_cost           | 6.22e+03    |\n",
      "|    total_reward         | 2.81e+04    |\n",
      "|    total_reward_pct     | 56.3        |\n",
      "|    total_trades         | 7028        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016152881 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0253      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.01e+04   |\n",
      "|    total_cost           | 7.07e+03   |\n",
      "|    total_reward         | 2.01e+04   |\n",
      "|    total_reward_pct     | 40.2       |\n",
      "|    total_trades         | 7110       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 390        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03060573 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.295     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0318     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.36e+05    |\n",
      "|    total_cost           | 9.57e+03    |\n",
      "|    total_reward         | 8.58e+04    |\n",
      "|    total_reward_pct     | 172         |\n",
      "|    total_trades         | 7109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 390         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027764298 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0271      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 125\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97677.80\n",
      "total_reward: 47677.80\n",
      "total_cost: 9203.89\n",
      "total_trades: 7081\n",
      "Sharpe: 0.874\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.77e+04   |\n",
      "|    total_cost           | 9.2e+03    |\n",
      "|    total_reward         | 4.77e+04   |\n",
      "|    total_reward_pct     | 95.4       |\n",
      "|    total_trades         | 7081       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 390        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 146        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03506265 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.251      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.297     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0421     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.21e+05   |\n",
      "|    total_cost           | 9.96e+03   |\n",
      "|    total_reward         | 7.15e+04   |\n",
      "|    total_reward_pct     | 143        |\n",
      "|    total_trades         | 7113       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 390        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 152        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02686229 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.462      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.29      |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0289     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.55e+04    |\n",
      "|    total_cost           | 8.52e+03    |\n",
      "|    total_reward         | 4.55e+04    |\n",
      "|    total_reward_pct     | 91          |\n",
      "|    total_trades         | 7179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018237438 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0339      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 130\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 115746.53\n",
      "total_reward: 65746.53\n",
      "total_cost: 9346.98\n",
      "total_trades: 7110\n",
      "Sharpe: 1.101\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.16e+05   |\n",
      "|    total_cost           | 9.35e+03   |\n",
      "|    total_reward         | 6.57e+04   |\n",
      "|    total_reward_pct     | 131        |\n",
      "|    total_trades         | 7110       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 389        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03339367 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.289     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0282     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.85e+04    |\n",
      "|    total_cost           | 1.11e+04    |\n",
      "|    total_reward         | 4.85e+04    |\n",
      "|    total_reward_pct     | 97.1        |\n",
      "|    total_trades         | 7164        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022213843 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 9.22e+03    |\n",
      "|    total_reward         | 5.1e+04     |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 7022        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022813637 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0331      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 135\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 81354.36\n",
      "total_reward: 31354.36\n",
      "total_cost: 9034.08\n",
      "total_trades: 7024\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.14e+04    |\n",
      "|    total_cost           | 9.03e+03    |\n",
      "|    total_reward         | 3.14e+04    |\n",
      "|    total_reward_pct     | 62.7        |\n",
      "|    total_trades         | 7024        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028670596 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0223      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.74e+04    |\n",
      "|    total_cost           | 7.9e+03     |\n",
      "|    total_reward         | 2.74e+04    |\n",
      "|    total_reward_pct     | 54.9        |\n",
      "|    total_trades         | 7176        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018201593 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0224      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 8.98e+03    |\n",
      "|    total_reward         | 6.79e+04    |\n",
      "|    total_reward_pct     | 136         |\n",
      "|    total_trades         | 7345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044044256 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.269      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0185      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 140\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82642.90\n",
      "total_reward: 32642.90\n",
      "total_cost: 9579.91\n",
      "total_trades: 7206\n",
      "Sharpe: 0.613\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.26e+04    |\n",
      "|    total_cost           | 9.58e+03    |\n",
      "|    total_reward         | 3.26e+04    |\n",
      "|    total_reward_pct     | 65.3        |\n",
      "|    total_trades         | 7206        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025013812 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0221      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 7.73e+03    |\n",
      "|    total_reward         | 6.97e+04    |\n",
      "|    total_reward_pct     | 139         |\n",
      "|    total_trades         | 7225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020848114 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.09e+05   |\n",
      "|    total_cost           | 9.35e+03   |\n",
      "|    total_reward         | 5.88e+04   |\n",
      "|    total_reward_pct     | 118        |\n",
      "|    total_trades         | 7327       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 388        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02621961 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.446      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0276     |\n",
      "----------------------------------------\n",
      "day: 1255, episode: 145\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 64579.39\n",
      "total_reward: 14579.39\n",
      "total_cost: 7976.43\n",
      "total_trades: 7179\n",
      "Sharpe: 0.355\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.46e+04    |\n",
      "|    total_cost           | 7.98e+03    |\n",
      "|    total_reward         | 1.46e+04    |\n",
      "|    total_reward_pct     | 29.2        |\n",
      "|    total_trades         | 7179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023557326 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0231      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.75e+04    |\n",
      "|    total_cost           | 8.56e+03    |\n",
      "|    total_reward         | 3.75e+04    |\n",
      "|    total_reward_pct     | 75.1        |\n",
      "|    total_trades         | 7273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034906007 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0188      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.51e+04    |\n",
      "|    total_cost           | 5.78e+03    |\n",
      "|    total_reward         | 1.51e+04    |\n",
      "|    total_reward_pct     | 30.3        |\n",
      "|    total_trades         | 7238        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018832643 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0211      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 150\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92671.30\n",
      "total_reward: 42671.30\n",
      "total_cost: 6448.84\n",
      "total_trades: 7328\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.27e+04    |\n",
      "|    total_cost           | 6.45e+03    |\n",
      "|    total_reward         | 4.27e+04    |\n",
      "|    total_reward_pct     | 85.3        |\n",
      "|    total_trades         | 7328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030314025 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0259      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.3e+05    |\n",
      "|    total_cost           | 8.47e+03   |\n",
      "|    total_reward         | 8.02e+04   |\n",
      "|    total_reward_pct     | 160        |\n",
      "|    total_trades         | 7381       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 387        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02935842 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.29      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0298     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 5.9e+03     |\n",
      "|    total_reward         | 5.23e+04    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 7254        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038251586 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0335      |\n",
      "-----------------------------------------\n",
      "day: 1255, episode: 155\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70929.11\n",
      "total_reward: 20929.11\n",
      "total_cost: 4920.50\n",
      "total_trades: 7138\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.09e+04    |\n",
      "|    total_cost           | 4.92e+03    |\n",
      "|    total_reward         | 2.09e+04    |\n",
      "|    total_reward_pct     | 41.9        |\n",
      "|    total_trades         | 7138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028495058 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0263      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 7.52e+03    |\n",
      "|    total_reward         | 6.31e+04    |\n",
      "|    total_reward_pct     | 126         |\n",
      "|    total_trades         | 7500        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035094205 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.15e+05    |\n",
      "|    total_cost           | 7.4e+03     |\n",
      "|    total_reward         | 6.46e+04    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 7290        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032331537 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.033       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.91e+04    |\n",
      "|    total_cost           | 5.93e+03    |\n",
      "|    total_reward         | 4.91e+04    |\n",
      "|    total_reward_pct     | 98.2        |\n",
      "|    total_trades         | 7178        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037343696 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0255      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-01-03 to  2020-04-06\n",
      "PPO Sharpe Ratio:  -0.24759590697182235\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.63e+05 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 1.13e+05 |\n",
      "|    total_reward_pct | 226      |\n",
      "|    total_trades     | 7433     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total timesteps  | 5024     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -61.9    |\n",
      "|    critic_loss      | 516      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3768     |\n",
      "----------------------------------\n",
      "day: 1255, episode: 165\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 153435.45\n",
      "total_reward: 103435.45\n",
      "total_cost: 195.87\n",
      "total_trades: 6537\n",
      "Sharpe: 1.174\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.48e+05 |\n",
      "|    total_cost       | 97.6     |\n",
      "|    total_reward     | 9.79e+04 |\n",
      "|    total_reward_pct | 196      |\n",
      "|    total_trades     | 7115     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 127      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total timesteps  | 10048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -47.4    |\n",
      "|    critic_loss      | 90.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8792     |\n",
      "----------------------------------\n",
      "day: 1255, episode: 170\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 136612.72\n",
      "total_reward: 86612.72\n",
      "total_cost: 151.57\n",
      "total_trades: 8675\n",
      "Sharpe: 1.022\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.44e+05 |\n",
      "|    total_cost       | 481      |\n",
      "|    total_reward     | 9.45e+04 |\n",
      "|    total_reward_pct | 189      |\n",
      "|    total_trades     | 6722     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total timesteps  | 15072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -37.3    |\n",
      "|    critic_loss      | 22.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13816    |\n",
      "----------------------------------\n",
      "day: 1255, episode: 175\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 94575.52\n",
      "total_reward: 44575.52\n",
      "total_cost: 161.87\n",
      "total_trades: 7053\n",
      "Sharpe: 0.632\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.22e+05 |\n",
      "|    total_cost       | 268      |\n",
      "|    total_reward     | 7.16e+04 |\n",
      "|    total_reward_pct | 143      |\n",
      "|    total_trades     | 5940     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total timesteps  | 20096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -29.4    |\n",
      "|    critic_loss      | 9.19     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18840    |\n",
      "----------------------------------\n",
      "day: 1255, episode: 180\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 105448.11\n",
      "total_reward: 55448.11\n",
      "total_cost: 105.08\n",
      "total_trades: 6752\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.05e+05 |\n",
      "|    total_cost       | 105      |\n",
      "|    total_reward     | 5.54e+04 |\n",
      "|    total_reward_pct | 111      |\n",
      "|    total_trades     | 6752     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total timesteps  | 25120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -22.8    |\n",
      "|    critic_loss      | 4.46     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 23864    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.28e+04 |\n",
      "|    total_cost       | 129      |\n",
      "|    total_reward     | 4.28e+04 |\n",
      "|    total_reward_pct | 85.7     |\n",
      "|    total_trades     | 6714     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total timesteps  | 30144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -17.6    |\n",
      "|    critic_loss      | 3.24     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28888    |\n",
      "----------------------------------\n",
      "day: 1255, episode: 185\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 156451.97\n",
      "total_reward: 106451.97\n",
      "total_cost: 143.14\n",
      "total_trades: 8531\n",
      "Sharpe: 1.218\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.48e+05 |\n",
      "|    total_cost       | 101      |\n",
      "|    total_reward     | 9.79e+04 |\n",
      "|    total_reward_pct | 196      |\n",
      "|    total_trades     | 6314     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total timesteps  | 35168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -13.7    |\n",
      "|    critic_loss      | 1.91     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33912    |\n",
      "----------------------------------\n",
      "day: 1255, episode: 190\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113698.80\n",
      "total_reward: 63698.80\n",
      "total_cost: 108.38\n",
      "total_trades: 6017\n",
      "Sharpe: 0.772\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.92e+04 |\n",
      "|    total_cost       | 106      |\n",
      "|    total_reward     | 3.92e+04 |\n",
      "|    total_reward_pct | 78.4     |\n",
      "|    total_trades     | 4796     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total timesteps  | 40192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -10.9    |\n",
      "|    critic_loss      | 1.98     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 38936    |\n",
      "----------------------------------\n",
      "day: 1255, episode: 195\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 151655.90\n",
      "total_reward: 101655.90\n",
      "total_cost: 168.66\n",
      "total_trades: 4822\n",
      "Sharpe: 1.142\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.16e+05 |\n",
      "|    total_cost       | 181      |\n",
      "|    total_reward     | 6.55e+04 |\n",
      "|    total_reward_pct | 131      |\n",
      "|    total_trades     | 6223     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 383      |\n",
      "|    total timesteps  | 45216    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.55    |\n",
      "|    critic_loss      | 2.03     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43960    |\n",
      "----------------------------------\n",
      "day: 1255, episode: 200\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 137266.44\n",
      "total_reward: 87266.44\n",
      "total_cost: 177.55\n",
      "total_trades: 7590\n",
      "Sharpe: 1.044\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.37e+05 |\n",
      "|    total_cost       | 178      |\n",
      "|    total_reward     | 8.73e+04 |\n",
      "|    total_reward_pct | 175      |\n",
      "|    total_trades     | 7590     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 427      |\n",
      "|    total timesteps  | 50240    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.84    |\n",
      "|    critic_loss      | 1.95     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 48984    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-01-03 to  2020-04-06\n",
      "======Best Model Retraining from:  2015-01-01 to  2020-04-06\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_378_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.05e+04 |\n",
      "|    total_cost       | 103      |\n",
      "|    total_reward     | 2.05e+04 |\n",
      "|    total_reward_pct | 41       |\n",
      "|    total_trades     | 2822     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total timesteps  | 5276     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 56.5     |\n",
      "|    critic_loss      | 268      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3957     |\n",
      "----------------------------------\n",
      "day: 1318, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92207.52\n",
      "total_reward: 42207.52\n",
      "total_cost: 166.63\n",
      "total_trades: 4622\n",
      "Sharpe: 0.588\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.67e+04  |\n",
      "|    total_cost       | 113       |\n",
      "|    total_reward     | -1.33e+04 |\n",
      "|    total_reward_pct | -26.6     |\n",
      "|    total_trades     | 5247      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 84        |\n",
      "|    total timesteps  | 10552     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 22.7      |\n",
      "|    critic_loss      | 57        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 9233      |\n",
      "-----------------------------------\n",
      "day: 1318, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 111960.01\n",
      "total_reward: 61960.01\n",
      "total_cost: 125.23\n",
      "total_trades: 4937\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.81e+04 |\n",
      "|    total_cost       | 116      |\n",
      "|    total_reward     | 3.81e+04 |\n",
      "|    total_reward_pct | 76.2     |\n",
      "|    total_trades     | 4024     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total timesteps  | 15828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 14.4     |\n",
      "|    critic_loss      | 11       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 14509    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70684.42\n",
      "total_reward: 20684.42\n",
      "total_cost: 95.57\n",
      "total_trades: 7139\n",
      "Sharpe: 0.400\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.09e+05 |\n",
      "|    total_cost       | 149      |\n",
      "|    total_reward     | 5.92e+04 |\n",
      "|    total_reward_pct | 118      |\n",
      "|    total_trades     | 5530     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total timesteps  | 21104    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 10.2     |\n",
      "|    critic_loss      | 4.32     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19785    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 35296.91\n",
      "total_reward: -14703.09\n",
      "total_cost: 108.22\n",
      "total_trades: 3861\n",
      "Sharpe: -0.136\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.53e+04  |\n",
      "|    total_cost       | 108       |\n",
      "|    total_reward     | -1.47e+04 |\n",
      "|    total_reward_pct | -29.4     |\n",
      "|    total_trades     | 3861      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 221       |\n",
      "|    total timesteps  | 26380     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 7.11      |\n",
      "|    critic_loss      | 2.86      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 25061     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.64e+05 |\n",
      "|    total_cost       | 125      |\n",
      "|    total_reward     | 1.14e+05 |\n",
      "|    total_reward_pct | 228      |\n",
      "|    total_trades     | 4849     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total timesteps  | 31656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 5.07     |\n",
      "|    critic_loss      | 1.62     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 30337    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 141751.54\n",
      "total_reward: 91751.54\n",
      "total_cost: 139.99\n",
      "total_trades: 7753\n",
      "Sharpe: 0.941\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.19e+04 |\n",
      "|    total_cost       | 110      |\n",
      "|    total_reward     | 2.19e+04 |\n",
      "|    total_reward_pct | 43.9     |\n",
      "|    total_trades     | 3987     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total timesteps  | 36932    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.44     |\n",
      "|    critic_loss      | 1.19     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35613    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 140850.26\n",
      "total_reward: 90850.26\n",
      "total_cost: 104.40\n",
      "total_trades: 5929\n",
      "Sharpe: 0.941\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.1e+04  |\n",
      "|    total_cost       | 114      |\n",
      "|    total_reward     | 4.1e+04  |\n",
      "|    total_reward_pct | 82       |\n",
      "|    total_trades     | 5265     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total timesteps  | 42208    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.25     |\n",
      "|    critic_loss      | 1.47     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 40889    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89468.34\n",
      "total_reward: 39468.34\n",
      "total_cost: 106.24\n",
      "total_trades: 5965\n",
      "Sharpe: 0.597\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.14e+05 |\n",
      "|    total_cost       | 129      |\n",
      "|    total_reward     | 6.38e+04 |\n",
      "|    total_reward_pct | 128      |\n",
      "|    total_trades     | 5087     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 404      |\n",
      "|    total timesteps  | 47484    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.35     |\n",
      "|    critic_loss      | 1.16     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46165    |\n",
      "----------------------------------\n",
      "======Trading from:  2020-04-06 to  2020-07-09\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  529.7283042530553\n",
      "======Model training from:  2015-01-01 to  2020-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -35      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.41     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0373   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.119    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.958   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.00247  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.21e+04 |\n",
      "|    total_cost         | 4.31e+03 |\n",
      "|    total_reward       | 4.21e+04 |\n",
      "|    total_reward_pct   | 84.2     |\n",
      "|    total_trades       | 6160     |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -42.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -5.35    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0722   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.6      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.000641 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -2.15    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00768  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.89e+04 |\n",
      "|    total_cost         | 3.45e+03 |\n",
      "|    total_reward       | 4.89e+04 |\n",
      "|    total_reward_pct   | 97.8     |\n",
      "|    total_trades       | 5991     |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0.0451   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.33    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00696  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -3.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 4.12     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0349   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.16e+04 |\n",
      "|    total_cost         | 4.21e+03 |\n",
      "|    total_reward       | 3.16e+04 |\n",
      "|    total_reward_pct   | 63.3     |\n",
      "|    total_trades       | 6405     |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -19.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -8.12    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -0.197   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -1.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00554  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -4.39    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 2.55     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0182   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.56e+04 |\n",
      "|    total_cost         | 2.49e+03 |\n",
      "|    total_reward       | 3.56e+04 |\n",
      "|    total_reward_pct   | 71.1     |\n",
      "|    total_trades       | 6247     |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 4.78     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0306   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0.0442   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 5.76     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0507   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0.119    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 1.86     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0175   |\n",
      "------------------------------------\n",
      "day: 1318, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82660.37\n",
      "total_reward: 32660.37\n",
      "total_cost: 3951.15\n",
      "total_trades: 6104\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.27e+04 |\n",
      "|    total_cost         | 3.95e+03 |\n",
      "|    total_reward       | 3.27e+04 |\n",
      "|    total_reward_pct   | 65.3     |\n",
      "|    total_trades       | 6104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -30.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -6.8     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.145    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 335      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -2.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.22    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.018    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.06e+04 |\n",
      "|    total_cost         | 6.88e+03 |\n",
      "|    total_reward       | 2.06e+04 |\n",
      "|    total_reward_pct   | 41.3     |\n",
      "|    total_trades       | 6479     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -2.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.719    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.00116  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.263   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0286   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.651   |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.000741 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.86e+04 |\n",
      "|    total_cost         | 5.51e+03 |\n",
      "|    total_reward       | 1.86e+04 |\n",
      "|    total_reward_pct   | 37.3     |\n",
      "|    total_trades       | 6994     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -3.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.195    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0223   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.411    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.922    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.00185  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 6.31     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0965   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.45e+04 |\n",
      "|    total_cost         | 4.23e+03 |\n",
      "|    total_reward       | 3.45e+04 |\n",
      "|    total_reward_pct   | 69       |\n",
      "|    total_trades       | 7108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 2.54     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.00937  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -1.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -4.5     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0369   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.23e+04 |\n",
      "|    total_cost         | 1.87e+03 |\n",
      "|    total_reward       | 2.23e+04 |\n",
      "|    total_reward_pct   | 44.6     |\n",
      "|    total_trades       | 7178     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | -0.0134  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.228    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.000988 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.136   |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00356  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -2.92    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.0133   |\n",
      "------------------------------------\n",
      "day: 1318, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74870.57\n",
      "total_reward: 24870.57\n",
      "total_cost: 4018.40\n",
      "total_trades: 8187\n",
      "Sharpe: 0.485\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.49e+04 |\n",
      "|    total_cost         | 4.02e+03 |\n",
      "|    total_reward       | 2.49e+04 |\n",
      "|    total_reward_pct   | 49.7     |\n",
      "|    total_trades       | 8187     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | -1.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -3.42    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.0416  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 4.53     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0268   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -0.265   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -16.3    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.314    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.19e+04 |\n",
      "|    total_cost         | 1.58e+03 |\n",
      "|    total_reward       | 2.19e+04 |\n",
      "|    total_reward_pct   | 43.9     |\n",
      "|    total_trades       | 7742     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | 0.0757   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 4.78     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0294   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.853   |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.00255  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.44e+04 |\n",
      "|    total_cost         | 1.23e+03 |\n",
      "|    total_reward       | 2.44e+04 |\n",
      "|    total_reward_pct   | 48.7     |\n",
      "|    total_trades       | 8058     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | -1.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.973    |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.00441  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | -5.9     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.755   |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.000826 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 2.98     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.00972  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.36e+04 |\n",
      "|    total_cost         | 1.8e+03  |\n",
      "|    total_reward       | 1.36e+04 |\n",
      "|    total_reward_pct   | 27.2     |\n",
      "|    total_trades       | 8592     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | -3.26    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.177   |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.00235  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -5.52    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.0371   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.25e+04 |\n",
      "|    total_cost         | 2.16e+03 |\n",
      "|    total_reward       | 2.25e+04 |\n",
      "|    total_reward_pct   | 44.9     |\n",
      "|    total_trades       | 8465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.205   |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | -0.172   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -7.38    |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.0563   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 333       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -2.03     |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.0079    |\n",
      "-------------------------------------\n",
      "day: 1318, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 72873.49\n",
      "total_reward: 22873.49\n",
      "total_cost: 2808.18\n",
      "total_trades: 9311\n",
      "Sharpe: 0.444\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.29e+04 |\n",
      "|    total_cost         | 2.81e+03 |\n",
      "|    total_reward       | 2.29e+04 |\n",
      "|    total_reward_pct   | 45.7     |\n",
      "|    total_trades       | 9311     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0148   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | -0.0725  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.256    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00496  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | -0.084   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.988   |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.00136  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.51e+04 |\n",
      "|    total_cost         | 3.89e+03 |\n",
      "|    total_reward       | 4.51e+04 |\n",
      "|    total_reward_pct   | 90.3     |\n",
      "|    total_trades       | 10113    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | -8.41    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 4.27     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.0199   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | -0.00583 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -4.93    |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.0365   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.91e+04 |\n",
      "|    total_cost         | 2.95e+03 |\n",
      "|    total_reward       | 1.91e+04 |\n",
      "|    total_reward_pct   | 38.2     |\n",
      "|    total_trades       | 9788     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | -1.86    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 3.37     |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -3.92    |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0286   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | -2.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.0731  |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.00107  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.55e+04 |\n",
      "|    total_cost         | 3.05e+03 |\n",
      "|    total_reward       | 4.55e+04 |\n",
      "|    total_reward_pct   | 91       |\n",
      "|    total_trades       | 10049    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -0.148   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -2.42    |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | -1.27    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.0702   |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.00114  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -1.69    |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.00314  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.85e+04 |\n",
      "|    total_cost         | 2.43e+03 |\n",
      "|    total_reward       | 3.85e+04 |\n",
      "|    total_reward_pct   | 77       |\n",
      "|    total_trades       | 9774     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -8.88    |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.0654   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 2.67     |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00672  |\n",
      "------------------------------------\n",
      "day: 1318, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 76104.80\n",
      "total_reward: 26104.80\n",
      "total_cost: 1776.15\n",
      "total_trades: 9204\n",
      "Sharpe: 0.506\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.61e+04 |\n",
      "|    total_cost         | 1.78e+03 |\n",
      "|    total_reward       | 2.61e+04 |\n",
      "|    total_reward_pct   | 52.2     |\n",
      "|    total_trades       | 9204     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -0.314   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -3.62    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | 0.407    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 6.23     |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.0345   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -2.3     |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.00621  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.99e+04 |\n",
      "|    total_cost         | 2.55e+03 |\n",
      "|    total_reward       | 2.99e+04 |\n",
      "|    total_reward_pct   | 59.7     |\n",
      "|    total_trades       | 10202    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -2.69    |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.00783  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | -0.0472  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 4.77     |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.0258   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -15.4    |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.402    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.7e+04  |\n",
      "|    total_cost         | 3.13e+03 |\n",
      "|    total_reward       | 4.7e+04  |\n",
      "|    total_reward_pct   | 94       |\n",
      "|    total_trades       | 10245    |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | 0.226    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -2.32    |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.0066   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -1.97    |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.00765  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.21e+04 |\n",
      "|    total_cost         | 2.83e+03 |\n",
      "|    total_reward       | 3.21e+04 |\n",
      "|    total_reward_pct   | 64.2     |\n",
      "|    total_trades       | 10204    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -7.22    |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.0429   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 5.02     |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.0258   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | -0.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -8.47    |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.0557   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.91e+04 |\n",
      "|    total_cost         | 2.84e+03 |\n",
      "|    total_reward       | 4.91e+04 |\n",
      "|    total_reward_pct   | 98.2     |\n",
      "|    total_trades       | 10302    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -0.126   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 3.17     |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.00732  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.1    |\n",
      "|    explained_variance | -0.0284  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 6.55     |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.061    |\n",
      "------------------------------------\n",
      "day: 1318, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 129273.05\n",
      "total_reward: 79273.05\n",
      "total_cost: 3602.69\n",
      "total_trades: 10378\n",
      "Sharpe: 0.770\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+05 |\n",
      "|    total_cost         | 3.6e+03  |\n",
      "|    total_reward       | 7.93e+04 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 10378    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.1    |\n",
      "|    explained_variance | 0.77     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.000877 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | 0.367    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 8.07     |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.0664   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 4.37     |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.0228   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 3.7e+03  |\n",
      "|    total_reward       | 5.82e+04 |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 10801    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 0.296    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -2.67    |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.00514  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -1.2      |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 0.00125   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | -0.165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.00929  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.2e+04  |\n",
      "|    total_cost         | 2.93e+03 |\n",
      "|    total_reward       | 4.2e+04  |\n",
      "|    total_reward_pct   | 84       |\n",
      "|    total_trades       | 10998    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | 1.71e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.861   |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.00705  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | -0.127   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.913    |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.00827  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.92e+04 |\n",
      "|    total_cost         | 2.56e+03 |\n",
      "|    total_reward       | 2.92e+04 |\n",
      "|    total_reward_pct   | 58.4     |\n",
      "|    total_trades       | 10735    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | 0.248    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 2.76     |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.0098   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | 0.557    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -4.35    |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.0138   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -1.78    |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.00283  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.39e+04 |\n",
      "|    total_cost         | 2.49e+03 |\n",
      "|    total_reward       | 3.39e+04 |\n",
      "|    total_reward_pct   | 67.7     |\n",
      "|    total_trades       | 10835    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | 0.0193   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 1.94     |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.00613  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39      |\n",
      "|    explained_variance | -0.0209  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -6.75    |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.0403   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 7.24     |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.0438   |\n",
      "------------------------------------\n",
      "day: 1318, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92207.65\n",
      "total_reward: 42207.65\n",
      "total_cost: 2538.91\n",
      "total_trades: 11537\n",
      "Sharpe: 0.614\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.22e+04 |\n",
      "|    total_cost         | 2.54e+03 |\n",
      "|    total_reward       | 4.22e+04 |\n",
      "|    total_reward_pct   | 84.4     |\n",
      "|    total_trades       | 11537    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -7.12    |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 0.0428   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | -0.104   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.00387  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.5e+04  |\n",
      "|    total_cost         | 2.42e+03 |\n",
      "|    total_reward       | 3.5e+04  |\n",
      "|    total_reward_pct   | 70       |\n",
      "|    total_trades       | 11272    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | 0.578    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -1.68    |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.00224  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.00318  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.0943   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.612    |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.000883 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.96e+04 |\n",
      "|    total_cost         | 2.21e+03 |\n",
      "|    total_reward       | 1.96e+04 |\n",
      "|    total_reward_pct   | 39.2     |\n",
      "|    total_trades       | 11419    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.791   |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.00127  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0.000142 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 3.28     |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.00693  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -4.31    |\n",
      "|    std                | 2.04     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.71e+04  |\n",
      "|    total_cost         | 1.67e+03  |\n",
      "|    total_reward       | -2.87e+03 |\n",
      "|    total_reward_pct   | -5.74     |\n",
      "|    total_trades       | 11100     |\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -0.052    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -0.81     |\n",
      "|    std                | 2.06      |\n",
      "|    value_loss         | 0.00236   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.968    |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.00483  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.9e+04  |\n",
      "|    total_cost         | 2e+03    |\n",
      "|    total_reward       | -972     |\n",
      "|    total_reward_pct   | -1.94    |\n",
      "|    total_trades       | 11433    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 1.25     |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.00162  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -0.785   |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.00746  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -1.99    |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.00319  |\n",
      "------------------------------------\n",
      "day: 1318, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 84794.72\n",
      "total_reward: 34794.72\n",
      "total_cost: 3827.23\n",
      "total_trades: 12583\n",
      "Sharpe: 0.587\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.48e+04 |\n",
      "|    total_cost         | 3.83e+03 |\n",
      "|    total_reward       | 3.48e+04 |\n",
      "|    total_reward_pct   | 69.6     |\n",
      "|    total_trades       | 12583    |\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | -0.00848 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 14.5     |\n",
      "|    std                | 2.15     |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | 0.766    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 2.16     |\n",
      "|    value_loss         | 0.00375  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.89e+04  |\n",
      "|    total_cost         | 4.73e+03  |\n",
      "|    total_reward       | 4.89e+04  |\n",
      "|    total_reward_pct   | 97.7      |\n",
      "|    total_trades       | 13042     |\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -0.000189 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -0.343    |\n",
      "|    std                | 2.18      |\n",
      "|    value_loss         | 0.00053   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.8    |\n",
      "|    explained_variance | -0.224   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.191    |\n",
      "|    std                | 2.19     |\n",
      "|    value_loss         | 0.00274  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 9.03     |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 0.0728   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.36e+04 |\n",
      "|    total_cost         | 3.76e+03 |\n",
      "|    total_reward       | 3.36e+04 |\n",
      "|    total_reward_pct   | 67.1     |\n",
      "|    total_trades       | 12736    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | -0.0337  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 3.71     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.0182   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | -2.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.707    |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 0.00495  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.127    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.344    |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.000171 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.99e+04 |\n",
      "|    total_cost         | 2.23e+03 |\n",
      "|    total_reward       | -126     |\n",
      "|    total_reward_pct   | -0.251   |\n",
      "|    total_trades       | 12233    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0963  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 4.13     |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.0159   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -2.3     |\n",
      "|    std                | 2.32     |\n",
      "|    value_loss         | 0.00477  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7e+04    |\n",
      "|    total_cost         | 3.33e+03 |\n",
      "|    total_reward       | 2e+04    |\n",
      "|    total_reward_pct   | 40       |\n",
      "|    total_trades       | 12458    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -2.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 1.98     |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 0.00274  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.136    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 3.63     |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.0118   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.43    |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.00131  |\n",
      "------------------------------------\n",
      "day: 1318, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 87745.67\n",
      "total_reward: 37745.67\n",
      "total_cost: 4184.59\n",
      "total_trades: 13574\n",
      "Sharpe: 0.580\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.77e+04 |\n",
      "|    total_cost         | 4.18e+03 |\n",
      "|    total_reward       | 3.77e+04 |\n",
      "|    total_reward_pct   | 75.5     |\n",
      "|    total_trades       | 13574    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -3.05    |\n",
      "|    std                | 2.41     |\n",
      "|    value_loss         | 0.00818  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -7.8     |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.0354   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 0.525    |\n",
      "|    std                | 2.46     |\n",
      "|    value_loss         | 0.000312 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.61e+04  |\n",
      "|    total_cost         | 2.2e+03   |\n",
      "|    total_reward       | -3.86e+03 |\n",
      "|    total_reward_pct   | -7.73     |\n",
      "|    total_trades       | 13065     |\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | 0.681     |\n",
      "|    std                | 2.48      |\n",
      "|    value_loss         | 0.000675  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 5.24     |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.0151   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.34e+04 |\n",
      "|    total_cost         | 3.98e+03 |\n",
      "|    total_reward       | 1.34e+04 |\n",
      "|    total_reward_pct   | 26.9     |\n",
      "|    total_trades       | 13725    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0.0854   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 1.24     |\n",
      "|    std                | 2.53     |\n",
      "|    value_loss         | 0.00121  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0.247    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -0.873   |\n",
      "|    std                | 2.55     |\n",
      "|    value_loss         | 0.00159  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -2.53    |\n",
      "|    std                | 2.57     |\n",
      "|    value_loss         | 0.0045   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 5.26e+03 |\n",
      "|    total_reward       | 5.72e+04 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 14040    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | -0.122   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 2.85     |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 0.00757  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | -0.0318  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -6.73    |\n",
      "|    std                | 2.62     |\n",
      "|    value_loss         | 0.0309   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0.039    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 2.64     |\n",
      "|    value_loss         | 0.0236   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.97e+04 |\n",
      "|    total_cost         | 4.75e+03 |\n",
      "|    total_reward       | 2.97e+04 |\n",
      "|    total_reward_pct   | 59.4     |\n",
      "|    total_trades       | 13914    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | -0.187   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -6.26    |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "day: 1318, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 107554.03\n",
      "total_reward: 57554.03\n",
      "total_cost: 5720.40\n",
      "total_trades: 14157\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 5.72e+03 |\n",
      "|    total_reward       | 5.76e+04 |\n",
      "|    total_reward_pct   | 115      |\n",
      "|    total_trades       | 14157    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | -0.587   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 2.62     |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 0.00777  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -3.17    |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.00679  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 2.69     |\n",
      "|    std                | 2.75     |\n",
      "|    value_loss         | 0.00464  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 5.11e+03 |\n",
      "|    total_reward       | 5.21e+04 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 13828    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | -0.464   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.274    |\n",
      "|    std                | 2.77     |\n",
      "|    value_loss         | 0.00495  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | -0.0194  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -1.6     |\n",
      "|    std                | 2.79     |\n",
      "|    value_loss         | 0.0934   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 4.94e+03 |\n",
      "|    total_reward       | 5.37e+04 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 14044    |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | -0.227   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 2.81     |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0.0302   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 9.77     |\n",
      "|    std                | 2.83     |\n",
      "|    value_loss         | 0.0609   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.74    |\n",
      "|    std                | 2.84     |\n",
      "|    value_loss         | 0.0036   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.93e+04 |\n",
      "|    total_cost         | 3.99e+03 |\n",
      "|    total_reward       | 4.93e+04 |\n",
      "|    total_reward_pct   | 98.5     |\n",
      "|    total_trades       | 14704    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -8.29    |\n",
      "|    std                | 2.87     |\n",
      "|    value_loss         | 0.0366   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -6.68    |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.0211   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | -0.174   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.828   |\n",
      "|    std                | 2.92     |\n",
      "|    value_loss         | 0.00925  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 4.28e+03 |\n",
      "|    total_reward       | 5.07e+04 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 14516    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 5.13     |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -1.18    |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "day: 1318, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95829.70\n",
      "total_reward: 45829.70\n",
      "total_cost: 3801.31\n",
      "total_trades: 14660\n",
      "Sharpe: 0.675\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.58e+04 |\n",
      "|    total_cost         | 3.8e+03  |\n",
      "|    total_reward       | 4.58e+04 |\n",
      "|    total_reward_pct   | 91.7     |\n",
      "|    total_trades       | 14660    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 0.166    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -6.4     |\n",
      "|    std                | 2.99     |\n",
      "|    value_loss         | 0.0361   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | -0.0214  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -8.55    |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.0351   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -6.59    |\n",
      "|    std                | 3.04     |\n",
      "|    value_loss         | 0.0191   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+05 |\n",
      "|    total_cost         | 4.42e+03 |\n",
      "|    total_reward       | 5.19e+04 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 15056    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | 0.00188  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 0.313    |\n",
      "|    std                | 3.07     |\n",
      "|    value_loss         | 0.00197  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | -0.115   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 6.48     |\n",
      "|    std                | 3.1      |\n",
      "|    value_loss         | 0.0199   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -2.52    |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.00399  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.84e+04 |\n",
      "|    total_cost         | 4.02e+03 |\n",
      "|    total_reward       | 2.84e+04 |\n",
      "|    total_reward_pct   | 56.7     |\n",
      "|    total_trades       | 14894    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.463   |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.00242  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -3.56    |\n",
      "|    std                | 3.19     |\n",
      "|    value_loss         | 0.00803  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.81e+04 |\n",
      "|    total_cost         | 3.74e+03 |\n",
      "|    total_reward       | 1.81e+04 |\n",
      "|    total_reward_pct   | 36.2     |\n",
      "|    total_trades       | 14964    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.75    |\n",
      "|    std                | 3.23     |\n",
      "|    value_loss         | 0.000504 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 330       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 213       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 0.845     |\n",
      "|    std                | 3.26      |\n",
      "|    value_loss         | 0.00233   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 3.31     |\n",
      "|    value_loss         | 0.00158  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.16e+04 |\n",
      "|    total_cost         | 4.43e+03 |\n",
      "|    total_reward       | 1.64e+03 |\n",
      "|    total_reward_pct   | 3.28     |\n",
      "|    total_trades       | 15065    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 4.39     |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.0151   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | -0.654   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 3.55     |\n",
      "|    std                | 3.36     |\n",
      "|    value_loss         | 0.00876  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 5.58     |\n",
      "|    std                | 3.38     |\n",
      "|    value_loss         | 0.0218   |\n",
      "------------------------------------\n",
      "day: 1318, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 158694.29\n",
      "total_reward: 108694.29\n",
      "total_cost: 7718.52\n",
      "total_trades: 15409\n",
      "Sharpe: 1.104\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.59e+05 |\n",
      "|    total_cost         | 7.72e+03 |\n",
      "|    total_reward       | 1.09e+05 |\n",
      "|    total_reward_pct   | 217      |\n",
      "|    total_trades       | 15409    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | -0.367   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.484    |\n",
      "|    std                | 3.41     |\n",
      "|    value_loss         | 0.0104   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.3    |\n",
      "|    explained_variance | -0.0593  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    std                | 3.42     |\n",
      "|    value_loss         | 0.0119   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 7.37e+03 |\n",
      "|    total_reward       | 6.27e+04 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 15301    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 5.25     |\n",
      "|    std                | 3.46     |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 3.49     |\n",
      "|    value_loss         | 0.00558  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | -0.264   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 7.46     |\n",
      "|    std                | 3.52     |\n",
      "|    value_loss         | 0.0293   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.48e+04 |\n",
      "|    total_cost         | 8.12e+03 |\n",
      "|    total_reward       | 3.48e+04 |\n",
      "|    total_reward_pct   | 69.6     |\n",
      "|    total_trades       | 15515    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | -0.0191  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 3.55     |\n",
      "|    value_loss         | 0.00137  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 330       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -3.85     |\n",
      "|    std                | 3.57      |\n",
      "|    value_loss         | 0.0166    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | -0.102   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 34.3     |\n",
      "|    std                | 3.6      |\n",
      "|    value_loss         | 0.694    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.28e+05 |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 7.83e+04 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 15964    |\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | -0.442   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -7.39    |\n",
      "|    std                | 3.63     |\n",
      "|    value_loss         | 0.0215   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | 0.0894   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -2.85    |\n",
      "|    std                | 3.66     |\n",
      "|    value_loss         | 0.00497  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.61e+04 |\n",
      "|    total_cost         | 7.47e+03 |\n",
      "|    total_reward       | 2.61e+04 |\n",
      "|    total_reward_pct   | 52.1     |\n",
      "|    total_trades       | 15409    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | -0.0998  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 8.98     |\n",
      "|    std                | 3.7      |\n",
      "|    value_loss         | 0.0335   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 4.87     |\n",
      "|    std                | 3.73     |\n",
      "|    value_loss         | 0.0147   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 1.86     |\n",
      "|    std                | 3.76     |\n",
      "|    value_loss         | 0.00277  |\n",
      "------------------------------------\n",
      "day: 1318, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 84124.98\n",
      "total_reward: 34124.98\n",
      "total_cost: 7840.12\n",
      "total_trades: 15837\n",
      "Sharpe: 0.633\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.41e+04 |\n",
      "|    total_cost         | 7.84e+03 |\n",
      "|    total_reward       | 3.41e+04 |\n",
      "|    total_reward_pct   | 68.2     |\n",
      "|    total_trades       | 15837    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0.0219   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 9.59     |\n",
      "|    std                | 3.8      |\n",
      "|    value_loss         | 0.0405   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 0.364     |\n",
      "|    std                | 3.84      |\n",
      "|    value_loss         | 0.00369   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.07e+04 |\n",
      "|    total_cost         | 6.23e+03 |\n",
      "|    total_reward       | 1.07e+04 |\n",
      "|    total_reward_pct   | 21.4     |\n",
      "|    total_trades       | 15391    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | 0.064    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -7.01    |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 0.0219   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 0.0333   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -2.92    |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.0061   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -2.86    |\n",
      "|    std                | 3.95     |\n",
      "|    value_loss         | 0.00449  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.82e+04 |\n",
      "|    total_cost         | 5.94e+03 |\n",
      "|    total_reward       | 1.82e+04 |\n",
      "|    total_reward_pct   | 36.4     |\n",
      "|    total_trades       | 15210    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -2.72    |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.00316  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 8.86     |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 0.0354   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.6    |\n",
      "|    explained_variance | -0.0499  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 8.89     |\n",
      "|    std                | 4.08     |\n",
      "|    value_loss         | 0.0356   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.38e+04 |\n",
      "|    total_cost         | 3.31e+03 |\n",
      "|    total_reward       | 3.83e+03 |\n",
      "|    total_reward_pct   | 7.67     |\n",
      "|    total_trades       | 14673    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.357   |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 0.00145  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -1.58    |\n",
      "|    std                | 4.16     |\n",
      "|    value_loss         | 0.00621  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.95e+04 |\n",
      "|    total_cost         | 5.32e+03 |\n",
      "|    total_reward       | 9.52e+03 |\n",
      "|    total_reward_pct   | 19       |\n",
      "|    total_trades       | 14854    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | 0.116    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -7.02    |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 0.0185   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 258       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 3.53      |\n",
      "|    std                | 4.24      |\n",
      "|    value_loss         | 0.00871   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | 3.02      |\n",
      "|    std                | 4.27      |\n",
      "|    value_loss         | 0.00337   |\n",
      "-------------------------------------\n",
      "day: 1318, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 71475.39\n",
      "total_reward: 21475.39\n",
      "total_cost: 4576.52\n",
      "total_trades: 15660\n",
      "Sharpe: 0.449\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.15e+04 |\n",
      "|    total_cost         | 4.58e+03 |\n",
      "|    total_reward       | 2.15e+04 |\n",
      "|    total_reward_pct   | 43       |\n",
      "|    total_trades       | 15660    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | -0.256   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -6.01    |\n",
      "|    std                | 4.31     |\n",
      "|    value_loss         | 0.0174   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.9    |\n",
      "|    explained_variance | 0.0356   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 2.55     |\n",
      "|    std                | 4.36     |\n",
      "|    value_loss         | 0.00668  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 16.8     |\n",
      "|    std                | 4.4      |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.92e+04 |\n",
      "|    total_cost         | 3.09e+03 |\n",
      "|    total_reward       | 1.92e+04 |\n",
      "|    total_reward_pct   | 38.4     |\n",
      "|    total_trades       | 15290    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -25      |\n",
      "|    std                | 4.42     |\n",
      "|    value_loss         | 0.253    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 0.137    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -9.81    |\n",
      "|    std                | 4.47     |\n",
      "|    value_loss         | 0.039    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.19e+04 |\n",
      "|    total_cost         | 2.82e+03 |\n",
      "|    total_reward       | 2.19e+04 |\n",
      "|    total_reward_pct   | 43.8     |\n",
      "|    total_trades       | 15412    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -2.08    |\n",
      "|    std                | 4.52     |\n",
      "|    value_loss         | 0.00212  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 5.59     |\n",
      "|    std                | 4.55     |\n",
      "|    value_loss         | 0.0169   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | 0.075    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 1.9      |\n",
      "|    std                | 4.59     |\n",
      "|    value_loss         | 0.00313  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.22e+04 |\n",
      "|    total_cost         | 2.85e+03 |\n",
      "|    total_reward       | 3.22e+04 |\n",
      "|    total_reward_pct   | 64.4     |\n",
      "|    total_trades       | 15449    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56      |\n",
      "|    explained_variance | 0.0201   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -7.02    |\n",
      "|    std                | 4.63     |\n",
      "|    value_loss         | 0.0166   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -3.14    |\n",
      "|    std                | 4.67     |\n",
      "|    value_loss         | 0.00495  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | -0.119   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -21.8    |\n",
      "|    std                | 4.7      |\n",
      "|    value_loss         | 0.167    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.9e+04   |\n",
      "|    total_cost         | 2.69e+03  |\n",
      "|    total_reward       | 3.9e+04   |\n",
      "|    total_reward_pct   | 78        |\n",
      "|    total_trades       | 15148     |\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 278       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | -0.137    |\n",
      "|    std                | 4.75      |\n",
      "|    value_loss         | 0.000501  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.7    |\n",
      "|    explained_variance | 0.0168   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.851   |\n",
      "|    std                | 4.79     |\n",
      "|    value_loss         | 0.000505 |\n",
      "------------------------------------\n",
      "day: 1318, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 61023.63\n",
      "total_reward: 11023.63\n",
      "total_cost: 2048.79\n",
      "total_trades: 14988\n",
      "Sharpe: 0.284\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.1e+04  |\n",
      "|    total_cost         | 2.05e+03 |\n",
      "|    total_reward       | 1.1e+04  |\n",
      "|    total_reward_pct   | 22       |\n",
      "|    total_trades       | 14988    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    std                | 4.85     |\n",
      "|    value_loss         | 0.00133  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 2.41     |\n",
      "|    std                | 4.89     |\n",
      "|    value_loss         | 0.00331  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | 0.278    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 5.09     |\n",
      "|    std                | 4.93     |\n",
      "|    value_loss         | 0.0084   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.96e+04 |\n",
      "|    total_cost         | 2.09e+03 |\n",
      "|    total_reward       | 2.96e+04 |\n",
      "|    total_reward_pct   | 59.2     |\n",
      "|    total_trades       | 15179    |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -1.52    |\n",
      "|    std                | 4.98     |\n",
      "|    value_loss         | 0.000985 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.6    |\n",
      "|    explained_variance | 0.0537   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 5.04     |\n",
      "|    value_loss         | 0.00163  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.86e+04  |\n",
      "|    total_cost         | 1.45e+03  |\n",
      "|    total_reward       | -1.38e+03 |\n",
      "|    total_reward_pct   | -2.76     |\n",
      "|    total_trades       | 14729     |\n",
      "| time/                 |           |\n",
      "|    fps                | 328       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.8     |\n",
      "|    explained_variance | -0.502    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 2         |\n",
      "|    std                | 5.09      |\n",
      "|    value_loss         | 0.0117    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 1.67     |\n",
      "|    std                | 5.15     |\n",
      "|    value_loss         | 0.00153  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.2    |\n",
      "|    explained_variance | -0.326   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -2.96    |\n",
      "|    std                | 5.19     |\n",
      "|    value_loss         | 0.00373  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.17e+04 |\n",
      "|    total_cost         | 2.24e+03 |\n",
      "|    total_reward       | 2.17e+04 |\n",
      "|    total_reward_pct   | 43.5     |\n",
      "|    total_trades       | 15229    |\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 6.77     |\n",
      "|    std                | 5.24     |\n",
      "|    value_loss         | 0.0269   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 328       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 294       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -6.83     |\n",
      "|    std                | 5.28      |\n",
      "|    value_loss         | 0.0154    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 328       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 296       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 5.04      |\n",
      "|    std                | 5.33      |\n",
      "|    value_loss         | 0.0067    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.3e+04  |\n",
      "|    total_cost         | 2.4e+03  |\n",
      "|    total_reward       | 2.3e+04  |\n",
      "|    total_reward_pct   | 45.9     |\n",
      "|    total_trades       | 15735    |\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 3.89     |\n",
      "|    std                | 5.38     |\n",
      "|    value_loss         | 0.0105   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59      |\n",
      "|    explained_variance | -0.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -7.52    |\n",
      "|    std                | 5.43     |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "day: 1318, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 59661.80\n",
      "total_reward: 9661.80\n",
      "total_cost: 1811.15\n",
      "total_trades: 15527\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.97e+04 |\n",
      "|    total_cost         | 1.81e+03 |\n",
      "|    total_reward       | 9.66e+03 |\n",
      "|    total_reward_pct   | 19.3     |\n",
      "|    total_trades       | 15527    |\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 8.24     |\n",
      "|    std                | 5.48     |\n",
      "|    value_loss         | 0.0213   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.4    |\n",
      "|    explained_variance | 0.0556   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 0.257    |\n",
      "|    std                | 5.54     |\n",
      "|    value_loss         | 0.00507  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.6    |\n",
      "|    explained_variance | -0.316   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -1.36    |\n",
      "|    std                | 5.59     |\n",
      "|    value_loss         | 0.000751 |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-04-06 to  2020-07-09\n",
      "A2C Sharpe Ratio:  0.11472907877133318\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.08e+04 |\n",
      "|    total_cost       | 1.32e+04 |\n",
      "|    total_reward     | 2.08e+04 |\n",
      "|    total_reward_pct | 41.6     |\n",
      "|    total_trades     | 7387     |\n",
      "| time/               |          |\n",
      "|    fps              | 406      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.45e+04    |\n",
      "|    total_cost           | 1.23e+04    |\n",
      "|    total_reward         | 3.45e+04    |\n",
      "|    total_reward_pct     | 68.9        |\n",
      "|    total_trades         | 7475        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017093968 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.189      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.259      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 55197.40\n",
      "total_reward: 5197.40\n",
      "total_cost: 12366.95\n",
      "total_trades: 7162\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.52e+04    |\n",
      "|    total_cost           | 1.24e+04    |\n",
      "|    total_reward         | 5.2e+03     |\n",
      "|    total_reward_pct     | 10.4        |\n",
      "|    total_trades         | 7162        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020518346 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0578      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.02e+04    |\n",
      "|    total_cost           | 1.1e+04     |\n",
      "|    total_reward         | 3.02e+04    |\n",
      "|    total_reward_pct     | 60.4        |\n",
      "|    total_trades         | 7333        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 386         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013151659 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0278      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.02e+04    |\n",
      "|    total_cost           | 1.31e+04    |\n",
      "|    total_reward         | 2.02e+04    |\n",
      "|    total_reward_pct     | 40.3        |\n",
      "|    total_trades         | 7385        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026288465 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0324      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 71876.64\n",
      "total_reward: 21876.64\n",
      "total_cost: 10045.07\n",
      "total_trades: 7197\n",
      "Sharpe: 0.442\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.19e+04    |\n",
      "|    total_cost           | 1e+04       |\n",
      "|    total_reward         | 2.19e+04    |\n",
      "|    total_reward_pct     | 43.8        |\n",
      "|    total_trades         | 7197        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 381         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018020831 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0286      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.61e+04    |\n",
      "|    total_cost           | 8.85e+03    |\n",
      "|    total_reward         | -3.88e+03   |\n",
      "|    total_reward_pct     | -7.76       |\n",
      "|    total_trades         | 7234        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 380         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018744715 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.26       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.047       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.1e+04     |\n",
      "|    total_cost           | 1.09e+04    |\n",
      "|    total_reward         | 1.1e+04     |\n",
      "|    total_reward_pct     | 21.9        |\n",
      "|    total_trades         | 7323        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 379         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019235453 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0234      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.11e+04    |\n",
      "|    total_cost           | 1.02e+04    |\n",
      "|    total_reward         | 1.11e+04    |\n",
      "|    total_reward_pct     | 22.2        |\n",
      "|    total_trades         | 7282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 378         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013416041 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0374      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 86707.35\n",
      "total_reward: 36707.35\n",
      "total_cost: 11258.72\n",
      "total_trades: 7534\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.38e+04    |\n",
      "|    total_cost           | 1.17e+04    |\n",
      "|    total_reward         | 2.38e+04    |\n",
      "|    total_reward_pct     | 47.6        |\n",
      "|    total_trades         | 7417        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011961946 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0276      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.8e+04     |\n",
      "|    total_cost           | 1.06e+04    |\n",
      "|    total_reward         | 1.8e+04     |\n",
      "|    total_reward_pct     | 36.1        |\n",
      "|    total_trades         | 7381        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026105931 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0369      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 6.03e+04     |\n",
      "|    total_cost           | 8.54e+03     |\n",
      "|    total_reward         | 1.03e+04     |\n",
      "|    total_reward_pct     | 20.6         |\n",
      "|    total_trades         | 7465         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100513585 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.275       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0206      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.053        |\n",
      "------------------------------------------\n",
      "day: 1318, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97867.34\n",
      "total_reward: 47867.34\n",
      "total_cost: 10963.76\n",
      "total_trades: 7407\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9e+04      |\n",
      "|    total_cost           | 9.19e+03   |\n",
      "|    total_reward         | 4e+04      |\n",
      "|    total_reward_pct     | 80.1       |\n",
      "|    total_trades         | 7351       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 376        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02059551 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.469      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.271     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0452     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 8.48e+04  |\n",
      "|    total_cost           | 9.1e+03   |\n",
      "|    total_reward         | 3.48e+04  |\n",
      "|    total_reward_pct     | 69.5      |\n",
      "|    total_trades         | 7553      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 377       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0191531 |\n",
      "|    clip_fraction        | 0.162     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.4     |\n",
      "|    explained_variance   | 0.439     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.261    |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -0.0184   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 0.0741    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.77e+04    |\n",
      "|    total_cost           | 1.12e+04    |\n",
      "|    total_reward         | 2.77e+04    |\n",
      "|    total_reward_pct     | 55.5        |\n",
      "|    total_trades         | 7477        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022899024 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0535      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 83068.07\n",
      "total_reward: 33068.07\n",
      "total_cost: 10006.70\n",
      "total_trades: 7678\n",
      "Sharpe: 0.640\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.31e+04    |\n",
      "|    total_cost           | 1e+04       |\n",
      "|    total_reward         | 3.31e+04    |\n",
      "|    total_reward_pct     | 66.1        |\n",
      "|    total_trades         | 7678        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023692794 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.254      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0688      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.51e+04    |\n",
      "|    total_cost           | 1.11e+04    |\n",
      "|    total_reward         | 2.51e+04    |\n",
      "|    total_reward_pct     | 50.2        |\n",
      "|    total_trades         | 7654        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029786732 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.034       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.65e+04    |\n",
      "|    total_cost           | 1.14e+04    |\n",
      "|    total_reward         | 1.65e+04    |\n",
      "|    total_reward_pct     | 33          |\n",
      "|    total_trades         | 7668        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024031583 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.251      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0519      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 78278.19\n",
      "total_reward: 28278.19\n",
      "total_cost: 7978.08\n",
      "total_trades: 7512\n",
      "Sharpe: 0.493\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.83e+04   |\n",
      "|    total_cost           | 7.98e+03   |\n",
      "|    total_reward         | 2.83e+04   |\n",
      "|    total_reward_pct     | 56.6       |\n",
      "|    total_trades         | 7512       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 376        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02608041 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.529      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0514     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.67e+04   |\n",
      "|    total_cost           | 1.14e+04   |\n",
      "|    total_reward         | 4.67e+04   |\n",
      "|    total_reward_pct     | 93.4       |\n",
      "|    total_trades         | 7562       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 376        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01926075 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.269     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0617     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.86e+04   |\n",
      "|    total_cost           | 1.09e+04   |\n",
      "|    total_reward         | 3.86e+04   |\n",
      "|    total_reward_pct     | 77.2       |\n",
      "|    total_trades         | 7602       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 375        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 114        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02626004 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.252     |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0581     |\n",
      "----------------------------------------\n",
      "day: 1318, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 94722.68\n",
      "total_reward: 44722.68\n",
      "total_cost: 11564.40\n",
      "total_trades: 7532\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.47e+04    |\n",
      "|    total_cost           | 1.16e+04    |\n",
      "|    total_reward         | 4.47e+04    |\n",
      "|    total_reward_pct     | 89.4        |\n",
      "|    total_trades         | 7532        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025945313 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0432      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.23e+04    |\n",
      "|    total_cost           | 7.56e+03    |\n",
      "|    total_reward         | 3.23e+04    |\n",
      "|    total_reward_pct     | 64.5        |\n",
      "|    total_trades         | 7668        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026171753 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.237      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0674      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.93e+04    |\n",
      "|    total_cost           | 7.54e+03    |\n",
      "|    total_reward         | 2.93e+04    |\n",
      "|    total_reward_pct     | 58.6        |\n",
      "|    total_trades         | 7673        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026489057 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0361      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 8.21e+03    |\n",
      "|    total_reward         | 5.09e+04    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 7574        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015479645 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0504      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 100817.57\n",
      "total_reward: 50817.57\n",
      "total_cost: 8327.36\n",
      "total_trades: 7638\n",
      "Sharpe: 0.779\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.02e+05   |\n",
      "|    total_cost           | 7.78e+03   |\n",
      "|    total_reward         | 5.25e+04   |\n",
      "|    total_reward_pct     | 105        |\n",
      "|    total_trades         | 7713       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 375        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 141        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03046989 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0474     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+05    |\n",
      "|    total_cost           | 9.91e+03    |\n",
      "|    total_reward         | 5.6e+04     |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 7889        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025962882 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.249      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.072       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 8.15e+03    |\n",
      "|    total_reward         | 5.1e+04     |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 7940        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019320562 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0676      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 120\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110120.26\n",
      "total_reward: 60120.26\n",
      "total_cost: 8129.52\n",
      "total_trades: 7803\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.81e+04    |\n",
      "|    total_cost           | 7.04e+03    |\n",
      "|    total_reward         | 2.81e+04    |\n",
      "|    total_reward_pct     | 56.1        |\n",
      "|    total_trades         | 7444        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026449237 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0671      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 8.01e+03    |\n",
      "|    total_reward         | 6.64e+04    |\n",
      "|    total_reward_pct     | 133         |\n",
      "|    total_trades         | 7600        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026590206 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.246      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0659      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.24e+04    |\n",
      "|    total_cost           | 9.27e+03    |\n",
      "|    total_reward         | 4.24e+04    |\n",
      "|    total_reward_pct     | 84.7        |\n",
      "|    total_trades         | 7846        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024952855 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.074       |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 125\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103830.77\n",
      "total_reward: 53830.77\n",
      "total_cost: 10711.36\n",
      "total_trades: 7977\n",
      "Sharpe: 0.826\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+05    |\n",
      "|    total_cost           | 1.07e+04    |\n",
      "|    total_reward         | 5.38e+04    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 7977        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031091131 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0535      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.26e+04    |\n",
      "|    total_cost           | 7.77e+03    |\n",
      "|    total_reward         | 4.26e+04    |\n",
      "|    total_reward_pct     | 85.1        |\n",
      "|    total_trades         | 7740        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035543367 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.264      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0519      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 7.61e+03    |\n",
      "|    total_reward         | 5.26e+04    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 7787        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020319857 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0674      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 130\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89035.09\n",
      "total_reward: 39035.09\n",
      "total_cost: 8930.21\n",
      "total_trades: 7830\n",
      "Sharpe: 0.692\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.9e+04    |\n",
      "|    total_cost           | 8.93e+03   |\n",
      "|    total_reward         | 3.9e+04    |\n",
      "|    total_reward_pct     | 78.1       |\n",
      "|    total_trades         | 7830       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 375        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03430919 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.753      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.28      |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0605     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.85e+04    |\n",
      "|    total_cost           | 7.55e+03    |\n",
      "|    total_reward         | 3.85e+04    |\n",
      "|    total_reward_pct     | 77.1        |\n",
      "|    total_trades         | 7877        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031345263 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.057       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.49e+04    |\n",
      "|    total_cost           | 1.05e+04    |\n",
      "|    total_reward         | 4.49e+04    |\n",
      "|    total_reward_pct     | 89.8        |\n",
      "|    total_trades         | 7875        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018353254 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.256      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0457      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 135\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 88394.57\n",
      "total_reward: 38394.57\n",
      "total_cost: 6686.88\n",
      "total_trades: 7878\n",
      "Sharpe: 0.648\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.84e+04    |\n",
      "|    total_cost           | 6.69e+03    |\n",
      "|    total_reward         | 3.84e+04    |\n",
      "|    total_reward_pct     | 76.8        |\n",
      "|    total_trades         | 7878        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022303257 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.27       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.054       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.1e+04     |\n",
      "|    total_cost           | 7.18e+03    |\n",
      "|    total_reward         | 4.1e+04     |\n",
      "|    total_reward_pct     | 82.1        |\n",
      "|    total_trades         | 7920        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037748948 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0529      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.94e+04   |\n",
      "|    total_cost           | 5.11e+03   |\n",
      "|    total_reward         | 1.94e+04   |\n",
      "|    total_reward_pct     | 38.9       |\n",
      "|    total_trades         | 7718       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 375        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 217        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03173574 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.789      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.321     |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0418     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.54e+04    |\n",
      "|    total_cost           | 6.86e+03    |\n",
      "|    total_reward         | 2.54e+04    |\n",
      "|    total_reward_pct     | 50.8        |\n",
      "|    total_trades         | 7928        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026171852 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0476      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 140\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85661.24\n",
      "total_reward: 35661.24\n",
      "total_cost: 8632.43\n",
      "total_trades: 8022\n",
      "Sharpe: 0.642\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.08e+04    |\n",
      "|    total_cost           | 7.83e+03    |\n",
      "|    total_reward         | 3.08e+04    |\n",
      "|    total_reward_pct     | 61.6        |\n",
      "|    total_trades         | 7823        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025895186 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0311      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.93e+04    |\n",
      "|    total_cost           | 6.39e+03    |\n",
      "|    total_reward         | 1.93e+04    |\n",
      "|    total_reward_pct     | 38.6        |\n",
      "|    total_trades         | 7867        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020957612 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.43e+04    |\n",
      "|    total_cost           | 6.65e+03    |\n",
      "|    total_reward         | 4.43e+04    |\n",
      "|    total_reward_pct     | 88.7        |\n",
      "|    total_trades         | 7920        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035468448 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0263      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 145\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 99233.77\n",
      "total_reward: 49233.77\n",
      "total_cost: 7209.28\n",
      "total_trades: 8030\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.92e+04    |\n",
      "|    total_cost           | 7.21e+03    |\n",
      "|    total_reward         | 4.92e+04    |\n",
      "|    total_reward_pct     | 98.5        |\n",
      "|    total_trades         | 8030        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024893103 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0433      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.9e+04     |\n",
      "|    total_cost           | 6.03e+03    |\n",
      "|    total_reward         | 4.9e+04     |\n",
      "|    total_reward_pct     | 98.1        |\n",
      "|    total_trades         | 7909        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035096843 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0469      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.12e+04    |\n",
      "|    total_cost           | 7.15e+03    |\n",
      "|    total_reward         | 3.12e+04    |\n",
      "|    total_reward_pct     | 62.4        |\n",
      "|    total_trades         | 7787        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029737808 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0488      |\n",
      "-----------------------------------------\n",
      "day: 1318, episode: 150\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 83761.80\n",
      "total_reward: 33761.80\n",
      "total_cost: 5121.88\n",
      "total_trades: 7940\n",
      "Sharpe: 0.542\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.38e+04    |\n",
      "|    total_cost           | 5.12e+03    |\n",
      "|    total_reward         | 3.38e+04    |\n",
      "|    total_reward_pct     | 67.5        |\n",
      "|    total_trades         | 7940        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024335466 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0428      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.17e+04    |\n",
      "|    total_cost           | 7.58e+03    |\n",
      "|    total_reward         | 3.17e+04    |\n",
      "|    total_reward_pct     | 63.4        |\n",
      "|    total_trades         | 8211        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023698013 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-04-06 to  2020-07-09\n",
      "PPO Sharpe Ratio:  0.31524017935982235\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_1\n",
      "day: 1318, episode: 155\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90591.59\n",
      "total_reward: 40591.59\n",
      "total_cost: 123.98\n",
      "total_trades: 7169\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.13e+05 |\n",
      "|    total_cost       | 167      |\n",
      "|    total_reward     | 6.31e+04 |\n",
      "|    total_reward_pct | 126      |\n",
      "|    total_trades     | 7647     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 136      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total timesteps  | 5276     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 101      |\n",
      "|    critic_loss      | 118      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3957     |\n",
      "----------------------------------\n",
      "day: 1318, episode: 160\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 121876.13\n",
      "total_reward: 71876.13\n",
      "total_cost: 131.23\n",
      "total_trades: 5603\n",
      "Sharpe: 0.936\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.1e+05  |\n",
      "|    total_cost       | 99.8     |\n",
      "|    total_reward     | 5.99e+04 |\n",
      "|    total_reward_pct | 120      |\n",
      "|    total_trades     | 7200     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total timesteps  | 10552    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 66.2     |\n",
      "|    critic_loss      | 22.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 9233     |\n",
      "----------------------------------\n",
      "day: 1318, episode: 165\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 111516.73\n",
      "total_reward: 61516.73\n",
      "total_cost: 113.25\n",
      "total_trades: 8029\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.12e+05 |\n",
      "|    total_cost       | 113      |\n",
      "|    total_reward     | 6.15e+04 |\n",
      "|    total_reward_pct | 123      |\n",
      "|    total_trades     | 8029     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total timesteps  | 15828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 47.7     |\n",
      "|    critic_loss      | 7.46     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 14509    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.16e+05 |\n",
      "|    total_cost       | 117      |\n",
      "|    total_reward     | 6.65e+04 |\n",
      "|    total_reward_pct | 133      |\n",
      "|    total_trades     | 8614     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total timesteps  | 21104    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 35.6     |\n",
      "|    critic_loss      | 3.83     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19785    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 170\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 105724.29\n",
      "total_reward: 55724.29\n",
      "total_cost: 95.59\n",
      "total_trades: 8885\n",
      "Sharpe: 0.722\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.22e+05 |\n",
      "|    total_cost       | 102      |\n",
      "|    total_reward     | 7.15e+04 |\n",
      "|    total_reward_pct | 143      |\n",
      "|    total_trades     | 7894     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 116      |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total timesteps  | 26380    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 26.4     |\n",
      "|    critic_loss      | 2.86     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25061    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 175\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 119597.43\n",
      "total_reward: 69597.43\n",
      "total_cost: 98.46\n",
      "total_trades: 6403\n",
      "Sharpe: 0.895\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.15e+05 |\n",
      "|    total_cost       | 98.5     |\n",
      "|    total_reward     | 6.51e+04 |\n",
      "|    total_reward_pct | 130      |\n",
      "|    total_trades     | 9683     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 115      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total timesteps  | 31656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 19.6     |\n",
      "|    critic_loss      | 1.84     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 30337    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 180\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114368.59\n",
      "total_reward: 64368.59\n",
      "total_cost: 117.99\n",
      "total_trades: 7063\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.26e+05 |\n",
      "|    total_cost       | 131      |\n",
      "|    total_reward     | 7.62e+04 |\n",
      "|    total_reward_pct | 152      |\n",
      "|    total_trades     | 6783     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 115      |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total timesteps  | 36932    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 14.4     |\n",
      "|    critic_loss      | 1.4      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35613    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 185\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 117291.10\n",
      "total_reward: 67291.10\n",
      "total_cost: 117.24\n",
      "total_trades: 7504\n",
      "Sharpe: 0.854\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.17e+05 |\n",
      "|    total_cost       | 117      |\n",
      "|    total_reward     | 6.73e+04 |\n",
      "|    total_reward_pct | 135      |\n",
      "|    total_trades     | 7504     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 367      |\n",
      "|    total timesteps  | 42208    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 10.5     |\n",
      "|    critic_loss      | 1.66     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 40889    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.1e+05  |\n",
      "|    total_cost       | 114      |\n",
      "|    total_reward     | 5.97e+04 |\n",
      "|    total_reward_pct | 119      |\n",
      "|    total_trades     | 10552    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 414      |\n",
      "|    total timesteps  | 47484    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 7.5      |\n",
      "|    critic_loss      | 1.83     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46165    |\n",
      "----------------------------------\n",
      "day: 1318, episode: 190\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 111455.82\n",
      "total_reward: 61455.82\n",
      "total_cost: 118.00\n",
      "total_trades: 10927\n",
      "Sharpe: 0.941\n",
      "=================================\n",
      "======DDPG Validation from:  2020-04-06 to  2020-07-09\n",
      "======Best Model Retraining from:  2015-01-01 to  2020-07-09\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_441_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.23e+04 |\n",
      "|    total_cost       | 1.26e+04 |\n",
      "|    total_reward     | 3.23e+04 |\n",
      "|    total_reward_pct | 64.7     |\n",
      "|    total_trades     | 7728     |\n",
      "| time/               |          |\n",
      "|    fps              | 387      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.14e+05   |\n",
      "|    total_cost           | 1.43e+04   |\n",
      "|    total_reward         | 6.37e+04   |\n",
      "|    total_reward_pct     | 127        |\n",
      "|    total_trades         | 7762       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 374        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01918239 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | -0.29      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.34e+04    |\n",
      "|    total_cost           | 1.36e+04    |\n",
      "|    total_reward         | 3.34e+04    |\n",
      "|    total_reward_pct     | 66.8        |\n",
      "|    total_trades         | 7651        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016544143 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.0383     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0625      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 99694.18\n",
      "total_reward: 49694.18\n",
      "total_cost: 11966.10\n",
      "total_trades: 7876\n",
      "Sharpe: 0.786\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.97e+04   |\n",
      "|    total_cost           | 1.2e+04    |\n",
      "|    total_reward         | 4.97e+04   |\n",
      "|    total_reward_pct     | 99.4       |\n",
      "|    total_trades         | 7876       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 366        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01816472 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.213      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.284     |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0445     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.08e+04   |\n",
      "|    total_cost           | 1.21e+04   |\n",
      "|    total_reward         | 4.08e+04   |\n",
      "|    total_reward_pct     | 81.5       |\n",
      "|    total_trades         | 7728       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 364        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01103143 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.233      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0318     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.07e+04    |\n",
      "|    total_cost           | 1.18e+04    |\n",
      "|    total_reward         | 4.07e+04    |\n",
      "|    total_reward_pct     | 81.5        |\n",
      "|    total_trades         | 7728        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014863394 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.000912    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0703      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97182.06\n",
      "total_reward: 47182.06\n",
      "total_cost: 9721.33\n",
      "total_trades: 7716\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.72e+04    |\n",
      "|    total_cost           | 9.72e+03    |\n",
      "|    total_reward         | 4.72e+04    |\n",
      "|    total_reward_pct     | 94.4        |\n",
      "|    total_trades         | 7716        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023408512 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0515      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.9e+04     |\n",
      "|    total_cost           | 5.45e+03    |\n",
      "|    total_reward         | 2.9e+04     |\n",
      "|    total_reward_pct     | 58.1        |\n",
      "|    total_trades         | 7557        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012253427 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.27       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0663      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.06e+05   |\n",
      "|    total_cost           | 9.37e+03   |\n",
      "|    total_reward         | 5.63e+04   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 7707       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02110935 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.273     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0552     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.27e+04    |\n",
      "|    total_cost           | 1.11e+04    |\n",
      "|    total_reward         | 4.27e+04    |\n",
      "|    total_reward_pct     | 85.4        |\n",
      "|    total_trades         | 7789        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018787991 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.229      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95455.34\n",
      "total_reward: 45455.34\n",
      "total_cost: 6893.15\n",
      "total_trades: 7694\n",
      "Sharpe: 0.585\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.22e+04    |\n",
      "|    total_cost           | 4.88e+03    |\n",
      "|    total_reward         | 3.22e+04    |\n",
      "|    total_reward_pct     | 64.4        |\n",
      "|    total_trades         | 7447        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021319652 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.26       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0668      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.89e+04    |\n",
      "|    total_cost           | 7.94e+03    |\n",
      "|    total_reward         | 4.89e+04    |\n",
      "|    total_reward_pct     | 97.8        |\n",
      "|    total_trades         | 7741        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020930104 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0851      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 6.7e+03     |\n",
      "|    total_reward         | 6.1e+04     |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 7874        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029436968 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0551      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 73581.64\n",
      "total_reward: 23581.64\n",
      "total_cost: 5691.36\n",
      "total_trades: 7700\n",
      "Sharpe: 0.409\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.36e+04    |\n",
      "|    total_cost           | 5.69e+03    |\n",
      "|    total_reward         | 2.36e+04    |\n",
      "|    total_reward_pct     | 47.2        |\n",
      "|    total_trades         | 7700        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021359496 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.228      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0966      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 8.55e+03    |\n",
      "|    total_reward         | 5.09e+04    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 7805        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022460107 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0431      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.28e+04    |\n",
      "|    total_cost           | 7.46e+03    |\n",
      "|    total_reward         | 4.28e+04    |\n",
      "|    total_reward_pct     | 85.7        |\n",
      "|    total_trades         | 7775        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022083212 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.272      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0688      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 87281.72\n",
      "total_reward: 37281.72\n",
      "total_cost: 4834.84\n",
      "total_trades: 7682\n",
      "Sharpe: 0.545\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.73e+04    |\n",
      "|    total_cost           | 4.83e+03    |\n",
      "|    total_reward         | 3.73e+04    |\n",
      "|    total_reward_pct     | 74.6        |\n",
      "|    total_trades         | 7682        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013921471 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0505      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.21e+05   |\n",
      "|    total_cost           | 8.09e+03   |\n",
      "|    total_reward         | 7.12e+04   |\n",
      "|    total_reward_pct     | 142        |\n",
      "|    total_trades         | 8039       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02447856 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.258     |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0784     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.45e+05    |\n",
      "|    total_cost           | 8.14e+03    |\n",
      "|    total_reward         | 9.45e+04    |\n",
      "|    total_reward_pct     | 189         |\n",
      "|    total_trades         | 8073        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023811644 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0563      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.05e+05   |\n",
      "|    total_cost           | 7.17e+03   |\n",
      "|    total_reward         | 5.46e+04   |\n",
      "|    total_reward_pct     | 109        |\n",
      "|    total_trades         | 7872       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02637907 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.225     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0973     |\n",
      "----------------------------------------\n",
      "day: 1381, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113796.45\n",
      "total_reward: 63796.45\n",
      "total_cost: 6511.75\n",
      "total_trades: 7771\n",
      "Sharpe: 0.772\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.43e+05    |\n",
      "|    total_cost           | 8.79e+03    |\n",
      "|    total_reward         | 9.35e+04    |\n",
      "|    total_reward_pct     | 187         |\n",
      "|    total_trades         | 8096        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019714113 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.266      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0597      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.99e+04    |\n",
      "|    total_cost           | 6.73e+03    |\n",
      "|    total_reward         | 4.99e+04    |\n",
      "|    total_reward_pct     | 99.8        |\n",
      "|    total_trades         | 7943        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031400006 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.225      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.94e+04   |\n",
      "|    total_cost           | 6.5e+03    |\n",
      "|    total_reward         | 3.94e+04   |\n",
      "|    total_reward_pct     | 78.7       |\n",
      "|    total_trades         | 8083       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02739691 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.484      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.246     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0628     |\n",
      "----------------------------------------\n",
      "day: 1381, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 140833.21\n",
      "total_reward: 90833.21\n",
      "total_cost: 8352.22\n",
      "total_trades: 8275\n",
      "Sharpe: 1.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.41e+05    |\n",
      "|    total_cost           | 8.35e+03    |\n",
      "|    total_reward         | 9.08e+04    |\n",
      "|    total_reward_pct     | 182         |\n",
      "|    total_trades         | 8275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036867153 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.262      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0875      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.22e+04    |\n",
      "|    total_cost           | 5.57e+03    |\n",
      "|    total_reward         | 1.22e+04    |\n",
      "|    total_reward_pct     | 24.4        |\n",
      "|    total_trades         | 8102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028786322 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0731      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.34e+04    |\n",
      "|    total_cost           | 7.46e+03    |\n",
      "|    total_reward         | 4.34e+04    |\n",
      "|    total_reward_pct     | 86.7        |\n",
      "|    total_trades         | 7937        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026468642 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0461      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110783.78\n",
      "total_reward: 60783.78\n",
      "total_cost: 6759.26\n",
      "total_trades: 8149\n",
      "Sharpe: 0.838\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+05    |\n",
      "|    total_cost           | 6.76e+03    |\n",
      "|    total_reward         | 6.08e+04    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 8149        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022788988 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0432      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+05    |\n",
      "|    total_cost           | 7.71e+03    |\n",
      "|    total_reward         | 6.36e+04    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 8147        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017633045 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.261      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0724      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.39e+05   |\n",
      "|    total_cost           | 9.06e+03   |\n",
      "|    total_reward         | 8.86e+04   |\n",
      "|    total_reward_pct     | 177        |\n",
      "|    total_trades         | 8353       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03116259 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.282     |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0847     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.09e+05    |\n",
      "|    total_cost           | 7.1e+03     |\n",
      "|    total_reward         | 5.91e+04    |\n",
      "|    total_reward_pct     | 118         |\n",
      "|    total_trades         | 8146        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028442675 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90563.43\n",
      "total_reward: 40563.43\n",
      "total_cost: 8142.51\n",
      "total_trades: 8192\n",
      "Sharpe: 0.587\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.06e+04    |\n",
      "|    total_cost           | 8.14e+03    |\n",
      "|    total_reward         | 4.06e+04    |\n",
      "|    total_reward_pct     | 81.1        |\n",
      "|    total_trades         | 8192        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035464115 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0723      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.28e+05    |\n",
      "|    total_cost           | 7.93e+03    |\n",
      "|    total_reward         | 7.81e+04    |\n",
      "|    total_reward_pct     | 156         |\n",
      "|    total_trades         | 8184        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025196198 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0862      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 6.89e+03    |\n",
      "|    total_reward         | 6.77e+04    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 8306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033634514 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.257      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82091.48\n",
      "total_reward: 32091.48\n",
      "total_cost: 5036.50\n",
      "total_trades: 8223\n",
      "Sharpe: 0.553\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.21e+04    |\n",
      "|    total_cost           | 5.04e+03    |\n",
      "|    total_reward         | 3.21e+04    |\n",
      "|    total_reward_pct     | 64.2        |\n",
      "|    total_trades         | 8223        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035492472 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0942      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.68e+04   |\n",
      "|    total_cost           | 3.91e+03   |\n",
      "|    total_reward         | 1.68e+04   |\n",
      "|    total_reward_pct     | 33.5       |\n",
      "|    total_trades         | 8036       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 198        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03994496 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.283     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.07       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+05    |\n",
      "|    total_cost           | 6.54e+03    |\n",
      "|    total_reward         | 6.91e+04    |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 8420        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035154685 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0374      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 5.61e+03    |\n",
      "|    total_reward         | 6.26e+04    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 8228        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025186714 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0886      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97529.71\n",
      "total_reward: 47529.71\n",
      "total_cost: 5354.52\n",
      "total_trades: 8330\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.15e+05    |\n",
      "|    total_cost           | 5.31e+03    |\n",
      "|    total_reward         | 6.48e+04    |\n",
      "|    total_reward_pct     | 130         |\n",
      "|    total_trades         | 8409        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024742903 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0722      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.23e+05    |\n",
      "|    total_cost           | 8.4e+03     |\n",
      "|    total_reward         | 7.35e+04    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 8553        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020277632 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.255      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 6.6e+03     |\n",
      "|    total_reward         | 6.57e+04    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 8205        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024411084 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0811      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114484.90\n",
      "total_reward: 64484.90\n",
      "total_cost: 4947.00\n",
      "total_trades: 8110\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+05    |\n",
      "|    total_cost           | 4.95e+03    |\n",
      "|    total_reward         | 6.45e+04    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 8110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024223164 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0864      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 7.15e+03    |\n",
      "|    total_reward         | 6.55e+04    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 8338        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023392253 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0781      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+05    |\n",
      "|    total_cost           | 4.76e+03    |\n",
      "|    total_reward         | 6.21e+04    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 8415        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022242894 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.212      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 128729.93\n",
      "total_reward: 78729.93\n",
      "total_cost: 6473.93\n",
      "total_trades: 8554\n",
      "Sharpe: 0.889\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+05    |\n",
      "|    total_cost           | 6.47e+03    |\n",
      "|    total_reward         | 7.87e+04    |\n",
      "|    total_reward_pct     | 157         |\n",
      "|    total_trades         | 8554        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028215034 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.264      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 4.57e+03    |\n",
      "|    total_reward         | 6.57e+04    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 8405        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028026339 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.15e+05    |\n",
      "|    total_cost           | 6.46e+03    |\n",
      "|    total_reward         | 6.55e+04    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 8530        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031797007 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0755      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 6.63e+03    |\n",
      "|    total_reward         | 6.27e+04    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 8442        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036087982 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 72306.79\n",
      "total_reward: 22306.79\n",
      "total_cost: 4295.07\n",
      "total_trades: 8225\n",
      "Sharpe: 0.403\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.15e+05    |\n",
      "|    total_cost           | 7.41e+03    |\n",
      "|    total_reward         | 6.47e+04    |\n",
      "|    total_reward_pct     | 129         |\n",
      "|    total_trades         | 8576        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031009782 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0689      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+05    |\n",
      "|    total_cost           | 6.69e+03    |\n",
      "|    total_reward         | 7.92e+04    |\n",
      "|    total_reward_pct     | 158         |\n",
      "|    total_trades         | 8514        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029587697 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0941      |\n",
      "-----------------------------------------\n",
      "======Trading from:  2020-07-09 to  2020-10-06\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  529.7283042530553\n",
      "======Model training from:  2015-01-01 to  2020-07-09\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 321      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -11.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -4.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0539   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 324      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00933  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.87e+04 |\n",
      "|    total_cost         | 4.41e+03 |\n",
      "|    total_reward       | 4.87e+04 |\n",
      "|    total_reward_pct   | 97.3     |\n",
      "|    total_trades       | 6895     |\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -1       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -7.69    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0971   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.73    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -2.03    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00966  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 2.03     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00666  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.57e+04 |\n",
      "|    total_cost         | 4.96e+03 |\n",
      "|    total_reward       | 1.57e+04 |\n",
      "|    total_reward_pct   | 31.4     |\n",
      "|    total_trades       | 7034     |\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.275   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.53     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00553  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -22.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.527    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00812  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -3.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.81e+04 |\n",
      "|    total_cost         | 5.65e+03 |\n",
      "|    total_reward       | 3.81e+04 |\n",
      "|    total_reward_pct   | 76.3     |\n",
      "|    total_trades       | 7706     |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -173     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 3.34     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0241   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -6.83    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0578   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 4.84     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0308   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.04e+04 |\n",
      "|    total_cost         | 3.98e+03 |\n",
      "|    total_reward       | 2.04e+04 |\n",
      "|    total_reward_pct   | 40.8     |\n",
      "|    total_trades       | 7606     |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.803    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0235   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0.0635   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 2.48     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103816.34\n",
      "total_reward: 53816.34\n",
      "total_cost: 3824.57\n",
      "total_trades: 8120\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+05 |\n",
      "|    total_cost         | 3.82e+03 |\n",
      "|    total_reward       | 5.38e+04 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 8120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -0.728   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 5.36     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0361   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -11.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -5.82    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0517   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.839   |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.000947 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.02e+04 |\n",
      "|    total_cost         | 1.93e+03 |\n",
      "|    total_reward       | 1.02e+04 |\n",
      "|    total_reward_pct   | 20.5     |\n",
      "|    total_trades       | 7641     |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.2     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00219  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.00269  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -1.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 5.66     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.041    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.71e+04 |\n",
      "|    total_cost         | 4.02e+03 |\n",
      "|    total_reward       | 2.71e+04 |\n",
      "|    total_reward_pct   | 54.3     |\n",
      "|    total_trades       | 8086     |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -0.453   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -2.47    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0122   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.457   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -1.45    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0374   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.0333   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 9.91     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 4.87e+03 |\n",
      "|    total_reward       | 6.92e+04 |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 8125     |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -2.33    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00511  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0.422    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 5.59     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0335   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 8.44e+03 |\n",
      "|    total_reward       | 6.15e+04 |\n",
      "|    total_reward_pct   | 123      |\n",
      "|    total_trades       | 8434     |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0.428    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 4.23     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0212   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -0.657   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.245   |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00243  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -7.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00336  |\n",
      "------------------------------------\n",
      "day: 1381, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95540.59\n",
      "total_reward: 45540.59\n",
      "total_cost: 9584.27\n",
      "total_trades: 9253\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.55e+04 |\n",
      "|    total_cost         | 9.58e+03 |\n",
      "|    total_reward       | 4.55e+04 |\n",
      "|    total_reward_pct   | 91.1     |\n",
      "|    total_trades       | 9253     |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | -2.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.5      |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00394  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.00326  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | 0.465    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 2.96     |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.0109   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.46e+04 |\n",
      "|    total_cost         | 3.71e+03 |\n",
      "|    total_reward       | 3.46e+04 |\n",
      "|    total_reward_pct   | 69.1     |\n",
      "|    total_trades       | 8973     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -21      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 3.02     |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | -0.0893  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -5.46    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0307   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | 0.0496   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -14.2    |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.205    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.59e+04 |\n",
      "|    total_cost         | 2.57e+03 |\n",
      "|    total_reward       | 4.59e+04 |\n",
      "|    total_reward_pct   | 91.7     |\n",
      "|    total_trades       | 9012     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.269    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.000747 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | 0.143    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.155   |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.00279  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 2.74e+03 |\n",
      "|    total_reward       | 7.03e+04 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 9163     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | -0.0545  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 2.08     |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0222   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | -0.138   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -7.11    |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.0508   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | -5.79    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -2.81    |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0186   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+05 |\n",
      "|    total_cost         | 3.79e+03 |\n",
      "|    total_reward       | 6.91e+04 |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 9158     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -0.0335  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 4.95     |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0288   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 5.01     |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | -1.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 2.95     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 96587.69\n",
      "total_reward: 46587.69\n",
      "total_cost: 3663.64\n",
      "total_trades: 9326\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.66e+04 |\n",
      "|    total_cost         | 3.66e+03 |\n",
      "|    total_reward       | 4.66e+04 |\n",
      "|    total_reward_pct   | 93.2     |\n",
      "|    total_trades       | 9326     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | -0.296   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 4.88     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.0335   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | -2.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 2.91     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.0114   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | -0.349   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 3.35     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 2.7e+03  |\n",
      "|    total_reward       | 5.93e+04 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 9495     |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.756    |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.00131  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -3.95    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.019    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 3.13e+03 |\n",
      "|    total_reward       | 6.58e+04 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 9496     |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -1.87    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -21.9    |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.693    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | -1.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 2.89     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.8    |\n",
      "|    explained_variance | -0.0062  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -5.5     |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.0358   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+05 |\n",
      "|    total_cost         | 3.43e+03 |\n",
      "|    total_reward       | 7.06e+04 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 9352     |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | -2.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -7.69    |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.0595   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 2.33     |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.009    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -9.52    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -5.49    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.0414   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 3.21e+03 |\n",
      "|    total_reward       | 6.4e+04  |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 9355     |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | -0.376   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.00913  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | -1.82    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.623   |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.00374  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | 0.0319   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -3.53    |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.0211   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 114222.68\n",
      "total_reward: 64222.68\n",
      "total_cost: 3005.27\n",
      "total_trades: 9699\n",
      "Sharpe: 0.843\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 3.01e+03 |\n",
      "|    total_reward       | 6.42e+04 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 9699     |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | -0.463   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 4.91     |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.0201   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | 0.18     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.0706  |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.000791 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | 0.344    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 5.3      |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0268   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.9e+04  |\n",
      "|    total_cost         | 4.66e+03 |\n",
      "|    total_reward       | 4.9e+04  |\n",
      "|    total_reward_pct   | 98       |\n",
      "|    total_trades       | 9845     |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 4.51     |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.0186   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 4.01     |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.0268   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.6e+04  |\n",
      "|    total_cost         | 3.87e+03 |\n",
      "|    total_reward       | 3.6e+04  |\n",
      "|    total_reward_pct   | 71.9     |\n",
      "|    total_trades       | 10482    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | -8.65    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -4.36    |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.0262   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -1.64    |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.00517  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -0.328   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -5.24    |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.0205   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.85e+04 |\n",
      "|    total_cost         | 3.27e+03 |\n",
      "|    total_reward       | 4.85e+04 |\n",
      "|    total_reward_pct   | 97.1     |\n",
      "|    total_trades       | 9824     |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.1    |\n",
      "|    explained_variance | 0.0586   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.00214  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0.754   |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.00303  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 8.65     |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.0623   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 4.28e+03 |\n",
      "|    total_reward       | 7.04e+04 |\n",
      "|    total_reward_pct   | 141      |\n",
      "|    total_trades       | 10240    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | -0.555   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 4.27     |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.0233   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | 0.0421   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 1.69     |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.00422  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.9    |\n",
      "|    explained_variance | 0.347    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -3.09    |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 80725.66\n",
      "total_reward: 30725.66\n",
      "total_cost: 2452.41\n",
      "total_trades: 10058\n",
      "Sharpe: 0.505\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.07e+04 |\n",
      "|    total_cost         | 2.45e+03 |\n",
      "|    total_reward       | 3.07e+04 |\n",
      "|    total_reward_pct   | 61.5     |\n",
      "|    total_trades       | 10058    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.00217  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.225   |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.00303  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.3e+04  |\n",
      "|    total_cost         | 2.32e+03 |\n",
      "|    total_reward       | 2.3e+04  |\n",
      "|    total_reward_pct   | 45.9     |\n",
      "|    total_trades       | 10369    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | 0.275    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 5.13     |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.0233   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | -0.00171 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -6.6     |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.0357   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | 0.0114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -3.25    |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 4.11e+03 |\n",
      "|    total_reward       | 5.74e+04 |\n",
      "|    total_reward_pct   | 115      |\n",
      "|    total_trades       | 10650    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39      |\n",
      "|    explained_variance | -0.137   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -9.41    |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.0643   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 3.23     |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.00839  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | -0.0205  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 5.28     |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.92e+04 |\n",
      "|    total_cost         | 5.57e+03 |\n",
      "|    total_reward       | 4.92e+04 |\n",
      "|    total_reward_pct   | 98.5     |\n",
      "|    total_trades       | 10992    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.375    |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.0013   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | 0.465    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0.537   |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.00112  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.218    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.46e+04 |\n",
      "|    total_cost         | 5.69e+03 |\n",
      "|    total_reward       | 3.46e+04 |\n",
      "|    total_reward_pct   | 69.2     |\n",
      "|    total_trades       | 11369    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 0.299    |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.0026   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0.0378   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 11.7     |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.0936   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 83767.05\n",
      "total_reward: 33767.05\n",
      "total_cost: 4539.62\n",
      "total_trades: 11394\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.38e+04 |\n",
      "|    total_cost         | 4.54e+03 |\n",
      "|    total_reward       | 3.38e+04 |\n",
      "|    total_reward_pct   | 67.5     |\n",
      "|    total_trades       | 11394    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | -1.88    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -3.13    |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.00732  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0.608    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -2.93    |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.00582  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0.157    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -3.85    |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 0.0131   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.87e+04 |\n",
      "|    total_cost         | 3.51e+03 |\n",
      "|    total_reward       | 2.87e+04 |\n",
      "|    total_reward_pct   | 57.5     |\n",
      "|    total_trades       | 11451    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.9    |\n",
      "|    explained_variance | 0.552    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.0013   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -1.3     |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.00479  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | -0.0849  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.571   |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.0133   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.78e+04 |\n",
      "|    total_cost         | 3.11e+03 |\n",
      "|    total_reward       | 3.78e+04 |\n",
      "|    total_reward_pct   | 75.6     |\n",
      "|    total_trades       | 11748    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | -0.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -3.64    |\n",
      "|    std                | 2.14     |\n",
      "|    value_loss         | 0.0156   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -6.24    |\n",
      "|    std                | 2.16     |\n",
      "|    value_loss         | 0.0257   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -22.6    |\n",
      "|    std                | 2.18     |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.87e+03 |\n",
      "|    total_reward       | 5.04e+04 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 12151    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | -0.0324  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 0.292    |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.000292 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | 0.412    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -3.77    |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 0.00873  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.25e+04 |\n",
      "|    total_cost         | 1.67e+03 |\n",
      "|    total_reward       | 2.25e+04 |\n",
      "|    total_reward_pct   | 45       |\n",
      "|    total_trades       | 12156    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.00153  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | -0.0161  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 2.84     |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.018    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0709   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 3.67     |\n",
      "|    std                | 2.28     |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92706.53\n",
      "total_reward: 42706.53\n",
      "total_cost: 2338.28\n",
      "total_trades: 12422\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.27e+04 |\n",
      "|    total_cost         | 2.34e+03 |\n",
      "|    total_reward       | 4.27e+04 |\n",
      "|    total_reward_pct   | 85.4     |\n",
      "|    total_trades       | 12422    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.428   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.667   |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.000949 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 7.05     |\n",
      "|    std                | 2.31     |\n",
      "|    value_loss         | 0.0339   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.655   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -2.43    |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 0.00805  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.69e+04 |\n",
      "|    total_cost         | 2.59e+03 |\n",
      "|    total_reward       | 4.69e+04 |\n",
      "|    total_reward_pct   | 93.7     |\n",
      "|    total_trades       | 12557    |\n",
      "| time/                 |          |\n",
      "|    fps                | 318      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -1.33    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -2.08    |\n",
      "|    std                | 2.35     |\n",
      "|    value_loss         | 0.0165   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.341   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.00985  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.202    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 8.08     |\n",
      "|    std                | 2.39     |\n",
      "|    value_loss         | 0.0349   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 2.16e+03 |\n",
      "|    total_reward       | 5.67e+04 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 12687    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.838   |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.00152  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.0817   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -4.4     |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | -0.00952 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 13.2     |\n",
      "|    std                | 2.45     |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 3.06e+03 |\n",
      "|    total_reward       | 5.26e+04 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 12797    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | -1.52    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -13.4    |\n",
      "|    std                | 2.48     |\n",
      "|    value_loss         | 0.0926   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | -0.0597  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.51e+04 |\n",
      "|    total_cost         | 1.61e+03 |\n",
      "|    total_reward       | 3.51e+04 |\n",
      "|    total_reward_pct   | 70.2     |\n",
      "|    total_trades       | 12752    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 3.03     |\n",
      "|    std                | 2.52     |\n",
      "|    value_loss         | 0.00866  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -0.0098  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.0034   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -2.42    |\n",
      "|    std                | 2.57     |\n",
      "|    value_loss         | 0.00394  |\n",
      "------------------------------------\n",
      "day: 1381, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89515.73\n",
      "total_reward: 39515.73\n",
      "total_cost: 1543.39\n",
      "total_trades: 12486\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.95e+04  |\n",
      "|    total_cost         | 1.54e+03  |\n",
      "|    total_reward       | 3.95e+04  |\n",
      "|    total_reward_pct   | 79        |\n",
      "|    total_trades       | 12486     |\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -1.08     |\n",
      "|    std                | 2.6       |\n",
      "|    value_loss         | 0.00126   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -4.64    |\n",
      "|    std                | 2.62     |\n",
      "|    value_loss         | 0.0423   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 6.67      |\n",
      "|    std                | 2.64      |\n",
      "|    value_loss         | 0.0276    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.68e+04 |\n",
      "|    total_cost         | 2.55e+03 |\n",
      "|    total_reward       | 4.68e+04 |\n",
      "|    total_reward_pct   | 93.5     |\n",
      "|    total_trades       | 12492    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | -0.0685  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.805   |\n",
      "|    std                | 2.65     |\n",
      "|    value_loss         | 0.00433  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 6.05     |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.0221   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 3.23     |\n",
      "|    std                | 2.7      |\n",
      "|    value_loss         | 0.0192   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.01e+05  |\n",
      "|    total_cost         | 1.81e+03  |\n",
      "|    total_reward       | 5.06e+04  |\n",
      "|    total_reward_pct   | 101       |\n",
      "|    total_trades       | 12465     |\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -2.14     |\n",
      "|    std                | 2.72      |\n",
      "|    value_loss         | 0.00237   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | -0.00951 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -4.59    |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 0.016    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+05 |\n",
      "|    total_cost         | 1.48e+03 |\n",
      "|    total_reward       | 5.05e+04 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 12602    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0.437    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.205    |\n",
      "|    std                | 2.76     |\n",
      "|    value_loss         | 0.00153  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -13.7    |\n",
      "|    std                | 2.79     |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0.00424  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.191   |\n",
      "|    std                | 2.81     |\n",
      "|    value_loss         | 0.000142 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.45e+04 |\n",
      "|    total_cost         | 1.92e+03 |\n",
      "|    total_reward       | 4.45e+04 |\n",
      "|    total_reward_pct   | 88.9     |\n",
      "|    total_trades       | 12552    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0.0133   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -0.52    |\n",
      "|    std                | 2.83     |\n",
      "|    value_loss         | 0.00369  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 2.74     |\n",
      "|    std                | 2.85     |\n",
      "|    value_loss         | 0.00476  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -4.87    |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 94761.22\n",
      "total_reward: 44761.22\n",
      "total_cost: 1395.29\n",
      "total_trades: 12556\n",
      "Sharpe: 0.672\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.48e+04 |\n",
      "|    total_cost         | 1.4e+03  |\n",
      "|    total_reward       | 4.48e+04 |\n",
      "|    total_reward_pct   | 89.5     |\n",
      "|    total_trades       | 12556    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | -1.83    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -1.32    |\n",
      "|    std                | 2.9      |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -1.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.96     |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 0.0048   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | -0.0422  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 0.229    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.66e+04 |\n",
      "|    total_cost         | 927      |\n",
      "|    total_reward       | 1.66e+04 |\n",
      "|    total_reward_pct   | 33.3     |\n",
      "|    total_trades       | 12600    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -4.93    |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 0.012    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | -0.229   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -2.92    |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.00655  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+05 |\n",
      "|    total_cost         | 2.09e+03 |\n",
      "|    total_reward       | 5.77e+04 |\n",
      "|    total_reward_pct   | 115      |\n",
      "|    total_trades       | 12632    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | -0.563   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -3.26    |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.00815  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.2     |\n",
      "|    explained_variance | -0.000949 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    std                | 3.06      |\n",
      "|    value_loss         | 0.0843    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | -0.116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -1.51    |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.00332  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+05 |\n",
      "|    total_cost         | 2.25e+03 |\n",
      "|    total_reward       | 6.52e+04 |\n",
      "|    total_reward_pct   | 130      |\n",
      "|    total_trades       | 12446    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 3.1      |\n",
      "|    value_loss         | 0.0548   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 3.07     |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.00739  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | -0.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    std                | 3.15     |\n",
      "|    value_loss         | 0.00211  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.28e+04 |\n",
      "|    total_cost         | 1.68e+03 |\n",
      "|    total_reward       | 2.28e+04 |\n",
      "|    total_reward_pct   | 45.7     |\n",
      "|    total_trades       | 12233    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 0.227    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -7.32    |\n",
      "|    std                | 3.18     |\n",
      "|    value_loss         | 0.026    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | -0.00122 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.527   |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.00569  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | -0.0907  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 7.39     |\n",
      "|    std                | 3.23     |\n",
      "|    value_loss         | 0.0338   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 83717.89\n",
      "total_reward: 33717.89\n",
      "total_cost: 1597.50\n",
      "total_trades: 12655\n",
      "Sharpe: 0.548\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.37e+04 |\n",
      "|    total_cost         | 1.6e+03  |\n",
      "|    total_reward       | 3.37e+04 |\n",
      "|    total_reward_pct   | 67.4     |\n",
      "|    total_trades       | 12655    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | -0.124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -3.04    |\n",
      "|    std                | 3.26     |\n",
      "|    value_loss         | 0.00589  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    std                | 3.28     |\n",
      "|    value_loss         | 0.00197  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.98e+04 |\n",
      "|    total_cost         | 1.7e+03  |\n",
      "|    total_reward       | 2.98e+04 |\n",
      "|    total_reward_pct   | 59.5     |\n",
      "|    total_trades       | 12706    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | -0.0775  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    std                | 3.31     |\n",
      "|    value_loss         | 0.00442  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0.0853   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 5.56     |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.0201   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 4.37     |\n",
      "|    std                | 3.37     |\n",
      "|    value_loss         | 0.00925  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.96e+04 |\n",
      "|    total_cost         | 1.23e+03 |\n",
      "|    total_reward       | -433     |\n",
      "|    total_reward_pct   | -0.866   |\n",
      "|    total_trades       | 12357    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | -0.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 5.26     |\n",
      "|    std                | 3.4      |\n",
      "|    value_loss         | 0.0144   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 3.42     |\n",
      "|    value_loss         | 0.153    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | -0.0337  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    std                | 3.45     |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.71e+04 |\n",
      "|    total_cost         | 2.02e+03 |\n",
      "|    total_reward       | 1.71e+04 |\n",
      "|    total_reward_pct   | 34.1     |\n",
      "|    total_trades       | 12727    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.6    |\n",
      "|    explained_variance | -0.014   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 3.33     |\n",
      "|    std                | 3.47     |\n",
      "|    value_loss         | 0.00563  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | -0.193   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -4.11    |\n",
      "|    std                | 3.5      |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | 0.0175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -2.96    |\n",
      "|    std                | 3.52     |\n",
      "|    value_loss         | 0.00441  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.79e+04 |\n",
      "|    total_cost         | 1.92e+03 |\n",
      "|    total_reward       | 7.94e+03 |\n",
      "|    total_reward_pct   | 15.9     |\n",
      "|    total_trades       | 12757    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -7.66    |\n",
      "|    std                | 3.55     |\n",
      "|    value_loss         | 0.0239   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -1.16    |\n",
      "|    std                | 3.58     |\n",
      "|    value_loss         | 0.0182   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -5       |\n",
      "|    std                | 3.6      |\n",
      "|    value_loss         | 0.039    |\n",
      "------------------------------------\n",
      "day: 1381, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 66689.83\n",
      "total_reward: 16689.83\n",
      "total_cost: 1869.52\n",
      "total_trades: 12905\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.67e+04 |\n",
      "|    total_cost         | 1.87e+03 |\n",
      "|    total_reward       | 1.67e+04 |\n",
      "|    total_reward_pct   | 33.4     |\n",
      "|    total_trades       | 12905    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 0.144    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 16.2     |\n",
      "|    std                | 3.63     |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | -0.176   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -14.7    |\n",
      "|    std                | 3.65     |\n",
      "|    value_loss         | 0.083    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.35e+04  |\n",
      "|    total_cost         | 3e+03     |\n",
      "|    total_reward       | 3.35e+04  |\n",
      "|    total_reward_pct   | 67        |\n",
      "|    total_trades       | 13391     |\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 244       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | 3.21      |\n",
      "|    std                | 3.68      |\n",
      "|    value_loss         | 0.0058    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 3.7      |\n",
      "|    value_loss         | 0.00377  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 6.18     |\n",
      "|    std                | 3.73     |\n",
      "|    value_loss         | 0.0167   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.11e+04 |\n",
      "|    total_cost         | 1.71e+03 |\n",
      "|    total_reward       | 1.11e+04 |\n",
      "|    total_reward_pct   | 22.2     |\n",
      "|    total_trades       | 13192    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | -0.035   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 7.4      |\n",
      "|    std                | 3.76     |\n",
      "|    value_loss         | 0.0378   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | -1.5     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -8.42    |\n",
      "|    std                | 3.79     |\n",
      "|    value_loss         | 0.0433   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -5.13    |\n",
      "|    std                | 3.82     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.15e+04 |\n",
      "|    total_cost         | 1.81e+03 |\n",
      "|    total_reward       | 2.15e+04 |\n",
      "|    total_reward_pct   | 43.1     |\n",
      "|    total_trades       | 13455    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | -0.035   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 3.85     |\n",
      "|    value_loss         | 0.00469  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -6.92    |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 0.0282   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | -0.0133  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 5.01     |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.99e+04 |\n",
      "|    total_cost         | 1.99e+03 |\n",
      "|    total_reward       | 2.99e+04 |\n",
      "|    total_reward_pct   | 59.8     |\n",
      "|    total_trades       | 13506    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 3.93     |\n",
      "|    std                | 3.95     |\n",
      "|    value_loss         | 0.00705  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -16.7    |\n",
      "|    std                | 3.97     |\n",
      "|    value_loss         | 0.155    |\n",
      "------------------------------------\n",
      "day: 1381, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 82663.43\n",
      "total_reward: 32663.43\n",
      "total_cost: 1925.42\n",
      "total_trades: 13418\n",
      "Sharpe: 0.494\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.27e+04 |\n",
      "|    total_cost         | 1.93e+03 |\n",
      "|    total_reward       | 3.27e+04 |\n",
      "|    total_reward_pct   | 65.3     |\n",
      "|    total_trades       | 13418    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | -0.351   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -0.746   |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.00763  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -7.93    |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 0.036    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | -0.155   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 6.67     |\n",
      "|    std                | 4.05     |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.72e+04 |\n",
      "|    total_cost         | 2.11e+03 |\n",
      "|    total_reward       | 3.72e+04 |\n",
      "|    total_reward_pct   | 74.5     |\n",
      "|    total_trades       | 13212    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.6    |\n",
      "|    explained_variance | -0.0103  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 5.04     |\n",
      "|    std                | 4.07     |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 267       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -1.82     |\n",
      "|    std                | 4.11      |\n",
      "|    value_loss         | 0.00434   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | -12.3     |\n",
      "|    std                | 4.14      |\n",
      "|    value_loss         | 0.0497    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.57e+04 |\n",
      "|    total_cost         | 2.52e+03 |\n",
      "|    total_reward       | 4.57e+04 |\n",
      "|    total_reward_pct   | 91.5     |\n",
      "|    total_trades       | 13464    |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 0.653    |\n",
      "|    std                | 4.17     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -5.18    |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 41.9     |\n",
      "|    std                | 4.23     |\n",
      "|    value_loss         | 0.678    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.28e+04 |\n",
      "|    total_cost         | 1.95e+03 |\n",
      "|    total_reward       | 2.28e+04 |\n",
      "|    total_reward_pct   | 45.6     |\n",
      "|    total_trades       | 13418    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 4.26     |\n",
      "|    value_loss         | 0.00609  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 316       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 277       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -6.36     |\n",
      "|    std                | 4.28      |\n",
      "|    value_loss         | 0.0183    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.55e+04 |\n",
      "|    total_cost         | 2.35e+03 |\n",
      "|    total_reward       | 2.55e+04 |\n",
      "|    total_reward_pct   | 51       |\n",
      "|    total_trades       | 13652    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | -0.0497  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -4.66    |\n",
      "|    std                | 4.31     |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 0.0184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.362    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 316       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 282       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 2.93      |\n",
      "|    std                | 4.37      |\n",
      "|    value_loss         | 0.00396   |\n",
      "-------------------------------------\n",
      "day: 1381, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 53530.90\n",
      "total_reward: 3530.90\n",
      "total_cost: 1583.10\n",
      "total_trades: 13478\n",
      "Sharpe: 0.206\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.35e+04 |\n",
      "|    total_cost         | 1.58e+03 |\n",
      "|    total_reward       | 3.53e+03 |\n",
      "|    total_reward_pct   | 7.06     |\n",
      "|    total_trades       | 13478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | -0.106   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 1.49     |\n",
      "|    std                | 4.41     |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    std                | 4.44     |\n",
      "|    value_loss         | 0.0694   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -2.67    |\n",
      "|    std                | 4.46     |\n",
      "|    value_loss         | 0.00481  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.51e+04 |\n",
      "|    total_cost         | 2.09e+03 |\n",
      "|    total_reward       | 2.51e+04 |\n",
      "|    total_reward_pct   | 50.2     |\n",
      "|    total_trades       | 13919    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -0.834   |\n",
      "|    std                | 4.49     |\n",
      "|    value_loss         | 0.0038   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 316       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 290       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | 1.17      |\n",
      "|    std                | 4.53      |\n",
      "|    value_loss         | 0.00258   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | 8.51e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 2.47     |\n",
      "|    std                | 4.56     |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.55e+04 |\n",
      "|    total_cost         | 2.18e+03 |\n",
      "|    total_reward       | 3.55e+04 |\n",
      "|    total_reward_pct   | 71.1     |\n",
      "|    total_trades       | 13907    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | -4.93    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 2.05     |\n",
      "|    std                | 4.6      |\n",
      "|    value_loss         | 0.00571  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -5.98    |\n",
      "|    std                | 4.64     |\n",
      "|    value_loss         | 0.0232   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.33e+04 |\n",
      "|    total_cost         | 1.67e+03 |\n",
      "|    total_reward       | 3.33e+04 |\n",
      "|    total_reward_pct   | 66.5     |\n",
      "|    total_trades       | 13887    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | -0.0381  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -12      |\n",
      "|    std                | 4.67     |\n",
      "|    value_loss         | 0.0589   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.4    |\n",
      "|    explained_variance | -0.308   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 4.72     |\n",
      "|    value_loss         | 0.0439   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.5    |\n",
      "|    explained_variance | 0.305    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    std                | 4.75     |\n",
      "|    value_loss         | 0.00207  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.18e+04 |\n",
      "|    total_cost         | 1.34e+03 |\n",
      "|    total_reward       | 1.18e+04 |\n",
      "|    total_reward_pct   | 23.6     |\n",
      "|    total_trades       | 13633    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.7    |\n",
      "|    explained_variance | -0.358   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -3.68    |\n",
      "|    std                | 4.79     |\n",
      "|    value_loss         | 0.00617  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 3.43     |\n",
      "|    std                | 4.84     |\n",
      "|    value_loss         | 0.00654  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -9.47    |\n",
      "|    std                | 4.88     |\n",
      "|    value_loss         | 0.0379   |\n",
      "------------------------------------\n",
      "day: 1381, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 95360.96\n",
      "total_reward: 45360.96\n",
      "total_cost: 1780.15\n",
      "total_trades: 13941\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.54e+04 |\n",
      "|    total_cost         | 1.78e+03 |\n",
      "|    total_reward       | 4.54e+04 |\n",
      "|    total_reward_pct   | 90.7     |\n",
      "|    total_trades       | 13941    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -8.74    |\n",
      "|    std                | 4.9      |\n",
      "|    value_loss         | 0.0425   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 19.1     |\n",
      "|    std                | 4.96     |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 0.0347   |\n",
      "|    std                | 5        |\n",
      "|    value_loss         | 0.000835 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.37e+04 |\n",
      "|    total_cost         | 1.57e+03 |\n",
      "|    total_reward       | 3.37e+04 |\n",
      "|    total_reward_pct   | 67.5     |\n",
      "|    total_trades       | 13490    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 4.87     |\n",
      "|    std                | 5.04     |\n",
      "|    value_loss         | 0.018    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -4.09    |\n",
      "|    std                | 5.08     |\n",
      "|    value_loss         | 0.0054   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.9    |\n",
      "|    explained_variance | 0.0058   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 7.97     |\n",
      "|    std                | 5.11     |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.62e+04 |\n",
      "|    total_cost         | 2.32e+03 |\n",
      "|    total_reward       | 4.62e+04 |\n",
      "|    total_reward_pct   | 92.4     |\n",
      "|    total_trades       | 13848    |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | -0.0738  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    std                | 5.15     |\n",
      "|    value_loss         | 0.00899  |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-07-09 to  2020-10-06\n",
      "A2C Sharpe Ratio:  0.40885089556016485\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.04e+05 |\n",
      "|    total_cost       | 1.26e+04 |\n",
      "|    total_reward     | 5.39e+04 |\n",
      "|    total_reward_pct | 108      |\n",
      "|    total_trades     | 7801     |\n",
      "| time/               |          |\n",
      "|    fps              | 387      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "day: 1381, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 59360.30\n",
      "total_reward: 9360.30\n",
      "total_cost: 9145.59\n",
      "total_trades: 7494\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.94e+04    |\n",
      "|    total_cost           | 9.15e+03    |\n",
      "|    total_reward         | 9.36e+03    |\n",
      "|    total_reward_pct     | 18.7        |\n",
      "|    total_trades         | 7494        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017687932 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.257      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0916      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.2e+04    |\n",
      "|    total_cost           | 1.36e+04   |\n",
      "|    total_reward         | 1.2e+04    |\n",
      "|    total_reward_pct     | 24.1       |\n",
      "|    total_trades         | 7656       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 372        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02033137 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.0311     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.293     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0268    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0446     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.96e+04    |\n",
      "|    total_cost           | 1.2e+04     |\n",
      "|    total_reward         | 9.62e+03    |\n",
      "|    total_reward_pct     | 19.2        |\n",
      "|    total_trades         | 7620        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024956994 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0308      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85801.20\n",
      "total_reward: 35801.20\n",
      "total_cost: 13266.76\n",
      "total_trades: 7736\n",
      "Sharpe: 0.650\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.58e+04   |\n",
      "|    total_cost           | 1.33e+04   |\n",
      "|    total_reward         | 3.58e+04   |\n",
      "|    total_reward_pct     | 71.6       |\n",
      "|    total_trades         | 7736       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00806785 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.0321     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0285     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.08e+04    |\n",
      "|    total_cost           | 1.24e+04    |\n",
      "|    total_reward         | 3.08e+04    |\n",
      "|    total_reward_pct     | 61.6        |\n",
      "|    total_trades         | 7832        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015580323 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0411      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+05    |\n",
      "|    total_cost           | 1.06e+04    |\n",
      "|    total_reward         | 8.35e+04    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 7912        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017581705 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0824      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0385      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.54e+04    |\n",
      "|    total_cost           | 1.02e+04    |\n",
      "|    total_reward         | 3.54e+04    |\n",
      "|    total_reward_pct     | 70.8        |\n",
      "|    total_trades         | 7697        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025511794 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.242      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0636      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 164334.74\n",
      "total_reward: 114334.74\n",
      "total_cost: 10876.88\n",
      "total_trades: 7705\n",
      "Sharpe: 1.084\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.41e+04    |\n",
      "|    total_cost           | 1.01e+04    |\n",
      "|    total_reward         | 3.41e+04    |\n",
      "|    total_reward_pct     | 68.2        |\n",
      "|    total_trades         | 7514        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017074289 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0433      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.17e+04   |\n",
      "|    total_cost           | 8.9e+03    |\n",
      "|    total_reward         | 4.17e+04   |\n",
      "|    total_reward_pct     | 83.4       |\n",
      "|    total_trades         | 7664       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02680282 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.25      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0212    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0627     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.3e+04     |\n",
      "|    total_cost           | 6.12e+03    |\n",
      "|    total_reward         | 4.3e+04     |\n",
      "|    total_reward_pct     | 86          |\n",
      "|    total_trades         | 7519        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024009157 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0458      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 126009.19\n",
      "total_reward: 76009.19\n",
      "total_cost: 7605.75\n",
      "total_trades: 7572\n",
      "Sharpe: 0.879\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+05    |\n",
      "|    total_cost           | 7.61e+03    |\n",
      "|    total_reward         | 7.6e+04     |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 7572        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023339324 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.254      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0541      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+05    |\n",
      "|    total_cost           | 7.08e+03    |\n",
      "|    total_reward         | 6.94e+04    |\n",
      "|    total_reward_pct     | 139         |\n",
      "|    total_trades         | 7477        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022824617 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.252      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0616      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.75e+04    |\n",
      "|    total_cost           | 6.52e+03    |\n",
      "|    total_reward         | 4.75e+04    |\n",
      "|    total_reward_pct     | 95          |\n",
      "|    total_trades         | 7649        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013587067 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.269      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0653      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 125553.76\n",
      "total_reward: 75553.76\n",
      "total_cost: 8733.46\n",
      "total_trades: 7812\n",
      "Sharpe: 0.968\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+05    |\n",
      "|    total_cost           | 8.73e+03    |\n",
      "|    total_reward         | 7.56e+04    |\n",
      "|    total_reward_pct     | 151         |\n",
      "|    total_trades         | 7812        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021660779 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.03e+04    |\n",
      "|    total_cost           | 5.3e+03     |\n",
      "|    total_reward         | 3.03e+04    |\n",
      "|    total_reward_pct     | 60.6        |\n",
      "|    total_trades         | 7636        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015943576 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0761      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.16e+04    |\n",
      "|    total_cost           | 6.78e+03    |\n",
      "|    total_reward         | 4.16e+04    |\n",
      "|    total_reward_pct     | 83.1        |\n",
      "|    total_trades         | 7686        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018154707 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0415      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.06e+05   |\n",
      "|    total_cost           | 8.07e+03   |\n",
      "|    total_reward         | 5.64e+04   |\n",
      "|    total_reward_pct     | 113        |\n",
      "|    total_trades         | 7834       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 363        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02891548 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.29      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0499     |\n",
      "----------------------------------------\n",
      "day: 1381, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 115985.33\n",
      "total_reward: 65985.33\n",
      "total_cost: 6371.19\n",
      "total_trades: 7831\n",
      "Sharpe: 0.879\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.12e+05   |\n",
      "|    total_cost           | 6.11e+03   |\n",
      "|    total_reward         | 6.24e+04   |\n",
      "|    total_reward_pct     | 125        |\n",
      "|    total_trades         | 7612       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 363        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02069538 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.321      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.249     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0475     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 6.58e+03    |\n",
      "|    total_reward         | 7.02e+04    |\n",
      "|    total_reward_pct     | 140         |\n",
      "|    total_trades         | 7830        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015185845 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0572      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.07e+05     |\n",
      "|    total_cost           | 7.75e+03     |\n",
      "|    total_reward         | 5.72e+04     |\n",
      "|    total_reward_pct     | 114          |\n",
      "|    total_trades         | 7979         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096834665 |\n",
      "|    clip_fraction        | 0.239        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.7        |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.273       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0237      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0564       |\n",
      "------------------------------------------\n",
      "day: 1381, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 110603.53\n",
      "total_reward: 60603.53\n",
      "total_cost: 5093.71\n",
      "total_trades: 7727\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.11e+05     |\n",
      "|    total_cost           | 5.09e+03     |\n",
      "|    total_reward         | 6.06e+04     |\n",
      "|    total_reward_pct     | 121          |\n",
      "|    total_trades         | 7727         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 363          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153683545 |\n",
      "|    clip_fraction        | 0.237        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.7        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.272       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0632       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.25e+05   |\n",
      "|    total_cost           | 6.22e+03   |\n",
      "|    total_reward         | 7.45e+04   |\n",
      "|    total_reward_pct     | 149        |\n",
      "|    total_trades         | 7738       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 363        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02340803 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.254     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0614     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.61e+05    |\n",
      "|    total_cost           | 6.4e+03     |\n",
      "|    total_reward         | 1.11e+05    |\n",
      "|    total_reward_pct     | 223         |\n",
      "|    total_trades         | 7827        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025675789 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.265      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0737      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 148114.11\n",
      "total_reward: 98114.11\n",
      "total_cost: 4862.07\n",
      "total_trades: 7529\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.48e+05    |\n",
      "|    total_cost           | 4.86e+03    |\n",
      "|    total_reward         | 9.81e+04    |\n",
      "|    total_reward_pct     | 196         |\n",
      "|    total_trades         | 7529        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021444913 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.256      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0943      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.51e+05    |\n",
      "|    total_cost           | 5.75e+03    |\n",
      "|    total_reward         | 1.01e+05    |\n",
      "|    total_reward_pct     | 202         |\n",
      "|    total_trades         | 7809        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027399175 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.222      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.54e+05    |\n",
      "|    total_cost           | 6.54e+03    |\n",
      "|    total_reward         | 1.04e+05    |\n",
      "|    total_reward_pct     | 209         |\n",
      "|    total_trades         | 7859        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021296293 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.088       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.1e+05    |\n",
      "|    total_cost           | 5.86e+03   |\n",
      "|    total_reward         | 5.99e+04   |\n",
      "|    total_reward_pct     | 120        |\n",
      "|    total_trades         | 7784       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 364        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02335079 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.511      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.268     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0894     |\n",
      "----------------------------------------\n",
      "day: 1381, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 153728.65\n",
      "total_reward: 103728.65\n",
      "total_cost: 7806.03\n",
      "total_trades: 7893\n",
      "Sharpe: 1.065\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.54e+05    |\n",
      "|    total_cost           | 7.81e+03    |\n",
      "|    total_reward         | 1.04e+05    |\n",
      "|    total_reward_pct     | 207         |\n",
      "|    total_trades         | 7893        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028943304 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0526      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.48e+05    |\n",
      "|    total_cost           | 5.73e+03    |\n",
      "|    total_reward         | 9.82e+04    |\n",
      "|    total_reward_pct     | 196         |\n",
      "|    total_trades         | 7892        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027874697 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.241      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0983      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.13e+04    |\n",
      "|    total_cost           | 5.36e+03    |\n",
      "|    total_reward         | 3.13e+04    |\n",
      "|    total_reward_pct     | 62.6        |\n",
      "|    total_trades         | 7726        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020447977 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0893      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 120\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 121321.25\n",
      "total_reward: 71321.25\n",
      "total_cost: 6041.42\n",
      "total_trades: 7808\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.21e+05   |\n",
      "|    total_cost           | 6.04e+03   |\n",
      "|    total_reward         | 7.13e+04   |\n",
      "|    total_reward_pct     | 143        |\n",
      "|    total_trades         | 7808       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 364        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02999388 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.251     |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.116      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+05    |\n",
      "|    total_cost           | 6.37e+03    |\n",
      "|    total_reward         | 8.37e+04    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 7837        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021037657 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0846      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.73e+05   |\n",
      "|    total_cost           | 7.3e+03    |\n",
      "|    total_reward         | 1.23e+05   |\n",
      "|    total_reward_pct     | 246        |\n",
      "|    total_trades         | 7962       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 364        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02695496 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.263     |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0909     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.51e+05    |\n",
      "|    total_cost           | 6.25e+03    |\n",
      "|    total_reward         | 1.01e+05    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 7965        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025174435 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 125\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 174526.22\n",
      "total_reward: 124526.22\n",
      "total_cost: 6446.59\n",
      "total_trades: 7777\n",
      "Sharpe: 1.086\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.27e+05    |\n",
      "|    total_cost           | 6.72e+03    |\n",
      "|    total_reward         | 7.71e+04    |\n",
      "|    total_reward_pct     | 154         |\n",
      "|    total_trades         | 8039        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019744145 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.52e+05    |\n",
      "|    total_cost           | 6.7e+03     |\n",
      "|    total_reward         | 1.02e+05    |\n",
      "|    total_reward_pct     | 203         |\n",
      "|    total_trades         | 8065        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018732628 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.255      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.49e+05   |\n",
      "|    total_cost           | 5.02e+03   |\n",
      "|    total_reward         | 9.89e+04   |\n",
      "|    total_reward_pct     | 198        |\n",
      "|    total_trades         | 8063       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 363        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02349646 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.229     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "day: 1381, episode: 130\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 137461.25\n",
      "total_reward: 87461.25\n",
      "total_cost: 6306.05\n",
      "total_trades: 8239\n",
      "Sharpe: 0.918\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.37e+05    |\n",
      "|    total_cost           | 6.31e+03    |\n",
      "|    total_reward         | 8.75e+04    |\n",
      "|    total_reward_pct     | 175         |\n",
      "|    total_trades         | 8239        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017610352 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.232      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 5.49e+03    |\n",
      "|    total_reward         | 6.56e+04    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 7906        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030190803 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0926      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+05    |\n",
      "|    total_cost           | 5.03e+03    |\n",
      "|    total_reward         | 7.6e+04     |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 8112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021671414 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0852      |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 135\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 146573.69\n",
      "total_reward: 96573.69\n",
      "total_cost: 6449.75\n",
      "total_trades: 8061\n",
      "Sharpe: 0.958\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.47e+05    |\n",
      "|    total_cost           | 6.45e+03    |\n",
      "|    total_reward         | 9.66e+04    |\n",
      "|    total_reward_pct     | 193         |\n",
      "|    total_trades         | 8061        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019493304 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0949      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.35e+05    |\n",
      "|    total_cost           | 6.17e+03    |\n",
      "|    total_reward         | 8.51e+04    |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 8258        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025985837 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.234      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.35e+05    |\n",
      "|    total_cost           | 5.91e+03    |\n",
      "|    total_reward         | 8.51e+04    |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 8180        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020063609 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.261      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0998      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.35e+05    |\n",
      "|    total_cost           | 5.41e+03    |\n",
      "|    total_reward         | 8.5e+04     |\n",
      "|    total_reward_pct     | 170         |\n",
      "|    total_trades         | 8255        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033305265 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.24       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "day: 1381, episode: 140\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 129548.07\n",
      "total_reward: 79548.07\n",
      "total_cost: 6298.78\n",
      "total_trades: 8192\n",
      "Sharpe: 0.912\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.53e+05    |\n",
      "|    total_cost           | 5.08e+03    |\n",
      "|    total_reward         | 1.03e+05    |\n",
      "|    total_reward_pct     | 206         |\n",
      "|    total_trades         | 8115        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018126264 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0795      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.5e+05     |\n",
      "|    total_cost           | 5.03e+03    |\n",
      "|    total_reward         | 9.96e+04    |\n",
      "|    total_reward_pct     | 199         |\n",
      "|    total_trades         | 8207        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024232242 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.221      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.39e+05   |\n",
      "|    total_cost           | 5.27e+03   |\n",
      "|    total_reward         | 8.91e+04   |\n",
      "|    total_reward_pct     | 178        |\n",
      "|    total_trades         | 8230       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 363        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 270        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01519106 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.6      |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.254     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "day: 1381, episode: 145\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 133511.77\n",
      "total_reward: 83511.77\n",
      "total_cost: 6728.21\n",
      "total_trades: 8334\n",
      "Sharpe: 0.925\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+05    |\n",
      "|    total_cost           | 6.73e+03    |\n",
      "|    total_reward         | 8.35e+04    |\n",
      "|    total_reward_pct     | 167         |\n",
      "|    total_trades         | 8334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016713709 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.243      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-07-09 to  2020-10-06\n",
      "PPO Sharpe Ratio:  0.19200479238200682\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_1\n",
      "day: 1381, episode: 150\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 135845.32\n",
      "total_reward: 85845.32\n",
      "total_cost: 525.80\n",
      "total_trades: 7278\n",
      "Sharpe: 0.791\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.36e+05 |\n",
      "|    total_cost       | 526      |\n",
      "|    total_reward     | 8.58e+04 |\n",
      "|    total_reward_pct | 172      |\n",
      "|    total_trades     | 7278     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 133      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total timesteps  | 5528     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 22       |\n",
      "|    critic_loss      | 177      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4146     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.26e+05 |\n",
      "|    total_cost       | 505      |\n",
      "|    total_reward     | 7.56e+04 |\n",
      "|    total_reward_pct | 151      |\n",
      "|    total_trades     | 8781     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total timesteps  | 11056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 13.7     |\n",
      "|    critic_loss      | 25.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 9674     |\n",
      "----------------------------------\n",
      "day: 1381, episode: 155\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 134136.01\n",
      "total_reward: 84136.01\n",
      "total_cost: 158.04\n",
      "total_trades: 8635\n",
      "Sharpe: 0.977\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.06e+05 |\n",
      "|    total_cost       | 462      |\n",
      "|    total_reward     | 5.6e+04  |\n",
      "|    total_reward_pct | 112      |\n",
      "|    total_trades     | 4180     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total timesteps  | 16584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 9.52     |\n",
      "|    critic_loss      | 9.7      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15202    |\n",
      "----------------------------------\n",
      "day: 1381, episode: 160\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 90872.48\n",
      "total_reward: 40872.48\n",
      "total_cost: 343.98\n",
      "total_trades: 5726\n",
      "Sharpe: 0.539\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.31e+05 |\n",
      "|    total_cost       | 373      |\n",
      "|    total_reward     | 8.13e+04 |\n",
      "|    total_reward_pct | 163      |\n",
      "|    total_trades     | 8746     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 113      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total timesteps  | 22112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 6.84     |\n",
      "|    critic_loss      | 4.81     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20730    |\n",
      "----------------------------------\n",
      "day: 1381, episode: 165\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 93527.93\n",
      "total_reward: 43527.93\n",
      "total_cost: 321.93\n",
      "total_trades: 6982\n",
      "Sharpe: 0.564\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.21e+05 |\n",
      "|    total_cost       | 274      |\n",
      "|    total_reward     | 7.1e+04  |\n",
      "|    total_reward_pct | 142      |\n",
      "|    total_trades     | 7940     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 113      |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total timesteps  | 27640    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 4.79     |\n",
      "|    critic_loss      | 3        |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 26258    |\n",
      "----------------------------------\n",
      "day: 1381, episode: 170\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 136663.10\n",
      "total_reward: 86663.10\n",
      "total_cost: 716.87\n",
      "total_trades: 6168\n",
      "Sharpe: 0.907\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.37e+05 |\n",
      "|    total_cost       | 717      |\n",
      "|    total_reward     | 8.67e+04 |\n",
      "|    total_reward_pct | 173      |\n",
      "|    total_trades     | 6168     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 112      |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total timesteps  | 33168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.15     |\n",
      "|    critic_loss      | 4.18     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31786    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.27e+05 |\n",
      "|    total_cost       | 275      |\n",
      "|    total_reward     | 7.68e+04 |\n",
      "|    total_reward_pct | 154      |\n",
      "|    total_trades     | 9626     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 111      |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total timesteps  | 38696    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.88     |\n",
      "|    critic_loss      | 3.6      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37314    |\n",
      "----------------------------------\n",
      "day: 1381, episode: 175\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85804.02\n",
      "total_reward: 35804.02\n",
      "total_cost: 415.65\n",
      "total_trades: 6319\n",
      "Sharpe: 0.512\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.4e+05  |\n",
      "|    total_cost       | 545      |\n",
      "|    total_reward     | 8.95e+04 |\n",
      "|    total_reward_pct | 179      |\n",
      "|    total_trades     | 9034     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 111      |\n",
      "|    time_elapsed     | 398      |\n",
      "|    total timesteps  | 44224    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.968    |\n",
      "|    critic_loss      | 1.04     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 42842    |\n",
      "----------------------------------\n",
      "day: 1381, episode: 180\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 88524.81\n",
      "total_reward: 38524.81\n",
      "total_cost: 597.11\n",
      "total_trades: 6251\n",
      "Sharpe: 0.523\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.41e+05 |\n",
      "|    total_cost       | 577      |\n",
      "|    total_reward     | 9.12e+04 |\n",
      "|    total_reward_pct | 182      |\n",
      "|    total_trades     | 5544     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 110      |\n",
      "|    time_elapsed     | 448      |\n",
      "|    total timesteps  | 49752    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.361    |\n",
      "|    critic_loss      | 1.15     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 48370    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-07-09 to  2020-10-06\n",
      "======Best Model Retraining from:  2015-01-01 to  2020-10-06\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_504_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.0103   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -5.43    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0503   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.729   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -1.38    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0199   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.28e+05 |\n",
      "|    total_cost         | 3.43e+03 |\n",
      "|    total_reward       | 7.76e+04 |\n",
      "|    total_reward_pct   | 155      |\n",
      "|    total_trades       | 7864     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.076   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.711   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00401  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.0313   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.212    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -1.21    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -2.72    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0144   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.15e+05  |\n",
      "|    total_cost         | 2.07e+03  |\n",
      "|    total_reward       | 6.51e+04  |\n",
      "|    total_reward_pct   | 130       |\n",
      "|    total_trades       | 8723      |\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 2.1       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.00839   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0.708    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00464  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -2.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 3.92     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0255   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.11e+04 |\n",
      "|    total_cost         | 1.21e+03 |\n",
      "|    total_reward       | 4.11e+04 |\n",
      "|    total_reward_pct   | 82.3     |\n",
      "|    total_trades       | 9144     |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -1.96    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00611  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -113     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 4.95     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0419   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.644   |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0243   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 1.86e+03 |\n",
      "|    total_reward       | 5.89e+04 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 9010     |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -2.16    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00677  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0.218    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 8.15     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0857   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -0.0858  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00803  |\n",
      "------------------------------------\n",
      "day: 1444, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 134917.17\n",
      "total_reward: 84917.17\n",
      "total_cost: 1422.81\n",
      "total_trades: 9063\n",
      "Sharpe: 0.877\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.35e+05 |\n",
      "|    total_cost         | 1.42e+03 |\n",
      "|    total_reward       | 8.49e+04 |\n",
      "|    total_reward_pct   | 170      |\n",
      "|    total_trades       | 9063     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -0.179   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0197   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.0113   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0.266    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -3.36    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+05 |\n",
      "|    total_cost         | 1.49e+03 |\n",
      "|    total_reward       | 7.93e+04 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 9525     |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.389   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.397   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.00224  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.261   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.206    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 0.0394   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -15.6    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.308    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.4e+05  |\n",
      "|    total_cost         | 2.54e+03 |\n",
      "|    total_reward       | 9.03e+04 |\n",
      "|    total_reward_pct   | 181      |\n",
      "|    total_trades       | 8917     |\n",
      "| time/                 |          |\n",
      "|    fps                | 316      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 6.77     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0572   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0.56     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 5.84     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.044    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.0604   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.318    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+05 |\n",
      "|    total_cost         | 2.44e+03 |\n",
      "|    total_reward       | 8.74e+04 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 8796     |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -5.99    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0463   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 5.21     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0365   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -5.03    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0535   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+05   |\n",
      "|    total_cost         | 2.04e+03  |\n",
      "|    total_reward       | 9.04e+04  |\n",
      "|    total_reward_pct   | 181       |\n",
      "|    total_trades       | 9987      |\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 1.85      |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.00651   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.267    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -6.02    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.0394   |\n",
      "------------------------------------\n",
      "day: 1444, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 112463.58\n",
      "total_reward: 62463.58\n",
      "total_cost: 1579.35\n",
      "total_trades: 10280\n",
      "Sharpe: 0.777\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 1.58e+03 |\n",
      "|    total_reward       | 6.25e+04 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 10280    |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -5.67    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.0472   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.629   |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.00328  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.0434  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00595  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.41e+05 |\n",
      "|    total_cost         | 2.01e+03 |\n",
      "|    total_reward       | 9.09e+04 |\n",
      "|    total_reward_pct   | 182      |\n",
      "|    total_trades       | 10001    |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00413  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -58.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 3.77     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0468   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 3.63      |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.0277    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.81e+04 |\n",
      "|    total_cost         | 2.82e+03 |\n",
      "|    total_reward       | 4.81e+04 |\n",
      "|    total_reward_pct   | 96.1     |\n",
      "|    total_trades       | 10618    |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -2.35    |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.00579  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | 0.28     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -2.46    |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.0113   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | -0.101   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -4.7     |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.0241   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+05 |\n",
      "|    total_cost         | 6.7e+03  |\n",
      "|    total_reward       | 7.4e+04  |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 10699    |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -0.157   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.00407  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | -0.319   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 3.02     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0252   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | -0.196   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.009    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.23e+05 |\n",
      "|    total_cost         | 8.07e+03 |\n",
      "|    total_reward       | 7.26e+04 |\n",
      "|    total_reward_pct   | 145      |\n",
      "|    total_trades       | 10656    |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.63     |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.0131   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -0.0217  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 7.48     |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.0629   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 6.17      |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 0.0556    |\n",
      "-------------------------------------\n",
      "day: 1444, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 159104.53\n",
      "total_reward: 109104.53\n",
      "total_cost: 4230.10\n",
      "total_trades: 10925\n",
      "Sharpe: 1.091\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.59e+05 |\n",
      "|    total_cost         | 4.23e+03 |\n",
      "|    total_reward       | 1.09e+05 |\n",
      "|    total_reward_pct   | 218      |\n",
      "|    total_trades       | 10925    |\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | 0.362    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -2.34    |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.00751  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.1    |\n",
      "|    explained_variance | 0.037    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 6.55     |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.0613   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 7.88     |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0868   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 3.3e+03  |\n",
      "|    total_reward       | 6.29e+04 |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 11400    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.852    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00219  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 2.11     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.00802  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.342   |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.00909  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 2.84e+03 |\n",
      "|    total_reward       | 5.56e+04 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 11274    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -3.3     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.00958  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.9     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.00246  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 19.2      |\n",
      "|    std                | 1.46      |\n",
      "|    value_loss         | 0.36      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.36e+05 |\n",
      "|    total_cost         | 2.13e+03 |\n",
      "|    total_reward       | 8.58e+04 |\n",
      "|    total_reward_pct   | 172      |\n",
      "|    total_trades       | 12046    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | -0.381   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 4.32     |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.0326   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -0.156   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 2.83     |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.0205   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 1.36e+03 |\n",
      "|    total_reward       | 6.35e+04 |\n",
      "|    total_reward_pct   | 127      |\n",
      "|    total_trades       | 11806    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | -3.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -5.29    |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.029    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.8    |\n",
      "|    explained_variance | -2       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -8.24    |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.0614   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | -8.27    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.178   |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "day: 1444, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 86474.46\n",
      "total_reward: 36474.46\n",
      "total_cost: 816.69\n",
      "total_trades: 11651\n",
      "Sharpe: 0.524\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.65e+04 |\n",
      "|    total_cost         | 817      |\n",
      "|    total_reward       | 3.65e+04 |\n",
      "|    total_reward_pct   | 72.9     |\n",
      "|    total_trades       | 11651    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.0347  |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00156  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -2.57    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.00841  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 3.05      |\n",
      "|    std                | 1.57      |\n",
      "|    value_loss         | 0.0215    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.43e+05 |\n",
      "|    total_cost         | 1.41e+03 |\n",
      "|    total_reward       | 9.26e+04 |\n",
      "|    total_reward_pct   | 185      |\n",
      "|    total_trades       | 11854    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -1.08    |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.00266  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | -0.554   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.903    |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.00289  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.0807   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.09e+04 |\n",
      "|    total_cost         | 1.14e+03 |\n",
      "|    total_reward       | 4.09e+04 |\n",
      "|    total_reward_pct   | 81.8     |\n",
      "|    total_trades       | 11831    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | 0.00405  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 2.73     |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0063   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | -0.428   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -2.14    |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.00766  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 2.16     |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.00773  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+05 |\n",
      "|    total_cost         | 962      |\n",
      "|    total_reward       | 5.94e+04 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 11752    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | 0.074    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | 0.324    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -1.57    |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.00242  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 2.02     |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.033    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.25e+05  |\n",
      "|    total_cost         | 1.06e+03  |\n",
      "|    total_reward       | 7.45e+04  |\n",
      "|    total_reward_pct   | 149       |\n",
      "|    total_trades       | 12260     |\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -0.6      |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 0.000333  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | -0.449   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.00288  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 3.97     |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.0282   |\n",
      "------------------------------------\n",
      "day: 1444, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 86755.43\n",
      "total_reward: 36755.43\n",
      "total_cost: 800.87\n",
      "total_trades: 13052\n",
      "Sharpe: 0.504\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.68e+04 |\n",
      "|    total_cost         | 801      |\n",
      "|    total_reward       | 3.68e+04 |\n",
      "|    total_reward_pct   | 73.5     |\n",
      "|    total_trades       | 13052    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 2.78     |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | -0.0587  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 3.25     |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.0221   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.662    |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.00183  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+04  |\n",
      "|    total_cost         | 1.01e+03 |\n",
      "|    total_reward       | 4.1e+04  |\n",
      "|    total_reward_pct   | 82       |\n",
      "|    total_trades       | 13058    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -4.81    |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.0228   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | -0.121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 2.76     |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.0276   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.00961  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+05 |\n",
      "|    total_cost         | 1.06e+03 |\n",
      "|    total_reward       | 6.82e+04 |\n",
      "|    total_reward_pct   | 136      |\n",
      "|    total_trades       | 12908    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | -63.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -19.9    |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.307    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | -0.0892  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -8.95    |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.0598   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+05 |\n",
      "|    total_cost         | 785      |\n",
      "|    total_reward       | 5.34e+04 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 12901    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39      |\n",
      "|    explained_variance | -1.25    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -2.86    |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.00637  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | 0.0152   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.00161  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | 0.0751   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -6.9     |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.0493   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.72e+04 |\n",
      "|    total_cost         | 634      |\n",
      "|    total_reward       | 3.72e+04 |\n",
      "|    total_reward_pct   | 74.5     |\n",
      "|    total_trades       | 13717    |\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 0.055    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -3.08    |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.00794  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | -1.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -6.67    |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 0.0325   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.941    |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.00661  |\n",
      "------------------------------------\n",
      "day: 1444, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 141189.20\n",
      "total_reward: 91189.20\n",
      "total_cost: 1016.49\n",
      "total_trades: 14428\n",
      "Sharpe: 0.989\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.41e+05 |\n",
      "|    total_cost         | 1.02e+03 |\n",
      "|    total_reward       | 9.12e+04 |\n",
      "|    total_reward_pct   | 182      |\n",
      "|    total_trades       | 14428    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 2.59     |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 0.00738  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.0899   |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.000889 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 7.99     |\n",
      "|    std                | 2.04     |\n",
      "|    value_loss         | 0.0428   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.9e+04  |\n",
      "|    total_cost         | 596      |\n",
      "|    total_reward       | 3.9e+04  |\n",
      "|    total_reward_pct   | 78       |\n",
      "|    total_trades       | 14876    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.00229  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 0.726    |\n",
      "|    std                | 2.08     |\n",
      "|    value_loss         | 0.00213  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.9    |\n",
      "|    explained_variance | 0.0361   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 10.4     |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.0737   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.27e+05 |\n",
      "|    total_cost         | 1.06e+03 |\n",
      "|    total_reward       | 7.71e+04 |\n",
      "|    total_reward_pct   | 154      |\n",
      "|    total_trades       | 15275    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0.0029   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -2.88    |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.00684  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 6.13     |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.026    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 2.16     |\n",
      "|    value_loss         | 0.0017   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.52e+04 |\n",
      "|    total_cost         | 668      |\n",
      "|    total_reward       | 2.52e+04 |\n",
      "|    total_reward_pct   | 50.3     |\n",
      "|    total_trades       | 15184    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | -0.498   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -3.22    |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -7.82    |\n",
      "|    std                | 2.19     |\n",
      "|    value_loss         | 0.0412   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | -2.86e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 24.1      |\n",
      "|    std                | 2.21      |\n",
      "|    value_loss         | 0.404     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.29e+05  |\n",
      "|    total_cost         | 1.02e+03  |\n",
      "|    total_reward       | 7.94e+04  |\n",
      "|    total_reward_pct   | 159       |\n",
      "|    total_trades       | 14925     |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 2.01      |\n",
      "|    std                | 2.23      |\n",
      "|    value_loss         | 0.0058    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -8.5      |\n",
      "|    std                | 2.24      |\n",
      "|    value_loss         | 0.0412    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -13      |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "day: 1444, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 124202.52\n",
      "total_reward: 74202.52\n",
      "total_cost: 979.59\n",
      "total_trades: 14959\n",
      "Sharpe: 0.913\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+05 |\n",
      "|    total_cost         | 980      |\n",
      "|    total_reward       | 7.42e+04 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 14959    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 3.98     |\n",
      "|    std                | 2.28     |\n",
      "|    value_loss         | 0.0102   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -0.44     |\n",
      "|    std                | 2.3       |\n",
      "|    value_loss         | 0.00406   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -2.43    |\n",
      "|    std                | 2.32     |\n",
      "|    value_loss         | 0.0147   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.91e+04  |\n",
      "|    total_cost         | 888       |\n",
      "|    total_reward       | 4.91e+04  |\n",
      "|    total_reward_pct   | 98.2      |\n",
      "|    total_trades       | 15013     |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -0.000273 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 5.64      |\n",
      "|    std                | 2.34      |\n",
      "|    value_loss         | 0.0218    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.625   |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.00968  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.26e+05 |\n",
      "|    total_cost         | 840      |\n",
      "|    total_reward       | 7.59e+04 |\n",
      "|    total_reward_pct   | 152      |\n",
      "|    total_trades       | 15382    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -0.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -8.42    |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.0457   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -4.42    |\n",
      "|    std                | 2.41     |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0.168    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.00374  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+05 |\n",
      "|    total_cost         | 833      |\n",
      "|    total_reward       | 5.5e+04  |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 15840    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 2.45     |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    std                | 2.48     |\n",
      "|    value_loss         | 0.00327  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0.219    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.974    |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.00271  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 1.03e+03 |\n",
      "|    total_reward       | 5.62e+04 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 16338    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 1.86     |\n",
      "|    std                | 2.52     |\n",
      "|    value_loss         | 0.00268  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.338   |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.00345  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -7.34    |\n",
      "|    std                | 2.57     |\n",
      "|    value_loss         | 0.0289   |\n",
      "------------------------------------\n",
      "day: 1444, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 94606.96\n",
      "total_reward: 44606.96\n",
      "total_cost: 936.38\n",
      "total_trades: 16630\n",
      "Sharpe: 0.620\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.46e+04  |\n",
      "|    total_cost         | 936       |\n",
      "|    total_reward       | 4.46e+04  |\n",
      "|    total_reward_pct   | 89.2      |\n",
      "|    total_trades       | 16630     |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 1.17      |\n",
      "|    std                | 2.59      |\n",
      "|    value_loss         | 0.000994  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | -27.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 4.84     |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -7.45    |\n",
      "|    std                | 2.65     |\n",
      "|    value_loss         | 0.0335   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.75e+04 |\n",
      "|    total_cost         | 893      |\n",
      "|    total_reward       | 2.75e+04 |\n",
      "|    total_reward_pct   | 55       |\n",
      "|    total_trades       | 16148    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0.0827   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.698    |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 0.0025   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | -0.6     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -1.89    |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.00379  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0.16     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 4.24     |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 0.0131   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+05 |\n",
      "|    total_cost         | 1.16e+03 |\n",
      "|    total_reward       | 6.27e+04 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 15436    |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.383    |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.0024   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 2.88     |\n",
      "|    std                | 2.75     |\n",
      "|    value_loss         | 0.00626  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -10.7     |\n",
      "|    std                | 2.77      |\n",
      "|    value_loss         | 0.172     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.06e+05  |\n",
      "|    total_cost         | 1.03e+03  |\n",
      "|    total_reward       | 5.57e+04  |\n",
      "|    total_reward_pct   | 111       |\n",
      "|    total_trades       | 15191     |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -9.39     |\n",
      "|    std                | 2.79      |\n",
      "|    value_loss         | 0.0482    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0.00806  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -4.62    |\n",
      "|    std                | 2.81     |\n",
      "|    value_loss         | 0.0169   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0.0161   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 9.2      |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.0654   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.25e+05 |\n",
      "|    total_cost         | 1.96e+03 |\n",
      "|    total_reward       | 7.51e+04 |\n",
      "|    total_reward_pct   | 150      |\n",
      "|    total_trades       | 15637    |\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0.418    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -9.07    |\n",
      "|    std                | 2.85     |\n",
      "|    value_loss         | 0.0345   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 2.87     |\n",
      "|    value_loss         | 0.0864   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -2.71     |\n",
      "|    std                | 2.89      |\n",
      "|    value_loss         | 0.0129    |\n",
      "-------------------------------------\n",
      "day: 1444, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 120175.02\n",
      "total_reward: 70175.02\n",
      "total_cost: 1602.61\n",
      "total_trades: 15354\n",
      "Sharpe: 0.909\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 1.6e+03  |\n",
      "|    total_reward       | 7.02e+04 |\n",
      "|    total_reward_pct   | 140      |\n",
      "|    total_trades       | 15354    |\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | -0.229   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.374   |\n",
      "|    std                | 2.92     |\n",
      "|    value_loss         | 0.000963 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | -0.039   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -6.53    |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 0.0203   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.97e+04 |\n",
      "|    total_cost         | 1.18e+03 |\n",
      "|    total_reward       | 2.97e+04 |\n",
      "|    total_reward_pct   | 59.5     |\n",
      "|    total_trades       | 15284    |\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0.39     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 5.05     |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -6.09    |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.0231   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | 0.337    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 3.39     |\n",
      "|    std                | 3.04     |\n",
      "|    value_loss         | 0.00924  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.65e+04 |\n",
      "|    total_cost         | 1.23e+03 |\n",
      "|    total_reward       | 3.65e+04 |\n",
      "|    total_reward_pct   | 73       |\n",
      "|    total_trades       | 15594    |\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 5.54     |\n",
      "|    std                | 3.06     |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 8.1      |\n",
      "|    std                | 3.09     |\n",
      "|    value_loss         | 0.0335   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0.519    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 0.233    |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.000228 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.85e+04 |\n",
      "|    total_cost         | 1.24e+03 |\n",
      "|    total_reward       | 2.85e+04 |\n",
      "|    total_reward_pct   | 57       |\n",
      "|    total_trades       | 15657    |\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -2.23    |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.00274  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 2.11     |\n",
      "|    std                | 3.19     |\n",
      "|    value_loss         | 0.00487  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -9.69    |\n",
      "|    std                | 3.22     |\n",
      "|    value_loss         | 0.0408   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.99e+04 |\n",
      "|    total_cost         | 1.4e+03  |\n",
      "|    total_reward       | 3.99e+04 |\n",
      "|    total_reward_pct   | 79.7     |\n",
      "|    total_trades       | 15530    |\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 2.17     |\n",
      "|    std                | 3.24     |\n",
      "|    value_loss         | 0.00225  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 229       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -2.75     |\n",
      "|    std                | 3.27      |\n",
      "|    value_loss         | 0.00397   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -2.32    |\n",
      "|    std                | 3.31     |\n",
      "|    value_loss         | 0.00476  |\n",
      "------------------------------------\n",
      "day: 1444, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 68124.74\n",
      "total_reward: 18124.74\n",
      "total_cost: 1080.56\n",
      "total_trades: 15555\n",
      "Sharpe: 0.370\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.81e+04 |\n",
      "|    total_cost         | 1.08e+03 |\n",
      "|    total_reward       | 1.81e+04 |\n",
      "|    total_reward_pct   | 36.2     |\n",
      "|    total_trades       | 15555    |\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 1.83     |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.00783  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -5.02    |\n",
      "|    std                | 3.37     |\n",
      "|    value_loss         | 0.0109   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 8.83     |\n",
      "|    std                | 3.39     |\n",
      "|    value_loss         | 0.0393   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.33e+05  |\n",
      "|    total_cost         | 1.85e+03  |\n",
      "|    total_reward       | 8.31e+04  |\n",
      "|    total_reward_pct   | 166       |\n",
      "|    total_trades       | 15771     |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -1.2      |\n",
      "|    std                | 3.42      |\n",
      "|    value_loss         | 0.00169   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | 0.0121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 0.193    |\n",
      "|    std                | 3.44     |\n",
      "|    value_loss         | 0.000356 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -16.3    |\n",
      "|    std                | 3.48     |\n",
      "|    value_loss         | 0.104    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.21e+04 |\n",
      "|    total_cost         | 1.28e+03 |\n",
      "|    total_reward       | 3.21e+04 |\n",
      "|    total_reward_pct   | 64.2     |\n",
      "|    total_trades       | 15235    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 6.37     |\n",
      "|    std                | 3.51     |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | -0.0417  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -5.07    |\n",
      "|    std                | 3.55     |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 3.57     |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.29e+04 |\n",
      "|    total_cost         | 1.24e+03 |\n",
      "|    total_reward       | 4.29e+04 |\n",
      "|    total_reward_pct   | 85.8     |\n",
      "|    total_trades       | 15548    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.231    |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 0.00315  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | -0.00625 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 5.04     |\n",
      "|    std                | 3.64     |\n",
      "|    value_loss         | 0.0129   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -9.38    |\n",
      "|    std                | 3.66     |\n",
      "|    value_loss         | 0.0437   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 1.53e+03 |\n",
      "|    total_reward       | 6.99e+04 |\n",
      "|    total_reward_pct   | 140      |\n",
      "|    total_trades       | 15576    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.7    |\n",
      "|    explained_variance | 0.00752  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    std                | 3.69     |\n",
      "|    value_loss         | 0.184    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 0.221    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 3.71     |\n",
      "|    value_loss         | 0.068    |\n",
      "------------------------------------\n",
      "day: 1444, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 140771.90\n",
      "total_reward: 90771.90\n",
      "total_cost: 2195.65\n",
      "total_trades: 15681\n",
      "Sharpe: 1.044\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.41e+05 |\n",
      "|    total_cost         | 2.2e+03  |\n",
      "|    total_reward       | 9.08e+04 |\n",
      "|    total_reward_pct   | 182      |\n",
      "|    total_trades       | 15681    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | -1.86    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.0252  |\n",
      "|    std                | 3.73     |\n",
      "|    value_loss         | 0.00893  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 13       |\n",
      "|    std                | 3.77     |\n",
      "|    value_loss         | 0.0684   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -4.45    |\n",
      "|    std                | 3.81     |\n",
      "|    value_loss         | 0.00755  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.55e+04 |\n",
      "|    total_cost         | 1.87e+03 |\n",
      "|    total_reward       | 1.55e+04 |\n",
      "|    total_reward_pct   | 31       |\n",
      "|    total_trades       | 15901    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | -3.62    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -6.13    |\n",
      "|    std                | 3.84     |\n",
      "|    value_loss         | 0.0253   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -8.12    |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 0.0273   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | -0.0199  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 6.79     |\n",
      "|    std                | 3.9      |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 2.39e+03 |\n",
      "|    total_reward       | 6.11e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 16756    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 6.01     |\n",
      "|    std                | 3.93     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.1    |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 4.09     |\n",
      "|    std                | 3.96     |\n",
      "|    value_loss         | 0.00816  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | -0.098   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.9      |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.0224   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+04 |\n",
      "|    total_cost         | 2.75e+03 |\n",
      "|    total_reward       | 4.99e+04 |\n",
      "|    total_reward_pct   | 99.9     |\n",
      "|    total_trades       | 17391    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0.244    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 4.05     |\n",
      "|    std                | 4.01     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 2.31     |\n",
      "|    std                | 4.04     |\n",
      "|    value_loss         | 0.00744  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -16.4    |\n",
      "|    std                | 4.06     |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+05 |\n",
      "|    total_cost         | 2.54e+03 |\n",
      "|    total_reward       | 7.39e+04 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 17233    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | -2.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 3.73     |\n",
      "|    std                | 4.08     |\n",
      "|    value_loss         | 0.0131   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 3.97     |\n",
      "|    std                | 4.1      |\n",
      "|    value_loss         | 0.0109   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 3.84     |\n",
      "|    std                | 4.13     |\n",
      "|    value_loss         | 0.0212   |\n",
      "------------------------------------\n",
      "day: 1444, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 115805.49\n",
      "total_reward: 65805.49\n",
      "total_cost: 2136.69\n",
      "total_trades: 17185\n",
      "Sharpe: 0.832\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+05 |\n",
      "|    total_cost         | 2.14e+03 |\n",
      "|    total_reward       | 6.58e+04 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 17185    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 3.03     |\n",
      "|    std                | 4.16     |\n",
      "|    value_loss         | 0.00705  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | 0.0257   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    std                | 4.19     |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | 0.0367   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -65.2    |\n",
      "|    std                | 4.21     |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+05 |\n",
      "|    total_cost         | 2.06e+03 |\n",
      "|    total_reward       | 7.93e+04 |\n",
      "|    total_reward_pct   | 159      |\n",
      "|    total_trades       | 17168    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | -1.18    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -3.05    |\n",
      "|    std                | 4.24     |\n",
      "|    value_loss         | 0.00532  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 3.39     |\n",
      "|    std                | 4.28     |\n",
      "|    value_loss         | 0.00689  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 8.72     |\n",
      "|    std                | 4.31     |\n",
      "|    value_loss         | 0.0669   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+05 |\n",
      "|    total_cost         | 1.84e+03 |\n",
      "|    total_reward       | 6.47e+04 |\n",
      "|    total_reward_pct   | 129      |\n",
      "|    total_trades       | 17163    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -1.43    |\n",
      "|    std                | 4.36     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 291       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -6.31     |\n",
      "|    std                | 4.38      |\n",
      "|    value_loss         | 0.0345    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 0.182    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 4.4      |\n",
      "|    value_loss         | 0.0696   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+05 |\n",
      "|    total_cost         | 2.01e+03 |\n",
      "|    total_reward       | 7.87e+04 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 17142    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -4.97    |\n",
      "|    std                | 4.44     |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | -0.0964  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -6.03    |\n",
      "|    std                | 4.48     |\n",
      "|    value_loss         | 0.0298   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+05 |\n",
      "|    total_cost         | 2.2e+03  |\n",
      "|    total_reward       | 6.16e+04 |\n",
      "|    total_reward_pct   | 123      |\n",
      "|    total_trades       | 16935    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | -11.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -3.46    |\n",
      "|    std                | 4.5      |\n",
      "|    value_loss         | 0.0483   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 299       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -10.7     |\n",
      "|    std                | 4.53      |\n",
      "|    value_loss         | 0.0427    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -1.25    |\n",
      "|    std                | 4.57     |\n",
      "|    value_loss         | 0.00235  |\n",
      "------------------------------------\n",
      "day: 1444, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113732.21\n",
      "total_reward: 63732.21\n",
      "total_cost: 2512.08\n",
      "total_trades: 16954\n",
      "Sharpe: 0.832\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 2.51e+03 |\n",
      "|    total_reward       | 6.37e+04 |\n",
      "|    total_reward_pct   | 127      |\n",
      "|    total_trades       | 16954    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | -0.216   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 2.9      |\n",
      "|    std                | 4.6      |\n",
      "|    value_loss         | 0.00359  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | -0.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -5.71    |\n",
      "|    std                | 4.64     |\n",
      "|    value_loss         | 0.022    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 2.65     |\n",
      "|    std                | 4.69     |\n",
      "|    value_loss         | 0.00376  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.39e+04 |\n",
      "|    total_cost         | 2.16e+03 |\n",
      "|    total_reward       | 2.39e+04 |\n",
      "|    total_reward_pct   | 47.8     |\n",
      "|    total_trades       | 16453    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.5    |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.731   |\n",
      "|    std                | 4.73     |\n",
      "|    value_loss         | 0.000392 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.7    |\n",
      "|    explained_variance | -0.00841 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 6.63     |\n",
      "|    std                | 4.79     |\n",
      "|    value_loss         | 0.0187   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 4.83     |\n",
      "|    value_loss         | 0.0394   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.89e+04 |\n",
      "|    total_cost         | 2.74e+03 |\n",
      "|    total_reward       | 4.89e+04 |\n",
      "|    total_reward_pct   | 97.8     |\n",
      "|    total_trades       | 17187    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 4.86     |\n",
      "|    value_loss         | 0.0353   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    std                | 4.9      |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 1.91     |\n",
      "|    std                | 4.91     |\n",
      "|    value_loss         | 0.00442  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.31e+05 |\n",
      "|    total_cost         | 3.82e+03 |\n",
      "|    total_reward       | 8.09e+04 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 17744    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -6.94    |\n",
      "|    std                | 4.94     |\n",
      "|    value_loss         | 0.0191   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 319       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | -6.2      |\n",
      "|    std                | 5         |\n",
      "|    value_loss         | 0.0124    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -1.76    |\n",
      "|    std                | 5.04     |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.32e+04 |\n",
      "|    total_cost         | 2.74e+03 |\n",
      "|    total_reward       | 2.32e+04 |\n",
      "|    total_reward_pct   | 46.5     |\n",
      "|    total_trades       | 17486    |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.396   |\n",
      "|    std                | 5.08     |\n",
      "|    value_loss         | 9.14e-05 |\n",
      "------------------------------------\n",
      "======Trading from:  2020-10-06 to  2021-01-06\n",
      "Ensemble Strategy took:  158.7291516105334  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.0301276</td>\n",
       "      <td>0.085959</td>\n",
       "      <td>0.147242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.262076</td>\n",
       "      <td>0.274841</td>\n",
       "      <td>0.494049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.0691218</td>\n",
       "      <td>-0.0430087</td>\n",
       "      <td>0.216779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.460723</td>\n",
       "      <td>0.489314</td>\n",
       "      <td>0.341511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.133107</td>\n",
       "      <td>-0.247596</td>\n",
       "      <td>-0.0493602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.114729</td>\n",
       "      <td>0.31524</td>\n",
       "      <td>0.262936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.408851</td>\n",
       "      <td>0.192005</td>\n",
       "      <td>-0.210995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126  2019-01-03  2019-04-04       DDPG -0.0301276   0.085959    0.147242\n",
       "1  189  2019-04-04  2019-07-05       DDPG   0.262076   0.274841    0.494049\n",
       "2  252  2019-07-05  2019-10-02       DDPG -0.0691218 -0.0430087    0.216779\n",
       "3  315  2019-10-02  2020-01-03        PPO   0.460723   0.489314    0.341511\n",
       "4  378  2020-01-03  2020-04-06       DDPG  -0.133107  -0.247596  -0.0493602\n",
       "5  441  2020-04-06  2020-07-09        PPO   0.114729    0.31524    0.262936\n",
       "6  504  2020-07-09  2020-10-06        A2C   0.408851   0.192005   -0.210995"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  1.332804175128286\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49935.688560</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>2019-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49989.948380</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>2019-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49895.476662</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>-0.001890</td>\n",
       "      <td>2019-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49778.883379</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>2019-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   50000.000000  2019-04-04           NaN  2019-04-04\n",
       "1   49935.688560  2019-04-05     -0.001286  2019-04-05\n",
       "2   49989.948380  2019-04-08      0.001087  2019-04-08\n",
       "3   49895.476662  2019-04-09     -0.001890  2019-04-09\n",
       "4   49778.883379  2019-04-10     -0.002337  2019-04-10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8NElEQVR4nO3dd3hc1Zn48e8rjUa9N8uW3I2NsXHB2AbTSYwxoaSxNkkwCYEkQDbZbEJJ8kvZhJQlWRY2hIQAAbIEQgmLAwZjjKnBxgX3KstNsnob9ZE05/fHvTMaNUuyNEXS+3meeTRz5s6dMxc875z2HjHGoJRSanSLCHUFlFJKhZ4GA6WUUhoMlFJKaTBQSimFBgOllFKAI9QVOF0ZGRlm4sSJoa6GUkoNK1u3bq0wxmR2LR+2wWDixIls2bIl1NVQSqlhRUSO9VSu3URKKaU0GCillNJgoJRSCg0GSiml0GCglFIKDQZKKaXQYKCUUgoNBkopFdba2j0889FxWts9AX2fYbvoTCmlRoMn/nmUn7+6D48xjEmK4bwp6cQ5h/6rW4OBUkqFsT0nXQBsO1bDi9sKGZcSy1vfvZhoR+SQvo92EymlVBg7XF4PwKYjlQAU1TRR29Q65O+jwUAppcKUMYb9JXUAFFY3AbDp+5eTlRgz5O+lwUAppcJUVYMbd1vHwHGcM5KsxOiAvJcGA6WUClPFtc0A5KbGAhAf7UBEAvJeGgyUUipMldjB4F8vmwZATaM7YO+ls4mUUipMFdda4wSXTM/kZ9fNYmJ6XMDeS4OBUkqFqV1FtTgihIyEaL60eEJA30u7iZRSKgxtKqjkuS2F5KXFERERmHECf30GAxGZLiLb/W4uEfm2iPxERIr8ypf7veYeEckXkQMicoVf+TK7LF9E7vYrnyQim+zyv4mIc+g/qlJKDR87CmsAeGzVgqC8X5/BwBhzwBgz1xgzFzgHaAResp++3/ucMWYNgIjMBFYAZwHLgN+LSKSIRAIPAVcCM4GV9rEAv7bPNRWoBm4esk+olFLD0OGyBjISopmcmRCU9xtoN9HlwGFjTI8bKtuuBZ41xrQYY44A+cBC+5ZvjCkwxriBZ4FrxZondRnwgv36J4HrBlgvpZQaUQ6X1zMlMz5o7zfQAeQVwDN+j+8QkRuBLcC/G2OqgXHARr9jCu0ygBNdyhcB6UCNMaath+M7EZFbgVsBxo8fP8CqK6VUeFu3t5S/bjrG3mIX1Q2tfG5BbtDeu98tA7sf/xrgebvoYWAKMBcoBn471JXryhjziDFmgTFmQWZmZqDfTimlguqWp7aw4UA5pa4W3O0e32KzYBhIN9GVwDZjTCmAMabUGNNujPEAf8LqBgIoAvL8Xpdrl/VWXgmkiIijS7lSSo0qcc7OmUgz4gOTeqInAwkGK/HrIhKRHL/nPg3stu+vBlaISLSITAKmAR8Bm4Fp9swhJ1aX02pjjAE2AJ+zX78KePl0PoxSSg1Xza3tNLrbuXrOWF9ZWnzwJlb2KxiISDzwSeDvfsX/KSK7RGQncCnwbwDGmD3Ac8Be4HXgdrsF0QbcAawF9gHP2ccC3AV8R0TyscYQHhv0J1NKqWHEm3piZk6SrywtIXjBoF8DyMaYBqwvaf+yL53i+HuBe3soXwOs6aG8gI5uJqWUGnW8SenOzEn0laWHW8tAKaVU4Hg8hl+/vh+AvLSO/ENh102klFIqcD4+Uc32EzUA5CR3bFyTEB289HEaDJRSKsR2F1n7HP/t1sWdNrsP1N4FPdFgoJRSIba7qJb0eCcLJ6UBkJEQvCmlXprCWimlQmxvsYuZY5N8LYF377yENo8Jah20ZaCUUiFWVNPExPSOPERxTgdJMVFBrYMGA6WUCqHm1nZqGlvJTgp+15A/DQZKKRVC5XUtAGQlxfRxZGBpMFBKqRAqdVmLzbI1GCil1OhV6rJaBtpNpJRSo1iJt2WQqC0DpZQatYqqm4iJiiAlLrizh7rSYKCUUiG0s7CGs8YmB3W1cU80GCilVIi0tnvYVVTL3LyUUFdFg4FSSoXKgZI6Wto8GgyUUmo0O1haB8CZfhvahIoGA6WUCpFDZfVERQoT0uP6PjjANBgopVSIHCqtY1JGPFGRof8qDn0NlFJqFDpYWseb+8qYlp3Y98FB0GcwEJHpIrLd7+YSkW+LSJqIrBORQ/bfVPt4EZEHRSRfRHaKyHy/c62yjz8kIqv8ys8RkV32ax6UUM+xUkqpALtv7QEAVp03MbQVsfUZDIwxB4wxc40xc4FzgEbgJeBuYL0xZhqw3n4McCUwzb7dCjwMICJpwI+BRcBC4MfeAGIfc4vf65YNxYdTSqlwZIxh+4kaPjNvnG9Dm1AbaDfR5cBhY8wx4FrgSbv8SeA6+/61wFPGshFIEZEc4ApgnTGmyhhTDawDltnPJRljNhpjDPCU37mUUmpEaW5tp6CigfK6Fs7OTQ51dXwGutPZCuAZ+362MabYvl8CZNv3xwEn/F5TaJedqrywh3KllBpxvv/SLv6+rQiA2bkpoa2Mn363DETECVwDPN/1OfsXfcD3aBORW0Vki4hsKS8vD/TbKaXUkNt+osZ3f1JGfO8HBtlAuomuBLYZY0rtx6V2Fw/23zK7vAjI83tdrl12qvLcHsq7McY8YoxZYIxZkJmZOYCqK6VU6LW2ezhe2eh7nBri5HT+BhIMVtLRRQSwGvDOCFoFvOxXfqM9q2gxUGt3J60FlopIqj1wvBRYaz/nEpHF9iyiG/3OpZRSI8axyoZOG92H08TJfo0ZiEg88Enga37FvwKeE5GbgWPA9Xb5GmA5kI818+jLAMaYKhH5GbDZPu4/jDFV9v3bgCeAWOA1+6aUUiNKfllDqKvQq34FA2NMA5DepawSa3ZR12MNcHsv53kceLyH8i3ArP7URSmlhqvD5fWhrkKvBjqbSCml1GnweAyHSuvITorm8jOzuXbO2FBXqRMNBkopFQQ3PLqRjQVVLJmazi8+PTvU1elGcxMppVSAlbqa2VhgDZFGRoTn12541koppUaQN/aW+u5fOWtMCGvSO+0mUkqpANt7spbUuCj+efflxESF529wDQZKKRVgh0rrmZaVSKwzMtRV6VV4hiillBohjDEcLK1jWnZCqKtyShoMlFIqgD7Ir8TV3MYZYbKJTW80GCil1BAxxjDx7lf57RsHfGU//ccexqfFsXx2Tghr1jcNBkopNURqm1oB+J+38imsthLSFdc284kzs8lMjA5l1fqkwUAppYZIWV2L7/4Fv95Ao7uN+pa2sA8EoMFAKaWGTLlfMADYXeQC0GCglFKjSddg8M5Ba5sXDQZKKRVmPjxcyT1/34WVYHloldU1d3r80IbDAGQmaDBQSqnTdrC0zjcoO1RW/mkjz3x0vNuv+NN1pKKBB948hDGm0zlnj+vY7F5bBkopdZr2nnSx9P53uffVvQE5/4HSuiE5z+1Pb+P+Nw9SWN1EWV0L49PiOPqrq/jHNy/wHZMW7xyS9wokTUehlApLj75XAEBhddOQnK+lrZ2vPLHZ93jPSRcXThv8Xuqt7R4ASlzN7Ct2MTmzY5P7D+6+jL0nXURGhM/2lr3RloFSKiydrLWCgLvNMyTn+/MHR/kgv9L3+Fev7WfDgbJBnzc+2vpNvaeoloOl9SyYkOp7blxKLJ+cmT3o9wgGDQZKqbDknbNf2mVQdiCqGtw8tCEfd5uHD/IryEuL5ZYLJ3HLhZMA2HmilvqWNjYfrerjTL2Ls5PPvbT9JADnTEg77XOFknYTKaXCUrnLDgauFowxiAy8q+XR9wr4/duHiY2KZO9JF5fNyOIHV80EYPWOkxypqGfOT9+g3WN453uXMCE9vo8zdtfU2g7AjhM1ZCQ4mTc+ZcDnCAf9ahmISIqIvCAi+0Vkn4icJyI/EZEiEdlu35b7HX+PiOSLyAERucKvfJldli8id/uVTxKRTXb530Qk/EdblFIB0+Rup66ljYwEJ+42Dz9/dR8tbe0DOsf2EzW8bP9a/8M7h6lscHPW2CTf83mpcbyys5h2jzXFtKT29FogtY0ds52+fvEUYqLCN031qfS3m+gB4HVjzAxgDrDPLr/fGDPXvq0BEJGZwArgLGAZ8HsRiRSRSOAh4EpgJrDSPhbg1/a5pgLVwM1D8NmUUsOUd4rmjDHWl/dj7x/h/nWHBnSO6x76gKIaa9zB2+U0I6cjGOSmxtLm6VhrUNXgPq26Vje6WTI1nWduWczNF0w6rXOEgz6DgYgkAxcBjwEYY9zGmJpTvORa4FljTIsx5giQDyy0b/nGmAJjjBt4FrhWrLbfZcAL9uufBK47vY+jlBou/rb5OPuKXT0+5x0nuGLWGKbbqZ/zy+p9z+8qrOXj49UDfs+c5Bjf/XGpsQBkJ1lrACpOIxh4PIbaplbmj0/lvCnpp9WVFS760zKYBJQDfxaRj0XkURHxdqzdISI7ReRxEfEOoY8DTvi9vtAu6608HagxxrR1Ke9GRG4VkS0isqW8vLw/n08pFWaqG9z8/JW93PXiLlY8srHb863tHj7/hw8BWDAhlbX/dhHnTU6nptH6svZ4DN94eis/Xr2n1/cwxuB0RHDZjCzuvnKGrzzDbyXw8tk5XDlrDE99ZREAVfUDDwZ1zW14DKTEDf+e7f4EAwcwH3jYGDMPaADuBh4GpgBzgWLgtwGqo48x5hFjzAJjzILMzMHPD1ZKBd/9bx7k0fePAPS4uvik3bVz4bQMZoyxWgUpcVFU28Hg/fwKa4GXq/cVxLVNrbjbPCyZmtGpNeCdBgpw1thkHv7iOUwfk0hKXBSVDdb5imubuPi+DVz30Ae8f6jilJ/Fm34iLT6qz88d7voTDAqBQmPMJvvxC8B8Y0ypMabdGOMB/oTVDQRQBOT5vT7XLuutvBJIERFHl3Kl1Ai09VhH905ybPcv0eNV1j4At1861dftkhLnpMYeqH1283EAKupb8Hh6zi9UageK7KRo0uP7TgWRFu+kst7NtuPVrHr8I45VNrL9RA2PvV9wytftKKwFrMAy3PUZDIwxJcAJEZluF10O7BUR/217Pg3stu+vBlaISLSITAKmAR8Bm4Fp9swhJ9Yg82pjZYvaAHzOfv0q4OVBfi6lVBgqq2tmz0kXCyakkh7vpLaplUZ3W6djvMFgfFqcryw1LoqaplYOltaxbm8pSTEO2uz++p6UuKxf7NlJMf1KBZERH01lQwt3PL2Ng6XW2MRFZ2T2Oaj88fFqEqMdTM0M7/2N+6O/6wy+CTxtf4kXAF8GHhSRuYABjgJfAzDG7BGR54C9QBtwuzGmHUBE7gDWApHA48YYb6ffXcCzIvJz4GPswWql1MiyscBa3PWjq2dyoqqJ2/+6jaMVjSREO/i357bT5G4nJioCZ2QE2Ukd3TupcU7aPYZvPbud5FgnX794Mj9/dR/l9S2kdvmyr21qZdXjHwGQnRhDdFTfHSCZSdF8dKQKbyLTa+eOJUKEgvL6U75uZ2EtZ+clEzEM0k30pV/BwBizHVjQpfhLpzj+XuDeHsrXAGt6KC+go5tJKTVCbSyoJDHawcycJGLt+fh7Ttby0ZEqdhbWkBbvpNTVQmZidKd8PilxVnfSvmIXX14y0dctU1HX0m2j+SI7l1FGgpNxqbG+dQSncv2CPF7dWQzAFxeP54dXzeS+tQf6bBkU1zYxa9yYfn768KYrkJVSQbOxoJJzJ6XhiIxgSmYCiTEONh+t4o29pVx99lh+dPVM/vReAZMyOne7pPrN1jkjO5HMROtxeX33QWTvrKP/WTmfyAghMkL47Pxcls/u/Uv7omkZLJqUxqYjVSyclE5MVCRp8U4a3e00t7b3uJCs3WOoanAPi/TU/aHBQCkVFKWuZgrKG1hxrjWPJCJCmJuXwsvbT9LS5uGTM7NJiXPyvStmdHttqt9snTOyE8hMsLqQyutafJvUeAebq+2BZv/X/Pb6Oaesm4jww6tm8p3ntrNwopVbKN3ufqpscDMuJbbbayobWvAYyEwY/tNKQRPVKaWC5KMj1njB4snpvrJ541NpsbOSzhrX+4yc6WM6Vg5PzUwkKdaBMzKC8voWZv5oLb96bb/v+Sq7ZZA2wLn/s3OTWfedixljT0X1DjxX1bt5YWshl9y3oVPKCu8q6ZHSMtBgoJQKimI7JfVkv5k38+2kbvHOyB5/fXslRDt4785L+Z+V80iOi0JEyEhwsqfIRVNrO398t2MKaI3dzz/YhWDp9i/+gop6vvv8Do5WNvLclo51sxoMlFLqNNQ0tuKIEOKdHf3v8/KsxAVnjEnsc0ZOXlocV88Z63uckRjNB4c7FoX9ZPUe9p50Ud3YSrwzEqdjcF9vWYlWC+Fbz24HIELgzx8cobDamvrqDQYZw2B/4/7QYKCUCoqaplZS7F/1XslxUVw4LYOLzxh4RoHMhGjfVNDMxGie+OdRfvPGAWoa3UOSHiIvLa5TKouXb7+AuuY2/rrJWvTmHbzWYKCUUgNQ29ja44rjv9y8iG9/4owBn8/7JZyREM3Gey7nqtk5fHy8mqpGd6fB48G49cLJvvuzc5PJToqhpLaZdo9h9faTTEiP65TiYjgbGZ9CKRX2apqG5he7V4Y9vXT++BQiI4QLp2Xw6q5iPj5ew9m5Q5MeIiJC+Ptt5+Nty2QlRVNa18y249XsL6nj/n859Syl4USDgVIqKGoaWxnjt6p4sBrd1mY33gVo8+29h2ubWjulshis+eM79jTOSoymoLzBtzJ5wTDd4rIn2k2klAqKmsZWkuOGLrvnefYU1WWzrMVk/vmBZp9imupgZCXGkF9ezzsHy3FGRjD2FDOghhttGSilgqK2qZWU2KHrJlp61hj2/2yZb3Ww/2ykU61ZGIysRGvQes2uEsYmx3RKmTHcactAKRVwre0e6lvafDmGhkrXNBFfXjIRoFu+oqES5zdYfPI090wOV9oyUEoFnDfV9FAHg65+eNVMvrt0+qDXGPTmzBwryCTGOPh/V83s4+jhRYOBUirgvBvT9DS1dChFRkhAp3qePyWDnT9ZSlLM8N/ZrCvtJlJKBVxt09CkiAgHIzEQgAYDpVQQeFsGKQFuGajTp8FAKRVwvmAQ4DEDdfo0GCilAq7GO4A8hFNL1dDSYKCUCrjaRjci1iwcFZ40GCilAq6myUpSNxI2jh+p+hUMRCRFRF4Qkf0isk9EzhORNBFZJyKH7L+p9rEiIg+KSL6I7BSR+X7nWWUff0hEVvmVnyMiu+zXPCj+OW6VUsNeTWOrDh6Huf62DB4AXjfGzADmAPuAu4H1xphpwHr7McCVwDT7divwMICIpAE/BhYBC4EfewOIfcwtfq9bNriPpZQKNmMMv1yzj52FNfz7czv4wzuH2XrM2uqypqmV5BEwrXQk67MDT0SSgYuAmwCMMW7ALSLXApfYhz0JvA3cBVwLPGWsXao32q2KHPvYdcaYKvu864BlIvI2kGSM2WiXPwVcB7w2FB9QKRUcruY2/vhuQactKAFe+9aFfHy8miVTMkJUM9Uf/WkZTALKgT+LyMci8qiIxAPZxphi+5gSINu+Pw444ff6QrvsVOWFPZR3IyK3isgWEdlSXl7ej6orpYLFuw1kV7c9vQ1HhPD95WcGuUZqIPoTDBzAfOBhY8w8oIGOLiEA7FaAGfrqdWaMecQYs8AYsyAzc+Db5CmlAqdrMLj1ImuXsCMVDdxy0WTGpw/dHgNq6PUnGBQChcaYTfbjF7CCQ6nd/YP9t8x+vgjI83t9rl12qvLcHsqVUsOId09gL+9+AwCfnZ/b9XAVZvoMBsaYEuCEiEy3iy4H9gKrAe+MoFXAy/b91cCN9qyixUCt3Z20FlgqIqn2wPFSYK39nEtEFtuziG70O5dSapjo2jI4MyfJdz97CHc4U4HR3xUg3wSeFhEnUAB8GSuQPCciNwPHgOvtY9cAy4F8oNE+FmNMlYj8DNhsH/cf3sFk4DbgCSAWa+BYB4+VGmbK61pwRAhtHqvHOCPByS8+PZvc1JGzG9hI1q9gYIzZDizo4anLezjWALf3cp7Hgcd7KN8CzOpPXZRS4am8roWsxGjfpi+OyAhuWDQ+xLVS/aVrw5VSg+bxGHYU1pCbGsdfvrqIMlfPM4tU+NJ0FEqpQXsvv4L8snpWLspjSmYC501J7/tFKqxoMFBKDdrhsnoALjkjK8Q1UadLg4FSatDqmtsAzUo6nOl/OaXUaSuubeK9gxXUNbcS54zEEam/L4crDQZKDYF1e0sxxrD0rDGhrkpQ3b/uIM9tsbLJZCdFh7g2ajA0GCg1SCeqGrnlqS0AHP3VVSGuTfC8saeE13aX+B4nROvXyXCmbTqlevDx8Wo8ns7ptsrrWmhpawfg4bcPs25vKQCv7S7u9vqRzuMx3PqXrb6xAoDEGN2vYDjTYKBUF/tLXHz69//kF2v2+creP1TBufe+yWd+/0/KXM38+vX93PLUFk5UNVJY3eQ7rtbe63ekO1LZ0K1MB4+HNw0GSnVR22h9oT/6/hFf2cHSOgD2nHTxys6OlsClv3mbw+X1vscnazoCw0i2/XgNAGeNTWLlQiv/ZLRDv06GM/2vp1QX9S0dXR91zVZgKHU1+8o2HCgjNzWWlQvzaPMYPsiv9A2eFlWPjmCw56SL2KhIVt9xAXPzUgBoafOEtlJqUDQYKNWFfzDYdryGV3cWdwoGHx6uZFJGPF9ZMslXtnCSteL2q09t6XWTl5GksLqRvLRYIiOEzEQrELa0ajAYzrSTT6kuXH6Doqse/wiAcSmxOB0RuNs8tHkMkzPimZgR7ztuXl4KJ2ua2HqsmgMldb4vyJGqsLqJcSlWNtLkWGtvY+/guhqetGWgVBf1fsHAq6imiXl2dwjAxIx4oiIjmJqVAMCnzs7hgRVzAfjn4Qq+8OhGyuqau51npCisbiQ31dq5LC3eCgZ5abqT2XCmLQOluqhvaSUyQpg9LpntJ2p85WeNTWbTEWsLjsmZVhD461cXERUZQWq8k3aPwREh/Om9AlrbDR8eruTauT1u5z2suZpbcTW3Mc7ep2BSRjyP3riARZPTQlwzNRjaMlCqi7rmNhKiHVwzZ2yn8ry0WJ78ykL+49qzON/OypmVFEOq/cs4MkIYmxJLa7u1PmFvsSu4FQ8S7yC5/6Y1n5iZresMhjltGSjVRX1zG4kxDv7l3Dw+OlLF63usVbbzxqfaM2cye31tXlosx6saSYt3sr+4LjgVDrIKe6/jrETdynIk0ZaBUl3UtVgtg/hoB3/40jm+8pl+e/r25po5Y7np/IlcckYmB0pGZjDwLqxLjtWWwEiiLQOluvC2DLyWTE2nqLoJZz8WVf3LudY2j79cs4+aJnfA6hhKriZrgF2DwciiwUCpLupaWjt1gTz91cVYW3v3X5zTQXOrh3aPITJChrqKIeVtGSTF6tfHSNKvbiIROSoiu0Rku4hssct+IiJFdtl2EVnud/w9IpIvIgdE5Aq/8mV2Wb6I3O1XPklENtnlfxMR51B+SKUGoqaxtVsGTpGBfaHHR0cC0OjuPk11uKttaiUqUoiNigx1VdQQGsiYwaXGmLnGmAV+ZffbZXONMWsARGQmsAI4C1gG/F5EIkUkEngIuBKYCay0jwX4tX2uqUA1cPPgPpZSp+dYZQOF1U3MHpc8qPPEOa1g0tAy8hZiuZpbSYqJGnCAVOEtEAPI1wLPGmNajDFHgHxgoX3LN8YUGGPcwLPAtWL9H3UZ8IL9+ieB6wJQL6X69Lqdn//K2YPbpMbbMmgYAS2DtnYPRys6spTWNrXqeMEI1N9gYIA3RGSriNzqV36HiOwUkcdFJNUuGwec8Dum0C7rrTwdqDHGtHUp70ZEbhWRLSKypby8vJ9VV6r/CsobyEqM9q2uPV3elkHjCGgZPL+1kEt+8zav7DwJgKuplSQNBiNOf4PBBcaY+VhdPLeLyEXAw8AUYC5QDPw2IDX0Y4x5xBizwBizIDOz97neSp2uqka3L73CYMQ7R0bL4KY/f8Q9f98FwM9f2Ue7x2gwGKH6FQyMMUX23zLgJWChMabUGNNujPEAf8LqBgIoAvL8Xp5rl/VWXgmkiIijS7kC3j1Yzi/W7BvwbBZ1eqob3KTGDT4YxNkD0MN9APntAx0t8BJXM+8eKsfV3KbdRCNQn8FAROJFJNF7H1gK7BaRHL/DPg3stu+vBlaISLSITAKmAR8Bm4Fp9swhJ9Yg82pjfcttAD5nv34V8PLgP9rIcMdft/HIuwWs3nEy1FUZFaqHumUwjLuJ/Lf9/MqSSWQkRPPQW/mU17WQrNNKR5z+/BfNBl6yZw44gL8aY14Xkb+IyFys8YSjwNcAjDF7ROQ5YC/QBtxujGkHEJE7gLVAJPC4MWaP/R53Ac+KyM+Bj4HHhubjDW/VDW5fOuUfvrSb+eNTNTNkgFU3tpIaP/hfvSOhZVDRYKWdWLkwj7uunE56gpP71h4AGJEJ+Ea7PoOBMaYAmNND+ZdO8Zp7gXt7KF8DrOnlPRZ2LR/NylzN3PXiTgAe/sJ8vvH0Npbe/y5Xz8nhzmUzyEgY2fnyQ8HjMdQ0ukkbgm6i4dwycLd5+M0bB/BOHL10ehbRjkhuuXAyMVGRJMY4OHeiZigdabStF4ba2j3c9OfN7C12cfmMLK6cnUNavJOqBjfPbSnkg/xK/n7b+WQnaaKwoeRqbsVj8GUhHQzfbKJh2DL4wzuHeeTdAt/jsfYmNk5HBDdfMKm3l6lhThPVhZGtx6ppaWtn/f4y9ha7uGHReO77vNUoy7J3zrr307OobnRz5ws7Q1nVEamqwcolNBQDyE5HBCLw9KbjNLcOr9bBpiOVnR7nJOuPjtFAWwZhoqS2mc8+/E8uOiOTWWOTcEQIP756JtEOq7vhf1bO4819ZdywcDwVdW7uf/MgJ6oadQxhCFU3WsEgJW5oZsoYA8W1zazdUzIs+tif/eg4m49Ws6uwltS4KKobrRxEQzGgrsKftgxC7ERVI9UNbg6X1wPWVNLfv32YadmJvkAAMC07kW9cMgUR4TPzxyECVz7wnu/XrBq8Y5WNAINecOblzXLa6B4eLYO7/76LF7cV4mpu49aLpnB2bjIvfuM8TTsxSmgwCLEL/3MD8362zre605sz3xnZ+z/AvLQ47rxiBvUtbbx7sJwdJ2o6rUOobWzVdQmnIb+sHkeEMCF9aILBpnsuBzqyfA4niyensfqOCzhngg4UjxbaTRRC/l8Sz3xkZep4/uvn8cXHNvGNi6ec8rWfnT+OX7++n2//bTtg5Za/+8oZJEQ7+OYzH/P7L8xn+eycU55DgTGGH/7fbmaMSeSRdwt8G90PhZS4KCIjZFgGA+8ez2r00GAQQodKrZ2wEmMc1NnrCeKjHbx025I+X5uZ2HlqaW1Tqy9tAMC+YpcGg36oqHfz9KbjvseOIdx7QERIjo0aFsGgtd3T6bGuMB59tJsohA7YwWDNv17Ip87O4fZLT90a8Offj/v95TN89zMTo3FGRgyLL6BwUFTT5LvviBC+smRop04Ol2BQXtcS6iqoENOWQQh9eLiSpBgH41Ji+d0N8wf8+kWT0th0pIpbL5rCNXPGccOjG7nvc3O468WdlLn0H3d/FFZbg8Zr/vVCZo7te4/jgUqKjcIVhsGgtqmV9ftKOWdCKuPT4iiu7QiKWYm6oHE00mAQIkU1TazZVcxXL5xMxGl2TTz5lYW+5v2Y5Bje+vdLAOsfc3m9BoPeFFY34mpqY+bYJIqqrS/B3LTYgLxXcmwUNY2hn/H1+u5iDpbW86+XTwPgkXcP89CGwyyclEZSTBRv7isF4Defn8NFZ2SEsqoqRDQYhMiHhyvxGPjcObmnfY6YqEhieth6MCsxmq3HqwdTvRHraEUDl/zmbcCaMWMMJMU4SIoJTB95SmwUxyob+j4wQNo9hlJXM1//320AfOOSKURFRvDuwQrAGlvyjlcBfGbeuNP+caKGNw0GIbK7qJY4ZyRTAjBrIysphjJXC8aYAc0R93gMLW0eYp0jd2/bt/aX+e5vLKgC4KwAdA95hXLMYM2uYr73/A4umZ7lKztcXs+YpBh2n6wlKzGaMr+xgtS4KA0Eo5gOIAfZ8cpGbnlqC0/88yhnjU0iMgD/+LISo2lp8/gynvbXf795kMt++zZ1zb1/eTW62yirax5sFUPmg/wKJmXE86vPzPaVfXpe4FYHJ9tjBv7poIPBGMNP/7GHBnc7r+4q9qWU2F9cx/GqRoyB6/w+9/zxKfz5y5orcjTTYBBk7x4qZ91eq382UAt6vOkDqge4Onl/SR3Ftc38bkN+j89vOFDGzB+tZdl/vzcsF7XVNbfyfn4FF03LYMXC8bz2rQu5du5YvrBoQsDeMzk2Co+B+iAnrCuva6HU1cIFUzO4anYO/7NyHk5HBPetPUB+mbXa/fwp6STGODgjO4G/3rKYuXkpQa2jCi/aTRRkJ6qs2St/vWVRwNIAe7NuVjW6mUh8v19X4rJ+8T/ybgGv7y5h+ewc7lo2gzJXM99/aRdv7rO6WKoa3JS4mslJDsyga6C8tquEljYP18wdC8CZOUk8sGJeQN/TO1+/trE1YOMSPamot34I3LBovG+9yTcunsID6w/x+u4SACakx7P5B58g2hGhKSeUtgyC7VhlI1My4zl/SsaQrXTtypuPf6Atg+LaZi6bkUWC08GxykYefvswu4tq+ekre3lzXxkZCU4eW7UAgL0nXUNe70AqqW3mZ6/uZWZOEvPHpwbtfb17BQd73MCbsyrdL8ncyoXjAXwtg7R4JzFRkRoIFKDBIOiOVjYwIb3/v9ZPh7ebaCBJ7NxtHirqW5g9Lpl137mYh26Yj9MRwY9X7+HVncV8YdF4XvnmhSyanA7AnmEWDDYcKKOuuY3fXj8nqF9+3pZBsNcaVNq7lKUndAQD7w5uBRUNREUKSTHaMaA6aDAIImMMx6sahywRWm+83UTVvcxv31/i6jbdsayuGWOs9QpjkmO46uwcFkxIZeuxajISovn+8jMZkxxDQrSDGWMSWbe3dFiNG2w5Wk16vJMZYxKD+r7JIWoZVNZ7WwYdC8iiHdYuZWD9YNAWgfKnwSCIKurdNLrbmRDgPQjinZFECPxizX7W7imhsr6F2qZWX5rsZf/9Hhff93anL/OSWmu8YIzfRiYrF44nMdrBgyvmEh/d8SvyC4vGs6uoltfsvufhYOuxKuZPSA36F2CyvTdCVZAXnlU1uImMkG45hrzbpabF6ypj1Zm2E4PoeJX1azzQ3UQigncm49f+shWwUmPvLXbx5ncu9h23+Wg1CydZg9jbT9QAcEZ2xy/nq+eM5arZOd3mnn/unDye21LI957fwdKZ2TgCNPYxWCeqGmlubSc13snRykZfn3kweb+Mf/DSbt7cW8qjq84NyHTiriobWkiNc3b7b5ce7+RIRUOnsQSloJ8tAxE5KiK7RGS7iGyxy9JEZJ2IHLL/ptrlIiIPiki+iOwUkfl+51llH39IRFb5lZ9jnz/ffm1YtF+La5sotWfY5JfV87W/bBlUagHv5injA9xN1JO9xVYf/w//ryOz6T1/30mbnc7inYPlTMtKYFxK5xlCPS1CinVG8sXF42lwt3OyJjzXHNQ2tXL1797nk/e/y4PrDwFwzoTgDRx7xfst4NtwoJz9JcEZa6msd/f4hZ9gdxPlpg6vmWAq8Abyk+5SY8xcY8wC+/HdwHpjzDRgvf0Y4Epgmn27FXgYrOAB/BhYBCwEfuwNIPYxt/i9btlpf6I+9NXP7W7zUFzbhDGG8375Fot/uR6Px3DXiztZu6eUlz4uGtD71be0caDEyk56rLIRkdD9QxyXEsvGgiqSYhzc/y9zOFzewNZj1RyrbGBjQSWXTM/s97km2q2bHYU1vLW/NFBVPqWimiZue3prj4vkXtxaSI29beNTHx4jKlKYNS452FXs1i111YPv88aewHevVTa4e9yucldhLYCmN1fdDKab6FrgEvv+k8DbwF12+VPG+tbdKCIpIpJjH7vOGFMFICLrgGUi8jaQZIzZaJc/BVwHvDaIuvXqu8/vxN3uITUuiu9eMd039/vhtw/z+u5iWto8HCitY+nMbMDax3by99cAEOeM5MVthdx0/sR+9T03udtZ+l/vcLK2mbl5KVTUtzA2ObbTdpaB8t6dl9La7qG13bB+fykLJ6axu6iWn/xjL0vPGsMnZ44hKnInbx0oI7+0HmdkBF+9cHK/zz8xwwoG33zmYwBevn0Jc4K8aOm3aw+wZlcJl0zP4voFeZ2e23qsmtzUWB5YMZfvvbCTT83O6TGPUyi8sLWQpWeNCeh7VDW4e0yz8f3lZ3L/mwc5f0p6QN9fDT/9DQYGeENEDPBHY8wjQLYxpth+vgTItu+PA074vbbQLjtVeWEP5d2IyK1YrQ3Gjx94/2+7x2Aw/GOHtcXkR0eq+MvNiwD4z7X7MQYSox04IyNYu8f6tTsnN5mWNg9TsxK4cFoGd724i9U7TvZrg/Otx6o5aQ/Mbj9Rw8ycJJbNCuyXgFee3yD1dHsGzVljkymra+HmCyaREO3g/CkZ/PGdAgB+sPxMspNiejxXT7ISo4mJiqC51epmevLDo/xX3tyh+wB9KHM1s/uk9SvXm3nUyxjDlmNVLJ6czjkT0nzZXEPle1dMJyUuioo6N/e/edC39iCQKupbeuwm+uw5uXx2EMkR1cjV32BwgTGmSESygHUist//SWOMsQNFQNlB6BGABQsWDPj9IiOE/7p+LvdeN5utx6q56c8f8Z3nthPtiMQYePM7FzE1K5H8sjo+/4cP+X+fmsln5nf8w/F4DPevO8SG/WX9Cgb77H765752HmnxTqZmhXYrwVhnJHcu69gI5+fXzeKmP3/EuRPTuGnJxAGdS0SYnp3IDrvbYe3uEpo/3R6wX9/uNg9RkYKIsLuoluse+oA2e5R8jx0UvI5WNlLqagnJGEFPbr90qu/++v2lAd9Ixt3moa65jfQEnTGk+q9fwcAYU2T/LRORl7D6/EtFJMcYU2x3A3nTQRYB/m32XLusiI5uJW/523Z5bg/HB0ysM5ILpmUwb3wK7x2yUvkmRDuYmmX9gp6alcjmH3yi2yyZiAhhSlY8Rysbcbd5iIyQU84M2VfsIjsp2jdjJ9zkpcWxfhC/mp+6eREbCyqJFOGrT23h+j9+yPNfP2/Iu8E8HsNnHv4AR0QEdy6bzg1/2tTp+a6roV/bbTVYLz8zm3CTmRBNcW1gB92960t6GjNQqjd9DiCLSLyIJHrvA0uB3cBqwDsjaBXwsn1/NXCjPatoMVBrdyetBZaKSKo9cLwUWGs/5xKRxfYsohv9zhVQiyZ19Jtea+er8eptuuT4tHiOVTZw3i/X8692f3lvdhXVcmZO4NIjh1pybBRXnDWGi6dnckZ2AjsLa9lxorbvFw7QB4cr2F3kYvuJGl8g+OFVZ3L4F8v5t0+cQbGrmebWdjwew1MfHuXx948yNy+l28yocJAZhI2HKuzzZyRoMFD915+WQTbwkj1g6gD+aox5XUQ2A8+JyM3AMeB6+/g1wHIgH2gEvgxgjKkSkZ8Bm+3j/sM7mAzcBjwBxGINHAdk8LirOy6bysJJaUzKiO+2wXxvJqbHUW3PUnl1VzEPtHt6DBwHSuo4VFYfkrntwRYVGcH/fnURC+9dz66i2iFvCb19oJyYqAhuPG8iT/zzKA+umMuyWdZsmAnpcRhj7V52rLKRH728h2hHBPd++twhrcNQyUyMprK+hXaPCdh6A28aEl1Ypgaiz2BgjCkA5vRQXglc3kO5AW7v5VyPA4/3UL4FmNWP+g6pmKhILjqj/9MpgW6pJD4+UdMt+2hxbRM3/GkjjgjxZcgc6bISY8hKjGZP0dC3DCrqW8hKjOGeK2fw7U9MI87Z8b+td83GN5/ZTpwzkpS4KDbec3nYzBzqKjMxGo+xvrD7+wNkoHypKLRloAYgPJeOhrFFk9K5fEYWD660Uh9vKqjsdszfNp+gssHN726Y51v+PxrMGpfMrgAEg8p6N+kJVi4d/0AA+FJ77Ct2sfVYNTcunhC2gQBOL4ngQHkHqHWVsRoIDQYDlBrv5LGbzuWaOWOZlpXAlmPWXsMvby/iLxuPsbuolsffP8J5k9N9XRmjxaxxyRwur6dxiDdysaZJ9hxU/QdJr5kzltsvm9rjceEiwc7xVN9yetfIu2iytd3D5qNVPR6zt9hFVmJ0t7xESp2K5iYahAUTU3l+SyGHy+v51rPbAWuT9XaP4c5l00NbuRCYNTYJj4F9xXVDOq2zqsHd6y5cIsJ7d15KeoKzW6shHHmzhp5OMCira2bhvet5YMVcdhXW8uj7R1j77Yt860i8dhTWcHZuimYlVQOiLYNB+JdzxyMCKx7Z6CvbWFDFTUsmMi+IG6iEC2+6h91D2FXk8Riqekmt4JWXFjcsAgFAQrT1a71+gPtTA760Jr994yCb7RZpfUvnVBx1za0UlDcwJzf4qTfU8KbBYBDm5qWw6ryJ3RYRfXJmcFYZh5uc5BjGpcSy4UBZ3wf3orm1nY1+4zCu5lbaPGbELKDyJoprOI2WwXF7y9TjVY2+/Sha7BXgXoX2auwpIV7gqIYfDQaDNL+H7pDR+qtMRPjUnBzeP1RxWtk5jTFc/8cPWfHIRgrsvRcq7YHWkTJn3jtmUHcawcCb9RbwJeFzdWlheBecpcTpeIEaGA0Gg+TdT3flwvGsXDieZ25ZPKr7aleeO56k2Cg+/4cP+dkreymr6/9q2w0Hythpp7f4+HgNAEcrrF/AWYn9z5sUzrwprU+nm2jL0SqmZSWwzC/JXdeMrd4gkRo3MoKnCp7h0dEaxsYkx7D22xcxOTM+YBvcDycTM+L5/vIz+e7zO3js/SPsOFHDC984v1+vfez9I4xLiaW8roV1e0vZWVjDkx8eI9oRwfwJKYGteJA4IiOIjYrs1tffl4c25LPteA3LZ4/h4jMyed1Og911IFqDgTpdGgyGQNfZHKOdf3rkbcerMcb0q7V0uKyBJVMzOFHd6PuyA7hwWkZQ0n4HS0KMY0CziRrdbfzxncPMHpfMT6+ZRVFNR5bWOr8WxoGSOt9GPtpNpAZKg4EacmNTYlk6M5sdhTWUulpwt3v6/DJvaWuntK6ZvLRYVp0/gf/7+CRXz8nB3eZhUmZgtwkNtsRoR6cv8b5sKqjC1dzGXctmkJkYTWKMgwnpcRyrbOzUTfTY+wWU2DvzhfPCOxWetF9DBcQjNy7gaxdNAaDZ7enjaGtPAmMgNzWOs3NT+NHVM5k3PpVFk9NHzHiB10BbBt5V3XPyrIkJMVGRvPO9S8lMjO4UVHYVBWdLTTUyactABUysPVja1NpOMqfutjhhT4nMGwV78yZEOwY0tXRXUS2TM+JJjOl8DRNjHNQ0tvLLNfuobnRzqLRuqKuqRhENBipgYu2uiv6kpzhhz6H336FtpEqIdrDnpIsmd7svYJ7KvmJXj4sYE2OiOo2tKDUY2k2kAsbbb93U2t7nsbuLakmKcTBmAFtvDldXnZ1DUU0Tj39wpM9jjTGUuVoYm9L9uiTF9Pxbbnq2TmhQA6fBQAWM91dvcx/BoKK+hTf3lbJwUhoRAcrxH06unTuO9HgnJb3seFbT6OYP7xzG4zHUtbThbveQ0UOiPm8r6qqzrYSIybFR7PzJUl6+Y0ngKq9GLO0mUgHj7SZq6mEA2Zt9c+2eEr7+v9sAwnZ70ECIj+59EPmev+/itd0lnDsx1ZettafcTD+7dhbfunwaybFRvLarmFnjkkiK0Sml6vRoMFABE3uKbqLvPr/T1xqIdkTwtYuncP2CvG7HjVQJp5heesRedd3k9vDbfx4Eet6oJjJCyLa71T47P5dFk9O7HaNUf2kwUAET67R6IbsGg5LaZl7cVgjAhv1lXDN3LN/55BlBr18oWdNLe16F7M0v9LsNh9hYYO1Z0Nt+Dl73fb7bZoRKDYiOGaiA8Q4gN7s7gkGju43Fv1zve9zmMaMy3XfiKbqJvHts+++GpltYqkDTYKACpqduom3Harodd8kA96EeCRJiHD0mq/N4DO42a4ylzC81+qn2c1BqKPQ7GIhIpIh8LCKv2I+fEJEjIrLdvs21y0VEHhSRfBHZKSLz/c6xSkQO2bdVfuXniMgu+zUPymhO+zmC+C8689pYUElkhLD7p1dw1ewcfvSpmaNibUFXCb20DI7a+xRAR9I50PQSKvAGMmbwLWAfkORX9j1jzAtdjrsSmGbfFgEPA4tEJA34MbAAMMBWEVltjKm2j7kF2ASsAZYBrw3846hwEuPwziZq56f/2IMzMoKtx6qZPS6ZhGgHD31hfh9nGLl6G0DuaV/jn1w9MxhVUqNcv4KBiOQCVwH3At/p4/BrgaeMNXdwo4ikiEgOcAmwzhhTZZ9zHbBMRN4GkowxG+3yp4Dr0GAw7EVECNGOiE77FAB8/eIpIaxVeEiIdtDS5sHd5sHp6Gigbz5aTVq8kxhHBCdrm1kyNZ2blkwKYU3VaNHfbqL/Bu4Euk4Yv9fuCrpfRLzTHcYBJ/yOKbTLTlVe2EN5NyJyq4hsEZEt5eXl/ay6CqVYZ2SnQACwePLoWU/Qm962v8wvq+fMnESSYq31ApkjZLtPFf76DAYi8imgzBiztctT9wAzgHOBNOCuoa9eZ8aYR4wxC4wxCzIzR9+g43DkHUSek5fCS7edz/LZY1g0SefDe7e/7DpuUNXgJiMhmnaPtSgvM1GDgQqO/rQMlgDXiMhR4FngMhH5X2NMsbG0AH8GFtrHFwH+q4dy7bJTlef2UK5GAO8g8sycJOaNT+X3XzinX8nZRrpEu2XQddygqsFNWryTSDstx2fPye32WqUCoc9gYIy5xxiTa4yZCKwA3jLGfNEeB8Ce+XMdsNt+yWrgRntW0WKg1hhTDKwFlopIqoikAkuBtfZzLhFZbJ/rRuDlof2YKlQ+dfZYAKZlJYS4JuElxd6WsrKhY/podYOb+pY20uOd/P4L83nh6+cxY0xSb6dQakgNZgXy0yKSCQiwHfi6Xb4GWA7kA43AlwGMMVUi8jNgs33cf3gHk4HbgCeAWKyBYx08HiG+ffk0zhyTyMXTtVvP3+QMa/e2w2X1XDgtk12FtVz9u/cBSIuPZnJmApP1kqkgGlAwMMa8Dbxt37+sl2MMcHsvzz0OPN5D+RZg1kDqooaHiAjhytk5oa5G2PFuX5lfXg/A/W8e9D2nq41VKOgKZKVCQESYkpnAbnuryj0nO2ZcpetqYxUCGgyUCpEzshPYfqKGX7++X1NPqJDTYKBUiHz7E2fgdETwt80nMAay7GmkOp1UhYIGA6VCZGxKLF9ZMsmXnfS+z89h50+Wdtv4Xqlg0GCgVAjNzUvx3R+XEqM7lamQ0WCgVAidP7VjNXZOcmwIa6JGO93pTKkQSoqJ4qXbzue9QxXER+s/RxU6+n+fUiE2b3zqqNztTYUX7SZSSimlwUAppZQGA6WUUmgwUEophQYDpZRSaDBQSimFBgOllFJoMFBKKQWItRfN8CMi5cCx03x5BlAxhNUZCfSadKfXpDu9Jj0bTtdlgjGm2z56wzYYDIaIbDHGLAh1PcKJXpPu9Jp0p9ekZyPhumg3kVJKKQ0GSimlRm8weCTUFQhDek2602vSnV6Tng376zIqxwyUUkp1NlpbBkoppfxoMFBKKTW6goGILBORAyKSLyJ3h7o+wSQij4tImYjs9itLE5F1InLI/ptql4uIPGhfp50iMj90NQ8cEckTkQ0isldE9ojIt+zyUXtdRCRGRD4SkR32NfmpXT5JRDbZn/1vIuK0y6Ptx/n28xND+gECSEQiReRjEXnFfjyirsmoCQYiEgk8BFwJzARWisjM0NYqqJ4AlnUpuxtYb4yZBqy3H4N1jabZt1uBh4NUx2BrA/7dGDMTWAzcbv8/MZqvSwtwmTFmDjAXWCYii4FfA/cbY6YC1cDN9vE3A9V2+f32cSPVt4B9fo9H1jUxxoyKG3AesNbv8T3APaGuV5CvwURgt9/jA0COfT8HOGDf/yOwsqfjRvINeBn4pF4X3+eLA7YBi7BW1zrsct+/JWAtcJ5932EfJ6GuewCuRS7WD4PLgFcAGWnXZNS0DIBxwAm/x4V22WiWbYwptu+XANn2/VF3reym/DxgE6P8utjdIduBMmAdcBioMca02Yf4f27fNbGfrwXSg1rh4Phv4E7AYz9OZ4Rdk9EUDNQpGOtnzKicZywiCcCLwLeNMS7/50bjdTHGtBtj5mL9Gl4IzAhtjUJLRD4FlBljtoa6LoE0moJBEZDn9zjXLhvNSkUkB8D+W2aXj5prJSJRWIHgaWPM3+3iUX9dAIwxNcAGrC6QFBFx2E/5f27fNbGfTwYqg1vTgFsCXCMiR4FnsbqKHmCEXZPRFAw2A9PsGQBOYAWwOsR1CrXVwCr7/iqsPnNv+Y327JnFQK1ft8mIISICPAbsM8b8l99To/a6iEimiKTY92OxxlD2YQWFz9mHdb0m3mv1OeAtuzU1Yhhj7jHG5BpjJmJ9b7xljPkCI+2ahHrQIpg3YDlwEKsP9Aehrk+QP/szQDHQitW/eTNWP+Z64BDwJpBmHytYM68OA7uABaGuf4CuyQVYXUA7ge32bflovi7A2cDH9jXZDfzILp8MfATkA88D0XZ5jP04335+cqg/Q4CvzyXAKyPxmmg6CqWUUqOqm0gppVQvNBgopZTSYKCUUkqDgVJKKTQYKKWUQoOBUkopNBgopZQC/j+WY6FFNVvYhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.278357\n",
      "Cumulative returns     0.536885\n",
      "Annual volatility      0.199767\n",
      "Sharpe ratio           1.332804\n",
      "Calmar ratio           1.072671\n",
      "Stability              0.570703\n",
      "Max drawdown          -0.259499\n",
      "Omega ratio            1.267395\n",
      "Sortino ratio          1.895606\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.112724\n",
      "Daily value at risk   -0.024112\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to IHSG===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (425, 8)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4fe69935546d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^JKSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n\u001b[0m",
      "\u001b[0;32m/home/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mbacktest_plot\u001b[0;34m(account_value, baseline_start, baseline_end, baseline_ticker, value_col_name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         pyfolio.create_full_tear_sheet(\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mreturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[0;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mturnover_denom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturnover_denom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mheader_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         set_context=set_context)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     create_interesting_times_tear_sheet(returns,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[0;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbenchmark_rets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_returns_to_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     plotting.show_perf_stats(returns, benchmark_rets,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/utils.py\u001b[0m in \u001b[0;36mclip_returns_to_benchmark\u001b[0;34m(rets, benchmark_rets)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     raise KeyError(\n\u001b[0;32m-> 1316\u001b[0;31m                         \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m                         \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                         \u001b[0;34mf\"The following labels were missing: {not_found}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to IHSG===========\")\n",
    "%matplotlib inline\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^JKSE', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_perf_stats=backtest_stats('^JKSE',\n",
    "                                  baseline_start = df_account_value.loc[0,'date'],\n",
    "                                  baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_multiple_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
