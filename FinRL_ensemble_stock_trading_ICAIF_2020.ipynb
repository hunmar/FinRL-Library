{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_multiple_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "802ae0b5-d88e-46ba-8082-9eb5890f9cba"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "c437c266-2780-4c50-af8b-6868e7fdaa1f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, get_baseline, backtest_plot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-01-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSLA', 'AMZN']\n"
     ]
    }
   ],
   "source": [
    "print(config.TOPCHIK_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3042, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = config.START_DATE,\n",
    "                     end_date = '2021-01-19',\n",
    "                     ticker_list = config.TOPCHIK_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>312.579987</td>\n",
       "      <td>314.750000</td>\n",
       "      <td>306.959991</td>\n",
       "      <td>308.519989</td>\n",
       "      <td>2783200</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>44.574001</td>\n",
       "      <td>44.650002</td>\n",
       "      <td>42.652000</td>\n",
       "      <td>43.862000</td>\n",
       "      <td>23822000</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>307.010010</td>\n",
       "      <td>308.380005</td>\n",
       "      <td>300.850006</td>\n",
       "      <td>302.190002</td>\n",
       "      <td>2774200</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>42.910000</td>\n",
       "      <td>43.299999</td>\n",
       "      <td>41.431999</td>\n",
       "      <td>42.018002</td>\n",
       "      <td>26842500</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>302.239990</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>292.380005</td>\n",
       "      <td>295.290009</td>\n",
       "      <td>3519000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close    volume   tic  \\\n",
       "0  2015-01-02  312.579987  314.750000  306.959991  308.519989   2783200  AMZN   \n",
       "1  2015-01-02   44.574001   44.650002   42.652000   43.862000  23822000  TSLA   \n",
       "2  2015-01-05  307.010010  308.380005  300.850006  302.190002   2774200  AMZN   \n",
       "3  2015-01-05   42.910000   43.299999   41.431999   42.018002  26842500  TSLA   \n",
       "4  2015-01-06  302.239990  303.000000  292.380005  295.290009   3519000  AMZN   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    0  \n",
       "3    0  \n",
       "4    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>852.760010</td>\n",
       "      <td>860.469971</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>854.409973</td>\n",
       "      <td>33312500</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>3167.520020</td>\n",
       "      <td>3178.000000</td>\n",
       "      <td>3120.590088</td>\n",
       "      <td>3127.469971</td>\n",
       "      <td>3070900</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>843.390015</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>838.750000</td>\n",
       "      <td>845.000000</td>\n",
       "      <td>31266300</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>3123.020020</td>\n",
       "      <td>3142.550049</td>\n",
       "      <td>3095.169922</td>\n",
       "      <td>3104.250000</td>\n",
       "      <td>4214200</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>859.900024</td>\n",
       "      <td>819.099976</td>\n",
       "      <td>826.159973</td>\n",
       "      <td>38647900</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date         open         high          low        close  \\\n",
       "3037  2021-01-13   852.760010   860.469971   832.000000   854.409973   \n",
       "3038  2021-01-14  3167.520020  3178.000000  3120.590088  3127.469971   \n",
       "3039  2021-01-14   843.390015   863.000000   838.750000   845.000000   \n",
       "3040  2021-01-15  3123.020020  3142.550049  3095.169922  3104.250000   \n",
       "3041  2021-01-15   852.000000   859.900024   819.099976   826.159973   \n",
       "\n",
       "        volume   tic  day  \n",
       "3037  33312500  TSLA    2  \n",
       "3038   3070900  AMZN    3  \n",
       "3039  31266300  TSLA    3  \n",
       "3040   4214200  AMZN    4  \n",
       "3041  38647900  TSLA    4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3042, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4hYkeaPiICHS",
    "outputId": "ce9d7463-a74c-4917-c96d-848a1e8ad493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>312.579987</td>\n",
       "      <td>314.750000</td>\n",
       "      <td>306.959991</td>\n",
       "      <td>308.519989</td>\n",
       "      <td>2783200</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>44.574001</td>\n",
       "      <td>44.650002</td>\n",
       "      <td>42.652000</td>\n",
       "      <td>43.862000</td>\n",
       "      <td>23822000</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>307.010010</td>\n",
       "      <td>308.380005</td>\n",
       "      <td>300.850006</td>\n",
       "      <td>302.190002</td>\n",
       "      <td>2774200</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>42.910000</td>\n",
       "      <td>43.299999</td>\n",
       "      <td>41.431999</td>\n",
       "      <td>42.018002</td>\n",
       "      <td>26842500</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>302.239990</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>292.380005</td>\n",
       "      <td>295.290009</td>\n",
       "      <td>3519000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close    volume   tic  \\\n",
       "0  2015-01-02  312.579987  314.750000  306.959991  308.519989   2783200  AMZN   \n",
       "1  2015-01-02   44.574001   44.650002   42.652000   43.862000  23822000  TSLA   \n",
       "2  2015-01-05  307.010010  308.380005  300.850006  302.190002   2774200  AMZN   \n",
       "3  2015-01-05   42.910000   43.299999   41.431999   42.018002  26842500  TSLA   \n",
       "4  2015-01-06  302.239990  303.000000  292.380005  295.290009   3519000  AMZN   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    0  \n",
       "3    0  \n",
       "4    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>59.540001</td>\n",
       "      <td>59.560001</td>\n",
       "      <td>57.348000</td>\n",
       "      <td>58.226002</td>\n",
       "      <td>29976000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.820634</td>\n",
       "      <td>52.986429</td>\n",
       "      <td>40.397371</td>\n",
       "      <td>39.089617</td>\n",
       "      <td>-134.876869</td>\n",
       "      <td>47.624022</td>\n",
       "      <td>48.305400</td>\n",
       "      <td>48.830100</td>\n",
       "      <td>2.397849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>1763.699951</td>\n",
       "      <td>1806.250000</td>\n",
       "      <td>1759.489990</td>\n",
       "      <td>1804.030029</td>\n",
       "      <td>4808200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.361956</td>\n",
       "      <td>72.707112</td>\n",
       "      <td>67.055288</td>\n",
       "      <td>45.849547</td>\n",
       "      <td>-105.426353</td>\n",
       "      <td>18.554568</td>\n",
       "      <td>71.140800</td>\n",
       "      <td>70.573133</td>\n",
       "      <td>1.881009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>944.750000</td>\n",
       "      <td>945.000000</td>\n",
       "      <td>934.219971</td>\n",
       "      <td>937.530029</td>\n",
       "      <td>2418400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-18.233927</td>\n",
       "      <td>1844.863266</td>\n",
       "      <td>1741.688724</td>\n",
       "      <td>49.887430</td>\n",
       "      <td>26.746790</td>\n",
       "      <td>0.538943</td>\n",
       "      <td>1816.168994</td>\n",
       "      <td>1879.145502</td>\n",
       "      <td>6.199242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3117.020020</td>\n",
       "      <td>3132.889893</td>\n",
       "      <td>3098.050049</td>\n",
       "      <td>3099.399902</td>\n",
       "      <td>3374400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.538428</td>\n",
       "      <td>483.738184</td>\n",
       "      <td>341.700817</td>\n",
       "      <td>56.133311</td>\n",
       "      <td>16.434071</td>\n",
       "      <td>2.491806</td>\n",
       "      <td>414.825600</td>\n",
       "      <td>358.338165</td>\n",
       "      <td>0.279862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>49.784000</td>\n",
       "      <td>49.880001</td>\n",
       "      <td>49.259998</td>\n",
       "      <td>49.669998</td>\n",
       "      <td>10674000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.845964</td>\n",
       "      <td>617.063721</td>\n",
       "      <td>504.526275</td>\n",
       "      <td>66.600315</td>\n",
       "      <td>199.656734</td>\n",
       "      <td>48.319171</td>\n",
       "      <td>549.597001</td>\n",
       "      <td>532.946667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic         open         high          low        close  \\\n",
       "2501  2018-06-05  TSLA    59.540001    59.560001    57.348000    58.226002   \n",
       "3234  2019-06-07  AMZN  1763.699951  1806.250000  1759.489990  1804.030029   \n",
       "1706  2017-05-04  AMZN   944.750000   945.000000   934.219971   937.530029   \n",
       "4298  2020-11-20  AMZN  3117.020020  3132.889893  3098.050049  3099.399902   \n",
       "303   2015-06-02  TSLA    49.784000    49.880001    49.259998    49.669998   \n",
       "\n",
       "          volume  day       macd      boll_ub      boll_lb     rsi_30  \\\n",
       "2501  29976000.0  1.0  -1.820634    52.986429    40.397371  39.089617   \n",
       "3234   4808200.0  4.0  -0.361956    72.707112    67.055288  45.849547   \n",
       "1706   2418400.0  3.0 -18.233927  1844.863266  1741.688724  49.887430   \n",
       "4298   3374400.0  4.0  10.538428   483.738184   341.700817  56.133311   \n",
       "303   10674000.0  1.0  20.845964   617.063721   504.526275  66.600315   \n",
       "\n",
       "          cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "2501 -134.876869  47.624022     48.305400     48.830100    2.397849  \n",
       "3234 -105.426353  18.554568     71.140800     70.573133    1.881009  \n",
       "1706   26.746790   0.538943   1816.168994   1879.145502    6.199242  \n",
       "4298   16.434071   2.491806    414.825600    358.338165    0.279862  \n",
       "303   199.656734  48.319171    549.597001    532.946667    0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 2, State Space: 21\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 50_000_000/100, #Since in Indonesia the minimum number of shares per trx is 100, then we scaled the initial amount by dividing it with 100 \n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2000-01-01'\n",
    "train_end = '2019-01-01'\n",
    "val_test_start = '2019-01-01'\n",
    "val_test_end = '2021-01-18'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 100_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "2.5307452504065413\n",
      "turbulence_threshold:  145.81027039194817\n",
      "======Model training from:  2000-01-01 to  2019-01-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.132    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.409    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.185    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -20.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 22.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.42e+06 |\n",
      "|    total_cost         | 1.33e+05 |\n",
      "|    total_reward       | 9.2e+05  |\n",
      "|    total_reward_pct   | 184      |\n",
      "|    total_trades       | 1822     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.735    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.351    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.101    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.31    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.95e+05 |\n",
      "|    total_cost         | 1.32e+05 |\n",
      "|    total_reward       | 3.95e+05 |\n",
      "|    total_reward_pct   | 79       |\n",
      "|    total_trades       | 1722     |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.0666  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -8.11    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.0878   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 51.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.77e+06 |\n",
      "|    total_cost         | 1.1e+05  |\n",
      "|    total_reward       | 1.27e+06 |\n",
      "|    total_reward_pct   | 255      |\n",
      "|    total_trades       | 1745     |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.233    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 8.06     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.0746   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -15.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 54.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.96e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 1.46e+06 |\n",
      "|    total_reward_pct   | 292      |\n",
      "|    total_trades       | 1760     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0455  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -18.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 32       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 4.63     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.36     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1687639.60\n",
      "total_reward: 1187639.60\n",
      "total_cost: 138217.71\n",
      "total_trades: 1689\n",
      "Sharpe: 1.226\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 1.38e+05 |\n",
      "|    total_reward       | 1.19e+06 |\n",
      "|    total_reward_pct   | 238      |\n",
      "|    total_trades       | 1689     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.0448   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -6.98    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -4.66    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.42     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.32e+06  |\n",
      "|    total_cost         | 1.37e+05  |\n",
      "|    total_reward       | 8.17e+05  |\n",
      "|    total_reward_pct   | 163       |\n",
      "|    total_trades       | 1517      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.87     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -1.1      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.408     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -4.94    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+06 |\n",
      "|    total_cost         | 1.27e+05 |\n",
      "|    total_reward       | 7.87e+05 |\n",
      "|    total_reward_pct   | 157      |\n",
      "|    total_trades       | 1533     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.84    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.0401   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 59.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.55e+06 |\n",
      "|    total_cost         | 1.29e+05 |\n",
      "|    total_reward       | 1.05e+06 |\n",
      "|    total_reward_pct   | 210      |\n",
      "|    total_trades       | 1367     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.0478   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -5.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.00456 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 129      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.96e+06 |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 1.46e+06 |\n",
      "|    total_reward_pct   | 292      |\n",
      "|    total_trades       | 1502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.00924  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 2.04     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.0176   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 18.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 57.1     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1747658.77\n",
      "total_reward: 1247658.77\n",
      "total_cost: 64014.59\n",
      "total_trades: 1246\n",
      "Sharpe: 1.138\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 6.4e+04  |\n",
      "|    total_reward       | 1.25e+06 |\n",
      "|    total_reward_pct   | 250      |\n",
      "|    total_trades       | 1246     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.0193   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 5.12     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.0129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -12.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 34.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.74e+06 |\n",
      "|    total_cost         | 6.13e+04 |\n",
      "|    total_reward       | 1.24e+06 |\n",
      "|    total_reward_pct   | 249      |\n",
      "|    total_trades       | 1208     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.0632  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.0143   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.000586 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 2.65     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.85e+06 |\n",
      "|    total_cost         | 5.19e+04 |\n",
      "|    total_reward       | 1.35e+06 |\n",
      "|    total_reward_pct   | 271      |\n",
      "|    total_trades       | 1184     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.039   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 5.14     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.00106 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 20.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 66       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.86e+06 |\n",
      "|    total_cost         | 5.04e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 273      |\n",
      "|    total_trades       | 1282     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.0473   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.962    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.0962   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 6.41     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 3.82e+04 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 275      |\n",
      "|    total_trades       | 1220     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -4.99    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.00149  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -7.84    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.07     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2066178.43\n",
      "total_reward: 1566178.43\n",
      "total_cost: 27714.60\n",
      "total_trades: 1166\n",
      "Sharpe: 1.291\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.07e+06 |\n",
      "|    total_cost         | 2.77e+04 |\n",
      "|    total_reward       | 1.57e+06 |\n",
      "|    total_reward_pct   | 313      |\n",
      "|    total_trades       | 1166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.0257  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.609    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.0919   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 14.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 35.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 2.27e+04 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 274      |\n",
      "|    total_trades       | 1099     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.113   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | -0.0299  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 42.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 2.41e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 269      |\n",
      "|    total_trades       | 1082     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -3.36    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -5.67    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.88e+06 |\n",
      "|    total_cost         | 2.8e+04  |\n",
      "|    total_reward       | 1.38e+06 |\n",
      "|    total_reward_pct   | 275      |\n",
      "|    total_trades       | 1032     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.00142 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -3.32    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0.0315   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 24.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 61.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 4.83e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 268      |\n",
      "|    total_trades       | 1039     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | -0.0655  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 6.52     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0.00284  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -1.25    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.27     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1817118.20\n",
      "total_reward: 1317118.20\n",
      "total_cost: 45526.75\n",
      "total_trades: 1039\n",
      "Sharpe: 1.156\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.82e+06 |\n",
      "|    total_cost         | 4.55e+04 |\n",
      "|    total_reward       | 1.32e+06 |\n",
      "|    total_reward_pct   | 263      |\n",
      "|    total_trades       | 1039     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 3.17     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | -0.0146  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -20.5    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 76       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 3.48e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 268      |\n",
      "|    total_trades       | 1025     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.635   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.556    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0102  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.85e+06 |\n",
      "|    total_cost         | 1.63e+04 |\n",
      "|    total_reward       | 1.35e+06 |\n",
      "|    total_reward_pct   | 269      |\n",
      "|    total_trades       | 1013     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0451  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -4.52    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.000781 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 7.04     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 6.09e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1013     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.159    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.746    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.411    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.000531 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 7.15     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+06 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 1.56e+06 |\n",
      "|    total_reward_pct   | 312      |\n",
      "|    total_trades       | 1009     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.346    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.54     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.407    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0152  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -2.08    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1917498.42\n",
      "total_reward: 1417498.42\n",
      "total_cost: 11513.63\n",
      "total_trades: 1030\n",
      "Sharpe: 1.194\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 1.15e+04 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 283      |\n",
      "|    total_trades       | 1030     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.0844   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -6.69    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.195   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 2.2e+03  |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1038     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0.0593   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0.0013   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 2.89e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1026     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 29.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0.000564 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -18.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 78       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 8.74e+03 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 280      |\n",
      "|    total_trades       | 1090     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.824   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.305    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.0576  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 22.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 63.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.91e+06 |\n",
      "|    total_cost         | 1.09e+04 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 283      |\n",
      "|    total_trades       | 1147     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 4.25     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0295  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -3.69    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1838547.25\n",
      "total_reward: 1338547.25\n",
      "total_cost: 36519.88\n",
      "total_trades: 1302\n",
      "Sharpe: 1.164\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 3.65e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 268      |\n",
      "|    total_trades       | 1302     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.052    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -6.06    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.00433 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 82.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.81e+06 |\n",
      "|    total_cost         | 7.02e+04 |\n",
      "|    total_reward       | 1.31e+06 |\n",
      "|    total_reward_pct   | 262      |\n",
      "|    total_trades       | 1553     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.0235   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 5.04     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.00564  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.306    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 4.52e+04 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 269      |\n",
      "|    total_trades       | 1473     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -4.55    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.018   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 6.61     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 5.16e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 1506     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.306    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -6.94    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.0263   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 5.15e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 1644     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 6.41     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.00608 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 8.49     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "day: 1005, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1858794.96\n",
      "total_reward: 1358794.96\n",
      "total_cost: 57154.15\n",
      "total_trades: 1713\n",
      "Sharpe: 1.176\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.86e+06 |\n",
      "|    total_cost         | 5.72e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 272      |\n",
      "|    total_trades       | 1713     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.128   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 2.81e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 104      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.14e+06 |\n",
      "|    total_cost         | 4.23e+04 |\n",
      "|    total_reward       | 1.64e+06 |\n",
      "|    total_reward_pct   | 327      |\n",
      "|    total_trades       | 1623     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.249   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0281  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 4.26     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 2.88e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 1559     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0549  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -28      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 71.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.0238   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 18.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 43       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 3.05e+04 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 275      |\n",
      "|    total_trades       | 1450     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 5.82     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0.075    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -1.61    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 3.87e+04 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 1355     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.0149   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -13.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 24.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.89     |\n",
      "|    explained_variance | -0.000995 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 10.8      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "day: 1005, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1864081.94\n",
      "total_reward: 1364081.94\n",
      "total_cost: 25299.34\n",
      "total_trades: 1166\n",
      "Sharpe: 1.173\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.86e+06 |\n",
      "|    total_cost         | 2.53e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 273      |\n",
      "|    total_trades       | 1166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -26.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 48.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.697   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 2.53     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 2.73e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 1187     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.000144 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 7.63     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -3.26    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.91e+06 |\n",
      "|    total_cost         | 1.55e+04 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 282      |\n",
      "|    total_trades       | 1136     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.24     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.233    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.89     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -0.391    |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.301     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 2.58e+04 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 1093     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -3.57    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -8.51    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 18.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 3.67e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 1106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0119  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.181    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.388    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.00491  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 13.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 37       |\n",
      "------------------------------------\n",
      "day: 1005, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1899208.22\n",
      "total_reward: 1399208.22\n",
      "total_cost: 16976.18\n",
      "total_trades: 1121\n",
      "Sharpe: 1.186\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 280      |\n",
      "|    total_trades       | 1121     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.375   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 6.97     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.035   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.33     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.473    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.85e+06 |\n",
      "|    total_cost         | 3.27e+04 |\n",
      "|    total_reward       | 1.35e+06 |\n",
      "|    total_reward_pct   | 271      |\n",
      "|    total_trades       | 1166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | -1.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -7.68    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.91     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.86     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 8.3       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.88e+06 |\n",
      "|    total_cost         | 2.11e+04 |\n",
      "|    total_reward       | 1.38e+06 |\n",
      "|    total_reward_pct   | 275      |\n",
      "|    total_trades       | 1090     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 6.69     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 32.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 150      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.88e+06 |\n",
      "|    total_cost         | 2.65e+04 |\n",
      "|    total_reward       | 1.38e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 1025     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0125  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0166  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.86e+06 |\n",
      "|    total_cost         | 3.62e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 272      |\n",
      "|    total_trades       | 1028     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.406   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0.634   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 1.68     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.727    |\n",
      "------------------------------------\n",
      "day: 1005, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1870874.92\n",
      "total_reward: 1370874.92\n",
      "total_cost: 32375.52\n",
      "total_trades: 1024\n",
      "Sharpe: 1.177\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 3.24e+04 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 274      |\n",
      "|    total_trades       | 1024     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.424   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 2.59     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.0669  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 4.69     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.83e+06 |\n",
      "|    total_cost         | 3.86e+04 |\n",
      "|    total_reward       | 1.33e+06 |\n",
      "|    total_reward_pct   | 266      |\n",
      "|    total_trades       | 1004     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.234    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 4.73     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -3.48    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.09e+06 |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 1.59e+06 |\n",
      "|    total_reward_pct   | 317      |\n",
      "|    total_trades       | 1003     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -3.05    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -5.74    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 3.94e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1004     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.543   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.89     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.437    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.9      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | 1.31      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.909     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 2.26e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | -0.0699  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 3.12     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 7.56     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 9.41     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1921470.89\n",
      "total_reward: 1421470.89\n",
      "total_cost: 3672.32\n",
      "total_trades: 1004\n",
      "Sharpe: 1.195\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 3.67e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1004     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | -0.0324  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 11.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -2.53    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 5.9e+03  |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0.414    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -11.2    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 6.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | -0.0153  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 0.919    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 6.16e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 283      |\n",
      "|    total_trades       | 1004     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.828   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 4.4e+03  |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | -1.49    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -3.87    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | -0.0254  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -9.43    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 2.36e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1008     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0.0109   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 10.5     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 20.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 4.08     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.56     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1925107.11\n",
      "total_reward: 1425107.11\n",
      "total_cost: 3349.47\n",
      "total_trades: 1015\n",
      "Sharpe: 1.196\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 3.35e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1015     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | -0.37    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 5.84     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 9.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 2.78e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1006     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0.445    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -1.19    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.231    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 1.01e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -3.01    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 1.32     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.536    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.93e+06  |\n",
      "|    total_cost         | 1.65e+03  |\n",
      "|    total_reward       | 1.43e+06  |\n",
      "|    total_reward_pct   | 285       |\n",
      "|    total_trades       | 1014      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.94     |\n",
      "|    explained_variance | -7.15e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 0.857     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.396     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 2.16e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1010     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | -0.379   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.0879  |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 1.04     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.623    |\n",
      "------------------------------------\n",
      "day: 1005, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1926360.33\n",
      "total_reward: 1426360.33\n",
      "total_cost: 2686.55\n",
      "total_trades: 1007\n",
      "Sharpe: 1.196\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 2.69e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1007     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -1.04    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0.342    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 3.11     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 3.02e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | -0.344   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.0602   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.211    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 1.2e+03  |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1015     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -2.79    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.602    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.593    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.94e+06  |\n",
      "|    total_cost         | 2.79e+03  |\n",
      "|    total_reward       | 1.44e+06  |\n",
      "|    total_reward_pct   | 287       |\n",
      "|    total_trades       | 1028      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.95     |\n",
      "|    explained_variance | -1.55e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 4.1       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 3.8      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 7.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.5e+06  |\n",
      "|    total_cost         | 4.45e+03 |\n",
      "|    total_reward       | 2e+06    |\n",
      "|    total_reward_pct   | 400      |\n",
      "|    total_trades       | 1033     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | -0.0618  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -0.35    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 6.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 0.273    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.197    |\n",
      "------------------------------------\n",
      "day: 1005, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1925188.77\n",
      "total_reward: 1425188.77\n",
      "total_cost: 2776.83\n",
      "total_trades: 1046\n",
      "Sharpe: 1.196\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 2.78e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1046     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 0.496    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.425    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.396    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 4.56e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1023     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.532    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 0.0272    |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.83      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 4.22e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1068     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.791    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.137    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 8.59     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 7.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 286      |\n",
      "|    total_trades       | 1076     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | -0.765   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -5.81    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -6.75    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 6.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 8.04e+03 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 278      |\n",
      "|    total_trades       | 1212     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 0.212    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0981   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 0.226    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0342   |\n",
      "------------------------------------\n",
      "day: 1005, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1919217.66\n",
      "total_reward: 1419217.66\n",
      "total_cost: 4067.75\n",
      "total_trades: 1267\n",
      "Sharpe: 1.194\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 4.07e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.838    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -4.82    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.148   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.245    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 1.71e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1194     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.0664   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.255   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.305    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 1.3e+03  |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1264     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.894   |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.405    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 3.37     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 2.06e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1128     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -1.25    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 0.288    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.401    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -8.2     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 3.19e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1137     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.243    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 8.05     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 2.6      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1929416.11\n",
      "total_reward: 1429416.11\n",
      "total_cost: 2555.46\n",
      "total_trades: 1197\n",
      "Sharpe: 1.198\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 2.56e+03 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 286      |\n",
      "|    total_trades       | 1197     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | -6.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 6.75     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9.89     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -1.65     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.933     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.91e+06 |\n",
      "|    total_cost         | 8.45e+03 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 282      |\n",
      "|    total_trades       | 1202     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -2.63    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 4.13      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 7.95      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 4.96e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | -0.721   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -32.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 155      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -8.69    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 7.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 3.02e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1304     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 5.64     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | -0.182   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.00789  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -37.8    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 192      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 7.06e+03 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1414     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.596    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.00863  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -21.2    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 84.9     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1890998.04\n",
      "total_reward: 1390998.04\n",
      "total_cost: 10195.00\n",
      "total_trades: 1787\n",
      "Sharpe: 1.181\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 1.02e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 278      |\n",
      "|    total_trades       | 1787     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -0.0013  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 29.4     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 209      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.91e+06 |\n",
      "|    total_cost         | 9.79e+03 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 283      |\n",
      "|    total_trades       | 1783     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0.0018   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -43.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 187      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 1.6e+04  |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 280      |\n",
      "|    total_trades       | 1917     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.478   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 5.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -25.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 128      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.92e+06 |\n",
      "|    total_cost         | 2e+04    |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 284      |\n",
      "|    total_trades       | 1840     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 3.62     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -0.035   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 28.8     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 113      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.91e+06 |\n",
      "|    total_cost         | 3.12e+04 |\n",
      "|    total_reward       | 1.41e+06 |\n",
      "|    total_reward_pct   | 283      |\n",
      "|    total_trades       | 1958     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -10.7    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 26.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.0669  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 10.3     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 43.7     |\n",
      "------------------------------------\n",
      "day: 1005, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1885634.53\n",
      "total_reward: 1385634.53\n",
      "total_cost: 42321.69\n",
      "total_trades: 1967\n",
      "Sharpe: 1.188\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 4.23e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 277      |\n",
      "|    total_trades       | 1967     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.45     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 1.32     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.626    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.0473  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 15.2     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 57.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 3.68e+04 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 1957     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -0.886   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -7.52    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 5.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0.00112  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -19.1    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 76.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.85e+06 |\n",
      "|    total_cost         | 4.2e+04  |\n",
      "|    total_reward       | 1.35e+06 |\n",
      "|    total_reward_pct   | 271      |\n",
      "|    total_trades       | 1980     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.965   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 0.256    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.296    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -2.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 14.1     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 30.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.63e+06 |\n",
      "|    total_cost         | 2.69e+04 |\n",
      "|    total_reward       | 1.13e+06 |\n",
      "|    total_reward_pct   | 227      |\n",
      "|    total_trades       | 2002     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0.00304  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 4.37     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -1.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -19.7    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 49.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.66e+06 |\n",
      "|    total_cost         | 3.62e+04 |\n",
      "|    total_reward       | 1.16e+06 |\n",
      "|    total_reward_pct   | 233      |\n",
      "|    total_trades       | 2005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -4.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -2.66    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 6.05     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 7.5      |\n",
      "------------------------------------\n",
      "day: 1005, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1290893.81\n",
      "total_reward: 790893.81\n",
      "total_cost: 36201.89\n",
      "total_trades: 1996\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.29e+06 |\n",
      "|    total_cost         | 3.62e+04 |\n",
      "|    total_reward       | 7.91e+05 |\n",
      "|    total_reward_pct   | 158      |\n",
      "|    total_trades       | 1996     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.217    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -6.3     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.0826   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -4.92    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.53e+06 |\n",
      "|    total_cost         | 1.91e+04 |\n",
      "|    total_reward       | 1.03e+06 |\n",
      "|    total_reward_pct   | 206      |\n",
      "|    total_trades       | 2005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 0.393    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.352    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 5.33     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 2.06e+04 |\n",
      "|    total_reward       | 1.19e+06 |\n",
      "|    total_reward_pct   | 239      |\n",
      "|    total_trades       | 2003     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0.0966   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.456   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.231    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.0196   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -25.3    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 64       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.48e+06 |\n",
      "|    total_cost         | 2.25e+04 |\n",
      "|    total_reward       | 9.77e+05 |\n",
      "|    total_reward_pct   | 195      |\n",
      "|    total_trades       | 1998     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.361    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -0.138   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0412   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.95     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 0.618     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 13.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+06  |\n",
      "|    total_cost         | 3.13e+04 |\n",
      "|    total_reward       | 7e+05    |\n",
      "|    total_reward_pct   | 140      |\n",
      "|    total_trades       | 2004     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.0322   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -5.77    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.99     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-01-02 to  2019-04-03\n",
      "A2C Sharpe Ratio:  0.21289727962015897\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.03e+06 |\n",
      "|    total_cost       | 1.34e+05 |\n",
      "|    total_reward     | 5.35e+05 |\n",
      "|    total_reward_pct | 107      |\n",
      "|    total_trades     | 1959     |\n",
      "| time/               |          |\n",
      "|    fps              | 920      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 7.62e+05    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 1923        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 838         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003536325 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.06        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.59        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 967524.52\n",
      "total_reward: 467524.52\n",
      "total_cost: 126045.98\n",
      "total_trades: 1972\n",
      "Sharpe: 0.790\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+06    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 6.26e+05    |\n",
      "|    total_reward_pct     | 125         |\n",
      "|    total_trades         | 1996        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 817         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000763314 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.51        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.000654   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.41e+06     |\n",
      "|    total_cost           | 1.26e+05     |\n",
      "|    total_reward         | 9.09e+05     |\n",
      "|    total_reward_pct     | 182          |\n",
      "|    total_trades         | 1947         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 801          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024719457 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0379       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.01         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 9.22         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1325992.85\n",
      "total_reward: 825992.85\n",
      "total_cost: 130645.35\n",
      "total_trades: 1961\n",
      "Sharpe: 1.234\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.33e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 8.26e+05    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 1961        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 794         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002103492 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0633      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.97        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.65e+06   |\n",
      "|    total_cost           | 1.19e+05   |\n",
      "|    total_reward         | 1.15e+06   |\n",
      "|    total_reward_pct     | 230        |\n",
      "|    total_trades         | 1893       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 792        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00392489 |\n",
      "|    clip_fraction        | 0.0326     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.84      |\n",
      "|    explained_variance   | 0.0107     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.92       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.00445   |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.9e+06      |\n",
      "|    total_cost           | 1.07e+05     |\n",
      "|    total_reward         | 1.4e+06      |\n",
      "|    total_reward_pct     | 280          |\n",
      "|    total_trades         | 1917         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 789          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029922016 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0286       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1884731.77\n",
      "total_reward: 1384731.77\n",
      "total_cost: 106184.68\n",
      "total_trades: 1901\n",
      "Sharpe: 1.315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+06    |\n",
      "|    total_cost           | 1.07e+05    |\n",
      "|    total_reward         | 6.34e+05    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 1825        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008279088 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.6e+06     |\n",
      "|    total_cost           | 1.1e+05     |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 1824        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003745192 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1847369.89\n",
      "total_reward: 1347369.89\n",
      "total_cost: 99092.99\n",
      "total_trades: 1858\n",
      "Sharpe: 1.297\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+06    |\n",
      "|    total_cost           | 9.91e+04    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 1858        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 784         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005632966 |\n",
      "|    clip_fraction        | 0.00327     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 1.3e+06        |\n",
      "|    total_cost           | 9.72e+04       |\n",
      "|    total_reward         | 8.03e+05       |\n",
      "|    total_reward_pct     | 161            |\n",
      "|    total_trades         | 1913           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 783            |\n",
      "|    iterations           | 11             |\n",
      "|    time_elapsed         | 28             |\n",
      "|    total_timesteps      | 22528          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00038169988 |\n",
      "|    clip_fraction        | 0.00171        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | 0.162          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 17.8           |\n",
      "|    n_updates            | 100            |\n",
      "|    policy_gradient_loss | -0.00137       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 35.6           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.75e+06     |\n",
      "|    total_cost           | 1e+05        |\n",
      "|    total_reward         | 1.25e+06     |\n",
      "|    total_reward_pct     | 250          |\n",
      "|    total_trades         | 1800         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 781          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017109067 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1780528.61\n",
      "total_reward: 1280528.61\n",
      "total_cost: 99670.87\n",
      "total_trades: 1835\n",
      "Sharpe: 1.258\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.64e+06      |\n",
      "|    total_cost           | 9.01e+04      |\n",
      "|    total_reward         | 1.14e+06      |\n",
      "|    total_reward_pct     | 229           |\n",
      "|    total_trades         | 1780          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 781           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 34            |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087502954 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.139         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23            |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 40.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.81e+06     |\n",
      "|    total_cost           | 9.56e+04     |\n",
      "|    total_reward         | 1.31e+06     |\n",
      "|    total_reward_pct     | 262          |\n",
      "|    total_trades         | 1760         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 780          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051989835 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.175        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1563133.62\n",
      "total_reward: 1063133.62\n",
      "total_cost: 110405.92\n",
      "total_trades: 1769\n",
      "Sharpe: 1.154\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.56e+06     |\n",
      "|    total_cost           | 1.1e+05      |\n",
      "|    total_reward         | 1.06e+06     |\n",
      "|    total_reward_pct     | 213          |\n",
      "|    total_trades         | 1769         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 780          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033213082 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.74e+06     |\n",
      "|    total_cost           | 1.12e+05     |\n",
      "|    total_reward         | 1.24e+06     |\n",
      "|    total_reward_pct     | 248          |\n",
      "|    total_trades         | 1809         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 780          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033048522 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 1.93e+06       |\n",
      "|    total_cost           | 1.04e+05       |\n",
      "|    total_reward         | 1.43e+06       |\n",
      "|    total_reward_pct     | 286            |\n",
      "|    total_trades         | 1808           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 780            |\n",
      "|    iterations           | 17             |\n",
      "|    time_elapsed         | 44             |\n",
      "|    total_timesteps      | 34816          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.4729292e-05 |\n",
      "|    clip_fraction        | 0.0148         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | 0.294          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 15.5           |\n",
      "|    n_updates            | 160            |\n",
      "|    policy_gradient_loss | -0.00201       |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 27.6           |\n",
      "--------------------------------------------\n",
      "day: 1005, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1030074.78\n",
      "total_reward: 530074.78\n",
      "total_cost: 109353.32\n",
      "total_trades: 1805\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.77e+06     |\n",
      "|    total_cost           | 1.1e+05      |\n",
      "|    total_reward         | 1.27e+06     |\n",
      "|    total_reward_pct     | 253          |\n",
      "|    total_trades         | 1773         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 779          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051368726 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.124        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.28e+06    |\n",
      "|    total_cost           | 1.07e+05    |\n",
      "|    total_reward         | 7.76e+05    |\n",
      "|    total_reward_pct     | 155         |\n",
      "|    total_trades         | 1770        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 778         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005069767 |\n",
      "|    clip_fraction        | 0.00859     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1913636.80\n",
      "total_reward: 1413636.80\n",
      "total_cost: 95096.57\n",
      "total_trades: 1767\n",
      "Sharpe: 1.330\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.91e+06     |\n",
      "|    total_cost           | 9.51e+04     |\n",
      "|    total_reward         | 1.41e+06     |\n",
      "|    total_reward_pct     | 283          |\n",
      "|    total_trades         | 1767         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 777          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059085605 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.92         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.19e+06     |\n",
      "|    total_cost           | 1.07e+05     |\n",
      "|    total_reward         | 6.87e+05     |\n",
      "|    total_reward_pct     | 137          |\n",
      "|    total_trades         | 1776         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 776          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067475582 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.51e+06    |\n",
      "|    total_cost           | 1.09e+05    |\n",
      "|    total_reward         | 1.01e+06    |\n",
      "|    total_reward_pct     | 201         |\n",
      "|    total_trades         | 1738        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002147749 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1328208.28\n",
      "total_reward: 828208.28\n",
      "total_cost: 102618.78\n",
      "total_trades: 1776\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.79e+06     |\n",
      "|    total_cost           | 9.56e+04     |\n",
      "|    total_reward         | 1.29e+06     |\n",
      "|    total_reward_pct     | 258          |\n",
      "|    total_trades         | 1691         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 775          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052751126 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 9.44e+04    |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 315         |\n",
      "|    total_trades         | 1739        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001438102 |\n",
      "|    clip_fraction        | 0.00322     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1962626.32\n",
      "total_reward: 1462626.32\n",
      "total_cost: 91266.14\n",
      "total_trades: 1701\n",
      "Sharpe: 1.327\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.96e+06     |\n",
      "|    total_cost           | 9.13e+04     |\n",
      "|    total_reward         | 1.46e+06     |\n",
      "|    total_reward_pct     | 293          |\n",
      "|    total_trades         | 1701         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 775          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038743406 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000823    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.57e+06     |\n",
      "|    total_cost           | 1.04e+05     |\n",
      "|    total_reward         | 1.07e+06     |\n",
      "|    total_reward_pct     | 214          |\n",
      "|    total_trades         | 1748         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 774          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066603944 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.03e+06     |\n",
      "|    total_cost           | 1.07e+05     |\n",
      "|    total_reward         | 5.31e+05     |\n",
      "|    total_reward_pct     | 106          |\n",
      "|    total_trades         | 1789         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 774          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038399552 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.319        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1483717.85\n",
      "total_reward: 983717.85\n",
      "total_cost: 110256.22\n",
      "total_trades: 1772\n",
      "Sharpe: 1.147\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.68e+06     |\n",
      "|    total_cost           | 1.06e+05     |\n",
      "|    total_reward         | 1.18e+06     |\n",
      "|    total_reward_pct     | 235          |\n",
      "|    total_trades         | 1803         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047832434 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.48e+06   |\n",
      "|    total_cost           | 1.01e+05   |\n",
      "|    total_reward         | 9.83e+05   |\n",
      "|    total_reward_pct     | 197        |\n",
      "|    total_trades         | 1659       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 773        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01029751 |\n",
      "|    clip_fraction        | 0.0558     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.86      |\n",
      "|    explained_variance   | 0.25       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.9       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.00608   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 33         |\n",
      "----------------------------------------\n",
      "day: 1005, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1718822.40\n",
      "total_reward: 1218822.40\n",
      "total_cost: 94627.39\n",
      "total_trades: 1657\n",
      "Sharpe: 1.203\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+06    |\n",
      "|    total_cost           | 8.64e+04    |\n",
      "|    total_reward         | 1.53e+06    |\n",
      "|    total_reward_pct     | 307         |\n",
      "|    total_trades         | 1656        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 773         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008492821 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.000911   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.68e+06    |\n",
      "|    total_cost           | 8.78e+04    |\n",
      "|    total_reward         | 1.18e+06    |\n",
      "|    total_reward_pct     | 237         |\n",
      "|    total_trades         | 1665        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 773         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009672582 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.0832      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1537458.25\n",
      "total_reward: 1037458.25\n",
      "total_cost: 85586.72\n",
      "total_trades: 1684\n",
      "Sharpe: 1.056\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.54e+06     |\n",
      "|    total_cost           | 8.56e+04     |\n",
      "|    total_reward         | 1.04e+06     |\n",
      "|    total_reward_pct     | 207          |\n",
      "|    total_trades         | 1684         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032450273 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.42e+06     |\n",
      "|    total_cost           | 1.03e+05     |\n",
      "|    total_reward         | 9.16e+05     |\n",
      "|    total_reward_pct     | 183          |\n",
      "|    total_trades         | 1766         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040395977 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.12e+06     |\n",
      "|    total_cost           | 8.18e+04     |\n",
      "|    total_reward         | 1.62e+06     |\n",
      "|    total_reward_pct     | 325          |\n",
      "|    total_trades         | 1736         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049856566 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1901485.55\n",
      "total_reward: 1401485.55\n",
      "total_cost: 94811.73\n",
      "total_trades: 1724\n",
      "Sharpe: 1.307\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.87e+06     |\n",
      "|    total_cost           | 9.11e+04     |\n",
      "|    total_reward         | 1.37e+06     |\n",
      "|    total_reward_pct     | 274          |\n",
      "|    total_trades         | 1724         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058188923 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.0766       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.86e+06     |\n",
      "|    total_cost           | 1.04e+05     |\n",
      "|    total_reward         | 1.36e+06     |\n",
      "|    total_reward_pct     | 272          |\n",
      "|    total_trades         | 1782         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041558896 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1874892.91\n",
      "total_reward: 1374892.91\n",
      "total_cost: 99832.55\n",
      "total_trades: 1798\n",
      "Sharpe: 1.316\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.87e+06      |\n",
      "|    total_cost           | 9.98e+04      |\n",
      "|    total_reward         | 1.37e+06      |\n",
      "|    total_reward_pct     | 275           |\n",
      "|    total_trades         | 1798          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 773           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 97            |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019943365 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.88         |\n",
      "|    explained_variance   | 0.216         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.2          |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 37.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.84e+06     |\n",
      "|    total_cost           | 8.82e+04     |\n",
      "|    total_reward         | 1.34e+06     |\n",
      "|    total_reward_pct     | 269          |\n",
      "|    total_trades         | 1748         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035287128 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 43.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+06    |\n",
      "|    total_cost           | 9.33e+04    |\n",
      "|    total_reward         | 1.38e+06    |\n",
      "|    total_reward_pct     | 275         |\n",
      "|    total_trades         | 1766        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 773         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000592986 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1859546.27\n",
      "total_reward: 1359546.27\n",
      "total_cost: 86050.63\n",
      "total_trades: 1759\n",
      "Sharpe: 1.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.66e+06    |\n",
      "|    total_cost           | 7.81e+04    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 233         |\n",
      "|    total_trades         | 1749        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 773         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006675954 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+06    |\n",
      "|    total_cost           | 9.3e+04     |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 255         |\n",
      "|    total_trades         | 1772        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 773         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005232272 |\n",
      "|    clip_fraction        | 0.00825     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1550298.06\n",
      "total_reward: 1050298.06\n",
      "total_cost: 86090.88\n",
      "total_trades: 1763\n",
      "Sharpe: 1.068\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.55e+06     |\n",
      "|    total_cost           | 8.61e+04     |\n",
      "|    total_reward         | 1.05e+06     |\n",
      "|    total_reward_pct     | 210          |\n",
      "|    total_trades         | 1763         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075273784 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 2.18e+06       |\n",
      "|    total_cost           | 7.41e+04       |\n",
      "|    total_reward         | 1.68e+06       |\n",
      "|    total_reward_pct     | 337            |\n",
      "|    total_trades         | 1779           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 772            |\n",
      "|    iterations           | 43             |\n",
      "|    time_elapsed         | 113            |\n",
      "|    total_timesteps      | 88064          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00087189046 |\n",
      "|    clip_fraction        | 0.023          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.88          |\n",
      "|    explained_variance   | 0.31           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 19.1           |\n",
      "|    n_updates            | 420            |\n",
      "|    policy_gradient_loss | -0.00289       |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 36.2           |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+06    |\n",
      "|    total_cost           | 7.11e+04    |\n",
      "|    total_reward         | 1.45e+06    |\n",
      "|    total_reward_pct     | 289         |\n",
      "|    total_trades         | 1746        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 772         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004830905 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "day: 1005, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1962935.88\n",
      "total_reward: 1462935.88\n",
      "total_cost: 72681.22\n",
      "total_trades: 1775\n",
      "Sharpe: 1.331\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.66e+06     |\n",
      "|    total_cost           | 6.51e+04     |\n",
      "|    total_reward         | 1.16e+06     |\n",
      "|    total_reward_pct     | 232          |\n",
      "|    total_trades         | 1730         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 772          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051265405 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.58e+06     |\n",
      "|    total_cost           | 7.58e+04     |\n",
      "|    total_reward         | 1.08e+06     |\n",
      "|    total_reward_pct     | 215          |\n",
      "|    total_trades         | 1819         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 772          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046066004 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "day: 1005, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1916326.64\n",
      "total_reward: 1416326.64\n",
      "total_cost: 63659.89\n",
      "total_trades: 1741\n",
      "Sharpe: 1.260\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+06    |\n",
      "|    total_cost           | 6.37e+04    |\n",
      "|    total_reward         | 1.42e+06    |\n",
      "|    total_reward_pct     | 283         |\n",
      "|    total_trades         | 1741        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 772         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006512303 |\n",
      "|    clip_fraction        | 0.00425     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.08e+06     |\n",
      "|    total_cost           | 5.55e+04     |\n",
      "|    total_reward         | 1.58e+06     |\n",
      "|    total_reward_pct     | 317          |\n",
      "|    total_trades         | 1724         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 772          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019454609 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.72e+06     |\n",
      "|    total_cost           | 5.77e+04     |\n",
      "|    total_reward         | 1.22e+06     |\n",
      "|    total_reward_pct     | 245          |\n",
      "|    total_trades         | 1695         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 773          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042057503 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2019-01-02 to  2019-04-03\n",
      "PPO Sharpe Ratio:  0.2370237690435267\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0.], sigma=[0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total timesteps  | 4024     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -55.2    |\n",
      "|    critic_loss      | 2.2e+03  |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3018     |\n",
      "----------------------------------\n",
      "day: 1005, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 136      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total timesteps  | 8048     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -283     |\n",
      "|    critic_loss      | 232      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7042     |\n",
      "----------------------------------\n",
      "day: 1005, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total timesteps  | 12072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -315     |\n",
      "|    critic_loss      | 175      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11066    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.49e+05 |\n",
      "|    total_cost       | 7.84e+03 |\n",
      "|    total_reward     | 2.49e+05 |\n",
      "|    total_reward_pct | 49.9     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 127      |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total timesteps  | 16096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -312     |\n",
      "|    critic_loss      | 180      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15090    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 753598.57\n",
      "total_reward: 253598.57\n",
      "total_cost: 948.19\n",
      "total_trades: 1005\n",
      "Sharpe: 0.453\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.54e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.54e+05 |\n",
      "|    total_reward_pct | 50.7     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 126      |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total timesteps  | 20120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -246     |\n",
      "|    critic_loss      | 132      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19114    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.63e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.63e+05 |\n",
      "|    total_reward_pct | 52.6     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 125      |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total timesteps  | 24144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -203     |\n",
      "|    critic_loss      | 103      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 23138    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 753672.56\n",
      "total_reward: 253672.56\n",
      "total_cost: 948.17\n",
      "total_trades: 1005\n",
      "Sharpe: 0.453\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.64e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.64e+05 |\n",
      "|    total_reward_pct | 52.7     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total timesteps  | 28168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -168     |\n",
      "|    critic_loss      | 72.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27162    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 760670.68\n",
      "total_reward: 260670.68\n",
      "total_cost: 948.15\n",
      "total_trades: 1005\n",
      "Sharpe: 0.458\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.59e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.59e+05 |\n",
      "|    total_reward_pct | 51.9     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total timesteps  | 32192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -137     |\n",
      "|    critic_loss      | 69.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31186    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 763044.48\n",
      "total_reward: 263044.48\n",
      "total_cost: 948.20\n",
      "total_trades: 1005\n",
      "Sharpe: 0.460\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.61e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.61e+05 |\n",
      "|    total_reward_pct | 52.2     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total timesteps  | 36216    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -110     |\n",
      "|    critic_loss      | 53.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35210    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 757854.93\n",
      "total_reward: 257854.93\n",
      "total_cost: 948.19\n",
      "total_trades: 1005\n",
      "Sharpe: 0.456\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.58e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.58e+05 |\n",
      "|    total_reward_pct | 51.6     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total timesteps  | 40240    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -89.6    |\n",
      "|    critic_loss      | 53.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39234    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.63e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.63e+05 |\n",
      "|    total_reward_pct | 52.6     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 122      |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total timesteps  | 44264    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -70.7    |\n",
      "|    critic_loss      | 39.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43258    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 759927.09\n",
      "total_reward: 259927.09\n",
      "total_cost: 948.18\n",
      "total_trades: 1005\n",
      "Sharpe: 0.458\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.64e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 2.64e+05 |\n",
      "|    total_reward_pct | 52.7     |\n",
      "|    total_trades     | 1005     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 396      |\n",
      "|    total timesteps  | 48288    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -56.7    |\n",
      "|    critic_loss      | 27.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47282    |\n",
      "----------------------------------\n",
      "day: 1005, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 763178.37\n",
      "total_reward: 263178.37\n",
      "total_cost: 948.20\n",
      "total_trades: 1005\n",
      "Sharpe: 0.460\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-02 to  2019-04-03\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-04-03\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_126_2\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.02e+06 |\n",
      "|    total_cost       | 1.49e+05 |\n",
      "|    total_reward     | 5.19e+05 |\n",
      "|    total_reward_pct | 104      |\n",
      "|    total_trades     | 2079     |\n",
      "| time/               |          |\n",
      "|    fps              | 877      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.56e+06     |\n",
      "|    total_cost           | 1.48e+05     |\n",
      "|    total_reward         | 1.06e+06     |\n",
      "|    total_reward_pct     | 213          |\n",
      "|    total_trades         | 2100         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 818          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056976634 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.00484     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.96         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 4.27         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1292374.28\n",
      "total_reward: 792374.28\n",
      "total_cost: 147147.29\n",
      "total_trades: 2069\n",
      "Sharpe: 1.220\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.29e+06      |\n",
      "|    total_cost           | 1.47e+05      |\n",
      "|    total_reward         | 7.92e+05      |\n",
      "|    total_reward_pct     | 158           |\n",
      "|    total_trades         | 2069          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 798           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0010648457 |\n",
      "|    clip_fraction        | 0.00479       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -0.0198       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.88          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    std                  | 0.993         |\n",
      "|    value_loss           | 10.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.81e+06      |\n",
      "|    total_cost           | 1.44e+05      |\n",
      "|    total_reward         | 1.31e+06      |\n",
      "|    total_reward_pct     | 261           |\n",
      "|    total_trades         | 2021          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 786           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018804835 |\n",
      "|    clip_fraction        | 0.0303        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.82         |\n",
      "|    explained_variance   | -0.00269      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.63          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00256      |\n",
      "|    std                  | 0.989         |\n",
      "|    value_loss           | 11.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.77e+06     |\n",
      "|    total_cost           | 1.27e+05     |\n",
      "|    total_reward         | 1.27e+06     |\n",
      "|    total_reward_pct     | 254          |\n",
      "|    total_trades         | 2004         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 782          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017880514 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.00948      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.93         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1996167.71\n",
      "total_reward: 1496167.71\n",
      "total_cost: 138170.80\n",
      "total_trades: 2021\n",
      "Sharpe: 1.312\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.32e+06    |\n",
      "|    total_cost           | 1.41e+05    |\n",
      "|    total_reward         | 8.19e+05    |\n",
      "|    total_reward_pct     | 164         |\n",
      "|    total_trades         | 2057        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 780         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007904208 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.00574     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.23e+06     |\n",
      "|    total_cost           | 1.44e+05     |\n",
      "|    total_reward         | 7.29e+05     |\n",
      "|    total_reward_pct     | 146          |\n",
      "|    total_trades         | 2095         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 778          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026337542 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0157       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1339494.56\n",
      "total_reward: 839494.56\n",
      "total_cost: 143842.95\n",
      "total_trades: 2120\n",
      "Sharpe: 1.072\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.34e+06     |\n",
      "|    total_cost           | 1.44e+05     |\n",
      "|    total_reward         | 8.39e+05     |\n",
      "|    total_reward_pct     | 168          |\n",
      "|    total_trades         | 2120         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 776          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014761698 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0183       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.16         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.25e+06     |\n",
      "|    total_cost           | 1.45e+05     |\n",
      "|    total_reward         | 7.55e+05     |\n",
      "|    total_reward_pct     | 151          |\n",
      "|    total_trades         | 2110         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 774          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021366398 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.00482      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.83         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.4e+06     |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 8.99e+05    |\n",
      "|    total_reward_pct     | 180         |\n",
      "|    total_trades         | 2090        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 771         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002623784 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.95        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1257654.58\n",
      "total_reward: 757654.58\n",
      "total_cost: 148666.48\n",
      "total_trades: 2087\n",
      "Sharpe: 1.213\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.99e+05    |\n",
      "|    total_cost           | 1.44e+05    |\n",
      "|    total_reward         | 3.99e+05    |\n",
      "|    total_reward_pct     | 79.9        |\n",
      "|    total_trades         | 2096        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 770         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003223281 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0524      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.26        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.23e+06    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | 7.34e+05    |\n",
      "|    total_reward_pct     | 147         |\n",
      "|    total_trades         | 2109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 768         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009536877 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+06    |\n",
      "|    total_cost           | 1.27e+05    |\n",
      "|    total_reward         | 6.61e+05    |\n",
      "|    total_reward_pct     | 132         |\n",
      "|    total_trades         | 2035        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 768         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006252473 |\n",
      "|    clip_fraction        | 0.0199      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.37        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1494924.28\n",
      "total_reward: 994924.28\n",
      "total_cost: 115634.60\n",
      "total_trades: 2017\n",
      "Sharpe: 1.023\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.67e+06    |\n",
      "|    total_cost           | 1.07e+05    |\n",
      "|    total_reward         | 1.17e+06    |\n",
      "|    total_reward_pct     | 234         |\n",
      "|    total_trades         | 2039        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 767         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005087002 |\n",
      "|    clip_fraction        | 0.00615     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0764      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.6         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 2.21e+06      |\n",
      "|    total_cost           | 1e+05         |\n",
      "|    total_reward         | 1.71e+06      |\n",
      "|    total_reward_pct     | 342           |\n",
      "|    total_trades         | 2010          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 766           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 40            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087225635 |\n",
      "|    clip_fraction        | 0.00254       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0295        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15            |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 23.6          |\n",
      "-------------------------------------------\n",
      "day: 1068, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1925193.63\n",
      "total_reward: 1425193.63\n",
      "total_cost: 117297.77\n",
      "total_trades: 2057\n",
      "Sharpe: 1.284\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.93e+06     |\n",
      "|    total_cost           | 1.17e+05     |\n",
      "|    total_reward         | 1.43e+06     |\n",
      "|    total_reward_pct     | 285          |\n",
      "|    total_trades         | 2057         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 765          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015540364 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.3e+06       |\n",
      "|    total_cost           | 1.18e+05      |\n",
      "|    total_reward         | 8e+05         |\n",
      "|    total_reward_pct     | 160           |\n",
      "|    total_trades         | 2059          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 765           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 45            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012139551 |\n",
      "|    clip_fraction        | 0.00273       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.85         |\n",
      "|    explained_variance   | 0.0156        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.7          |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 25.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.08e+05     |\n",
      "|    total_cost           | 1.19e+05     |\n",
      "|    total_reward         | 2.08e+05     |\n",
      "|    total_reward_pct     | 41.6         |\n",
      "|    total_trades         | 2068         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 765          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014719183 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0231       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1331892.28\n",
      "total_reward: 831892.28\n",
      "total_cost: 111058.75\n",
      "total_trades: 2046\n",
      "Sharpe: 0.912\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.75e+06    |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | 1.25e+06    |\n",
      "|    total_reward_pct     | 249         |\n",
      "|    total_trades         | 2077        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 765         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005298442 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0689      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.48        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 6.12e+05     |\n",
      "|    total_cost           | 1.04e+05     |\n",
      "|    total_reward         | 1.12e+05     |\n",
      "|    total_reward_pct     | 22.5         |\n",
      "|    total_trades         | 2019         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050369166 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0725       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.3          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 781146.89\n",
      "total_reward: 281146.89\n",
      "total_cost: 128232.45\n",
      "total_trades: 2074\n",
      "Sharpe: 0.566\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.81e+05     |\n",
      "|    total_cost           | 1.28e+05     |\n",
      "|    total_reward         | 2.81e+05     |\n",
      "|    total_reward_pct     | 56.2         |\n",
      "|    total_trades         | 2074         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019960469 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.213        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.97         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 6.39         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+06    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 6.86e+05    |\n",
      "|    total_reward_pct     | 137         |\n",
      "|    total_trades         | 2077        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 764         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002276766 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 5.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.74e+06    |\n",
      "|    total_cost           | 1.13e+05    |\n",
      "|    total_reward         | 1.24e+06    |\n",
      "|    total_reward_pct     | 249         |\n",
      "|    total_trades         | 2044        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 764         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002831859 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.44        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1709348.29\n",
      "total_reward: 1209348.29\n",
      "total_cost: 96112.53\n",
      "total_trades: 1965\n",
      "Sharpe: 1.235\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.71e+06     |\n",
      "|    total_cost           | 9.61e+04     |\n",
      "|    total_reward         | 1.21e+06     |\n",
      "|    total_reward_pct     | 242          |\n",
      "|    total_trades         | 1965         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072634667 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0622       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 7.67e+04    |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 314         |\n",
      "|    total_trades         | 1879        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 764         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005454599 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0929      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.07e+06    |\n",
      "|    total_cost           | 7.7e+04     |\n",
      "|    total_reward         | 1.57e+06    |\n",
      "|    total_reward_pct     | 313         |\n",
      "|    total_trades         | 1893        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 764         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000358382 |\n",
      "|    clip_fraction        | 0.00483     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2190325.49\n",
      "total_reward: 1690325.49\n",
      "total_cost: 73215.45\n",
      "total_trades: 1799\n",
      "Sharpe: 1.368\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.24e+06     |\n",
      "|    total_cost           | 7.28e+04     |\n",
      "|    total_reward         | 1.74e+06     |\n",
      "|    total_reward_pct     | 347          |\n",
      "|    total_trades         | 1910         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057453522 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0618       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.16e+06     |\n",
      "|    total_cost           | 6.54e+04     |\n",
      "|    total_reward         | 1.66e+06     |\n",
      "|    total_reward_pct     | 332          |\n",
      "|    total_trades         | 1849         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067249653 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0711       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2474194.25\n",
      "total_reward: 1974194.25\n",
      "total_cost: 58596.95\n",
      "total_trades: 1896\n",
      "Sharpe: 1.446\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.47e+06     |\n",
      "|    total_cost           | 5.86e+04     |\n",
      "|    total_reward         | 1.97e+06     |\n",
      "|    total_reward_pct     | 395          |\n",
      "|    total_trades         | 1896         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015983249 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0917       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.83e+06     |\n",
      "|    total_cost           | 5.99e+04     |\n",
      "|    total_reward         | 1.33e+06     |\n",
      "|    total_reward_pct     | 267          |\n",
      "|    total_trades         | 1851         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053938786 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 53.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.15e+06     |\n",
      "|    total_cost           | 7.59e+04     |\n",
      "|    total_reward         | 1.65e+06     |\n",
      "|    total_reward_pct     | 331          |\n",
      "|    total_trades         | 1902         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013155655 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1469905.50\n",
      "total_reward: 969905.50\n",
      "total_cost: 72044.86\n",
      "total_trades: 1921\n",
      "Sharpe: 0.969\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.96e+06     |\n",
      "|    total_cost           | 8.25e+04     |\n",
      "|    total_reward         | 1.46e+06     |\n",
      "|    total_reward_pct     | 291          |\n",
      "|    total_trades         | 1987         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023720094 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.115        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.9e+06      |\n",
      "|    total_cost           | 9.9e+04      |\n",
      "|    total_reward         | 1.4e+06      |\n",
      "|    total_reward_pct     | 281          |\n",
      "|    total_trades         | 1969         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036673052 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.47         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2091326.93\n",
      "total_reward: 1591326.93\n",
      "total_cost: 60254.79\n",
      "total_trades: 1887\n",
      "Sharpe: 1.276\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 6.03e+04    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 318         |\n",
      "|    total_trades         | 1887        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 763         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004360229 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.17e+06     |\n",
      "|    total_cost           | 7.55e+04     |\n",
      "|    total_reward         | 1.67e+06     |\n",
      "|    total_reward_pct     | 335          |\n",
      "|    total_trades         | 1903         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034837206 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.25e+06     |\n",
      "|    total_cost           | 7.63e+04     |\n",
      "|    total_reward         | 1.75e+06     |\n",
      "|    total_reward_pct     | 351          |\n",
      "|    total_trades         | 1939         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014165104 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1711026.46\n",
      "total_reward: 1211026.46\n",
      "total_cost: 61857.74\n",
      "total_trades: 1924\n",
      "Sharpe: 1.072\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.71e+06     |\n",
      "|    total_cost           | 6.19e+04     |\n",
      "|    total_reward         | 1.21e+06     |\n",
      "|    total_reward_pct     | 242          |\n",
      "|    total_trades         | 1924         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031122146 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.19e+06     |\n",
      "|    total_cost           | 7.82e+04     |\n",
      "|    total_reward         | 1.69e+06     |\n",
      "|    total_reward_pct     | 338          |\n",
      "|    total_trades         | 2007         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064860317 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.63e+06     |\n",
      "|    total_cost           | 7.11e+04     |\n",
      "|    total_reward         | 1.13e+06     |\n",
      "|    total_reward_pct     | 225          |\n",
      "|    total_trades         | 1976         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066079465 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2283853.57\n",
      "total_reward: 1783853.57\n",
      "total_cost: 76551.81\n",
      "total_trades: 1951\n",
      "Sharpe: 1.404\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.58e+06    |\n",
      "|    total_cost           | 1.01e+05    |\n",
      "|    total_reward         | 1.08e+06    |\n",
      "|    total_reward_pct     | 215         |\n",
      "|    total_trades         | 1975        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 763         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004677858 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+06    |\n",
      "|    total_cost           | 9.61e+04    |\n",
      "|    total_reward         | 1.59e+06    |\n",
      "|    total_reward_pct     | 317         |\n",
      "|    total_trades         | 2010        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 763         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003269215 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2600372.10\n",
      "total_reward: 2100372.10\n",
      "total_cost: 68404.58\n",
      "total_trades: 1930\n",
      "Sharpe: 1.481\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+06     |\n",
      "|    total_cost           | 6.84e+04    |\n",
      "|    total_reward         | 2.1e+06     |\n",
      "|    total_reward_pct     | 420         |\n",
      "|    total_trades         | 1930        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 764         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009770223 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+06    |\n",
      "|    total_cost           | 7.63e+04    |\n",
      "|    total_reward         | 1.99e+06    |\n",
      "|    total_reward_pct     | 399         |\n",
      "|    total_trades         | 2009        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 763         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004371959 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.73e+06     |\n",
      "|    total_cost           | 6.28e+04     |\n",
      "|    total_reward         | 1.23e+06     |\n",
      "|    total_reward_pct     | 245          |\n",
      "|    total_trades         | 1947         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020177641 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1484938.67\n",
      "total_reward: 984938.67\n",
      "total_cost: 75302.23\n",
      "total_trades: 1966\n",
      "Sharpe: 0.973\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.99e+06    |\n",
      "|    total_cost           | 8.4e+04     |\n",
      "|    total_reward         | 1.49e+06    |\n",
      "|    total_reward_pct     | 298         |\n",
      "|    total_trades         | 1969        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 763         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005451536 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.37e+06     |\n",
      "|    total_cost           | 7.04e+04     |\n",
      "|    total_reward         | 1.87e+06     |\n",
      "|    total_reward_pct     | 374          |\n",
      "|    total_trades         | 1998         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066370834 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2205470.39\n",
      "total_reward: 1705470.39\n",
      "total_cost: 68325.51\n",
      "total_trades: 2064\n",
      "Sharpe: 1.370\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+06    |\n",
      "|    total_cost           | 6.83e+04    |\n",
      "|    total_reward         | 1.71e+06    |\n",
      "|    total_reward_pct     | 341         |\n",
      "|    total_trades         | 2064        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 763         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009337916 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.48e+06     |\n",
      "|    total_cost           | 9.24e+04     |\n",
      "|    total_reward         | 1.98e+06     |\n",
      "|    total_reward_pct     | 395          |\n",
      "|    total_trades         | 2042         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054652197 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.98e+06     |\n",
      "|    total_cost           | 9.42e+04     |\n",
      "|    total_reward         | 1.48e+06     |\n",
      "|    total_reward_pct     | 296          |\n",
      "|    total_trades         | 2026         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 762          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019731796 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.142        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "======Trading from:  2019-04-03 to  2019-07-03\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  145.81027039194817\n",
      "======Model training from:  2000-01-01 to  2019-04-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.0228   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.242   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.738    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 530       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.85     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -15.9     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 46.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.25e+06 |\n",
      "|    total_cost         | 9.65e+04 |\n",
      "|    total_reward       | 1.75e+06 |\n",
      "|    total_reward_pct   | 351      |\n",
      "|    total_trades       | 1749     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.859    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -16.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 21.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.65e+06 |\n",
      "|    total_cost         | 1.43e+05 |\n",
      "|    total_reward       | 1.15e+06 |\n",
      "|    total_reward_pct   | 230      |\n",
      "|    total_trades       | 1923     |\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.00864  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.671    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.386    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 536       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.87     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 1.28      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.19      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.51e+06 |\n",
      "|    total_cost         | 1.46e+05 |\n",
      "|    total_reward       | 1.01e+06 |\n",
      "|    total_reward_pct   | 202      |\n",
      "|    total_trades       | 1822     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.54     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 532       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.87     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 5.2       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 6.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.34e+06 |\n",
      "|    total_cost         | 1.37e+05 |\n",
      "|    total_reward       | 8.36e+05 |\n",
      "|    total_reward_pct   | 167      |\n",
      "|    total_trades       | 1476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -3.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.215    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 4.79     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1599532.74\n",
      "total_reward: 1099532.74\n",
      "total_cost: 126547.37\n",
      "total_trades: 1545\n",
      "Sharpe: 1.080\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.6e+06  |\n",
      "|    total_cost         | 1.27e+05 |\n",
      "|    total_reward       | 1.1e+06  |\n",
      "|    total_reward_pct   | 220      |\n",
      "|    total_trades       | 1545     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.075    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -4.44    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.0574  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -5.39    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.63e+06 |\n",
      "|    total_cost         | 1.36e+05 |\n",
      "|    total_reward       | 1.13e+06 |\n",
      "|    total_reward_pct   | 226      |\n",
      "|    total_trades       | 1602     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.0807   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.345    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+06 |\n",
      "|    total_cost         | 1.47e+05 |\n",
      "|    total_reward       | 7.37e+05 |\n",
      "|    total_reward_pct   | 147      |\n",
      "|    total_trades       | 1805     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.461   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0464   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.276   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 5.5      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.0233  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 71.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.05e+06 |\n",
      "|    total_cost         | 1.41e+05 |\n",
      "|    total_reward       | 1.55e+06 |\n",
      "|    total_reward_pct   | 309      |\n",
      "|    total_trades       | 1771     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 2.63     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0.0227   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 5.52     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 1.49e+05 |\n",
      "|    total_reward       | 1.34e+06 |\n",
      "|    total_reward_pct   | 269      |\n",
      "|    total_trades       | 1491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | -0.0162  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -1.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | -0.0294  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -5.29    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.7      |\n",
      "------------------------------------\n",
      "day: 1068, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1896653.90\n",
      "total_reward: 1396653.90\n",
      "total_cost: 144823.04\n",
      "total_trades: 1555\n",
      "Sharpe: 1.328\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 1.45e+05 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 279      |\n",
      "|    total_trades       | 1555     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | -0.206   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -4.06    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0.0171   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -1.33    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.547    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 1.53e+05 |\n",
      "|    total_reward       | 5.57e+05 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 1534     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | 0.12     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -2.52    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.818    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.22e+06 |\n",
      "|    total_cost         | 1.55e+05 |\n",
      "|    total_reward       | 7.15e+05 |\n",
      "|    total_reward_pct   | 143      |\n",
      "|    total_trades       | 1408     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -2.69    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -4.33    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 1.43e+05 |\n",
      "|    total_reward       | 1.02e+06 |\n",
      "|    total_reward_pct   | 204      |\n",
      "|    total_trades       | 1288     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -1.99    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.547    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.479   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.35e+06 |\n",
      "|    total_cost         | 1.4e+05  |\n",
      "|    total_reward       | 8.47e+05 |\n",
      "|    total_reward_pct   | 169      |\n",
      "|    total_trades       | 1319     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.236    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.0109  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.716   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.011    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.83     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 15.5     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1696430.38\n",
      "total_reward: 1196430.38\n",
      "total_cost: 148617.62\n",
      "total_trades: 1541\n",
      "Sharpe: 1.062\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+06  |\n",
      "|    total_cost         | 1.49e+05 |\n",
      "|    total_reward       | 1.2e+06  |\n",
      "|    total_reward_pct   | 239      |\n",
      "|    total_trades       | 1541     |\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.0188   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -17.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 24.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.0121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -35      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 145      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.81e+06 |\n",
      "|    total_cost         | 1.35e+05 |\n",
      "|    total_reward       | 1.31e+06 |\n",
      "|    total_reward_pct   | 261      |\n",
      "|    total_trades       | 1592     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.00935 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.446    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.00487  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 47.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.69e+06 |\n",
      "|    total_cost         | 1.22e+05 |\n",
      "|    total_reward       | 2.19e+06 |\n",
      "|    total_reward_pct   | 438      |\n",
      "|    total_trades       | 1422     |\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.0976  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 5.28     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.00439  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 6.17     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.71e+06 |\n",
      "|    total_cost         | 1.38e+05 |\n",
      "|    total_reward       | 1.21e+06 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 1281     |\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.0278  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 21.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0.136    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.248    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+06 |\n",
      "|    total_cost         | 1.3e+05  |\n",
      "|    total_reward       | 8.75e+05 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 1275     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | -0.182   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -4.84    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.031    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -3.42    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.21     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1693257.96\n",
      "total_reward: 1193257.96\n",
      "total_cost: 140699.84\n",
      "total_trades: 1395\n",
      "Sharpe: 1.092\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 1.41e+05 |\n",
      "|    total_reward       | 1.19e+06 |\n",
      "|    total_reward_pct   | 239      |\n",
      "|    total_trades       | 1395     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0.247    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.63     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.813    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.0361  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -4.26    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.51e+06 |\n",
      "|    total_cost         | 1.42e+05 |\n",
      "|    total_reward       | 1.01e+06 |\n",
      "|    total_reward_pct   | 201      |\n",
      "|    total_trades       | 1168     |\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -4.79    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0582  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -1.67    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.603    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 8.7      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.23e+06 |\n",
      "|    total_cost         | 1.32e+05 |\n",
      "|    total_reward       | 1.73e+06 |\n",
      "|    total_reward_pct   | 345      |\n",
      "|    total_trades       | 1204     |\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0212  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 6.96     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0222  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -13.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 31.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+06  |\n",
      "|    total_cost         | 1.41e+05 |\n",
      "|    total_reward       | 1.2e+06  |\n",
      "|    total_reward_pct   | 239      |\n",
      "|    total_trades       | 1221     |\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -3.64    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | -0.00741 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 7.83     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 1.43e+05 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 297      |\n",
      "|    total_trades       | 1402     |\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0255  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.0116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.05     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1979067.48\n",
      "total_reward: 1479067.48\n",
      "total_cost: 143441.17\n",
      "total_trades: 1512\n",
      "Sharpe: 1.210\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 1.43e+05 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 296      |\n",
      "|    total_trades       | 1512     |\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | -0.0442  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -6.74    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0.00877  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 9.78     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.02e+06 |\n",
      "|    total_cost         | 1.3e+05  |\n",
      "|    total_reward       | 1.52e+06 |\n",
      "|    total_reward_pct   | 305      |\n",
      "|    total_trades       | 1429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.017    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.945   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.0515  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.378    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.66e+06 |\n",
      "|    total_cost         | 1.28e+05 |\n",
      "|    total_reward       | 1.16e+06 |\n",
      "|    total_reward_pct   | 232      |\n",
      "|    total_trades       | 1407     |\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0.00583  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 6.16     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | -0.00424 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 1.31e+05 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 295      |\n",
      "|    total_trades       | 1437     |\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.485    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0.0121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 5.99     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | 0.00318  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.936   |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 1.33e+05 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 278      |\n",
      "|    total_trades       | 1568     |\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0.042    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -2.56    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | -0.0388  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -0.151   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 4.43     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1591254.57\n",
      "total_reward: 1091254.57\n",
      "total_cost: 129424.89\n",
      "total_trades: 1670\n",
      "Sharpe: 1.010\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.59e+06 |\n",
      "|    total_cost         | 1.29e+05 |\n",
      "|    total_reward       | 1.09e+06 |\n",
      "|    total_reward_pct   | 218      |\n",
      "|    total_trades       | 1670     |\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -6.27    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 6.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | -0.0186  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 0.229    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.02e+06 |\n",
      "|    total_cost         | 1.16e+05 |\n",
      "|    total_reward       | 1.52e+06 |\n",
      "|    total_reward_pct   | 304      |\n",
      "|    total_trades       | 1509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | -0.154   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.766    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | -0.0857  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 2.85     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.4e+06  |\n",
      "|    total_cost         | 1.23e+05 |\n",
      "|    total_reward       | 9.02e+05 |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 1520     |\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0.000433 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 2.63     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0.00956  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 11.3     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 37.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.12e+06 |\n",
      "|    total_cost         | 1.21e+05 |\n",
      "|    total_reward       | 1.62e+06 |\n",
      "|    total_reward_pct   | 324      |\n",
      "|    total_trades       | 1646     |\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0.00993  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 0.434    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.422    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | -0.00936 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 5.39     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.82e+06 |\n",
      "|    total_cost         | 1.31e+05 |\n",
      "|    total_reward       | 1.32e+06 |\n",
      "|    total_reward_pct   | 265      |\n",
      "|    total_trades       | 1431     |\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0.195    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -2.36    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.849    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | -0.0383  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1358079.29\n",
      "total_reward: 858079.29\n",
      "total_cost: 135082.67\n",
      "total_trades: 1374\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.36e+06 |\n",
      "|    total_cost         | 1.35e+05 |\n",
      "|    total_reward       | 8.58e+05 |\n",
      "|    total_reward_pct   | 172      |\n",
      "|    total_trades       | 1374     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | -0.0269  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 4.41     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.0396   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.323    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.2e+06  |\n",
      "|    total_cost         | 1.29e+05 |\n",
      "|    total_reward       | 1.7e+06  |\n",
      "|    total_reward_pct   | 340      |\n",
      "|    total_trades       | 1505     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -1.4     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.232    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.0402   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 3.87     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.00221 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 15.5     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 51       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.42e+06 |\n",
      "|    total_cost         | 1.47e+05 |\n",
      "|    total_reward       | 9.2e+05  |\n",
      "|    total_reward_pct   | 184      |\n",
      "|    total_trades       | 1642     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -0.132   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 0.956    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.513    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 1.54e+05 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 273      |\n",
      "|    total_trades       | 1556     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -6.74    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 8.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | -0.0314  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.932   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.76e+06 |\n",
      "|    total_cost         | 1.53e+05 |\n",
      "|    total_reward       | 1.26e+06 |\n",
      "|    total_reward_pct   | 252      |\n",
      "|    total_trades       | 1891     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.0935   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 8.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.306   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 3.56     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 8.38     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2163365.14\n",
      "total_reward: 1663365.14\n",
      "total_cost: 136878.76\n",
      "total_trades: 2068\n",
      "Sharpe: 1.374\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.16e+06 |\n",
      "|    total_cost         | 1.37e+05 |\n",
      "|    total_reward       | 1.66e+06 |\n",
      "|    total_reward_pct   | 333      |\n",
      "|    total_trades       | 2068     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0.00335  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.353    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.384    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0.0253   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -8.18    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 7.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.66e+06 |\n",
      "|    total_cost         | 1.39e+05 |\n",
      "|    total_reward       | 1.16e+06 |\n",
      "|    total_reward_pct   | 231      |\n",
      "|    total_trades       | 1978     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | -0.00176 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 7.91     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.289   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -3.15    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2e+06    |\n",
      "|    total_cost         | 1.27e+05 |\n",
      "|    total_reward       | 1.5e+06  |\n",
      "|    total_reward_pct   | 299      |\n",
      "|    total_trades       | 1915     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.279   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.165    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0.0723   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -4.86    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 1.13e+05 |\n",
      "|    total_reward       | 1.25e+06 |\n",
      "|    total_reward_pct   | 250      |\n",
      "|    total_trades       | 2010     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.0836  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 0.134    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.078    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -4.84    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 5.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.0108  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -7.91    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 29       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.13e+06  |\n",
      "|    total_cost         | 7.32e+04  |\n",
      "|    total_reward       | 1.63e+06  |\n",
      "|    total_reward_pct   | 326       |\n",
      "|    total_trades       | 1808      |\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.99     |\n",
      "|    explained_variance | -0.000522 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -3.06     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.36      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | -0.00872 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -7.82    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1972300.96\n",
      "total_reward: 1472300.96\n",
      "total_cost: 78299.05\n",
      "total_trades: 1730\n",
      "Sharpe: 1.141\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.97e+06  |\n",
      "|    total_cost         | 7.83e+04  |\n",
      "|    total_reward       | 1.47e+06  |\n",
      "|    total_reward_pct   | 294       |\n",
      "|    total_trades       | 1730      |\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 0.508     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.159     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0.0193   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 18.4     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 44.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.94e+06 |\n",
      "|    total_cost         | 7.2e+04  |\n",
      "|    total_reward       | 1.44e+06 |\n",
      "|    total_reward_pct   | 288      |\n",
      "|    total_trades       | 1720     |\n",
      "| time/                 |          |\n",
      "|    fps                | 543      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | -0.0292  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 4.18     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0.0301   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -1.66    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 7.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 7.71e+04 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 295      |\n",
      "|    total_trades       | 1583     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -15.3    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 29.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0.00891  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.623    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.788    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.96e+06 |\n",
      "|    total_cost         | 8.09e+04 |\n",
      "|    total_reward       | 1.46e+06 |\n",
      "|    total_reward_pct   | 292      |\n",
      "|    total_trades       | 1615     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | -0.0656  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -3.89    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | -0.00134 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -8.77    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 7.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.25e+06 |\n",
      "|    total_cost         | 9.64e+04 |\n",
      "|    total_reward       | 1.75e+06 |\n",
      "|    total_reward_pct   | 350      |\n",
      "|    total_trades       | 1667     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | -0.0662  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -1.45    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.663    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0.00674  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 23.1     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1901928.52\n",
      "total_reward: 1401928.52\n",
      "total_cost: 97675.49\n",
      "total_trades: 1587\n",
      "Sharpe: 1.122\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 9.77e+04 |\n",
      "|    total_reward       | 1.4e+06  |\n",
      "|    total_reward_pct   | 280      |\n",
      "|    total_trades       | 1587     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | -0.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -4.9     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 3.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | 0.14     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.834   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.159    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | -0.141   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 1.24     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.885    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.59e+06 |\n",
      "|    total_cost         | 9.99e+04 |\n",
      "|    total_reward       | 2.09e+06 |\n",
      "|    total_reward_pct   | 418      |\n",
      "|    total_trades       | 1400     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | -0.00277 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 10.2     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | -0.0216  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -22.2    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 72.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2e+06    |\n",
      "|    total_cost         | 6.5e+04  |\n",
      "|    total_reward       | 1.5e+06  |\n",
      "|    total_reward_pct   | 300      |\n",
      "|    total_trades       | 1355     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | -1.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -1.27    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 14       |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 28.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.05e+06 |\n",
      "|    total_cost         | 4.15e+04 |\n",
      "|    total_reward       | 1.55e+06 |\n",
      "|    total_reward_pct   | 311      |\n",
      "|    total_trades       | 1278     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0.0203   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 1.16     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | 0.00512  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 11.4     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 69.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.93e+06 |\n",
      "|    total_cost         | 3.85e+04 |\n",
      "|    total_reward       | 2.43e+06 |\n",
      "|    total_reward_pct   | 485      |\n",
      "|    total_trades       | 1341     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | -0.0523  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 23.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0.0617   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 18.1     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 41.5     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2106783.97\n",
      "total_reward: 1606783.97\n",
      "total_cost: 16304.05\n",
      "total_trades: 1377\n",
      "Sharpe: 1.179\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 1.63e+04 |\n",
      "|    total_reward       | 1.61e+06 |\n",
      "|    total_reward_pct   | 321      |\n",
      "|    total_trades       | 1377     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 5.08     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 3.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | -0.164   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 3.29     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 2.25e+04 |\n",
      "|    total_reward       | 1.61e+06 |\n",
      "|    total_reward_pct   | 323      |\n",
      "|    total_trades       | 1386     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | -0.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 4.56     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | 7.75e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -5.67    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 1.24e+04 |\n",
      "|    total_reward       | 1.61e+06 |\n",
      "|    total_reward_pct   | 322      |\n",
      "|    total_trades       | 1370     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0.0105   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -1.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | -0.0404  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 2.58     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.621    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0.00217  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -2.23    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.11e+06  |\n",
      "|    total_cost         | 1.19e+04  |\n",
      "|    total_reward       | 1.61e+06  |\n",
      "|    total_reward_pct   | 322       |\n",
      "|    total_trades       | 1354      |\n",
      "| time/                 |           |\n",
      "|    fps                | 541       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.02     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -3.16     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.86      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0.000469 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 1.51     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 9.21     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.07e+06  |\n",
      "|    total_cost         | 2.19e+04  |\n",
      "|    total_reward       | 1.57e+06  |\n",
      "|    total_reward_pct   | 313       |\n",
      "|    total_trades       | 1508      |\n",
      "| time/                 |           |\n",
      "|    fps                | 541       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.02     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 0.779     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.639     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | -0.0412  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 31.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 59.8     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2049540.01\n",
      "total_reward: 1549540.01\n",
      "total_cost: 39653.19\n",
      "total_trades: 1774\n",
      "Sharpe: 1.161\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.05e+06  |\n",
      "|    total_cost         | 3.97e+04  |\n",
      "|    total_reward       | 1.55e+06  |\n",
      "|    total_reward_pct   | 310       |\n",
      "|    total_trades       | 1774      |\n",
      "| time/                 |           |\n",
      "|    fps                | 541       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 0.905     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.361     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.0006  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 5.53     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+06 |\n",
      "|    total_cost         | 3.27e+04 |\n",
      "|    total_reward       | 1.56e+06 |\n",
      "|    total_reward_pct   | 313      |\n",
      "|    total_trades       | 1700     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0.0382   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 5.8      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 5.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.0273  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 22.4     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 77.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.01e+06 |\n",
      "|    total_cost         | 4.23e+04 |\n",
      "|    total_reward       | 1.51e+06 |\n",
      "|    total_reward_pct   | 303      |\n",
      "|    total_trades       | 1592     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -0.139   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 4.93     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0.131    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 4.27     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.1e+06  |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | 1.6e+06  |\n",
      "|    total_reward_pct   | 320      |\n",
      "|    total_trades       | 1539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | -0.403   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -0.406   |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.222    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | -0.0269  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -21.3    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 37       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 1.06e+05 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 275      |\n",
      "|    total_trades       | 1826     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | -0.109   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 6.55     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | -0.308   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.697    |\n",
      "------------------------------------\n",
      "day: 1068, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1635779.24\n",
      "total_reward: 1135779.24\n",
      "total_cost: 155041.63\n",
      "total_trades: 1998\n",
      "Sharpe: 1.017\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.64e+06 |\n",
      "|    total_cost         | 1.55e+05 |\n",
      "|    total_reward       | 1.14e+06 |\n",
      "|    total_reward_pct   | 227      |\n",
      "|    total_trades       | 1998     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -2.48    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.649    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | -0.157   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 2.61     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | -0.0201  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 28.4     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 103      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.64e+06  |\n",
      "|    total_cost         | 1.55e+05  |\n",
      "|    total_reward       | 1.14e+06  |\n",
      "|    total_reward_pct   | 228       |\n",
      "|    total_trades       | 2004      |\n",
      "| time/                 |           |\n",
      "|    fps                | 541       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.04     |\n",
      "|    explained_variance | -0.000819 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 3.99      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.22      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 20.9     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 37.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 1.27e+05 |\n",
      "|    total_reward       | 1.25e+06 |\n",
      "|    total_reward_pct   | 250      |\n",
      "|    total_trades       | 1781     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | -0.0139  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -4.51    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | -0.666   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 6.39     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 7.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 1.15e+05 |\n",
      "|    total_reward       | 1.25e+06 |\n",
      "|    total_reward_pct   | 250      |\n",
      "|    total_trades       | 1615     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | 0.0262   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -4.76    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 3.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 5.23     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 8.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 1.29e+05 |\n",
      "|    total_reward       | 1.25e+06 |\n",
      "|    total_reward_pct   | 249      |\n",
      "|    total_trades       | 1487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -1.92    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.927    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | -0.0349  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -2.99    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.97     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1729957.83\n",
      "total_reward: 1229957.83\n",
      "total_cost: 126528.94\n",
      "total_trades: 1579\n",
      "Sharpe: 1.059\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.73e+06 |\n",
      "|    total_cost         | 1.27e+05 |\n",
      "|    total_reward       | 1.23e+06 |\n",
      "|    total_reward_pct   | 246      |\n",
      "|    total_trades       | 1579     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | 0.0155   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 6.9      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | 0.0154   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -2.5     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.74e+06 |\n",
      "|    total_cost         | 1.19e+05 |\n",
      "|    total_reward       | 1.24e+06 |\n",
      "|    total_reward_pct   | 248      |\n",
      "|    total_trades       | 1532     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | 0.0012   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.785    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | -0.258   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 2.91     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.949    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.71e+06 |\n",
      "|    total_cost         | 9.51e+04 |\n",
      "|    total_reward       | 1.21e+06 |\n",
      "|    total_reward_pct   | 242      |\n",
      "|    total_trades       | 1462     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | -0.958   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.108   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | 0.0387   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -8.74    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 7.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 31.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.87e+06 |\n",
      "|    total_cost         | 8.13e+04 |\n",
      "|    total_reward       | 1.37e+06 |\n",
      "|    total_reward_pct   | 274      |\n",
      "|    total_trades       | 1287     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | 0.0175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -1.73    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.412    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 9.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.82e+06 |\n",
      "|    total_cost         | 8.01e+04 |\n",
      "|    total_reward       | 1.32e+06 |\n",
      "|    total_reward_pct   | 264      |\n",
      "|    total_trades       | 1246     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0.12     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 1.24     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.259    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0.0117   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 12.2     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 33       |\n",
      "------------------------------------\n",
      "day: 1068, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1889910.03\n",
      "total_reward: 1389910.03\n",
      "total_cost: 92837.42\n",
      "total_trades: 1280\n",
      "Sharpe: 1.114\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 9.28e+04 |\n",
      "|    total_reward       | 1.39e+06 |\n",
      "|    total_reward_pct   | 278      |\n",
      "|    total_trades       | 1280     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | -0.222   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 2.24     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -12      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.83e+06 |\n",
      "|    total_cost         | 8.68e+04 |\n",
      "|    total_reward       | 1.33e+06 |\n",
      "|    total_reward_pct   | 266      |\n",
      "|    total_trades       | 1283     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | -0.181   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -2.33    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | 0.0645   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -3.08    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.9e+06   |\n",
      "|    total_cost         | 8.41e+04  |\n",
      "|    total_reward       | 1.4e+06   |\n",
      "|    total_reward_pct   | 279       |\n",
      "|    total_trades       | 1331      |\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.06     |\n",
      "|    explained_variance | -0.000681 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | -1.32     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.773     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | -0.139   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -6.28    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 4.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 5.07e+04 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 296      |\n",
      "|    total_trades       | 1263     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | -0.127   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -2       |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.637    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | -0.0328  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -15      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 15.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.08e+06 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 1.58e+06 |\n",
      "|    total_reward_pct   | 316      |\n",
      "|    total_trades       | 1137     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | 0.0464   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -2.65    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.351    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 0.0284   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 3.06     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2086149.71\n",
      "total_reward: 1586149.71\n",
      "total_cost: 15089.94\n",
      "total_trades: 1098\n",
      "Sharpe: 1.173\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.09e+06 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 1.59e+06 |\n",
      "|    total_reward_pct   | 317      |\n",
      "|    total_trades       | 1098     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 6.09     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 4.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.1     |\n",
      "|    explained_variance | 0.00859  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -36.6    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 174      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+06 |\n",
      "|    total_cost         | 3.58e+04 |\n",
      "|    total_reward       | 1.56e+06 |\n",
      "|    total_reward_pct   | 311      |\n",
      "|    total_trades       | 1079     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.1     |\n",
      "|    explained_variance | 0.0105   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.108    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00628  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.1     |\n",
      "|    explained_variance | 0.00446  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 33.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.04e+06 |\n",
      "|    total_cost         | 2.75e+04 |\n",
      "|    total_reward       | 1.54e+06 |\n",
      "|    total_reward_pct   | 307      |\n",
      "|    total_trades       | 1082     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.1     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -1.34    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 4.32e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 69.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.97e+06 |\n",
      "|    total_cost         | 4.39e+04 |\n",
      "|    total_reward       | 1.47e+06 |\n",
      "|    total_reward_pct   | 293      |\n",
      "|    total_trades       | 1076     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0.00185  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -4.08    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0.313    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 9.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 5.94e+04 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 285      |\n",
      "|    total_trades       | 1067     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | -0.218   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 5.39     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 4.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0.0522   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 2.27     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "day: 1068, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2035313.12\n",
      "total_reward: 1535313.12\n",
      "total_cost: 39748.69\n",
      "total_trades: 1064\n",
      "Sharpe: 1.160\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.04e+06 |\n",
      "|    total_cost         | 3.97e+04 |\n",
      "|    total_reward       | 1.54e+06 |\n",
      "|    total_reward_pct   | 307      |\n",
      "|    total_trades       | 1064     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 0.0452   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 1.7      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.561    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | -0.029   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -3.77    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.07e+06 |\n",
      "|    total_cost         | 2.2e+04  |\n",
      "|    total_reward       | 1.57e+06 |\n",
      "|    total_reward_pct   | 315      |\n",
      "|    total_trades       | 1065     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | 0.091    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -1.35    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.328    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.14    |\n",
      "|    explained_variance | -0.584   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -1.27    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.15     |\n",
      "|    explained_variance | -0.000395 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -2.38     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 18.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 2.03e+04 |\n",
      "|    total_reward       | 1.61e+06 |\n",
      "|    total_reward_pct   | 322      |\n",
      "|    total_trades       | 1065     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -1.43    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.496    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | -0.00193 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -16.1    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 62.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.09e+06 |\n",
      "|    total_cost         | 1.56e+04 |\n",
      "|    total_reward       | 1.59e+06 |\n",
      "|    total_reward_pct   | 318      |\n",
      "|    total_trades       | 1068     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 2.75     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.15     |\n",
      "|    explained_variance | -2.06e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 15.8      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 53.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.03e+06 |\n",
      "|    total_cost         | 3.66e+04 |\n",
      "|    total_reward       | 1.53e+06 |\n",
      "|    total_reward_pct   | 306      |\n",
      "|    total_trades       | 1068     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | -0.229   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 4.07     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.15     |\n",
      "|    explained_variance | -0.000525 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 3.67      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 2.36      |\n",
      "-------------------------------------\n",
      "day: 1068, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1934605.62\n",
      "total_reward: 1434605.62\n",
      "total_cost: 63331.00\n",
      "total_trades: 1091\n",
      "Sharpe: 1.126\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 6.33e+04 |\n",
      "|    total_reward       | 1.43e+06 |\n",
      "|    total_reward_pct   | 287      |\n",
      "|    total_trades       | 1091     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | -0.482   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 9.79     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.17     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 17.4      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 57.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.95e+06 |\n",
      "|    total_cost         | 6.23e+04 |\n",
      "|    total_reward       | 1.45e+06 |\n",
      "|    total_reward_pct   | 290      |\n",
      "|    total_trades       | 1074     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | 0.13     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 2.45     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.873    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 9.57e+03 |\n",
      "|    total_reward       | 1.61e+06 |\n",
      "|    total_reward_pct   | 322      |\n",
      "|    total_trades       | 1069     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -1.62    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.386    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.15     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | -9.6      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 8.92      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.13e+06  |\n",
      "|    total_cost         | 1.21e+03  |\n",
      "|    total_reward       | 1.63e+06  |\n",
      "|    total_reward_pct   | 327       |\n",
      "|    total_trades       | 1070      |\n",
      "| time/                 |           |\n",
      "|    fps                | 542       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.15     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 10.4      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 21.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 0.393    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.523    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-04-03 to  2019-07-03\n",
      "A2C Sharpe Ratio:  0.14189137154287\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_2\n",
      "day: 1068, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 941600.76\n",
      "total_reward: 441600.76\n",
      "total_cost: 143315.62\n",
      "total_trades: 2059\n",
      "Sharpe: 0.888\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.42e+05 |\n",
      "|    total_cost       | 1.43e+05 |\n",
      "|    total_reward     | 4.42e+05 |\n",
      "|    total_reward_pct | 88.3     |\n",
      "|    total_trades     | 2059     |\n",
      "| time/               |          |\n",
      "|    fps              | 903      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.49e+05     |\n",
      "|    total_cost           | 1.49e+05     |\n",
      "|    total_reward         | 2.49e+05     |\n",
      "|    total_reward_pct     | 49.9         |\n",
      "|    total_trades         | 2046         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 829          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043324563 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.0556      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.64e+06    |\n",
      "|    total_cost           | 1.35e+05    |\n",
      "|    total_reward         | 1.14e+06    |\n",
      "|    total_reward_pct     | 229         |\n",
      "|    total_trades         | 2097        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 801         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006332945 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1137261.09\n",
      "total_reward: 637261.09\n",
      "total_cost: 140339.74\n",
      "total_trades: 2102\n",
      "Sharpe: 0.941\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.7e+06      |\n",
      "|    total_cost           | 1.45e+05     |\n",
      "|    total_reward         | 1.2e+06      |\n",
      "|    total_reward_pct     | 239          |\n",
      "|    total_trades         | 2115         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 791          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.002296174 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0137       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.43         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.29e+06     |\n",
      "|    total_cost           | 1.26e+05     |\n",
      "|    total_reward         | 7.87e+05     |\n",
      "|    total_reward_pct     | 157          |\n",
      "|    total_trades         | 2113         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 783          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033933602 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0398       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.07         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1467954.24\n",
      "total_reward: 967954.24\n",
      "total_cost: 111129.70\n",
      "total_trades: 2098\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.47e+06     |\n",
      "|    total_cost           | 1.11e+05     |\n",
      "|    total_reward         | 9.68e+05     |\n",
      "|    total_reward_pct     | 194          |\n",
      "|    total_trades         | 2098         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 780          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012200342 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0233       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000573    |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+06    |\n",
      "|    total_cost           | 1.23e+05    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 270         |\n",
      "|    total_trades         | 2092        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005847673 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.91        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.6e+06     |\n",
      "|    total_cost           | 1.07e+05    |\n",
      "|    total_reward         | 1.1e+06     |\n",
      "|    total_reward_pct     | 220         |\n",
      "|    total_trades         | 2077        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 772         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007032656 |\n",
      "|    clip_fraction        | 0.00728     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2173710.67\n",
      "total_reward: 1673710.67\n",
      "total_cost: 109020.09\n",
      "total_trades: 2067\n",
      "Sharpe: 1.371\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.2e+06      |\n",
      "|    total_cost           | 1.11e+05     |\n",
      "|    total_reward         | 1.7e+06      |\n",
      "|    total_reward_pct     | 341          |\n",
      "|    total_trades         | 2069         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 771          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027773092 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.0012      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000975    |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.54e+06      |\n",
      "|    total_cost           | 1.05e+05      |\n",
      "|    total_reward         | 1.04e+06      |\n",
      "|    total_reward_pct     | 208           |\n",
      "|    total_trades         | 2041          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 771           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027680548 |\n",
      "|    clip_fraction        | 0.00391       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0.02          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.9          |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.00201      |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 43.4          |\n",
      "-------------------------------------------\n",
      "day: 1068, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2038900.32\n",
      "total_reward: 1538900.32\n",
      "total_cost: 104146.30\n",
      "total_trades: 2061\n",
      "Sharpe: 1.323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+06    |\n",
      "|    total_cost           | 1.04e+05    |\n",
      "|    total_reward         | 1.54e+06    |\n",
      "|    total_reward_pct     | 308         |\n",
      "|    total_trades         | 2061        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 769         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004562988 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+06    |\n",
      "|    total_cost           | 1.04e+05    |\n",
      "|    total_reward         | 1.35e+06    |\n",
      "|    total_reward_pct     | 269         |\n",
      "|    total_trades         | 2032        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 768         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005380791 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.78e+06     |\n",
      "|    total_cost           | 1.05e+05     |\n",
      "|    total_reward         | 1.28e+06     |\n",
      "|    total_reward_pct     | 256          |\n",
      "|    total_trades         | 1988         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 767          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036696834 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2275497.49\n",
      "total_reward: 1775497.49\n",
      "total_cost: 103573.87\n",
      "total_trades: 1956\n",
      "Sharpe: 1.396\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+06    |\n",
      "|    total_cost           | 1.04e+05    |\n",
      "|    total_reward         | 1.78e+06    |\n",
      "|    total_reward_pct     | 355         |\n",
      "|    total_trades         | 1956        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 765         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004578568 |\n",
      "|    clip_fraction        | 0.00547     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.73e+06    |\n",
      "|    total_cost           | 1.01e+05    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 246         |\n",
      "|    total_trades         | 1939        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 764         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006464024 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.21e+06   |\n",
      "|    total_cost           | 1.01e+05   |\n",
      "|    total_reward         | 1.71e+06   |\n",
      "|    total_reward_pct     | 342        |\n",
      "|    total_trades         | 2001       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 762        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00510917 |\n",
      "|    clip_fraction        | 0.055      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.85      |\n",
      "|    explained_variance   | 0.074      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.4       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.004     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 30.3       |\n",
      "----------------------------------------\n",
      "day: 1068, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1705409.88\n",
      "total_reward: 1205409.88\n",
      "total_cost: 101104.66\n",
      "total_trades: 1965\n",
      "Sharpe: 1.063\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.18e+06     |\n",
      "|    total_cost           | 1.01e+05     |\n",
      "|    total_reward         | 1.68e+06     |\n",
      "|    total_reward_pct     | 337          |\n",
      "|    total_trades         | 1963         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 760          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022078766 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+06    |\n",
      "|    total_cost           | 1e+05       |\n",
      "|    total_reward         | 1.27e+06    |\n",
      "|    total_reward_pct     | 254         |\n",
      "|    total_trades         | 1963        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 758         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010884594 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0779      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2022452.76\n",
      "total_reward: 1522452.76\n",
      "total_cost: 112902.09\n",
      "total_trades: 2035\n",
      "Sharpe: 1.353\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+06    |\n",
      "|    total_cost           | 1.13e+05    |\n",
      "|    total_reward         | 1.52e+06    |\n",
      "|    total_reward_pct     | 304         |\n",
      "|    total_trades         | 2035        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 756         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004931425 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0341      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 2.27e+06       |\n",
      "|    total_cost           | 1.19e+05       |\n",
      "|    total_reward         | 1.77e+06       |\n",
      "|    total_reward_pct     | 353            |\n",
      "|    total_trades         | 2010           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 755            |\n",
      "|    iterations           | 20             |\n",
      "|    time_elapsed         | 54             |\n",
      "|    total_timesteps      | 40960          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00017342018 |\n",
      "|    clip_fraction        | 0.0102         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.85          |\n",
      "|    explained_variance   | 0.0735         |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 12.9           |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.00306       |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 28.7           |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.65e+06    |\n",
      "|    total_cost           | 1.02e+05    |\n",
      "|    total_reward         | 1.15e+06    |\n",
      "|    total_reward_pct     | 229         |\n",
      "|    total_trades         | 2020        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 753         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009131404 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.00645     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1719243.29\n",
      "total_reward: 1219243.29\n",
      "total_cost: 105332.21\n",
      "total_trades: 2042\n",
      "Sharpe: 1.085\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.59e+06     |\n",
      "|    total_cost           | 9.74e+04     |\n",
      "|    total_reward         | 1.09e+06     |\n",
      "|    total_reward_pct     | 217          |\n",
      "|    total_trades         | 1965         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 752          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061211903 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.0438       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.94         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.32e+06     |\n",
      "|    total_cost           | 1.07e+05     |\n",
      "|    total_reward         | 8.21e+05     |\n",
      "|    total_reward_pct     | 164          |\n",
      "|    total_trades         | 2025         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 751          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056362385 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.0857       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.96e+06   |\n",
      "|    total_cost           | 9.46e+04   |\n",
      "|    total_reward         | 1.46e+06   |\n",
      "|    total_reward_pct     | 293        |\n",
      "|    total_trades         | 2030       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 750        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00909982 |\n",
      "|    clip_fraction        | 0.0294     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.86      |\n",
      "|    explained_variance   | 0.0939     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.9       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00249   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "day: 1068, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2474908.25\n",
      "total_reward: 1974908.25\n",
      "total_cost: 95963.78\n",
      "total_trades: 1971\n",
      "Sharpe: 1.458\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.63e+06   |\n",
      "|    total_cost           | 9.41e+04   |\n",
      "|    total_reward         | 1.13e+06   |\n",
      "|    total_reward_pct     | 226        |\n",
      "|    total_trades         | 1933       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 751        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00861676 |\n",
      "|    clip_fraction        | 0.0164     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.86      |\n",
      "|    explained_variance   | 0.0552     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.2       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00414   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 42.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+06    |\n",
      "|    total_cost           | 1.13e+05    |\n",
      "|    total_reward         | 1.94e+06    |\n",
      "|    total_reward_pct     | 389         |\n",
      "|    total_trades         | 1993        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 751         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009409484 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.0728      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.55        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1791291.24\n",
      "total_reward: 1291291.24\n",
      "total_cost: 122243.58\n",
      "total_trades: 2002\n",
      "Sharpe: 1.252\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.79e+06     |\n",
      "|    total_cost           | 1.22e+05     |\n",
      "|    total_reward         | 1.29e+06     |\n",
      "|    total_reward_pct     | 258          |\n",
      "|    total_trades         | 2002         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 751          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053345533 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.76e+06     |\n",
      "|    total_cost           | 1.29e+05     |\n",
      "|    total_reward         | 1.26e+06     |\n",
      "|    total_reward_pct     | 253          |\n",
      "|    total_trades         | 1974         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064102295 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.0699       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.29e+06     |\n",
      "|    total_cost           | 1.27e+05     |\n",
      "|    total_reward         | 7.89e+05     |\n",
      "|    total_reward_pct     | 158          |\n",
      "|    total_trades         | 1957         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018662801 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.0668       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1910991.02\n",
      "total_reward: 1410991.02\n",
      "total_cost: 116582.50\n",
      "total_trades: 1987\n",
      "Sharpe: 1.225\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.72e+06    |\n",
      "|    total_cost           | 1.23e+05    |\n",
      "|    total_reward         | 1.22e+06    |\n",
      "|    total_reward_pct     | 244         |\n",
      "|    total_trades         | 1929        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 751         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008882024 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.0864      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.74        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.76e+06    |\n",
      "|    total_cost           | 1.1e+05     |\n",
      "|    total_reward         | 1.26e+06    |\n",
      "|    total_reward_pct     | 253         |\n",
      "|    total_trades         | 1877        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 751         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013892459 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0892      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "day: 1068, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1882008.17\n",
      "total_reward: 1382008.17\n",
      "total_cost: 124553.89\n",
      "total_trades: 1899\n",
      "Sharpe: 1.235\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.88e+06      |\n",
      "|    total_cost           | 1.25e+05      |\n",
      "|    total_reward         | 1.38e+06      |\n",
      "|    total_reward_pct     | 276           |\n",
      "|    total_trades         | 1899          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 751           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 87            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035029178 |\n",
      "|    clip_fraction        | 0.0294        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.86         |\n",
      "|    explained_variance   | 0.147         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.3          |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.00437      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 22.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.26e+06    |\n",
      "|    total_cost           | 1.03e+05    |\n",
      "|    total_reward         | 1.76e+06    |\n",
      "|    total_reward_pct     | 353         |\n",
      "|    total_trades         | 1951        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 751         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005348928 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.05e+06     |\n",
      "|    total_cost           | 1.02e+05     |\n",
      "|    total_reward         | 1.55e+06     |\n",
      "|    total_reward_pct     | 309          |\n",
      "|    total_trades         | 1885         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 751          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048088026 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.0788       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2326135.08\n",
      "total_reward: 1826135.08\n",
      "total_cost: 86921.69\n",
      "total_trades: 1875\n",
      "Sharpe: 1.404\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 2.38e+06      |\n",
      "|    total_cost           | 8.65e+04      |\n",
      "|    total_reward         | 1.88e+06      |\n",
      "|    total_reward_pct     | 377           |\n",
      "|    total_trades         | 1889          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 751           |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 95            |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0001700637 |\n",
      "|    clip_fraction        | 0.0084        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.87         |\n",
      "|    explained_variance   | 0.0808        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.4          |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.00137      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 30.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.56e+06    |\n",
      "|    total_cost           | 9.84e+04    |\n",
      "|    total_reward         | 1.06e+06    |\n",
      "|    total_reward_pct     | 211         |\n",
      "|    total_trades         | 1945        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 751         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005082451 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.0743      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.67e+06     |\n",
      "|    total_cost           | 1.02e+05     |\n",
      "|    total_reward         | 1.17e+06     |\n",
      "|    total_reward_pct     | 234          |\n",
      "|    total_trades         | 1953         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 751          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065969517 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2125147.67\n",
      "total_reward: 1625147.67\n",
      "total_cost: 94442.27\n",
      "total_trades: 1932\n",
      "Sharpe: 1.315\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.98e+06     |\n",
      "|    total_cost           | 1.06e+05     |\n",
      "|    total_reward         | 1.48e+06     |\n",
      "|    total_reward_pct     | 295          |\n",
      "|    total_trades         | 1958         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 751          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031786326 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.83e+06   |\n",
      "|    total_cost           | 9.39e+04   |\n",
      "|    total_reward         | 1.33e+06   |\n",
      "|    total_reward_pct     | 265        |\n",
      "|    total_trades         | 1911       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 752        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00440871 |\n",
      "|    clip_fraction        | 0.00898    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.86      |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.7       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00299   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 35.1       |\n",
      "----------------------------------------\n",
      "day: 1068, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1647853.16\n",
      "total_reward: 1147853.16\n",
      "total_cost: 94842.66\n",
      "total_trades: 1928\n",
      "Sharpe: 1.038\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.65e+06     |\n",
      "|    total_cost           | 9.48e+04     |\n",
      "|    total_reward         | 1.15e+06     |\n",
      "|    total_reward_pct     | 230          |\n",
      "|    total_trades         | 1928         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 752          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019719442 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.98e+06     |\n",
      "|    total_cost           | 9.03e+04     |\n",
      "|    total_reward         | 1.48e+06     |\n",
      "|    total_reward_pct     | 295          |\n",
      "|    total_trades         | 1969         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 752          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039537204 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.81e+06     |\n",
      "|    total_cost           | 9.19e+04     |\n",
      "|    total_reward         | 1.31e+06     |\n",
      "|    total_reward_pct     | 262          |\n",
      "|    total_trades         | 1893         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 752          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028682086 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1969514.51\n",
      "total_reward: 1469514.51\n",
      "total_cost: 97112.24\n",
      "total_trades: 1902\n",
      "Sharpe: 1.181\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.66e+06    |\n",
      "|    total_cost           | 9.89e+04    |\n",
      "|    total_reward         | 1.16e+06    |\n",
      "|    total_reward_pct     | 232         |\n",
      "|    total_trades         | 1931        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 752         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005857179 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.05e+06     |\n",
      "|    total_cost           | 9.63e+04     |\n",
      "|    total_reward         | 1.55e+06     |\n",
      "|    total_reward_pct     | 309          |\n",
      "|    total_trades         | 1872         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 753          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010684547 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1676717.10\n",
      "total_reward: 1176717.10\n",
      "total_cost: 110152.56\n",
      "total_trades: 1854\n",
      "Sharpe: 1.079\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.68e+06      |\n",
      "|    total_cost           | 1.1e+05       |\n",
      "|    total_reward         | 1.18e+06      |\n",
      "|    total_reward_pct     | 235           |\n",
      "|    total_trades         | 1854          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 753           |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 122           |\n",
      "|    total_timesteps      | 92160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0006154817 |\n",
      "|    clip_fraction        | 0.0187        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.86         |\n",
      "|    explained_variance   | 0.207         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.6          |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.00354      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 30.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.43e+06     |\n",
      "|    total_cost           | 1.02e+05     |\n",
      "|    total_reward         | 1.93e+06     |\n",
      "|    total_reward_pct     | 386          |\n",
      "|    total_trades         | 1871         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 753          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011289283 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.46e+06     |\n",
      "|    total_cost           | 8.81e+04     |\n",
      "|    total_reward         | 1.96e+06     |\n",
      "|    total_reward_pct     | 392          |\n",
      "|    total_trades         | 1868         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 753          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037006899 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "day: 1068, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2264051.25\n",
      "total_reward: 1764051.25\n",
      "total_cost: 91224.77\n",
      "total_trades: 1922\n",
      "Sharpe: 1.376\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.26e+06     |\n",
      "|    total_cost           | 9.12e+04     |\n",
      "|    total_reward         | 1.76e+06     |\n",
      "|    total_reward_pct     | 353          |\n",
      "|    total_trades         | 1922         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 753          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010246078 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.95e+06     |\n",
      "|    total_cost           | 9.69e+04     |\n",
      "|    total_reward         | 1.45e+06     |\n",
      "|    total_reward_pct     | 291          |\n",
      "|    total_trades         | 1820         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 753          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032766405 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2019-04-03 to  2019-07-03\n",
      "PPO Sharpe Ratio:  0.03904161853309149\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0.], sigma=[0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_2\n",
      "day: 1068, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 2097129.89\n",
      "total_reward: 1597129.89\n",
      "total_cost: 1163.76\n",
      "total_trades: 1092\n",
      "Sharpe: 1.174\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.52e+05 |\n",
      "|    total_cost       | 1.19e+03 |\n",
      "|    total_reward     | 1.52e+05 |\n",
      "|    total_reward_pct | 30.4     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total timesteps  | 4276     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -602     |\n",
      "|    critic_loss      | 1.57e+04 |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3207     |\n",
      "----------------------------------\n",
      "day: 1068, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 643296.28\n",
      "total_reward: 143296.28\n",
      "total_cost: 948.18\n",
      "total_trades: 1068\n",
      "Sharpe: 0.353\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.57e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.57e+05 |\n",
      "|    total_reward_pct | 31.3     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total timesteps  | 8552     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -474     |\n",
      "|    critic_loss      | 2.44e+03 |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7483     |\n",
      "----------------------------------\n",
      "day: 1068, episode: 200\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 656682.69\n",
      "total_reward: 156682.69\n",
      "total_cost: 948.17\n",
      "total_trades: 1068\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.57e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.57e+05 |\n",
      "|    total_reward_pct | 31.3     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 126      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total timesteps  | 12828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -322     |\n",
      "|    critic_loss      | 671      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11759    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.48e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.48e+05 |\n",
      "|    total_reward_pct | 29.6     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total timesteps  | 17104    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -213     |\n",
      "|    critic_loss      | 251      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16035    |\n",
      "----------------------------------\n",
      "day: 1068, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 652619.80\n",
      "total_reward: 152619.80\n",
      "total_cost: 948.17\n",
      "total_trades: 1068\n",
      "Sharpe: 0.361\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.57e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.57e+05 |\n",
      "|    total_reward_pct | 31.4     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total timesteps  | 21380    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -141     |\n",
      "|    critic_loss      | 107      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20311    |\n",
      "----------------------------------\n",
      "day: 1068, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 648835.43\n",
      "total_reward: 148835.43\n",
      "total_cost: 948.19\n",
      "total_trades: 1068\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.55e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.55e+05 |\n",
      "|    total_reward_pct | 30.9     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 122      |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total timesteps  | 25656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -96.3    |\n",
      "|    critic_loss      | 51.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24587    |\n",
      "----------------------------------\n",
      "day: 1068, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 656292.49\n",
      "total_reward: 156292.49\n",
      "total_cost: 948.15\n",
      "total_trades: 1068\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.57e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.57e+05 |\n",
      "|    total_reward_pct | 31.4     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total timesteps  | 29932    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -69.5    |\n",
      "|    critic_loss      | 35.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28863    |\n",
      "----------------------------------\n",
      "day: 1068, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 648338.97\n",
      "total_reward: 148338.97\n",
      "total_cost: 948.16\n",
      "total_trades: 1068\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.48e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.48e+05 |\n",
      "|    total_reward_pct | 29.7     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total timesteps  | 34208    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -54.2    |\n",
      "|    critic_loss      | 12       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33139    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.53e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.53e+05 |\n",
      "|    total_reward_pct | 30.6     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total timesteps  | 38484    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -45.9    |\n",
      "|    critic_loss      | 32.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37415    |\n",
      "----------------------------------\n",
      "day: 1068, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 655866.08\n",
      "total_reward: 155866.08\n",
      "total_cost: 948.20\n",
      "total_trades: 1068\n",
      "Sharpe: 0.363\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.57e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | 1.57e+05 |\n",
      "|    total_reward_pct | 31.4     |\n",
      "|    total_trades     | 1068     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total timesteps  | 42760    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -37.6    |\n",
      "|    critic_loss      | 91.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41691    |\n",
      "----------------------------------\n",
      "day: 1068, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 651651.41\n",
      "total_reward: 151651.41\n",
      "total_cost: 948.17\n",
      "total_trades: 1068\n",
      "Sharpe: 0.360\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to IHSG===========\")\n",
    "%matplotlib inline\n",
    "BackTestPlot(df_account_value, \n",
    "             baseline_ticker = '^JKSE', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_perf_stats=BaselineStats('^JKSE',\n",
    "                                  baseline_start = df_account_value.loc[0,'date'],\n",
    "                                  baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_multiple_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
