{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mPT0ipYE28wL"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "    \n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-01-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLY.ME', 'YNDX.ME', 'ALRS.ME', 'AFLT.ME', 'VTBR.ME', 'GAZP.ME', 'GMKN.ME', 'IRAO.ME', 'LKOH.ME', 'MGNT.ME', 'MOEX.ME', 'NLMK.ME', 'NVTK.ME', 'ROSN.ME', 'SBER.ME', 'CHMF.ME', 'AFKS.ME', 'SNGS.ME', 'TATN.ME']\n"
     ]
    }
   ],
   "source": [
    "print(config.TOPCHIK_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (14478, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = config.START_DATE,\n",
    "                     end_date = '2021-01-19',\n",
    "                     ticker_list = config.TOPCHIK_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GiRuFOTOtj1Y",
    "outputId": "bf7071db-d71a-4e1b-a28f-8e0145e0d204"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>12.485000</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>12.260000</td>\n",
       "      <td>11.994246</td>\n",
       "      <td>20687556.0</td>\n",
       "      <td>AFKS.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>139.100006</td>\n",
       "      <td>140.949997</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>127.199066</td>\n",
       "      <td>2126701.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>75.209999</td>\n",
       "      <td>75.959999</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>58.464432</td>\n",
       "      <td>3908567.0</td>\n",
       "      <td>ALRS.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>888.099976</td>\n",
       "      <td>899.900024</td>\n",
       "      <td>887.400024</td>\n",
       "      <td>613.168518</td>\n",
       "      <td>206795.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>131.029999</td>\n",
       "      <td>132.199997</td>\n",
       "      <td>130.630005</td>\n",
       "      <td>116.169998</td>\n",
       "      <td>10534020.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close      volume  \\\n",
       "0  2018-01-03   12.485000   12.550000   12.260000   11.994246  20687556.0   \n",
       "1  2018-01-03  139.100006  140.949997  138.600006  127.199066   2126701.0   \n",
       "2  2018-01-03   75.209999   75.959999   75.150002   58.464432   3908567.0   \n",
       "3  2018-01-03  888.099976  899.900024  887.400024  613.168518    206795.0   \n",
       "4  2018-01-03  131.029999  132.199997  130.630005  116.169998  10534020.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFKS.ME    2  \n",
       "1  AFLT.ME    2  \n",
       "2  ALRS.ME    2  \n",
       "3  CHMF.ME    2  \n",
       "4  GAZP.ME    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DSw4ZEzVtj1Z",
    "outputId": "1a04171b-04c8-4974-9c63-3195261d8fd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14473</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>275.720001</td>\n",
       "      <td>281.299988</td>\n",
       "      <td>272.950012</td>\n",
       "      <td>279.799988</td>\n",
       "      <td>7.096328e+07</td>\n",
       "      <td>SBER.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14474</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>35.865002</td>\n",
       "      <td>36.099998</td>\n",
       "      <td>4.088790e+07</td>\n",
       "      <td>SNGS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>532.400024</td>\n",
       "      <td>535.400024</td>\n",
       "      <td>523.099976</td>\n",
       "      <td>533.099976</td>\n",
       "      <td>4.929751e+06</td>\n",
       "      <td>TATN.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>0.039380</td>\n",
       "      <td>0.039440</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.039060</td>\n",
       "      <td>3.725212e+10</td>\n",
       "      <td>VTBR.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14477</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>5002.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>4990.000000</td>\n",
       "      <td>5034.000000</td>\n",
       "      <td>5.124640e+05</td>\n",
       "      <td>YNDX.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         open         high          low        close  \\\n",
       "14473  2021-01-18   275.720001   281.299988   272.950012   279.799988   \n",
       "14474  2021-01-18    36.580002    36.580002    35.865002    36.099998   \n",
       "14475  2021-01-18   532.400024   535.400024   523.099976   533.099976   \n",
       "14476  2021-01-18     0.039380     0.039440     0.038760     0.039060   \n",
       "14477  2021-01-18  5002.000000  5061.000000  4990.000000  5034.000000   \n",
       "\n",
       "             volume      tic  day  \n",
       "14473  7.096328e+07  SBER.ME    0  \n",
       "14474  4.088790e+07  SNGS.ME    0  \n",
       "14475  4.929751e+06  TATN.ME    0  \n",
       "14476  3.725212e+10  VTBR.ME    0  \n",
       "14477  5.124640e+05  YNDX.ME    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14478, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4hYkeaPiICHS",
    "outputId": "ce9d7463-a74c-4917-c96d-848a1e8ad493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>12.485000</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>12.260000</td>\n",
       "      <td>11.994246</td>\n",
       "      <td>20687556.0</td>\n",
       "      <td>AFKS.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>139.100006</td>\n",
       "      <td>140.949997</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>127.199066</td>\n",
       "      <td>2126701.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>75.209999</td>\n",
       "      <td>75.959999</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>58.464432</td>\n",
       "      <td>3908567.0</td>\n",
       "      <td>ALRS.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>888.099976</td>\n",
       "      <td>899.900024</td>\n",
       "      <td>887.400024</td>\n",
       "      <td>613.168518</td>\n",
       "      <td>206795.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>131.029999</td>\n",
       "      <td>132.199997</td>\n",
       "      <td>130.630005</td>\n",
       "      <td>116.169998</td>\n",
       "      <td>10534020.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close      volume  \\\n",
       "0  2018-01-03   12.485000   12.550000   12.260000   11.994246  20687556.0   \n",
       "1  2018-01-03  139.100006  140.949997  138.600006  127.199066   2126701.0   \n",
       "2  2018-01-03   75.209999   75.959999   75.150002   58.464432   3908567.0   \n",
       "3  2018-01-03  888.099976  899.900024  887.400024  613.168518    206795.0   \n",
       "4  2018-01-03  131.029999  132.199997  130.630005  116.169998  10534020.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFKS.ME    2  \n",
       "1  AFLT.ME    2  \n",
       "2  ALRS.ME    2  \n",
       "3  CHMF.ME    2  \n",
       "4  GAZP.ME    2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jgXfBcjxtj1a",
    "outputId": "abf8d5bb-2cd2-4c12-d4cb-ed1c429e60ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R_3v-ycktj1b"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16257</th>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>POLY.ME</td>\n",
       "      <td>1512.000000</td>\n",
       "      <td>1528.900024</td>\n",
       "      <td>1489.000000</td>\n",
       "      <td>1495.778198</td>\n",
       "      <td>859854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.212957</td>\n",
       "      <td>188.753485</td>\n",
       "      <td>171.662367</td>\n",
       "      <td>61.832981</td>\n",
       "      <td>196.080115</td>\n",
       "      <td>53.229832</td>\n",
       "      <td>179.902126</td>\n",
       "      <td>178.192387</td>\n",
       "      <td>14.637615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20492</th>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>NLMK.ME</td>\n",
       "      <td>212.899994</td>\n",
       "      <td>215.940002</td>\n",
       "      <td>211.800003</td>\n",
       "      <td>207.386459</td>\n",
       "      <td>9169704.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.413774</td>\n",
       "      <td>2534.997653</td>\n",
       "      <td>2346.342338</td>\n",
       "      <td>56.500490</td>\n",
       "      <td>100.181089</td>\n",
       "      <td>15.312330</td>\n",
       "      <td>2414.973332</td>\n",
       "      <td>2401.230009</td>\n",
       "      <td>23.726733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>IRAO.ME</td>\n",
       "      <td>3.787000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>3.787000</td>\n",
       "      <td>3.415191</td>\n",
       "      <td>80298483.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.533180</td>\n",
       "      <td>142.678172</td>\n",
       "      <td>125.581418</td>\n",
       "      <td>49.231451</td>\n",
       "      <td>-63.687371</td>\n",
       "      <td>19.451399</td>\n",
       "      <td>136.588010</td>\n",
       "      <td>134.591088</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20517</th>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>TATN.ME</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>517.799988</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>512.500000</td>\n",
       "      <td>4851684.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.031655</td>\n",
       "      <td>2587.528072</td>\n",
       "      <td>2397.091947</td>\n",
       "      <td>48.421591</td>\n",
       "      <td>-150.131827</td>\n",
       "      <td>5.336336</td>\n",
       "      <td>2481.713330</td>\n",
       "      <td>2442.616667</td>\n",
       "      <td>25.987587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>GMKN.ME</td>\n",
       "      <td>11155.000000</td>\n",
       "      <td>11305.000000</td>\n",
       "      <td>11125.000000</td>\n",
       "      <td>8641.870117</td>\n",
       "      <td>101807.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.936347</td>\n",
       "      <td>139.507417</td>\n",
       "      <td>129.205083</td>\n",
       "      <td>57.640964</td>\n",
       "      <td>121.809968</td>\n",
       "      <td>23.892359</td>\n",
       "      <td>133.350689</td>\n",
       "      <td>129.199492</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      tic          open          high           low  \\\n",
       "16257  2020-05-07  POLY.ME   1512.000000   1528.900024   1489.000000   \n",
       "20492  2020-12-16  NLMK.ME    212.899994    215.940002    211.800003   \n",
       "1298   2018-03-12  IRAO.ME      3.787000      3.840000      3.787000   \n",
       "20517  2020-12-17  TATN.ME    515.000000    517.799988    510.000000   \n",
       "4679   2018-09-06  GMKN.ME  11155.000000  11305.000000  11125.000000   \n",
       "\n",
       "             close      volume  day       macd      boll_ub      boll_lb  \\\n",
       "16257  1495.778198    859854.0  3.0   2.212957   188.753485   171.662367   \n",
       "20492   207.386459   9169704.0  2.0  17.413774  2534.997653  2346.342338   \n",
       "1298      3.415191  80298483.0  0.0  -1.533180   142.678172   125.581418   \n",
       "20517   512.500000   4851684.0  3.0  -7.031655  2587.528072  2397.091947   \n",
       "4679   8641.870117    101807.0  3.0   1.936347   139.507417   129.205083   \n",
       "\n",
       "          rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "16257  61.832981  196.080115  53.229832    179.902126    178.192387   \n",
       "20492  56.500490  100.181089  15.312330   2414.973332   2401.230009   \n",
       "1298   49.231451  -63.687371  19.451399    136.588010    134.591088   \n",
       "20517  48.421591 -150.131827   5.336336   2481.713330   2442.616667   \n",
       "4679   57.640964  121.809968  23.892359    133.350689    129.199492   \n",
       "\n",
       "       turbulence  \n",
       "16257   14.637615  \n",
       "20492   23.726733  \n",
       "1298     0.000000  \n",
       "20517   25.987587  \n",
       "4679     0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 19, State Space: 191\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 50_000_000/100, #Since in Indonesia the minimum number of shares per trx is 100, then we scaled the initial amount by dividing it with 100 \n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = config.START_DATE\n",
    "train_end = '2019-01-01'\n",
    "val_test_start = '2019-01-01'\n",
    "val_test_end = '2021-01-18'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KsfEHa_Etj1d"
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 100_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_1lyCECstj1e",
    "outputId": "72ac1ecc-909e-4d4c-d724-d906d7881ed9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "22.0153293850845\n",
      "turbulence_threshold:  0.0\n",
      "======Model training from:  2000-01-01 to  2019-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_1\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.45e+05  |\n",
      "|    total_cost         | 1.12e+05  |\n",
      "|    total_reward       | -1.55e+05 |\n",
      "|    total_reward_pct   | -31       |\n",
      "|    total_trades       | 3450      |\n",
      "| time/                 |           |\n",
      "|    fps                | 594       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | -1.13     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -2.16     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.0667    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.84e+05  |\n",
      "|    total_cost         | 1.15e+05  |\n",
      "|    total_reward       | -1.16e+05 |\n",
      "|    total_reward_pct   | -23.1     |\n",
      "|    total_trades       | 3341      |\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.202    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -2.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.186     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 698532.65\n",
      "total_reward: 198532.65\n",
      "total_cost: 139880.03\n",
      "total_trades: 3602\n",
      "Sharpe: 1.009\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.3e+05   |\n",
      "|    total_cost         | 1.25e+05  |\n",
      "|    total_reward       | -7.03e+04 |\n",
      "|    total_reward_pct   | -14.1     |\n",
      "|    total_trades       | 3561      |\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.138    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -17.7     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.452     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.72e+05 |\n",
      "|    total_cost         | 1.13e+05 |\n",
      "|    total_reward       | 2.72e+05 |\n",
      "|    total_reward_pct   | 54.5     |\n",
      "|    total_trades       | 3521     |\n",
      "| time/                 |          |\n",
      "|    fps                | 591      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -1.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -26.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.902    |\n",
      "------------------------------------\n",
      "day: 249, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 419700.36\n",
      "total_reward: -80299.64\n",
      "total_cost: 114272.64\n",
      "total_trades: 3591\n",
      "Sharpe: -0.619\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.2e+05   |\n",
      "|    total_cost         | 1.14e+05  |\n",
      "|    total_reward       | -8.03e+04 |\n",
      "|    total_reward_pct   | -16.1     |\n",
      "|    total_trades       | 3591      |\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.67     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 0.418     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.0296    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.1e+05  |\n",
      "|    total_cost         | 7.89e+04 |\n",
      "|    total_reward       | 9.65e+03 |\n",
      "|    total_reward_pct   | 1.93     |\n",
      "|    total_trades       | 3530     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.628   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.789    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.482    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.26e+05  |\n",
      "|    total_cost         | 7.03e+04  |\n",
      "|    total_reward       | -7.41e+04 |\n",
      "|    total_reward_pct   | -14.8     |\n",
      "|    total_trades       | 3428      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -0.657    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.328     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 452801.14\n",
      "total_reward: -47198.86\n",
      "total_cost: 87991.12\n",
      "total_trades: 3396\n",
      "Sharpe: -0.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.04e+05  |\n",
      "|    total_cost         | 6.92e+04  |\n",
      "|    total_reward       | -9.61e+04 |\n",
      "|    total_reward_pct   | -19.2     |\n",
      "|    total_trades       | 3372      |\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | 0.656     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.321     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.72e+05  |\n",
      "|    total_cost         | 5.34e+04  |\n",
      "|    total_reward       | -1.28e+05 |\n",
      "|    total_reward_pct   | -25.6     |\n",
      "|    total_trades       | 3109      |\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -0.0336   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -3.12     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.0281    |\n",
      "-------------------------------------\n",
      "day: 249, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 614036.88\n",
      "total_reward: 114036.88\n",
      "total_cost: 80939.66\n",
      "total_trades: 3254\n",
      "Sharpe: 0.813\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.14e+05 |\n",
      "|    total_cost         | 8.09e+04 |\n",
      "|    total_reward       | 1.14e+05 |\n",
      "|    total_reward_pct   | 22.8     |\n",
      "|    total_trades       | 3254     |\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.416    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -25.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.12e+05 |\n",
      "|    total_cost         | 5.38e+04 |\n",
      "|    total_reward       | 4.12e+05 |\n",
      "|    total_reward_pct   | 82.4     |\n",
      "|    total_trades       | 3169     |\n",
      "| time/                 |          |\n",
      "|    fps                | 588      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.356    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.12e+05 |\n",
      "|    total_cost         | 8.32e+04 |\n",
      "|    total_reward       | 2.12e+05 |\n",
      "|    total_reward_pct   | 42.5     |\n",
      "|    total_trades       | 3186     |\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -7.66    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.217    |\n",
      "------------------------------------\n",
      "day: 249, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 363719.35\n",
      "total_reward: -136280.65\n",
      "total_cost: 59493.34\n",
      "total_trades: 3159\n",
      "Sharpe: -0.669\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.28e+05  |\n",
      "|    total_cost         | 5e+04     |\n",
      "|    total_reward       | -1.72e+05 |\n",
      "|    total_reward_pct   | -34.5     |\n",
      "|    total_trades       | 3189      |\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0.294     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -7.71     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.0925    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.79e+05  |\n",
      "|    total_cost         | 7.34e+04  |\n",
      "|    total_reward       | -2.08e+04 |\n",
      "|    total_reward_pct   | -4.16     |\n",
      "|    total_trades       | 3176      |\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -0.66     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -32.5     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "day: 249, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 421835.85\n",
      "total_reward: -78164.15\n",
      "total_cost: 47864.76\n",
      "total_trades: 2872\n",
      "Sharpe: -0.464\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.22e+05  |\n",
      "|    total_cost         | 4.79e+04  |\n",
      "|    total_reward       | -7.82e+04 |\n",
      "|    total_reward_pct   | -15.6     |\n",
      "|    total_trades       | 2872      |\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0.133     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -22.8     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.815     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.75e+05  |\n",
      "|    total_cost         | 3.88e+04  |\n",
      "|    total_reward       | -2.52e+04 |\n",
      "|    total_reward_pct   | -5.04     |\n",
      "|    total_trades       | 2655      |\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | -0.992    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -15.9     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.459     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.47e+05  |\n",
      "|    total_cost         | 3.11e+04  |\n",
      "|    total_reward       | -1.53e+05 |\n",
      "|    total_reward_pct   | -30.6     |\n",
      "|    total_trades       | 2742      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0.341     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -16.3     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.371     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 416600.59\n",
      "total_reward: -83399.41\n",
      "total_cost: 36289.70\n",
      "total_trades: 2708\n",
      "Sharpe: -0.332\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.17e+05  |\n",
      "|    total_cost         | 4.19e+04  |\n",
      "|    total_reward       | -8.28e+04 |\n",
      "|    total_reward_pct   | -16.6     |\n",
      "|    total_trades       | 2781      |\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0.219     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -18.8     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.545     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.47e+05 |\n",
      "|    total_cost         | 2.61e+04 |\n",
      "|    total_reward       | 4.69e+04 |\n",
      "|    total_reward_pct   | 9.37     |\n",
      "|    total_trades       | 2857     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.235   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -20.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.747    |\n",
      "------------------------------------\n",
      "day: 249, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 656626.71\n",
      "total_reward: 156626.71\n",
      "total_cost: 30924.61\n",
      "total_trades: 2867\n",
      "Sharpe: 0.795\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.57e+05 |\n",
      "|    total_cost         | 3.09e+04 |\n",
      "|    total_reward       | 1.57e+05 |\n",
      "|    total_reward_pct   | 31.3     |\n",
      "|    total_trades       | 2867     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.481   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -25.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.53e+05 |\n",
      "|    total_cost         | 2.06e+04 |\n",
      "|    total_reward       | 1.53e+05 |\n",
      "|    total_reward_pct   | 30.7     |\n",
      "|    total_trades       | 2822     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.251   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -20.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.74e+05 |\n",
      "|    total_cost         | 2.65e+04 |\n",
      "|    total_reward       | 1.74e+05 |\n",
      "|    total_reward_pct   | 34.9     |\n",
      "|    total_trades       | 2971     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.273   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -37.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.72     |\n",
      "------------------------------------\n",
      "day: 249, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 669368.26\n",
      "total_reward: 169368.26\n",
      "total_cost: 48363.57\n",
      "total_trades: 3162\n",
      "Sharpe: 0.868\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.6e+05  |\n",
      "|    total_cost         | 3.57e+04 |\n",
      "|    total_reward       | 5.97e+04 |\n",
      "|    total_reward_pct   | 11.9     |\n",
      "|    total_trades       | 3077     |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.214   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -25.1    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.946    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.08e+05  |\n",
      "|    total_cost         | 2.39e+04  |\n",
      "|    total_reward       | -9.23e+04 |\n",
      "|    total_reward_pct   | -18.5     |\n",
      "|    total_trades       | 3100      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -9.92     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -28.7     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 2.01      |\n",
      "-------------------------------------\n",
      "day: 249, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 633414.20\n",
      "total_reward: 133414.20\n",
      "total_cost: 31142.95\n",
      "total_trades: 3095\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.33e+05 |\n",
      "|    total_cost         | 3.11e+04 |\n",
      "|    total_reward       | 1.33e+05 |\n",
      "|    total_reward_pct   | 26.7     |\n",
      "|    total_trades       | 3095     |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.329   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -29.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.1e+05   |\n",
      "|    total_cost         | 1.79e+04  |\n",
      "|    total_reward       | -9.05e+04 |\n",
      "|    total_reward_pct   | -18.1     |\n",
      "|    total_trades       | 3090      |\n",
      "| time/                 |           |\n",
      "|    fps                | 545       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -3.17     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -19.4     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.724     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.66e+05 |\n",
      "|    total_cost         | 1.52e+04 |\n",
      "|    total_reward       | 1.66e+05 |\n",
      "|    total_reward_pct   | 33.1     |\n",
      "|    total_trades       | 3071     |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -10.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -30.4    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.61     |\n",
      "------------------------------------\n",
      "day: 249, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 681537.11\n",
      "total_reward: 181537.11\n",
      "total_cost: 18369.31\n",
      "total_trades: 3169\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.12e+05 |\n",
      "|    total_cost         | 2.07e+04 |\n",
      "|    total_reward       | 1.12e+05 |\n",
      "|    total_reward_pct   | 22.5     |\n",
      "|    total_trades       | 3161     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.753   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -33.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.54e+05  |\n",
      "|    total_cost         | 1.03e+04  |\n",
      "|    total_reward       | -4.59e+04 |\n",
      "|    total_reward_pct   | -9.17     |\n",
      "|    total_trades       | 3209      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -0.259    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -18.8     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.556     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 690474.14\n",
      "total_reward: 190474.14\n",
      "total_cost: 11392.20\n",
      "total_trades: 3277\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.9e+05  |\n",
      "|    total_cost         | 1.14e+04 |\n",
      "|    total_reward       | 1.9e+05  |\n",
      "|    total_reward_pct   | 38.1     |\n",
      "|    total_trades       | 3277     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.496   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -21.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.27e+05 |\n",
      "|    total_cost         | 1.02e+04 |\n",
      "|    total_reward       | 1.27e+05 |\n",
      "|    total_reward_pct   | 25.5     |\n",
      "|    total_trades       | 3188     |\n",
      "| time/                 |          |\n",
      "|    fps                | 555      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.791   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -23.4    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.943    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.47e+05 |\n",
      "|    total_cost         | 1.93e+04 |\n",
      "|    total_reward       | 1.47e+05 |\n",
      "|    total_reward_pct   | 29.3     |\n",
      "|    total_trades       | 3268     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.249   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -25.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "day: 249, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 682635.03\n",
      "total_reward: 182635.03\n",
      "total_cost: 19447.32\n",
      "total_trades: 3271\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.93e+05  |\n",
      "|    total_cost         | 9.88e+03  |\n",
      "|    total_reward       | -1.07e+05 |\n",
      "|    total_reward_pct   | -21.3     |\n",
      "|    total_trades       | 3197      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -0.00913  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.321     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.08e+05 |\n",
      "|    total_cost         | 2.58e+04 |\n",
      "|    total_reward       | 2.08e+05 |\n",
      "|    total_reward_pct   | 41.5     |\n",
      "|    total_trades       | 3286     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -9.09    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.445    |\n",
      "------------------------------------\n",
      "day: 249, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 608527.05\n",
      "total_reward: 108527.05\n",
      "total_cost: 31370.97\n",
      "total_trades: 3188\n",
      "Sharpe: 0.867\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.09e+05 |\n",
      "|    total_cost         | 3.14e+04 |\n",
      "|    total_reward       | 1.09e+05 |\n",
      "|    total_reward_pct   | 21.7     |\n",
      "|    total_trades       | 3188     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -2.58    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.14e+05 |\n",
      "|    total_cost         | 6.32e+04 |\n",
      "|    total_reward       | 3.14e+05 |\n",
      "|    total_reward_pct   | 62.9     |\n",
      "|    total_trades       | 3348     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 4.22     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.53e+05 |\n",
      "|    total_cost         | 5.72e+04 |\n",
      "|    total_reward       | 3.53e+05 |\n",
      "|    total_reward_pct   | 70.5     |\n",
      "|    total_trades       | 3342     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -7.26    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -12.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3        |\n",
      "------------------------------------\n",
      "day: 249, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 817462.47\n",
      "total_reward: 317462.47\n",
      "total_cost: 50565.00\n",
      "total_trades: 3344\n",
      "Sharpe: 1.253\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.57e+05 |\n",
      "|    total_cost         | 3.67e+04 |\n",
      "|    total_reward       | 2.57e+05 |\n",
      "|    total_reward_pct   | 51.4     |\n",
      "|    total_trades       | 3294     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -4.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -6.92    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.77e+05 |\n",
      "|    total_cost         | 5.56e+04 |\n",
      "|    total_reward       | 1.77e+05 |\n",
      "|    total_reward_pct   | 35.4     |\n",
      "|    total_trades       | 3200     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -13.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -7.65    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n",
      "day: 249, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 673209.79\n",
      "total_reward: 173209.79\n",
      "total_cost: 39844.88\n",
      "total_trades: 3260\n",
      "Sharpe: 0.899\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.73e+05 |\n",
      "|    total_cost         | 3.98e+04 |\n",
      "|    total_reward       | 1.73e+05 |\n",
      "|    total_reward_pct   | 34.6     |\n",
      "|    total_trades       | 3260     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -11.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.353   |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.76e+05 |\n",
      "|    total_cost         | 3.49e+04 |\n",
      "|    total_reward       | 1.76e+05 |\n",
      "|    total_reward_pct   | 35.1     |\n",
      "|    total_trades       | 3146     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -8.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.33e+05 |\n",
      "|    total_cost         | 3.4e+04  |\n",
      "|    total_reward       | 3.3e+04  |\n",
      "|    total_reward_pct   | 6.59     |\n",
      "|    total_trades       | 3188     |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -19.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 2.77     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.74     |\n",
      "------------------------------------\n",
      "day: 249, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 642922.37\n",
      "total_reward: 142922.37\n",
      "total_cost: 31460.43\n",
      "total_trades: 3268\n",
      "Sharpe: 1.099\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.65e+05 |\n",
      "|    total_cost         | 4.76e+04 |\n",
      "|    total_reward       | 3.65e+05 |\n",
      "|    total_reward_pct   | 73       |\n",
      "|    total_trades       | 3238     |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -11.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -5.92    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.5e+05   |\n",
      "|    total_cost         | 1.71e+04  |\n",
      "|    total_reward       | -5.01e+04 |\n",
      "|    total_reward_pct   | -10       |\n",
      "|    total_trades       | 3221      |\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -24.6     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 8.03      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.63      |\n",
      "-------------------------------------\n",
      "day: 249, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 855373.75\n",
      "total_reward: 355373.75\n",
      "total_cost: 41566.09\n",
      "total_trades: 3262\n",
      "Sharpe: 1.310\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.55e+05 |\n",
      "|    total_cost         | 4.16e+04 |\n",
      "|    total_reward       | 3.55e+05 |\n",
      "|    total_reward_pct   | 71.1     |\n",
      "|    total_trades       | 3262     |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -7.51    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -17.9    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.54e+05 |\n",
      "|    total_cost         | 5.49e+04 |\n",
      "|    total_reward       | 3.54e+05 |\n",
      "|    total_reward_pct   | 70.8     |\n",
      "|    total_trades       | 3278     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -20.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -7.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.65e+05 |\n",
      "|    total_cost         | 3.36e+04 |\n",
      "|    total_reward       | 6.48e+04 |\n",
      "|    total_reward_pct   | 13       |\n",
      "|    total_trades       | 3299     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -30.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 14.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "day: 249, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 548004.38\n",
      "total_reward: 48004.38\n",
      "total_cost: 44056.14\n",
      "total_trades: 3287\n",
      "Sharpe: 0.393\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.66e+05 |\n",
      "|    total_cost         | 4.63e+04 |\n",
      "|    total_reward       | 1.66e+05 |\n",
      "|    total_reward_pct   | 33.1     |\n",
      "|    total_trades       | 3169     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -30.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.985    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.34e+05 |\n",
      "|    total_cost         | 2.93e+04 |\n",
      "|    total_reward       | -6.6e+04 |\n",
      "|    total_reward_pct   | -13.2    |\n",
      "|    total_trades       | 3176     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -35.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.613   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.71     |\n",
      "------------------------------------\n",
      "day: 249, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 695060.20\n",
      "total_reward: 195060.20\n",
      "total_cost: 20917.14\n",
      "total_trades: 3015\n",
      "Sharpe: 1.472\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.95e+05 |\n",
      "|    total_cost         | 2.09e+04 |\n",
      "|    total_reward       | 1.95e+05 |\n",
      "|    total_reward_pct   | 39       |\n",
      "|    total_trades       | 3015     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -18.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -5.93    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.34e+05 |\n",
      "|    total_cost         | 2.32e+04 |\n",
      "|    total_reward       | 3.4e+04  |\n",
      "|    total_reward_pct   | 6.81     |\n",
      "|    total_trades       | 3028     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -21.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -2.65    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.54e+05 |\n",
      "|    total_cost         | 2.65e+04 |\n",
      "|    total_reward       | -4.6e+04 |\n",
      "|    total_reward_pct   | -9.2     |\n",
      "|    total_trades       | 3132     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -38.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 10.1     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.81     |\n",
      "------------------------------------\n",
      "day: 249, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 550860.31\n",
      "total_reward: 50860.31\n",
      "total_cost: 32518.90\n",
      "total_trades: 3162\n",
      "Sharpe: 0.456\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.78e+05 |\n",
      "|    total_cost         | 3.69e+04 |\n",
      "|    total_reward       | 2.78e+05 |\n",
      "|    total_reward_pct   | 55.5     |\n",
      "|    total_trades       | 3155     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -17.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.77e+05 |\n",
      "|    total_cost         | 2.85e+04 |\n",
      "|    total_reward       | 1.77e+05 |\n",
      "|    total_reward_pct   | 35.4     |\n",
      "|    total_trades       | 3166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -11.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -17      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.9      |\n",
      "------------------------------------\n",
      "day: 249, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 744974.21\n",
      "total_reward: 244974.21\n",
      "total_cost: 31159.93\n",
      "total_trades: 3263\n",
      "Sharpe: 1.094\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.45e+05 |\n",
      "|    total_cost         | 3.12e+04 |\n",
      "|    total_reward       | 2.45e+05 |\n",
      "|    total_reward_pct   | 49       |\n",
      "|    total_trades       | 3263     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -13.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.514    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.95e+05 |\n",
      "|    total_cost         | 1.78e+04 |\n",
      "|    total_reward       | 9.48e+04 |\n",
      "|    total_reward_pct   | 19       |\n",
      "|    total_trades       | 3104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -8.49    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -9.68    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.82e+05 |\n",
      "|    total_cost         | 2.05e+04 |\n",
      "|    total_reward       | 1.82e+05 |\n",
      "|    total_reward_pct   | 36.4     |\n",
      "|    total_trades       | 3221     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -10.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "day: 249, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 590799.44\n",
      "total_reward: 90799.44\n",
      "total_cost: 33204.23\n",
      "total_trades: 3185\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.05e+05 |\n",
      "|    total_cost         | 1.78e+04 |\n",
      "|    total_reward       | 1.05e+05 |\n",
      "|    total_reward_pct   | 21       |\n",
      "|    total_trades       | 3116     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -12.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -3.66    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.02e+05 |\n",
      "|    total_cost         | 1.72e+04 |\n",
      "|    total_reward       | 2.02e+05 |\n",
      "|    total_reward_pct   | 40.3     |\n",
      "|    total_trades       | 3025     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -7.18    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -18.4    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "day: 249, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 452007.91\n",
      "total_reward: -47992.09\n",
      "total_cost: 19649.95\n",
      "total_trades: 3091\n",
      "Sharpe: -0.165\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.52e+05 |\n",
      "|    total_cost         | 1.96e+04 |\n",
      "|    total_reward       | -4.8e+04 |\n",
      "|    total_reward_pct   | -9.6     |\n",
      "|    total_trades       | 3091     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -13.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -7.77    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.56e+05  |\n",
      "|    total_cost         | 1.67e+04  |\n",
      "|    total_reward       | -4.38e+04 |\n",
      "|    total_reward_pct   | -8.77     |\n",
      "|    total_trades       | 3141      |\n",
      "| time/                 |           |\n",
      "|    fps                | 572       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -16.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -6.86     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.31e+05  |\n",
      "|    total_cost         | 1.4e+04   |\n",
      "|    total_reward       | -6.86e+04 |\n",
      "|    total_reward_pct   | -13.7     |\n",
      "|    total_trades       | 3088      |\n",
      "| time/                 |           |\n",
      "|    fps                | 572       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -13.3     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -6.32     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.788     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 334726.67\n",
      "total_reward: -165273.33\n",
      "total_cost: 9379.33\n",
      "total_trades: 3000\n",
      "Sharpe: -0.602\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.73e+05  |\n",
      "|    total_cost         | 1.15e+04  |\n",
      "|    total_reward       | -1.27e+05 |\n",
      "|    total_reward_pct   | -25.3     |\n",
      "|    total_trades       | 3053      |\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.95     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -8.78     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.265     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.46e+05  |\n",
      "|    total_cost         | 1.03e+04  |\n",
      "|    total_reward       | -1.54e+05 |\n",
      "|    total_reward_pct   | -30.9     |\n",
      "|    total_trades       | 3136      |\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -0.403    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -9.2      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 732286.52\n",
      "total_reward: 232286.52\n",
      "total_cost: 26672.65\n",
      "total_trades: 3205\n",
      "Sharpe: 0.936\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.32e+05 |\n",
      "|    total_cost         | 2.67e+04 |\n",
      "|    total_reward       | 2.32e+05 |\n",
      "|    total_reward_pct   | 46.5     |\n",
      "|    total_trades       | 3205     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -28.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.865    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.27e+05 |\n",
      "|    total_cost         | 2.36e+04 |\n",
      "|    total_reward       | 1.27e+05 |\n",
      "|    total_reward_pct   | 25.4     |\n",
      "|    total_trades       | 3124     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -15.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.438    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.07e+05 |\n",
      "|    total_cost         | 1.68e+04 |\n",
      "|    total_reward       | 2.07e+05 |\n",
      "|    total_reward_pct   | 41.3     |\n",
      "|    total_trades       | 3120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0.0757   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -27.1    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "day: 249, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 559333.76\n",
      "total_reward: 59333.76\n",
      "total_cost: 19162.29\n",
      "total_trades: 3106\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.42e+05 |\n",
      "|    total_cost         | 1.96e+04 |\n",
      "|    total_reward       | 2.42e+05 |\n",
      "|    total_reward_pct   | 48.5     |\n",
      "|    total_trades       | 3078     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.498   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -20      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.828    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.49e+05 |\n",
      "|    total_cost         | 1.48e+04 |\n",
      "|    total_reward       | 2.49e+05 |\n",
      "|    total_reward_pct   | 49.9     |\n",
      "|    total_trades       | 2963     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -7.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -46.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.59     |\n",
      "------------------------------------\n",
      "day: 249, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 475190.28\n",
      "total_reward: -24809.72\n",
      "total_cost: 16420.65\n",
      "total_trades: 2998\n",
      "Sharpe: -0.003\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.75e+05  |\n",
      "|    total_cost         | 1.64e+04  |\n",
      "|    total_reward       | -2.48e+04 |\n",
      "|    total_reward_pct   | -4.96     |\n",
      "|    total_trades       | 2998      |\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -0.0288   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -18.5     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.438     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.72e+05 |\n",
      "|    total_cost         | 1.75e+04 |\n",
      "|    total_reward       | 2.72e+05 |\n",
      "|    total_reward_pct   | 54.4     |\n",
      "|    total_trades       | 3019     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.0624  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -31.4    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.74e+05 |\n",
      "|    total_cost         | 1.78e+04 |\n",
      "|    total_reward       | 2.74e+05 |\n",
      "|    total_reward_pct   | 54.7     |\n",
      "|    total_trades       | 3030     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.303   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -26.3    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "day: 249, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 768908.14\n",
      "total_reward: 268908.14\n",
      "total_cost: 11572.81\n",
      "total_trades: 3026\n",
      "Sharpe: 1.013\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.08e+05 |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | 2.08e+05 |\n",
      "|    total_reward_pct   | 41.6     |\n",
      "|    total_trades       | 3022     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.421   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -36.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.54e+05 |\n",
      "|    total_cost         | 1.82e+04 |\n",
      "|    total_reward       | 2.54e+05 |\n",
      "|    total_reward_pct   | 50.8     |\n",
      "|    total_trades       | 3051     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -0.757   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -33.2    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "day: 249, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 725766.49\n",
      "total_reward: 225766.49\n",
      "total_cost: 27232.80\n",
      "total_trades: 3103\n",
      "Sharpe: 0.912\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.26e+05 |\n",
      "|    total_cost         | 2.72e+04 |\n",
      "|    total_reward       | 2.26e+05 |\n",
      "|    total_reward_pct   | 45.2     |\n",
      "|    total_trades       | 3103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0.156    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -28.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.4e+05  |\n",
      "|    total_cost         | 4.33e+04 |\n",
      "|    total_reward       | 3.4e+05  |\n",
      "|    total_reward_pct   | 68.1     |\n",
      "|    total_trades       | 3300     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -1       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.4e+05  |\n",
      "|    total_cost         | 2.84e+04 |\n",
      "|    total_reward       | 2.4e+05  |\n",
      "|    total_reward_pct   | 48.1     |\n",
      "|    total_trades       | 3206     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -7.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "day: 249, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 846379.75\n",
      "total_reward: 346379.75\n",
      "total_cost: 35236.88\n",
      "total_trades: 3163\n",
      "Sharpe: 1.235\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8e+05    |\n",
      "|    total_cost         | 2.74e+04 |\n",
      "|    total_reward       | 3e+05    |\n",
      "|    total_reward_pct   | 60       |\n",
      "|    total_trades       | 3149     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -5.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -18.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.6e+05  |\n",
      "|    total_cost         | 3.44e+04 |\n",
      "|    total_reward       | 2.6e+05  |\n",
      "|    total_reward_pct   | 52       |\n",
      "|    total_trades       | 3169     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -12      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -3.68    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "day: 249, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 762307.90\n",
      "total_reward: 262307.90\n",
      "total_cost: 32106.50\n",
      "total_trades: 3173\n",
      "Sharpe: 1.482\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.62e+05 |\n",
      "|    total_cost         | 3.21e+04 |\n",
      "|    total_reward       | 2.62e+05 |\n",
      "|    total_reward_pct   | 52.5     |\n",
      "|    total_trades       | 3173     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -28.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -7.28    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.34e+05 |\n",
      "|    total_cost         | 3.21e+04 |\n",
      "|    total_reward       | 3.34e+05 |\n",
      "|    total_reward_pct   | 66.8     |\n",
      "|    total_trades       | 3169     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -8.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -23.6    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.63e+05 |\n",
      "|    total_cost         | 2.03e+04 |\n",
      "|    total_reward       | 1.63e+05 |\n",
      "|    total_reward_pct   | 32.6     |\n",
      "|    total_trades       | 2931     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -5.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "day: 249, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 706063.97\n",
      "total_reward: 206063.97\n",
      "total_cost: 13902.28\n",
      "total_trades: 2924\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.54e+05 |\n",
      "|    total_cost         | 2.84e+04 |\n",
      "|    total_reward       | 2.54e+05 |\n",
      "|    total_reward_pct   | 50.8     |\n",
      "|    total_trades       | 3032     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -4.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -15      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.22e+05 |\n",
      "|    total_cost         | 2.04e+04 |\n",
      "|    total_reward       | 3.22e+05 |\n",
      "|    total_reward_pct   | 64.3     |\n",
      "|    total_trades       | 2974     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -2.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 48.8     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.42     |\n",
      "------------------------------------\n",
      "day: 249, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 450100.62\n",
      "total_reward: -49899.38\n",
      "total_cost: 25073.41\n",
      "total_trades: 2947\n",
      "Sharpe: -0.257\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.5e+05   |\n",
      "|    total_cost         | 2.51e+04  |\n",
      "|    total_reward       | -4.99e+04 |\n",
      "|    total_reward_pct   | -9.98     |\n",
      "|    total_trades       | 2947      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -3.69     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 10.5      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.417     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.91e+05 |\n",
      "|    total_cost         | 1.73e+04 |\n",
      "|    total_reward       | 1.91e+05 |\n",
      "|    total_reward_pct   | 38.2     |\n",
      "|    total_trades       | 2959     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -0.735   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -31      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.49e+05 |\n",
      "|    total_cost         | 7.42e+03 |\n",
      "|    total_reward       | 1.49e+05 |\n",
      "|    total_reward_pct   | 29.8     |\n",
      "|    total_trades       | 2984     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.0476  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -27.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "day: 249, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 468175.49\n",
      "total_reward: -31824.51\n",
      "total_cost: 8801.83\n",
      "total_trades: 3020\n",
      "Sharpe: -0.071\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.34e+05 |\n",
      "|    total_cost         | 9.82e+03 |\n",
      "|    total_reward       | 1.34e+05 |\n",
      "|    total_reward_pct   | 26.8     |\n",
      "|    total_trades       | 3035     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.986   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -25      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.97e+05 |\n",
      "|    total_cost         | 8.53e+03 |\n",
      "|    total_reward       | 1.97e+05 |\n",
      "|    total_reward_pct   | 39.3     |\n",
      "|    total_trades       | 2993     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.154   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -29.6    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "day: 249, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 467486.70\n",
      "total_reward: -32513.30\n",
      "total_cost: 8522.21\n",
      "total_trades: 3030\n",
      "Sharpe: -0.009\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.67e+05  |\n",
      "|    total_cost         | 8.52e+03  |\n",
      "|    total_reward       | -3.25e+04 |\n",
      "|    total_reward_pct   | -6.5      |\n",
      "|    total_trades       | 3030      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | -4.42     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -26.4     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.32      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.19e+05 |\n",
      "|    total_cost         | 7.05e+03 |\n",
      "|    total_reward       | 2.19e+05 |\n",
      "|    total_reward_pct   | 43.8     |\n",
      "|    total_trades       | 3044     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -2.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -35.1    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.9e+05  |\n",
      "|    total_cost         | 7.51e+03 |\n",
      "|    total_reward       | 1.9e+05  |\n",
      "|    total_reward_pct   | 37.9     |\n",
      "|    total_trades       | 3034     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -3.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -38.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.75     |\n",
      "------------------------------------\n",
      "day: 249, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 706637.83\n",
      "total_reward: 206637.83\n",
      "total_cost: 4776.63\n",
      "total_trades: 3051\n",
      "Sharpe: 0.842\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.29e+05  |\n",
      "|    total_cost         | 4.45e+03  |\n",
      "|    total_reward       | -7.14e+04 |\n",
      "|    total_reward_pct   | -14.3     |\n",
      "|    total_trades       | 3062      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | -9.01     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -24.4     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.82      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.52e+05  |\n",
      "|    total_cost         | 1.08e+04  |\n",
      "|    total_reward       | -4.81e+04 |\n",
      "|    total_reward_pct   | -9.61     |\n",
      "|    total_trades       | 3039      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | -4.25     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -24.7     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.24      |\n",
      "-------------------------------------\n",
      "day: 249, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 494682.22\n",
      "total_reward: -5317.78\n",
      "total_cost: 6735.07\n",
      "total_trades: 2954\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.95e+05  |\n",
      "|    total_cost         | 6.74e+03  |\n",
      "|    total_reward       | -5.32e+03 |\n",
      "|    total_reward_pct   | -1.06     |\n",
      "|    total_trades       | 2954      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | -11.5     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -32.5     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.75      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.01e+05 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 531      |\n",
      "|    total_reward_pct   | 0.106    |\n",
      "|    total_trades       | 3005     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -15.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -34.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.7e+05  |\n",
      "|    total_cost         | 2.66e+04 |\n",
      "|    total_reward       | 7.01e+04 |\n",
      "|    total_reward_pct   | 14       |\n",
      "|    total_trades       | 3125     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -9.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -31.3    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "day: 249, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 521922.06\n",
      "total_reward: 21922.06\n",
      "total_cost: 11470.35\n",
      "total_trades: 3013\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.65e+05 |\n",
      "|    total_cost         | 2.05e+04 |\n",
      "|    total_reward       | 1.65e+05 |\n",
      "|    total_reward_pct   | 33       |\n",
      "|    total_trades       | 3123     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -9.79    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -47.8    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.89e+05 |\n",
      "|    total_cost         | 7.27e+03 |\n",
      "|    total_reward       | 8.92e+04 |\n",
      "|    total_reward_pct   | 17.8     |\n",
      "|    total_trades       | 3095     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -6.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -32.6    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.52     |\n",
      "------------------------------------\n",
      "day: 249, episode: 200\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 695592.66\n",
      "total_reward: 195592.66\n",
      "total_cost: 4507.12\n",
      "total_trades: 3023\n",
      "Sharpe: 0.824\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.96e+05 |\n",
      "|    total_cost         | 4.51e+03 |\n",
      "|    total_reward       | 1.96e+05 |\n",
      "|    total_reward_pct   | 39.1     |\n",
      "|    total_trades       | 3023     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -8.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -44.3    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 4.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.7e+05  |\n",
      "|    total_cost         | 1.14e+04 |\n",
      "|    total_reward       | 1.7e+05  |\n",
      "|    total_reward_pct   | 34       |\n",
      "|    total_trades       | 3064     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -6.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -31      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.45e+05 |\n",
      "|    total_cost         | 1.76e+04 |\n",
      "|    total_reward       | 2.45e+05 |\n",
      "|    total_reward_pct   | 49       |\n",
      "|    total_trades       | 3127     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0.451    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -13.8    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.298    |\n",
      "------------------------------------\n",
      "day: 249, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 996231.37\n",
      "total_reward: 496231.37\n",
      "total_cost: 15145.71\n",
      "total_trades: 3074\n",
      "Sharpe: 1.750\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.05e+05 |\n",
      "|    total_cost         | 1.88e+04 |\n",
      "|    total_reward       | 4.05e+05 |\n",
      "|    total_reward_pct   | 81       |\n",
      "|    total_trades       | 3147     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -0.335   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -13.7    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.99e+05 |\n",
      "|    total_cost         | 9.62e+03 |\n",
      "|    total_reward       | 9.93e+04 |\n",
      "|    total_reward_pct   | 19.9     |\n",
      "|    total_trades       | 3059     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -2.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.293    |\n",
      "------------------------------------\n",
      "day: 249, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 467353.19\n",
      "total_reward: -32646.81\n",
      "total_cost: 10392.88\n",
      "total_trades: 3154\n",
      "Sharpe: -0.093\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.67e+05  |\n",
      "|    total_cost         | 1.04e+04  |\n",
      "|    total_reward       | -3.26e+04 |\n",
      "|    total_reward_pct   | -6.53     |\n",
      "|    total_trades       | 3154      |\n",
      "| time/                 |           |\n",
      "|    fps                | 577       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -1.4      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | -7.19     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.129     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.72e+05 |\n",
      "|    total_cost         | 8.47e+03 |\n",
      "|    total_reward       | 1.72e+05 |\n",
      "|    total_reward_pct   | 34.4     |\n",
      "|    total_trades       | 3283     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -0.912   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -7.42    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.1e+05  |\n",
      "|    total_cost         | 1.74e+04 |\n",
      "|    total_reward       | 3.1e+05  |\n",
      "|    total_reward_pct   | 62       |\n",
      "|    total_trades       | 3286     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -4.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.515    |\n",
      "------------------------------------\n",
      "day: 249, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 642359.29\n",
      "total_reward: 142359.29\n",
      "total_cost: 9816.80\n",
      "total_trades: 3261\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.82e+05 |\n",
      "|    total_cost         | 8.81e+03 |\n",
      "|    total_reward       | 8.16e+04 |\n",
      "|    total_reward_pct   | 16.3     |\n",
      "|    total_trades       | 3235     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -10      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.592    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.09e+05 |\n",
      "|    total_cost         | 1.59e+04 |\n",
      "|    total_reward       | 1.09e+05 |\n",
      "|    total_reward_pct   | 21.8     |\n",
      "|    total_trades       | 3510     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -12.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 6.93     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.432    |\n",
      "------------------------------------\n",
      "day: 249, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 814963.70\n",
      "total_reward: 314963.70\n",
      "total_cost: 25918.95\n",
      "total_trades: 3564\n",
      "Sharpe: 1.361\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.15e+05 |\n",
      "|    total_cost         | 2.59e+04 |\n",
      "|    total_reward       | 3.15e+05 |\n",
      "|    total_reward_pct   | 63       |\n",
      "|    total_trades       | 3564     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -6.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -17.9    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.693    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.15e+05 |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | 2.15e+05 |\n",
      "|    total_reward_pct   | 43       |\n",
      "|    total_trades       | 3575     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -9.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -7.27    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.449    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.79e+05 |\n",
      "|    total_cost         | 1.75e+04 |\n",
      "|    total_reward       | 1.79e+05 |\n",
      "|    total_reward_pct   | 35.9     |\n",
      "|    total_trades       | 3564     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -13.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.729    |\n",
      "------------------------------------\n",
      "day: 249, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 465882.11\n",
      "total_reward: -34117.89\n",
      "total_cost: 10833.96\n",
      "total_trades: 3492\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.76e+05 |\n",
      "|    total_cost         | 1.62e+04 |\n",
      "|    total_reward       | 7.6e+04  |\n",
      "|    total_reward_pct   | 15.2     |\n",
      "|    total_trades       | 3574     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -4.91    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -13.7    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.335    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.98e+05  |\n",
      "|    total_cost         | 1.21e+04  |\n",
      "|    total_reward       | -2.26e+03 |\n",
      "|    total_reward_pct   | -0.451    |\n",
      "|    total_trades       | 3582      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.8     |\n",
      "|    explained_variance | -1.93     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -18.2     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.559     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 489639.84\n",
      "total_reward: -10360.16\n",
      "total_cost: 22197.77\n",
      "total_trades: 3629\n",
      "Sharpe: 0.025\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.9e+05   |\n",
      "|    total_cost         | 2.22e+04  |\n",
      "|    total_reward       | -1.04e+04 |\n",
      "|    total_reward_pct   | -2.07     |\n",
      "|    total_trades       | 3629      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.8     |\n",
      "|    explained_variance | -0.159    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -10.3     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.23      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.3e+05  |\n",
      "|    total_cost         | 1.33e+04 |\n",
      "|    total_reward       | 1.3e+05  |\n",
      "|    total_reward_pct   | 26.1     |\n",
      "|    total_trades       | 3429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.167    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.254    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.01e+05 |\n",
      "|    total_cost         | 1.36e+04 |\n",
      "|    total_reward       | 1.24e+03 |\n",
      "|    total_reward_pct   | 0.248    |\n",
      "|    total_trades       | 3369     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -11.2    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.172    |\n",
      "------------------------------------\n",
      "day: 249, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 453603.69\n",
      "total_reward: -46396.31\n",
      "total_cost: 14663.17\n",
      "total_trades: 3344\n",
      "Sharpe: -0.010\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.12e+05  |\n",
      "|    total_cost         | 1.15e+04  |\n",
      "|    total_reward       | -8.76e+04 |\n",
      "|    total_reward_pct   | -17.5     |\n",
      "|    total_trades       | 3272      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.8     |\n",
      "|    explained_variance | -2.74     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -15.8     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.481     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.27e+05  |\n",
      "|    total_cost         | 5.82e+03  |\n",
      "|    total_reward       | -7.32e+04 |\n",
      "|    total_reward_pct   | -14.6     |\n",
      "|    total_trades       | 3194      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.8     |\n",
      "|    explained_variance | -5.1      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -22.9     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.963     |\n",
      "-------------------------------------\n",
      "day: 249, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 714623.35\n",
      "total_reward: 214623.35\n",
      "total_cost: 25288.76\n",
      "total_trades: 3196\n",
      "Sharpe: 1.105\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.15e+05 |\n",
      "|    total_cost         | 2.53e+04 |\n",
      "|    total_reward       | 2.15e+05 |\n",
      "|    total_reward_pct   | 42.9     |\n",
      "|    total_trades       | 3196     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.722   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -14.4    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.498    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.54e+05 |\n",
      "|    total_cost         | 2.34e+04 |\n",
      "|    total_reward       | 1.54e+05 |\n",
      "|    total_reward_pct   | 30.7     |\n",
      "|    total_trades       | 3178     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -1.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.392    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.84e+05 |\n",
      "|    total_cost         | 2.54e+04 |\n",
      "|    total_reward       | 3.84e+05 |\n",
      "|    total_reward_pct   | 76.7     |\n",
      "|    total_trades       | 3202     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -4.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -1.79    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.774    |\n",
      "------------------------------------\n",
      "day: 249, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 816649.86\n",
      "total_reward: 316649.86\n",
      "total_cost: 35288.66\n",
      "total_trades: 3218\n",
      "Sharpe: 1.232\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.53e+05 |\n",
      "|    total_cost         | 3.09e+04 |\n",
      "|    total_reward       | 5.29e+04 |\n",
      "|    total_reward_pct   | 10.6     |\n",
      "|    total_trades       | 3179     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -45.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -4.11    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.803    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.57e+05 |\n",
      "|    total_cost         | 2.89e+04 |\n",
      "|    total_reward       | 3.57e+05 |\n",
      "|    total_reward_pct   | 71.4     |\n",
      "|    total_trades       | 2998     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0.574    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "day: 249, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 882751.13\n",
      "total_reward: 382751.13\n",
      "total_cost: 22154.56\n",
      "total_trades: 2870\n",
      "Sharpe: 1.600\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.83e+05 |\n",
      "|    total_cost         | 2.22e+04 |\n",
      "|    total_reward       | 3.83e+05 |\n",
      "|    total_reward_pct   | 76.6     |\n",
      "|    total_trades       | 2870     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -8.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 3.62     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.747    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.5e+05  |\n",
      "|    total_cost         | 2.65e+04 |\n",
      "|    total_reward       | 3.5e+05  |\n",
      "|    total_reward_pct   | 70.1     |\n",
      "|    total_trades       | 2973     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -4.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -36.7    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.65e+05 |\n",
      "|    total_cost         | 2.15e+04 |\n",
      "|    total_reward       | 4.65e+05 |\n",
      "|    total_reward_pct   | 93       |\n",
      "|    total_trades       | 2966     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -1.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -27      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "day: 249, episode: 255\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 767462.39\n",
      "total_reward: 267462.39\n",
      "total_cost: 12724.16\n",
      "total_trades: 2976\n",
      "Sharpe: 2.008\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.2e+05  |\n",
      "|    total_cost         | 2.26e+04 |\n",
      "|    total_reward       | 2.2e+05  |\n",
      "|    total_reward_pct   | 44.1     |\n",
      "|    total_trades       | 3030     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -20.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -1.62    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.75e+05 |\n",
      "|    total_cost         | 2.46e+04 |\n",
      "|    total_reward       | 7.51e+04 |\n",
      "|    total_reward_pct   | 15       |\n",
      "|    total_trades       | 2947     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -4.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.374    |\n",
      "------------------------------------\n",
      "day: 249, episode: 260\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 598506.87\n",
      "total_reward: 98506.87\n",
      "total_cost: 23709.83\n",
      "total_trades: 2865\n",
      "Sharpe: 0.574\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.99e+05 |\n",
      "|    total_cost         | 2.37e+04 |\n",
      "|    total_reward       | 9.85e+04 |\n",
      "|    total_reward_pct   | 19.7     |\n",
      "|    total_trades       | 2865     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.309    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -18.4    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.442    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.21e+05 |\n",
      "|    total_cost         | 3.16e+04 |\n",
      "|    total_reward       | 1.21e+05 |\n",
      "|    total_reward_pct   | 24.2     |\n",
      "|    total_trades       | 2930     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0.322    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 5.94     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.454    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.63e+05  |\n",
      "|    total_cost         | 2.33e+04  |\n",
      "|    total_reward       | -3.72e+04 |\n",
      "|    total_reward_pct   | -7.45     |\n",
      "|    total_trades       | 2776      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | -0.442    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -7.76     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.29      |\n",
      "-------------------------------------\n",
      "day: 249, episode: 265\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 784413.53\n",
      "total_reward: 284413.53\n",
      "total_cost: 32834.11\n",
      "total_trades: 2833\n",
      "Sharpe: 1.079\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.4e+05  |\n",
      "|    total_cost         | 3.8e+04  |\n",
      "|    total_reward       | 1.4e+05  |\n",
      "|    total_reward_pct   | 27.9     |\n",
      "|    total_trades       | 2830     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -0.826   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -19.4    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.551    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.33e+05 |\n",
      "|    total_cost         | 4.97e+04 |\n",
      "|    total_reward       | 3.33e+05 |\n",
      "|    total_reward_pct   | 66.6     |\n",
      "|    total_trades       | 2847     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -1.84    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -41.4    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "day: 249, episode: 270\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 754824.57\n",
      "total_reward: 254824.57\n",
      "total_cost: 41016.51\n",
      "total_trades: 2769\n",
      "Sharpe: 1.058\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.55e+05 |\n",
      "|    total_cost         | 4.1e+04  |\n",
      "|    total_reward       | 2.55e+05 |\n",
      "|    total_reward_pct   | 51       |\n",
      "|    total_trades       | 2769     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.349    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -8.74    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.628    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.02e+05 |\n",
      "|    total_cost         | 3.26e+04 |\n",
      "|    total_reward       | 3.02e+05 |\n",
      "|    total_reward_pct   | 60.3     |\n",
      "|    total_trades       | 2700     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.203    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -17      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.375    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.72e+05 |\n",
      "|    total_cost         | 4.22e+04 |\n",
      "|    total_reward       | 2.72e+05 |\n",
      "|    total_reward_pct   | 54.4     |\n",
      "|    total_trades       | 2630     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -1.87    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -24.3    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.863    |\n",
      "------------------------------------\n",
      "day: 249, episode: 275\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 949018.99\n",
      "total_reward: 449018.99\n",
      "total_cost: 51388.43\n",
      "total_trades: 2727\n",
      "Sharpe: 1.517\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.27e+05 |\n",
      "|    total_cost         | 2.47e+04 |\n",
      "|    total_reward       | 2.27e+05 |\n",
      "|    total_reward_pct   | 45.5     |\n",
      "|    total_trades       | 2633     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -5.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -3.34    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.361    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.21e+05 |\n",
      "|    total_cost         | 2.69e+04 |\n",
      "|    total_reward       | 4.21e+05 |\n",
      "|    total_reward_pct   | 84.2     |\n",
      "|    total_trades       | 2663     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.512    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 7.17     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.258    |\n",
      "------------------------------------\n",
      "day: 249, episode: 280\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 958057.12\n",
      "total_reward: 458057.12\n",
      "total_cost: 32672.06\n",
      "total_trades: 2619\n",
      "Sharpe: 1.483\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.58e+05 |\n",
      "|    total_cost         | 3.27e+04 |\n",
      "|    total_reward       | 4.58e+05 |\n",
      "|    total_reward_pct   | 91.6     |\n",
      "|    total_trades       | 2619     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -2.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -12.5    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.3e+05  |\n",
      "|    total_cost         | 3.03e+04 |\n",
      "|    total_reward       | 4.3e+05  |\n",
      "|    total_reward_pct   | 86       |\n",
      "|    total_trades       | 2636     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -6.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -35.8    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.56e+05 |\n",
      "|    total_cost         | 2.87e+04 |\n",
      "|    total_reward       | 4.56e+05 |\n",
      "|    total_reward_pct   | 91.3     |\n",
      "|    total_trades       | 2615     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -1.58    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -23.5    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "day: 249, episode: 285\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 866331.61\n",
      "total_reward: 366331.61\n",
      "total_cost: 22996.01\n",
      "total_trades: 2626\n",
      "Sharpe: 1.791\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.29e+05 |\n",
      "|    total_cost         | 2.3e+04  |\n",
      "|    total_reward       | 3.29e+05 |\n",
      "|    total_reward_pct   | 65.8     |\n",
      "|    total_trades       | 2602     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0.405    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.351    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.72e+05 |\n",
      "|    total_cost         | 3e+04    |\n",
      "|    total_reward       | 3.72e+05 |\n",
      "|    total_reward_pct   | 74.4     |\n",
      "|    total_trades       | 2515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -3.6     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 28.4     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "day: 249, episode: 290\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 879310.49\n",
      "total_reward: 379310.49\n",
      "total_cost: 34048.81\n",
      "total_trades: 2589\n",
      "Sharpe: 1.309\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.79e+05 |\n",
      "|    total_cost         | 3.4e+04  |\n",
      "|    total_reward       | 3.79e+05 |\n",
      "|    total_reward_pct   | 75.9     |\n",
      "|    total_trades       | 2589     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -1.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -1.4     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.985    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.85e+05 |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | 3.85e+05 |\n",
      "|    total_reward_pct   | 77.1     |\n",
      "|    total_trades       | 2604     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.672   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.515   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.439    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.42e+05 |\n",
      "|    total_cost         | 2.36e+04 |\n",
      "|    total_reward       | 3.42e+05 |\n",
      "|    total_reward_pct   | 68.5     |\n",
      "|    total_trades       | 2568     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.649    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -16.6    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.359    |\n",
      "------------------------------------\n",
      "day: 249, episode: 295\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 960069.32\n",
      "total_reward: 460069.32\n",
      "total_cost: 23704.72\n",
      "total_trades: 2555\n",
      "Sharpe: 1.502\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.5e+05  |\n",
      "|    total_cost         | 2.06e+04 |\n",
      "|    total_reward       | 2.5e+05  |\n",
      "|    total_reward_pct   | 50       |\n",
      "|    total_trades       | 2591     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.697   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.411    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.6e+05  |\n",
      "|    total_cost         | 2.71e+04 |\n",
      "|    total_reward       | 4.6e+05  |\n",
      "|    total_reward_pct   | 92.1     |\n",
      "|    total_trades       | 2625     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -19.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -19.9    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "day: 249, episode: 300\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 965436.60\n",
      "total_reward: 465436.60\n",
      "total_cost: 27512.80\n",
      "total_trades: 2606\n",
      "Sharpe: 1.596\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.65e+05 |\n",
      "|    total_cost         | 2.75e+04 |\n",
      "|    total_reward       | 4.65e+05 |\n",
      "|    total_reward_pct   | 93.1     |\n",
      "|    total_trades       | 2606     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.0181   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.635    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.88e+05 |\n",
      "|    total_cost         | 1.88e+04 |\n",
      "|    total_reward       | 3.88e+05 |\n",
      "|    total_reward_pct   | 77.5     |\n",
      "|    total_trades       | 2671     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.588   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -6       |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.221    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.78e+05 |\n",
      "|    total_cost         | 1.24e+04 |\n",
      "|    total_reward       | 3.78e+05 |\n",
      "|    total_reward_pct   | 75.6     |\n",
      "|    total_trades       | 2739     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -1.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 2.67     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "day: 249, episode: 305\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 920624.71\n",
      "total_reward: 420624.71\n",
      "total_cost: 22677.81\n",
      "total_trades: 2810\n",
      "Sharpe: 1.661\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.66e+05 |\n",
      "|    total_cost         | 1.91e+04 |\n",
      "|    total_reward       | 2.66e+05 |\n",
      "|    total_reward_pct   | 53.2     |\n",
      "|    total_trades       | 2733     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -3.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -6.14    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.58e+05 |\n",
      "|    total_cost         | 1.67e+04 |\n",
      "|    total_reward       | 4.58e+05 |\n",
      "|    total_reward_pct   | 91.7     |\n",
      "|    total_trades       | 2816     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.244    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -6.13    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.494    |\n",
      "------------------------------------\n",
      "day: 249, episode: 310\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 718445.35\n",
      "total_reward: 218445.35\n",
      "total_cost: 16304.59\n",
      "total_trades: 2851\n",
      "Sharpe: 1.048\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.18e+05 |\n",
      "|    total_cost         | 1.63e+04 |\n",
      "|    total_reward       | 2.18e+05 |\n",
      "|    total_reward_pct   | 43.7     |\n",
      "|    total_trades       | 2851     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.397    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -8.13    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.199    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.04e+05 |\n",
      "|    total_cost         | 1.88e+04 |\n",
      "|    total_reward       | 2.04e+05 |\n",
      "|    total_reward_pct   | 40.9     |\n",
      "|    total_trades       | 2840     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.409   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -3.5     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.378    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.96e+05 |\n",
      "|    total_cost         | 2.02e+04 |\n",
      "|    total_reward       | 2.96e+05 |\n",
      "|    total_reward_pct   | 59.2     |\n",
      "|    total_trades       | 2981     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.648    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -32.2    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "day: 249, episode: 315\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 953651.33\n",
      "total_reward: 453651.33\n",
      "total_cost: 14320.05\n",
      "total_trades: 2942\n",
      "Sharpe: 1.500\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.68e+05 |\n",
      "|    total_cost         | 1.22e+04 |\n",
      "|    total_reward       | 1.68e+05 |\n",
      "|    total_reward_pct   | 33.6     |\n",
      "|    total_trades       | 3019     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.717   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 3.61     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.992    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.6e+05  |\n",
      "|    total_cost         | 1.74e+04 |\n",
      "|    total_reward       | 1.6e+05  |\n",
      "|    total_reward_pct   | 32       |\n",
      "|    total_trades       | 2994     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -67.2    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 5.79     |\n",
      "------------------------------------\n",
      "day: 249, episode: 320\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 718238.38\n",
      "total_reward: 218238.38\n",
      "total_cost: 27043.00\n",
      "total_trades: 3036\n",
      "Sharpe: 1.005\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.18e+05 |\n",
      "|    total_cost         | 2.7e+04  |\n",
      "|    total_reward       | 2.18e+05 |\n",
      "|    total_reward_pct   | 43.6     |\n",
      "|    total_trades       | 3036     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.516    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -16      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.368    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.65e+05 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | -3.5e+04 |\n",
      "|    total_reward_pct   | -7.01    |\n",
      "|    total_trades       | 2945     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.187    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.72e+05 |\n",
      "|    total_cost         | 1.48e+04 |\n",
      "|    total_reward       | 1.72e+05 |\n",
      "|    total_reward_pct   | 34.5     |\n",
      "|    total_trades       | 3001     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -1.67    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.299    |\n",
      "------------------------------------\n",
      "day: 249, episode: 325\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 797884.53\n",
      "total_reward: 297884.53\n",
      "total_cost: 21016.84\n",
      "total_trades: 3144\n",
      "Sharpe: 1.421\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.24e+05 |\n",
      "|    total_cost         | 2.38e+04 |\n",
      "|    total_reward       | 2.24e+05 |\n",
      "|    total_reward_pct   | 44.7     |\n",
      "|    total_trades       | 3231     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -3.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.812    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.7e+05  |\n",
      "|    total_cost         | 1.35e+04 |\n",
      "|    total_reward       | 6.98e+04 |\n",
      "|    total_reward_pct   | 14       |\n",
      "|    total_trades       | 3123     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -7.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -26      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "day: 249, episode: 330\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 641817.92\n",
      "total_reward: 141817.92\n",
      "total_cost: 23549.42\n",
      "total_trades: 3097\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.42e+05 |\n",
      "|    total_cost         | 2.35e+04 |\n",
      "|    total_reward       | 1.42e+05 |\n",
      "|    total_reward_pct   | 28.4     |\n",
      "|    total_trades       | 3097     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -2.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -9.92    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.399    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4e+05     |\n",
      "|    total_cost         | 4.67e+03  |\n",
      "|    total_reward       | -9.97e+04 |\n",
      "|    total_reward_pct   | -19.9     |\n",
      "|    total_trades       | 3012      |\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | -26.4     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | -34.8     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 2.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.56e+05  |\n",
      "|    total_cost         | 5.21e+03  |\n",
      "|    total_reward       | -4.44e+04 |\n",
      "|    total_reward_pct   | -8.89     |\n",
      "|    total_trades       | 3102      |\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | -40.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -37.1     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 3.9       |\n",
      "-------------------------------------\n",
      "day: 249, episode: 335\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497526.54\n",
      "total_reward: -2473.46\n",
      "total_cost: 9663.97\n",
      "total_trades: 3180\n",
      "Sharpe: 0.134\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.35e+05 |\n",
      "|    total_cost         | 7.55e+03 |\n",
      "|    total_reward       | 3.46e+04 |\n",
      "|    total_reward_pct   | 6.92     |\n",
      "|    total_trades       | 3087     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -40.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -32.4    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.65e+05 |\n",
      "|    total_cost         | 8.71e+03 |\n",
      "|    total_reward       | 6.5e+04  |\n",
      "|    total_reward_pct   | 13       |\n",
      "|    total_trades       | 3031     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -16.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -29.8    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.41     |\n",
      "------------------------------------\n",
      "day: 249, episode: 340\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 582964.60\n",
      "total_reward: 82964.60\n",
      "total_cost: 9855.58\n",
      "total_trades: 2957\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.83e+05 |\n",
      "|    total_cost         | 9.86e+03 |\n",
      "|    total_reward       | 8.3e+04  |\n",
      "|    total_reward_pct   | 16.6     |\n",
      "|    total_trades       | 2957     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -48.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -21.5    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.07e+05 |\n",
      "|    total_cost         | 5.34e+03 |\n",
      "|    total_reward       | 7.1e+03  |\n",
      "|    total_reward_pct   | 1.42     |\n",
      "|    total_trades       | 2938     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -14.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -30      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.95e+05 |\n",
      "|    total_cost         | 1.64e+04 |\n",
      "|    total_reward       | 1.95e+05 |\n",
      "|    total_reward_pct   | 39       |\n",
      "|    total_trades       | 3115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -4.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -26      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "day: 249, episode: 345\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 666839.84\n",
      "total_reward: 166839.84\n",
      "total_cost: 16144.56\n",
      "total_trades: 3175\n",
      "Sharpe: 0.784\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.68e+05 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 6.8e+04  |\n",
      "|    total_reward_pct   | 13.6     |\n",
      "|    total_trades       | 3161     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -1.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 4.19     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.36e+05 |\n",
      "|    total_cost         | 1.77e+04 |\n",
      "|    total_reward       | 3.36e+05 |\n",
      "|    total_reward_pct   | 67.2     |\n",
      "|    total_trades       | 3119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -1.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -29.3    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "day: 249, episode: 350\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 673944.75\n",
      "total_reward: 173944.75\n",
      "total_cost: 13747.70\n",
      "total_trades: 3078\n",
      "Sharpe: 0.882\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.74e+05 |\n",
      "|    total_cost         | 1.37e+04 |\n",
      "|    total_reward       | 1.74e+05 |\n",
      "|    total_reward_pct   | 34.8     |\n",
      "|    total_trades       | 3078     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -7.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -21.4    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.65e+05 |\n",
      "|    total_cost         | 1.81e+04 |\n",
      "|    total_reward       | 1.65e+05 |\n",
      "|    total_reward_pct   | 32.9     |\n",
      "|    total_trades       | 2985     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -3.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.772    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.17e+05 |\n",
      "|    total_cost         | 2.47e+04 |\n",
      "|    total_reward       | 3.17e+05 |\n",
      "|    total_reward_pct   | 63.3     |\n",
      "|    total_trades       | 3078     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.0163  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -45.1    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "day: 249, episode: 355\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 827314.90\n",
      "total_reward: 327314.90\n",
      "total_cost: 22366.97\n",
      "total_trades: 2975\n",
      "Sharpe: 1.324\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.04e+05 |\n",
      "|    total_cost         | 1.92e+04 |\n",
      "|    total_reward       | 3.72e+03 |\n",
      "|    total_reward_pct   | 0.745    |\n",
      "|    total_trades       | 2974     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -2.3     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 3.77e+04 |\n",
      "|    total_reward       | 5.29e+05 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 3003     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -10.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -40.4    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 4.09     |\n",
      "------------------------------------\n",
      "day: 249, episode: 360\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 910533.26\n",
      "total_reward: 410533.26\n",
      "total_cost: 34943.14\n",
      "total_trades: 2824\n",
      "Sharpe: 1.593\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.11e+05 |\n",
      "|    total_cost         | 3.49e+04 |\n",
      "|    total_reward       | 4.11e+05 |\n",
      "|    total_reward_pct   | 82.1     |\n",
      "|    total_trades       | 2824     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -5.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 12.5     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 5.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.29e+05 |\n",
      "|    total_cost         | 1.44e+04 |\n",
      "|    total_reward       | 1.29e+05 |\n",
      "|    total_reward_pct   | 25.8     |\n",
      "|    total_trades       | 2668     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -5.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -34.8    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.63e+05 |\n",
      "|    total_cost         | 3.47e+04 |\n",
      "|    total_reward       | 3.63e+05 |\n",
      "|    total_reward_pct   | 72.6     |\n",
      "|    total_trades       | 2820     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -72.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -52.9    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 9.5      |\n",
      "------------------------------------\n",
      "day: 249, episode: 365\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 613259.73\n",
      "total_reward: 113259.73\n",
      "total_cost: 19315.95\n",
      "total_trades: 2764\n",
      "Sharpe: 1.039\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+06 |\n",
      "|    total_cost         | 3.76e+04 |\n",
      "|    total_reward       | 5.78e+05 |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 2810     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -2.9     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 30       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.08e+05 |\n",
      "|    total_cost         | 3.39e+04 |\n",
      "|    total_reward       | 4.08e+05 |\n",
      "|    total_reward_pct   | 81.5     |\n",
      "|    total_trades       | 2784     |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.577    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -68      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 5.9      |\n",
      "------------------------------------\n",
      "day: 249, episode: 370\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1016253.57\n",
      "total_reward: 516253.57\n",
      "total_cost: 32610.81\n",
      "total_trades: 2757\n",
      "Sharpe: 1.631\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 3.26e+04 |\n",
      "|    total_reward       | 5.16e+05 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 2757     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -9.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -61.6    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 7.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.92e+05 |\n",
      "|    total_cost         | 3.2e+04  |\n",
      "|    total_reward       | 4.92e+05 |\n",
      "|    total_reward_pct   | 98.3     |\n",
      "|    total_trades       | 2822     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -8.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -56.8    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 4.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.35e+05 |\n",
      "|    total_cost         | 4.07e+04 |\n",
      "|    total_reward       | 4.35e+05 |\n",
      "|    total_reward_pct   | 87       |\n",
      "|    total_trades       | 2800     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -0.0629  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 85.2     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 8.45     |\n",
      "------------------------------------\n",
      "day: 249, episode: 375\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 858094.75\n",
      "total_reward: 358094.75\n",
      "total_cost: 28053.62\n",
      "total_trades: 2763\n",
      "Sharpe: 2.602\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.17e+06 |\n",
      "|    total_cost         | 3.2e+04  |\n",
      "|    total_reward       | 6.65e+05 |\n",
      "|    total_reward_pct   | 133      |\n",
      "|    total_trades       | 2740     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.267    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -103     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.95e+05 |\n",
      "|    total_cost         | 2.64e+04 |\n",
      "|    total_reward       | 4.95e+05 |\n",
      "|    total_reward_pct   | 99.1     |\n",
      "|    total_trades       | 2694     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.31     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -84.8    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 8.64     |\n",
      "------------------------------------\n",
      "day: 249, episode: 380\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1065553.92\n",
      "total_reward: 565553.92\n",
      "total_cost: 34318.93\n",
      "total_trades: 2673\n",
      "Sharpe: 1.758\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 3.43e+04 |\n",
      "|    total_reward       | 5.66e+05 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 2673     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -45.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -73.8    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 7.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+06  |\n",
      "|    total_cost         | 3.3e+04  |\n",
      "|    total_reward       | 5.98e+05 |\n",
      "|    total_reward_pct   | 120      |\n",
      "|    total_trades       | 2674     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.0211   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -68      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.01e+05 |\n",
      "|    total_cost         | 2.39e+04 |\n",
      "|    total_reward       | 3.01e+05 |\n",
      "|    total_reward_pct   | 60.2     |\n",
      "|    total_trades       | 2728     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -0.402   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 73.3     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 6.07     |\n",
      "------------------------------------\n",
      "day: 249, episode: 385\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 960392.08\n",
      "total_reward: 460392.08\n",
      "total_cost: 31800.18\n",
      "total_trades: 2734\n",
      "Sharpe: 1.727\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.81e+05 |\n",
      "|    total_cost         | 4.03e+04 |\n",
      "|    total_reward       | 4.81e+05 |\n",
      "|    total_reward_pct   | 96.2     |\n",
      "|    total_trades       | 2616     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.219    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 90.6     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 9.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.27e+05 |\n",
      "|    total_cost         | 3.59e+04 |\n",
      "|    total_reward       | 3.27e+05 |\n",
      "|    total_reward_pct   | 65.5     |\n",
      "|    total_trades       | 2452     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -9.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 23.3     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "day: 249, episode: 390\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 867413.04\n",
      "total_reward: 367413.04\n",
      "total_cost: 32783.18\n",
      "total_trades: 2551\n",
      "Sharpe: 1.572\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.67e+05 |\n",
      "|    total_cost         | 3.28e+04 |\n",
      "|    total_reward       | 3.67e+05 |\n",
      "|    total_reward_pct   | 73.5     |\n",
      "|    total_trades       | 2551     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -5.56    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -84.6    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 9.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.45e+05 |\n",
      "|    total_cost         | 3.22e+04 |\n",
      "|    total_reward       | 3.45e+05 |\n",
      "|    total_reward_pct   | 69       |\n",
      "|    total_trades       | 2613     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -9.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 29.3     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.6e+05  |\n",
      "|    total_cost         | 3.63e+04 |\n",
      "|    total_reward       | 3.6e+05  |\n",
      "|    total_reward_pct   | 71.9     |\n",
      "|    total_trades       | 2619     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.103    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 49.4     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "day: 249, episode: 395\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 714562.65\n",
      "total_reward: 214562.65\n",
      "total_cost: 25899.51\n",
      "total_trades: 2656\n",
      "Sharpe: 1.674\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.64e+05 |\n",
      "|    total_cost         | 4.19e+04 |\n",
      "|    total_reward       | 3.64e+05 |\n",
      "|    total_reward_pct   | 72.8     |\n",
      "|    total_trades       | 2618     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -24.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 92.5     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 17.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 3.25e+04 |\n",
      "|    total_reward       | 5.05e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 2666     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -9.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -51.5    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 6.08     |\n",
      "------------------------------------\n",
      "day: 249, episode: 400\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 958749.87\n",
      "total_reward: 458749.87\n",
      "total_cost: 27096.29\n",
      "total_trades: 2764\n",
      "Sharpe: 1.541\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.59e+05 |\n",
      "|    total_cost         | 2.71e+04 |\n",
      "|    total_reward       | 4.59e+05 |\n",
      "|    total_reward_pct   | 91.7     |\n",
      "|    total_trades       | 2764     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -8.18    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -46      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-01-03 to  2019-04-04\n",
      "A2C Sharpe Ratio:  nan\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_1\n",
      "day: 249, episode: 405\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 321478.34\n",
      "total_reward: -178521.66\n",
      "total_cost: 126047.87\n",
      "total_trades: 3610\n",
      "Sharpe: -1.303\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.58e+05  |\n",
      "|    total_cost       | 1.7e+05   |\n",
      "|    total_reward     | -4.16e+04 |\n",
      "|    total_reward_pct | -8.31     |\n",
      "|    total_trades     | 3719      |\n",
      "| time/               |           |\n",
      "|    fps              | 909       |\n",
      "|    iterations       | 1         |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 2048      |\n",
      "-----------------------------------\n",
      "day: 249, episode: 410\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 360557.27\n",
      "total_reward: -139442.73\n",
      "total_cost: 146717.54\n",
      "total_trades: 3673\n",
      "Sharpe: -0.942\n",
      "=================================\n",
      "day: 249, episode: 415\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 259035.48\n",
      "total_reward: -240964.52\n",
      "total_cost: 114833.94\n",
      "total_trades: 3528\n",
      "Sharpe: -1.520\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+05    |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | -1.64e+05   |\n",
      "|    total_reward_pct     | -32.9       |\n",
      "|    total_trades         | 3738        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 844         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014361619 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.524       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 420\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 548792.61\n",
      "total_reward: 48792.61\n",
      "total_cost: 194243.00\n",
      "total_trades: 3786\n",
      "Sharpe: 0.413\n",
      "=================================\n",
      "day: 249, episode: 425\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 330584.84\n",
      "total_reward: -169415.16\n",
      "total_cost: 125737.03\n",
      "total_trades: 3749\n",
      "Sharpe: -1.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+05    |\n",
      "|    total_cost           | 1.26e+05    |\n",
      "|    total_reward         | -1.69e+05   |\n",
      "|    total_reward_pct     | -33.9       |\n",
      "|    total_trades         | 3749        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 824         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017728252 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.00609    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.611       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 430\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499227.24\n",
      "total_reward: -772.76\n",
      "total_cost: 136192.05\n",
      "total_trades: 3731\n",
      "Sharpe: 0.094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.29e+05    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | -7.12e+04   |\n",
      "|    total_reward_pct     | -14.2       |\n",
      "|    total_trades         | 3610        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 810         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011294153 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0507      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.11        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 435\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 379380.21\n",
      "total_reward: -120619.79\n",
      "total_cost: 131768.92\n",
      "total_trades: 3694\n",
      "Sharpe: -0.766\n",
      "=================================\n",
      "day: 249, episode: 440\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 468358.84\n",
      "total_reward: -31641.16\n",
      "total_cost: 186111.73\n",
      "total_trades: 3758\n",
      "Sharpe: 0.046\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.13e+05    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | 2.13e+05    |\n",
      "|    total_reward_pct     | 42.5        |\n",
      "|    total_trades         | 3876        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 804         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012875065 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0565      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.659       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.98        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 445\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 357988.96\n",
      "total_reward: -142011.04\n",
      "total_cost: 131097.52\n",
      "total_trades: 3597\n",
      "Sharpe: -0.949\n",
      "=================================\n",
      "day: 249, episode: 450\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 286619.47\n",
      "total_reward: -213380.53\n",
      "total_cost: 111217.44\n",
      "total_trades: 3585\n",
      "Sharpe: -1.277\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+05    |\n",
      "|    total_cost           | 1.11e+05    |\n",
      "|    total_reward         | -2.13e+05   |\n",
      "|    total_reward_pct     | -42.7       |\n",
      "|    total_trades         | 3585        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 799         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010572286 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.63        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 455\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 430911.92\n",
      "total_reward: -69088.08\n",
      "total_cost: 128588.69\n",
      "total_trades: 3664\n",
      "Sharpe: -0.573\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5e+05       |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | -83.3       |\n",
      "|    total_reward_pct     | -0.0167     |\n",
      "|    total_trades         | 3756        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 794         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004020674 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.76        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.89        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 460\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 716085.68\n",
      "total_reward: 216085.68\n",
      "total_cost: 216259.23\n",
      "total_trades: 3824\n",
      "Sharpe: 1.025\n",
      "=================================\n",
      "day: 249, episode: 465\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 580017.69\n",
      "total_reward: 80017.69\n",
      "total_cost: 141606.07\n",
      "total_trades: 3580\n",
      "Sharpe: 0.844\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+05    |\n",
      "|    total_cost           | 1.12e+05    |\n",
      "|    total_reward         | -2.01e+05   |\n",
      "|    total_reward_pct     | -40.2       |\n",
      "|    total_trades         | 3722        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016180262 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.575       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 470\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 559237.42\n",
      "total_reward: 59237.42\n",
      "total_cost: 122887.21\n",
      "total_trades: 3640\n",
      "Sharpe: 0.637\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.91e+05   |\n",
      "|    total_cost           | 1.88e+05   |\n",
      "|    total_reward         | 2.91e+05   |\n",
      "|    total_reward_pct     | 58.1       |\n",
      "|    total_trades         | 3738       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 792        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02241999 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.165      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.28       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.05       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 475\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 544196.75\n",
      "total_reward: 44196.75\n",
      "total_cost: 165625.89\n",
      "total_trades: 3678\n",
      "Sharpe: 0.479\n",
      "=================================\n",
      "day: 249, episode: 480\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 373151.32\n",
      "total_reward: -126848.68\n",
      "total_cost: 106997.62\n",
      "total_trades: 3640\n",
      "Sharpe: -0.893\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.55e+05    |\n",
      "|    total_cost           | 1.21e+05    |\n",
      "|    total_reward         | -1.45e+05   |\n",
      "|    total_reward_pct     | -29         |\n",
      "|    total_trades         | 3566        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 792         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019027477 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.744       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 485\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 782465.16\n",
      "total_reward: 282465.16\n",
      "total_cost: 179447.50\n",
      "total_trades: 3740\n",
      "Sharpe: 1.100\n",
      "=================================\n",
      "day: 249, episode: 490\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 597135.06\n",
      "total_reward: 97135.06\n",
      "total_cost: 172909.93\n",
      "total_trades: 3699\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.35e+05    |\n",
      "|    total_cost           | 1.67e+05    |\n",
      "|    total_reward         | 1.35e+05    |\n",
      "|    total_reward_pct     | 27.1        |\n",
      "|    total_trades         | 3711        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 792         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017368324 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.759       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 495\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 387594.54\n",
      "total_reward: -112405.46\n",
      "total_cost: 106682.89\n",
      "total_trades: 3551\n",
      "Sharpe: -0.813\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.89e+05    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 1.89e+05    |\n",
      "|    total_reward_pct     | 37.8        |\n",
      "|    total_trades         | 3708        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025486816 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 500\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 582611.00\n",
      "total_reward: 82611.00\n",
      "total_cost: 148848.06\n",
      "total_trades: 3655\n",
      "Sharpe: 0.640\n",
      "=================================\n",
      "day: 249, episode: 505\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 456182.02\n",
      "total_reward: -43817.98\n",
      "total_cost: 107977.89\n",
      "total_trades: 3560\n",
      "Sharpe: -0.233\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.8e+05     |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | 8e+04       |\n",
      "|    total_reward_pct     | 16          |\n",
      "|    total_trades         | 3721        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026915645 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.947       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 510\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 435381.62\n",
      "total_reward: -64618.38\n",
      "total_cost: 115373.71\n",
      "total_trades: 3560\n",
      "Sharpe: -0.334\n",
      "=================================\n",
      "day: 249, episode: 515\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 646226.67\n",
      "total_reward: 146226.67\n",
      "total_cost: 187413.49\n",
      "total_trades: 3727\n",
      "Sharpe: 1.154\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.46e+05    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | 1.46e+05    |\n",
      "|    total_reward_pct     | 29.2        |\n",
      "|    total_trades         | 3727        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 794         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014043588 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.36        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 520\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 613653.95\n",
      "total_reward: 113653.95\n",
      "total_cost: 122571.11\n",
      "total_trades: 3658\n",
      "Sharpe: 1.106\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.27e+05   |\n",
      "|    total_cost           | 1.3e+05    |\n",
      "|    total_reward         | 2.66e+04   |\n",
      "|    total_reward_pct     | 5.31       |\n",
      "|    total_trades         | 3732       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 794        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03360073 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.119      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.772      |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 2.98       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 525\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 788574.13\n",
      "total_reward: 288574.13\n",
      "total_cost: 122425.13\n",
      "total_trades: 3640\n",
      "Sharpe: 1.111\n",
      "=================================\n",
      "day: 249, episode: 530\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 418960.03\n",
      "total_reward: -81039.97\n",
      "total_cost: 83963.91\n",
      "total_trades: 3471\n",
      "Sharpe: -0.248\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.96e+05    |\n",
      "|    total_cost           | 9.17e+04    |\n",
      "|    total_reward         | 1.96e+05    |\n",
      "|    total_reward_pct     | 39.1        |\n",
      "|    total_trades         | 3537        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035439447 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.442       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.71        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 535\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 822180.16\n",
      "total_reward: 322180.16\n",
      "total_cost: 137282.27\n",
      "total_trades: 3732\n",
      "Sharpe: 1.364\n",
      "=================================\n",
      "day: 249, episode: 540\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 612816.41\n",
      "total_reward: 112816.41\n",
      "total_cost: 104489.14\n",
      "total_trades: 3601\n",
      "Sharpe: 1.100\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 6.13e+05  |\n",
      "|    total_cost           | 1.04e+05  |\n",
      "|    total_reward         | 1.13e+05  |\n",
      "|    total_reward_pct     | 22.6      |\n",
      "|    total_trades         | 3601      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 793       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0265309 |\n",
      "|    clip_fraction        | 0.229     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.3     |\n",
      "|    explained_variance   | 0.13      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 2.31      |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.0149   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 4.12      |\n",
      "---------------------------------------\n",
      "day: 249, episode: 545\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 790840.49\n",
      "total_reward: 290840.49\n",
      "total_cost: 126186.71\n",
      "total_trades: 3602\n",
      "Sharpe: 1.333\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.26e+05    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 2.62e+04    |\n",
      "|    total_reward_pct     | 5.24        |\n",
      "|    total_trades         | 3702        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025629792 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.88        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 550\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 946976.53\n",
      "total_reward: 446976.53\n",
      "total_cost: 155886.78\n",
      "total_trades: 3770\n",
      "Sharpe: 1.746\n",
      "=================================\n",
      "day: 249, episode: 555\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 449212.29\n",
      "total_reward: -50787.71\n",
      "total_cost: 76947.70\n",
      "total_trades: 3457\n",
      "Sharpe: -0.146\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.77e+05    |\n",
      "|    total_cost           | 1.28e+05    |\n",
      "|    total_reward         | 4.77e+05    |\n",
      "|    total_reward_pct     | 95.4        |\n",
      "|    total_trades         | 3692        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 792         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030407775 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.3         |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 560\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 842330.25\n",
      "total_reward: 342330.25\n",
      "total_cost: 109785.69\n",
      "total_trades: 3626\n",
      "Sharpe: 1.537\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.86e+05   |\n",
      "|    total_cost           | 8.16e+04   |\n",
      "|    total_reward         | 8.58e+04   |\n",
      "|    total_reward_pct     | 17.2       |\n",
      "|    total_trades         | 3467       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 789        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01709887 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.197      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.41       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 5.02       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 565\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 873209.45\n",
      "total_reward: 373209.45\n",
      "total_cost: 144770.27\n",
      "total_trades: 3678\n",
      "Sharpe: 1.365\n",
      "=================================\n",
      "day: 249, episode: 570\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 504638.28\n",
      "total_reward: 4638.28\n",
      "total_cost: 67580.34\n",
      "total_trades: 3381\n",
      "Sharpe: 0.246\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.14e+05    |\n",
      "|    total_cost           | 1.91e+05    |\n",
      "|    total_reward         | 2.14e+05    |\n",
      "|    total_reward_pct     | 42.9        |\n",
      "|    total_trades         | 3665        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 788         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022327445 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.04        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 575\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 843288.12\n",
      "total_reward: 343288.12\n",
      "total_cost: 113829.60\n",
      "total_trades: 3546\n",
      "Sharpe: 1.584\n",
      "=================================\n",
      "day: 249, episode: 580\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 920812.35\n",
      "total_reward: 420812.35\n",
      "total_cost: 125121.70\n",
      "total_trades: 3427\n",
      "Sharpe: 1.661\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.51e+05   |\n",
      "|    total_cost           | 8.23e+04   |\n",
      "|    total_reward         | -1.49e+05  |\n",
      "|    total_reward_pct     | -29.8      |\n",
      "|    total_trades         | 3527       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 788        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02965612 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.69       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 5.49       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 585\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 678936.98\n",
      "total_reward: 178936.98\n",
      "total_cost: 91318.41\n",
      "total_trades: 3504\n",
      "Sharpe: 1.548\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.22e+05   |\n",
      "|    total_cost           | 8.99e+04   |\n",
      "|    total_reward         | 2.16e+04   |\n",
      "|    total_reward_pct     | 4.33       |\n",
      "|    total_trades         | 3389       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 787        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 59         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03253365 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.19       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0094    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 5.22       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 590\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 608210.32\n",
      "total_reward: 108210.32\n",
      "total_cost: 103319.90\n",
      "total_trades: 3454\n",
      "Sharpe: 0.955\n",
      "=================================\n",
      "day: 249, episode: 595\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 891891.99\n",
      "total_reward: 391891.99\n",
      "total_cost: 142254.60\n",
      "total_trades: 3490\n",
      "Sharpe: 1.540\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.54e+05    |\n",
      "|    total_cost           | 1.08e+05    |\n",
      "|    total_reward         | 5.44e+04    |\n",
      "|    total_reward_pct     | 10.9        |\n",
      "|    total_trades         | 3489        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024054464 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.99        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 600\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 575866.42\n",
      "total_reward: 75866.42\n",
      "total_cost: 78296.66\n",
      "total_trades: 3407\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "day: 249, episode: 605\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 755740.05\n",
      "total_reward: 255740.05\n",
      "total_cost: 108831.80\n",
      "total_trades: 3511\n",
      "Sharpe: 1.625\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.56e+05    |\n",
      "|    total_cost           | 1.09e+05    |\n",
      "|    total_reward         | 2.56e+05    |\n",
      "|    total_reward_pct     | 51.1        |\n",
      "|    total_trades         | 3511        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 783         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021780249 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.97        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 610\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 978086.46\n",
      "total_reward: 478086.46\n",
      "total_cost: 129081.38\n",
      "total_trades: 3524\n",
      "Sharpe: 1.530\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.07e+06   |\n",
      "|    total_cost           | 1.03e+05   |\n",
      "|    total_reward         | 5.71e+05   |\n",
      "|    total_reward_pct     | 114        |\n",
      "|    total_trades         | 3494       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 781        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02916567 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.17       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 3.99       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 615\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 876057.26\n",
      "total_reward: 376057.26\n",
      "total_cost: 138547.06\n",
      "total_trades: 3417\n",
      "Sharpe: 1.276\n",
      "=================================\n",
      "day: 249, episode: 620\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 934692.27\n",
      "total_reward: 434692.27\n",
      "total_cost: 129274.12\n",
      "total_trades: 3431\n",
      "Sharpe: 1.560\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.49e+05    |\n",
      "|    total_cost           | 1.02e+05    |\n",
      "|    total_reward         | -5.06e+04   |\n",
      "|    total_reward_pct     | -10.1       |\n",
      "|    total_trades         | 3417        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 780         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015929792 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.67        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 625\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 923278.18\n",
      "total_reward: 423278.18\n",
      "total_cost: 94361.66\n",
      "total_trades: 3369\n",
      "Sharpe: 2.216\n",
      "=================================\n",
      "day: 249, episode: 630\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 704367.72\n",
      "total_reward: 204367.72\n",
      "total_cost: 77519.20\n",
      "total_trades: 3371\n",
      "Sharpe: 1.326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.04e+05    |\n",
      "|    total_cost           | 7.75e+04    |\n",
      "|    total_reward         | 2.04e+05    |\n",
      "|    total_reward_pct     | 40.9        |\n",
      "|    total_trades         | 3371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 779         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017235117 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.85        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6           |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 635\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 535850.79\n",
      "total_reward: 35850.79\n",
      "total_cost: 54548.59\n",
      "total_trades: 3302\n",
      "Sharpe: 0.409\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+06    |\n",
      "|    total_cost           | 1.19e+05    |\n",
      "|    total_reward         | 5.67e+05    |\n",
      "|    total_reward_pct     | 113         |\n",
      "|    total_trades         | 3528        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 778         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019580008 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.07        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.79        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 640\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 970859.39\n",
      "total_reward: 470859.39\n",
      "total_cost: 80495.74\n",
      "total_trades: 3345\n",
      "Sharpe: 1.489\n",
      "=================================\n",
      "day: 249, episode: 645\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 509440.53\n",
      "total_reward: 9440.53\n",
      "total_cost: 66802.87\n",
      "total_trades: 3359\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.65e+05    |\n",
      "|    total_cost           | 1.05e+05    |\n",
      "|    total_reward         | 4.65e+05    |\n",
      "|    total_reward_pct     | 92.9        |\n",
      "|    total_trades         | 3433        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 777         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009555102 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.67        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 650\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1017583.43\n",
      "total_reward: 517583.43\n",
      "total_cost: 95641.77\n",
      "total_trades: 3441\n",
      "Sharpe: 1.848\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.38e+05    |\n",
      "|    total_cost           | 1.11e+05    |\n",
      "|    total_reward         | 4.38e+05    |\n",
      "|    total_reward_pct     | 87.6        |\n",
      "|    total_trades         | 3480        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019842781 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.42        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 655\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 965233.01\n",
      "total_reward: 465233.01\n",
      "total_cost: 80608.71\n",
      "total_trades: 3488\n",
      "Sharpe: 1.752\n",
      "=================================\n",
      "day: 249, episode: 660\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1135916.36\n",
      "total_reward: 635916.36\n",
      "total_cost: 99048.59\n",
      "total_trades: 3499\n",
      "Sharpe: 2.091\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.84e+05    |\n",
      "|    total_cost           | 1.05e+05    |\n",
      "|    total_reward         | 4.84e+05    |\n",
      "|    total_reward_pct     | 96.9        |\n",
      "|    total_trades         | 3439        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018794812 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.83        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.6         |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 665\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1036624.56\n",
      "total_reward: 536624.56\n",
      "total_cost: 114035.16\n",
      "total_trades: 3541\n",
      "Sharpe: 1.662\n",
      "=================================\n",
      "day: 249, episode: 670\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 718617.78\n",
      "total_reward: 218617.78\n",
      "total_cost: 103929.54\n",
      "total_trades: 3458\n",
      "Sharpe: 1.735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+06    |\n",
      "|    total_cost           | 8.92e+04    |\n",
      "|    total_reward         | 6.18e+05    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 3377        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032200042 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.8         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.24        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 675\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1038557.16\n",
      "total_reward: 538557.16\n",
      "total_cost: 101443.11\n",
      "total_trades: 3512\n",
      "Sharpe: 1.753\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.04e+06   |\n",
      "|    total_cost           | 8.32e+04   |\n",
      "|    total_reward         | 5.4e+05    |\n",
      "|    total_reward_pct     | 108        |\n",
      "|    total_trades         | 3445       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 777        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04258971 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.57       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.96       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00104   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 5.63       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 680\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1065379.06\n",
      "total_reward: 565379.06\n",
      "total_cost: 110283.12\n",
      "total_trades: 3520\n",
      "Sharpe: 1.790\n",
      "=================================\n",
      "day: 249, episode: 685\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1101792.02\n",
      "total_reward: 601792.02\n",
      "total_cost: 81080.34\n",
      "total_trades: 3453\n",
      "Sharpe: 1.801\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.45e+05    |\n",
      "|    total_cost           | 9.33e+04    |\n",
      "|    total_reward         | 1.45e+05    |\n",
      "|    total_reward_pct     | 29          |\n",
      "|    total_trades         | 3389        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023676226 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.87        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 690\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 895413.46\n",
      "total_reward: 395413.46\n",
      "total_cost: 73155.58\n",
      "total_trades: 3385\n",
      "Sharpe: 1.878\n",
      "=================================\n",
      "day: 249, episode: 695\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1173225.60\n",
      "total_reward: 673225.60\n",
      "total_cost: 87521.04\n",
      "total_trades: 3404\n",
      "Sharpe: 1.964\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+06    |\n",
      "|    total_cost           | 8.75e+04    |\n",
      "|    total_reward         | 6.73e+05    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 3404        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035734236 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.18        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.51        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 700\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1017501.47\n",
      "total_reward: 517501.47\n",
      "total_cost: 105766.89\n",
      "total_trades: 3444\n",
      "Sharpe: 1.887\n",
      "=================================\n",
      "--------------------------------------\n",
      "| environment/            |          |\n",
      "|    portfolio_value      | 1.12e+06 |\n",
      "|    total_cost           | 8.33e+04 |\n",
      "|    total_reward         | 6.22e+05 |\n",
      "|    total_reward_pct     | 124      |\n",
      "|    total_trades         | 3492     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 776      |\n",
      "|    iterations           | 37       |\n",
      "|    time_elapsed         | 97       |\n",
      "|    total_timesteps      | 75776    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.022813 |\n",
      "|    clip_fraction        | 0.288    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -27.7    |\n",
      "|    explained_variance   | 0.634    |\n",
      "|    learning_rate        | 0.00025  |\n",
      "|    loss                 | 4.39     |\n",
      "|    n_updates            | 360      |\n",
      "|    policy_gradient_loss | -0.00639 |\n",
      "|    std                  | 1.04     |\n",
      "|    value_loss           | 6.48     |\n",
      "--------------------------------------\n",
      "day: 249, episode: 705\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1165587.48\n",
      "total_reward: 665587.48\n",
      "total_cost: 103486.12\n",
      "total_trades: 3513\n",
      "Sharpe: 1.922\n",
      "=================================\n",
      "day: 249, episode: 710\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1166377.23\n",
      "total_reward: 666377.23\n",
      "total_cost: 97579.67\n",
      "total_trades: 3451\n",
      "Sharpe: 2.146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.2e+06    |\n",
      "|    total_cost           | 9.48e+04   |\n",
      "|    total_reward         | 7.02e+05   |\n",
      "|    total_reward_pct     | 140        |\n",
      "|    total_trades         | 3438       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 776        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03797261 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.23       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00429   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 7.3        |\n",
      "----------------------------------------\n",
      "day: 249, episode: 715\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1142410.47\n",
      "total_reward: 642410.47\n",
      "total_cost: 105920.37\n",
      "total_trades: 3483\n",
      "Sharpe: 1.843\n",
      "=================================\n",
      "day: 249, episode: 720\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 641562.32\n",
      "total_reward: 141562.32\n",
      "total_cost: 72837.07\n",
      "total_trades: 3393\n",
      "Sharpe: 1.186\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.42e+05    |\n",
      "|    total_cost           | 7.28e+04    |\n",
      "|    total_reward         | 1.42e+05    |\n",
      "|    total_reward_pct     | 28.3        |\n",
      "|    total_trades         | 3393        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 777         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034895465 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.76        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 725\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1233048.78\n",
      "total_reward: 733048.78\n",
      "total_cost: 96440.39\n",
      "total_trades: 3417\n",
      "Sharpe: 2.214\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.14e+06    |\n",
      "|    total_cost           | 1.03e+05    |\n",
      "|    total_reward         | 6.36e+05    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 3491        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030266056 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.13        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.97        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 730\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1139997.67\n",
      "total_reward: 639997.67\n",
      "total_cost: 92254.65\n",
      "total_trades: 3441\n",
      "Sharpe: 2.264\n",
      "=================================\n",
      "day: 249, episode: 735\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1180893.49\n",
      "total_reward: 680893.49\n",
      "total_cost: 88795.89\n",
      "total_trades: 3431\n",
      "Sharpe: 2.202\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.72e+05    |\n",
      "|    total_cost           | 8.82e+04    |\n",
      "|    total_reward         | 4.72e+05    |\n",
      "|    total_reward_pct     | 94.4        |\n",
      "|    total_trades         | 3529        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 777         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023539975 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.15        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.09        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 740\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1088486.65\n",
      "total_reward: 588486.65\n",
      "total_cost: 100915.21\n",
      "total_trades: 3424\n",
      "Sharpe: 1.912\n",
      "=================================\n",
      "day: 249, episode: 745\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1109009.68\n",
      "total_reward: 609009.68\n",
      "total_cost: 97126.44\n",
      "total_trades: 3478\n",
      "Sharpe: 1.924\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+06    |\n",
      "|    total_cost           | 9.71e+04    |\n",
      "|    total_reward         | 6.09e+05    |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 3478        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038221285 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.68        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 750\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1214092.27\n",
      "total_reward: 714092.27\n",
      "total_cost: 109454.81\n",
      "total_trades: 3519\n",
      "Sharpe: 1.931\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+06    |\n",
      "|    total_cost           | 8.93e+04    |\n",
      "|    total_reward         | 6.9e+05     |\n",
      "|    total_reward_pct     | 138         |\n",
      "|    total_trades         | 3388        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061226573 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.41        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.81        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 755\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 937704.34\n",
      "total_reward: 437704.34\n",
      "total_cost: 89129.06\n",
      "total_trades: 3464\n",
      "Sharpe: 1.669\n",
      "=================================\n",
      "day: 249, episode: 760\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1116683.23\n",
      "total_reward: 616683.23\n",
      "total_cost: 81755.91\n",
      "total_trades: 3441\n",
      "Sharpe: 1.907\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.27e+05   |\n",
      "|    total_cost           | 6.77e+04   |\n",
      "|    total_reward         | 4.27e+05   |\n",
      "|    total_reward_pct     | 85.5       |\n",
      "|    total_trades         | 3351       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 775        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04132721 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.29       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0027    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 6.93       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 765\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1127828.98\n",
      "total_reward: 627828.98\n",
      "total_cost: 92226.43\n",
      "total_trades: 3398\n",
      "Sharpe: 2.138\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 9.86e+05  |\n",
      "|    total_cost           | 7.5e+04   |\n",
      "|    total_reward         | 4.86e+05  |\n",
      "|    total_reward_pct     | 97.2      |\n",
      "|    total_trades         | 3431      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 775       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0476873 |\n",
      "|    clip_fraction        | 0.27      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.9     |\n",
      "|    explained_variance   | 0.672     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.78      |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 0.00198   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 5.96      |\n",
      "---------------------------------------\n",
      "day: 249, episode: 770\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1095561.32\n",
      "total_reward: 595561.32\n",
      "total_cost: 85307.94\n",
      "total_trades: 3372\n",
      "Sharpe: 2.139\n",
      "=================================\n",
      "day: 249, episode: 775\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 868132.55\n",
      "total_reward: 368132.55\n",
      "total_cost: 51189.57\n",
      "total_trades: 3287\n",
      "Sharpe: 2.720\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.96e+05    |\n",
      "|    total_cost           | 1.01e+05    |\n",
      "|    total_reward         | 4.96e+05    |\n",
      "|    total_reward_pct     | 99.3        |\n",
      "|    total_trades         | 3528        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046902433 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.000658   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.13        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 780\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 996139.48\n",
      "total_reward: 496139.48\n",
      "total_cost: 86691.65\n",
      "total_trades: 3414\n",
      "Sharpe: 1.728\n",
      "=================================\n",
      "day: 249, episode: 785\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1085441.59\n",
      "total_reward: 585441.59\n",
      "total_cost: 72335.26\n",
      "total_trades: 3348\n",
      "Sharpe: 1.879\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.82e+05   |\n",
      "|    total_cost           | 5.73e+04   |\n",
      "|    total_reward         | 8.2e+04    |\n",
      "|    total_reward_pct     | 16.4       |\n",
      "|    total_trades         | 3282       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 776        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03440984 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.53       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0078    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 5.35       |\n",
      "----------------------------------------\n",
      "day: 249, episode: 790\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1142712.50\n",
      "total_reward: 642712.50\n",
      "total_cost: 80249.59\n",
      "total_trades: 3366\n",
      "Sharpe: 1.949\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+06    |\n",
      "|    total_cost           | 1.01e+05    |\n",
      "|    total_reward         | 5.24e+05    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 3507        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030715872 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.16        |\n",
      "-----------------------------------------\n",
      "day: 249, episode: 795\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 975792.70\n",
      "total_reward: 475792.70\n",
      "total_cost: 74256.11\n",
      "total_trades: 3306\n",
      "Sharpe: 1.592\n",
      "=================================\n",
      "day: 249, episode: 800\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1209509.38\n",
      "total_reward: 709509.38\n",
      "total_cost: 75733.73\n",
      "total_trades: 3342\n",
      "Sharpe: 2.422\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+06    |\n",
      "|    total_cost           | 6.61e+04    |\n",
      "|    total_reward         | 6.77e+05    |\n",
      "|    total_reward_pct     | 135         |\n",
      "|    total_trades         | 3275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022305524 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.98        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-01-03 to  2019-04-04\n",
      "PPO Sharpe Ratio:  nan\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
      "day: 249, episode: 805\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 464156.27\n",
      "total_reward: -35843.73\n",
      "total_cost: 3097.48\n",
      "total_trades: 2516\n",
      "Sharpe: -0.038\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 1.18e+03  |\n",
      "|    total_reward     | -2.35e+03 |\n",
      "|    total_reward_pct | -0.47     |\n",
      "|    total_trades     | 2413      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 161       |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total timesteps  | 1000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 160       |\n",
      "|    critic_loss      | 3.33e+03  |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 750       |\n",
      "-----------------------------------\n",
      "day: 249, episode: 810\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498199.28\n",
      "total_reward: -1800.72\n",
      "total_cost: 1041.83\n",
      "total_trades: 2410\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 991       |\n",
      "|    total_reward     | -1.46e+03 |\n",
      "|    total_reward_pct | -0.292    |\n",
      "|    total_trades     | 2420      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 141       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total timesteps  | 2000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 150       |\n",
      "|    critic_loss      | 2.31e+03  |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 1750      |\n",
      "-----------------------------------\n",
      "day: 249, episode: 815\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498075.43\n",
      "total_reward: -1924.57\n",
      "total_cost: 966.13\n",
      "total_trades: 2440\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 966       |\n",
      "|    total_reward     | -1.92e+03 |\n",
      "|    total_reward_pct | -0.385    |\n",
      "|    total_trades     | 2440      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 125       |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total timesteps  | 3000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 139       |\n",
      "|    critic_loss      | 1.39e+03  |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 2750      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 1.05e+03  |\n",
      "|    total_reward     | -3.23e+03 |\n",
      "|    total_reward_pct | -0.646    |\n",
      "|    total_trades     | 2448      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 122       |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total timesteps  | 4000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 130       |\n",
      "|    critic_loss      | 895       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 3750      |\n",
      "-----------------------------------\n",
      "day: 249, episode: 820\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 827765.78\n",
      "total_reward: 327765.78\n",
      "total_cost: 3839.40\n",
      "total_trades: 2451\n",
      "Sharpe: 1.296\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -949     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 2444     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 122      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 123      |\n",
      "|    critic_loss      | 542      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4750     |\n",
      "----------------------------------\n",
      "day: 249, episode: 825\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499047.74\n",
      "total_reward: -952.26\n",
      "total_cost: 948.28\n",
      "total_trades: 2445\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.93e+05  |\n",
      "|    total_cost       | 1.23e+03  |\n",
      "|    total_reward     | -7.32e+03 |\n",
      "|    total_reward_pct | -1.46     |\n",
      "|    total_trades     | 2449      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 122       |\n",
      "|    time_elapsed     | 49        |\n",
      "|    total timesteps  | 6000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 114       |\n",
      "|    critic_loss      | 320       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 5750      |\n",
      "-----------------------------------\n",
      "day: 249, episode: 830\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497997.44\n",
      "total_reward: -2002.56\n",
      "total_cost: 970.15\n",
      "total_trades: 2447\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.93e+05  |\n",
      "|    total_cost       | 1.34e+03  |\n",
      "|    total_reward     | -6.78e+03 |\n",
      "|    total_reward_pct | -1.36     |\n",
      "|    total_trades     | 2448      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 122       |\n",
      "|    time_elapsed     | 57        |\n",
      "|    total timesteps  | 7000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 107       |\n",
      "|    critic_loss      | 213       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6750      |\n",
      "-----------------------------------\n",
      "day: 249, episode: 835\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 483303.70\n",
      "total_reward: -16696.30\n",
      "total_cost: 1487.04\n",
      "total_trades: 2444\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.83e+05  |\n",
      "|    total_cost       | 1.49e+03  |\n",
      "|    total_reward     | -1.67e+04 |\n",
      "|    total_reward_pct | -3.34     |\n",
      "|    total_trades     | 2444      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 122       |\n",
      "|    time_elapsed     | 65        |\n",
      "|    total timesteps  | 8000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 101       |\n",
      "|    critic_loss      | 128       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7750      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 1.06e+03  |\n",
      "|    total_reward     | -2.18e+03 |\n",
      "|    total_reward_pct | -0.436    |\n",
      "|    total_trades     | 2439      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 122       |\n",
      "|    time_elapsed     | 73        |\n",
      "|    total timesteps  | 9000      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 94.9      |\n",
      "|    critic_loss      | 209       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 8750      |\n",
      "-----------------------------------\n",
      "day: 249, episode: 840\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 836151.60\n",
      "total_reward: 336151.60\n",
      "total_cost: 4658.87\n",
      "total_trades: 2445\n",
      "Sharpe: 1.418\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 1.08e+03 |\n",
      "|    total_reward     | 633      |\n",
      "|    total_reward_pct | 0.127    |\n",
      "|    total_trades     | 2439     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 122      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 88.8     |\n",
      "|    critic_loss      | 41       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 9750     |\n",
      "----------------------------------\n",
      "day: 249, episode: 845\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 886181.17\n",
      "total_reward: 386181.17\n",
      "total_cost: 3448.87\n",
      "total_trades: 2438\n",
      "Sharpe: 1.459\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.7e+05  |\n",
      "|    total_cost       | 3.62e+03 |\n",
      "|    total_reward     | 3.7e+05  |\n",
      "|    total_reward_pct | 74       |\n",
      "|    total_trades     | 2435     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 122      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total timesteps  | 11000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 83.7     |\n",
      "|    critic_loss      | 36.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 10750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 850\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 491609.07\n",
      "total_reward: -8390.93\n",
      "total_cost: 1341.98\n",
      "total_trades: 2435\n",
      "Sharpe: 0.109\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.98e+05 |\n",
      "|    total_cost       | 966      |\n",
      "|    total_reward     | -1.9e+03 |\n",
      "|    total_reward_pct | -0.381   |\n",
      "|    total_trades     | 2432     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 78.8     |\n",
      "|    critic_loss      | 30.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 855\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499182.99\n",
      "total_reward: -817.01\n",
      "total_cost: 956.40\n",
      "total_trades: 2424\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 956      |\n",
      "|    total_reward     | -817     |\n",
      "|    total_reward_pct | -0.163   |\n",
      "|    total_trades     | 2424     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total timesteps  | 13000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 74       |\n",
      "|    critic_loss      | 45.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 12750    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.98e+05 |\n",
      "|    total_cost       | 1.02e+03 |\n",
      "|    total_reward     | -1.7e+03 |\n",
      "|    total_reward_pct | -0.34    |\n",
      "|    total_trades     | 2424     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 69.3     |\n",
      "|    critic_loss      | 39.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 860\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 493968.03\n",
      "total_reward: -6031.97\n",
      "total_cost: 1192.93\n",
      "total_trades: 2420\n",
      "Sharpe: 0.175\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.08e+03 |\n",
      "|    total_reward     | -596     |\n",
      "|    total_reward_pct | -0.119   |\n",
      "|    total_trades     | 2420     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 65.3     |\n",
      "|    critic_loss      | 30.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 14750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 865\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 832146.25\n",
      "total_reward: 332146.25\n",
      "total_cost: 4137.47\n",
      "total_trades: 2427\n",
      "Sharpe: 1.290\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -949     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 2415     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 61.4     |\n",
      "|    critic_loss      | 31.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 870\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 490297.64\n",
      "total_reward: -9702.36\n",
      "total_cost: 1533.65\n",
      "total_trades: 2415\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 1.02e+03  |\n",
      "|    total_reward     | -1.26e+03 |\n",
      "|    total_reward_pct | -0.252    |\n",
      "|    total_trades     | 2415      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 137       |\n",
      "|    total timesteps  | 17000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 57.2      |\n",
      "|    critic_loss      | 27.1      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16750     |\n",
      "-----------------------------------\n",
      "day: 249, episode: 875\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498498.03\n",
      "total_reward: -1501.97\n",
      "total_cost: 959.96\n",
      "total_trades: 2415\n",
      "Sharpe: 0.180\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.98e+05 |\n",
      "|    total_cost       | 960      |\n",
      "|    total_reward     | -1.5e+03 |\n",
      "|    total_reward_pct | -0.3     |\n",
      "|    total_trades     | 2415     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 52.9     |\n",
      "|    critic_loss      | 73.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17750    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.02e+03 |\n",
      "|    total_reward     | -950     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 2411     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total timesteps  | 19000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 49.7     |\n",
      "|    critic_loss      | 88.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 880\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499680.64\n",
      "total_reward: -319.36\n",
      "total_cost: 973.48\n",
      "total_trades: 2414\n",
      "Sharpe: 0.183\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.87e+05  |\n",
      "|    total_cost       | 1.56e+03  |\n",
      "|    total_reward     | -1.28e+04 |\n",
      "|    total_reward_pct | -2.56     |\n",
      "|    total_trades     | 2417      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 161       |\n",
      "|    total timesteps  | 20000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 46        |\n",
      "|    critic_loss      | 23        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 19750     |\n",
      "-----------------------------------\n",
      "day: 249, episode: 885\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498614.99\n",
      "total_reward: -1385.01\n",
      "total_cost: 1026.60\n",
      "total_trades: 2412\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.01e+05 |\n",
      "|    total_cost       | 4.06e+03 |\n",
      "|    total_reward     | 4.01e+05 |\n",
      "|    total_reward_pct | 80.2     |\n",
      "|    total_trades     | 2418     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total timesteps  | 21000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 42.7     |\n",
      "|    critic_loss      | 130      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 890\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 491093.74\n",
      "total_reward: -8906.26\n",
      "total_cost: 1332.49\n",
      "total_trades: 2412\n",
      "Sharpe: 0.110\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -937     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 2410     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 39.7     |\n",
      "|    critic_loss      | 26.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 21750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 895\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 483169.74\n",
      "total_reward: -16830.26\n",
      "total_cost: 1323.08\n",
      "total_trades: 2416\n",
      "Sharpe: 0.121\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.83e+05  |\n",
      "|    total_cost       | 1.32e+03  |\n",
      "|    total_reward     | -1.68e+04 |\n",
      "|    total_reward_pct | -3.37     |\n",
      "|    total_trades     | 2416      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 185       |\n",
      "|    total timesteps  | 23000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 36.8      |\n",
      "|    critic_loss      | 20.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 22750     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.93e+05  |\n",
      "|    total_cost       | 1.67e+03  |\n",
      "|    total_reward     | -6.86e+03 |\n",
      "|    total_reward_pct | -1.37     |\n",
      "|    total_trades     | 2396      |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 193       |\n",
      "|    total timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 34.1      |\n",
      "|    critic_loss      | 44.7      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 23750     |\n",
      "-----------------------------------\n",
      "day: 249, episode: 900\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498289.23\n",
      "total_reward: -1710.77\n",
      "total_cost: 1029.40\n",
      "total_trades: 2401\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.09e+05 |\n",
      "|    total_cost       | 4.13e+03 |\n",
      "|    total_reward     | 4.09e+05 |\n",
      "|    total_reward_pct | 81.8     |\n",
      "|    total_trades     | 2401     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 31.2     |\n",
      "|    critic_loss      | 10.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 905\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 863059.94\n",
      "total_reward: 363059.94\n",
      "total_cost: 3511.64\n",
      "total_trades: 2409\n",
      "Sharpe: 1.373\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.06e+03 |\n",
      "|    total_reward     | -369     |\n",
      "|    total_reward_pct | -0.0739  |\n",
      "|    total_trades     | 2390     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 28.8     |\n",
      "|    critic_loss      | 19.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 910\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 856353.40\n",
      "total_reward: 356353.40\n",
      "total_cost: 3812.58\n",
      "total_trades: 2401\n",
      "Sharpe: 1.325\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.83e+05  |\n",
      "|    total_cost       | 1.49e+03  |\n",
      "|    total_reward     | -1.74e+04 |\n",
      "|    total_reward_pct | -3.48     |\n",
      "|    total_trades     | 2394      |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 217       |\n",
      "|    total timesteps  | 27000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 26.6      |\n",
      "|    critic_loss      | 57        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 26750     |\n",
      "-----------------------------------\n",
      "day: 249, episode: 915\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 488082.13\n",
      "total_reward: -11917.87\n",
      "total_cost: 1322.49\n",
      "total_trades: 2381\n",
      "Sharpe: 0.121\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.88e+05  |\n",
      "|    total_cost       | 1.32e+03  |\n",
      "|    total_reward     | -1.19e+04 |\n",
      "|    total_reward_pct | -2.38     |\n",
      "|    total_trades     | 2381      |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 225       |\n",
      "|    total timesteps  | 28000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 24.3      |\n",
      "|    critic_loss      | 9.58      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 27750     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 969       |\n",
      "|    total_reward     | -1.79e+03 |\n",
      "|    total_reward_pct | -0.358    |\n",
      "|    total_trades     | 2396      |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 233       |\n",
      "|    total timesteps  | 29000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 22.5      |\n",
      "|    critic_loss      | 4.91      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28750     |\n",
      "-----------------------------------\n",
      "day: 249, episode: 920\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 883644.58\n",
      "total_reward: 383644.58\n",
      "total_cost: 3980.12\n",
      "total_trades: 2390\n",
      "Sharpe: 1.515\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.49e+05 |\n",
      "|    total_cost       | 4.07e+03 |\n",
      "|    total_reward     | 3.49e+05 |\n",
      "|    total_reward_pct | 69.9     |\n",
      "|    total_trades     | 2395     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 20.3     |\n",
      "|    critic_loss      | 21.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 925\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 484021.89\n",
      "total_reward: -15978.11\n",
      "total_cost: 1445.61\n",
      "total_trades: 2386\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.56e+05 |\n",
      "|    total_cost       | 3.45e+03 |\n",
      "|    total_reward     | 3.56e+05 |\n",
      "|    total_reward_pct | 71.3     |\n",
      "|    total_trades     | 2386     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total timesteps  | 31000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 18.2     |\n",
      "|    critic_loss      | 8.55     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 30750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 930\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499953.05\n",
      "total_reward: -46.95\n",
      "total_cost: 1041.38\n",
      "total_trades: 2383\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 957      |\n",
      "|    total_reward     | -1e+03   |\n",
      "|    total_reward_pct | -0.2     |\n",
      "|    total_trades     | 2382     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 16.6     |\n",
      "|    critic_loss      | 26.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 935\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499065.15\n",
      "total_reward: -934.85\n",
      "total_cost: 948.48\n",
      "total_trades: 2378\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -935     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 2378     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total timesteps  | 33000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 14.9     |\n",
      "|    critic_loss      | 5.71     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32750    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.33e+05 |\n",
      "|    total_cost       | 3.58e+03 |\n",
      "|    total_reward     | 4.33e+05 |\n",
      "|    total_reward_pct | 86.6     |\n",
      "|    total_trades     | 2387     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 13.5     |\n",
      "|    critic_loss      | 55.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 940\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 918189.36\n",
      "total_reward: 418189.36\n",
      "total_cost: 3522.76\n",
      "total_trades: 2386\n",
      "Sharpe: 1.699\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.01e+03 |\n",
      "|    total_reward     | -866     |\n",
      "|    total_reward_pct | -0.173   |\n",
      "|    total_trades     | 2380     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 12.1     |\n",
      "|    critic_loss      | 8.04     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 945\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498233.24\n",
      "total_reward: -1766.76\n",
      "total_cost: 1027.45\n",
      "total_trades: 2378\n",
      "Sharpe: 0.180\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 960      |\n",
      "|    total_reward     | -439     |\n",
      "|    total_reward_pct | -0.0879  |\n",
      "|    total_trades     | 2379     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 10.8     |\n",
      "|    critic_loss      | 5.72     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 950\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500003.11\n",
      "total_reward: 3.11\n",
      "total_cost: 1043.77\n",
      "total_trades: 2382\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.51e+05 |\n",
      "|    total_cost       | 3.58e+03 |\n",
      "|    total_reward     | 3.51e+05 |\n",
      "|    total_reward_pct | 70.2     |\n",
      "|    total_trades     | 2376     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total timesteps  | 37000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 9.66     |\n",
      "|    critic_loss      | 7.34     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 36750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 955\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497388.86\n",
      "total_reward: -2611.14\n",
      "total_cost: 978.50\n",
      "total_trades: 2371\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 978       |\n",
      "|    total_reward     | -2.61e+03 |\n",
      "|    total_reward_pct | -0.522    |\n",
      "|    total_trades     | 2371      |\n",
      "| time/               |           |\n",
      "|    episodes         | 152       |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 306       |\n",
      "|    total timesteps  | 38000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 8.71      |\n",
      "|    critic_loss      | 16        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37750     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 953      |\n",
      "|    total_reward     | -960     |\n",
      "|    total_reward_pct | -0.192   |\n",
      "|    total_trades     | 2379     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total timesteps  | 39000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 7.58     |\n",
      "|    critic_loss      | 33.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 38750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 960\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 495470.68\n",
      "total_reward: -4529.32\n",
      "total_cost: 1334.44\n",
      "total_trades: 2385\n",
      "Sharpe: 0.139\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 950      |\n",
      "|    total_reward     | -872     |\n",
      "|    total_reward_pct | -0.174   |\n",
      "|    total_trades     | 2391     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 6.49     |\n",
      "|    critic_loss      | 4.83     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 965\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 493766.65\n",
      "total_reward: -6233.35\n",
      "total_cost: 1317.40\n",
      "total_trades: 2595\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 1.02e+03  |\n",
      "|    total_reward     | -1.25e+03 |\n",
      "|    total_reward_pct | -0.25     |\n",
      "|    total_trades     | 2594      |\n",
      "| time/               |           |\n",
      "|    episodes         | 164       |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 330       |\n",
      "|    total timesteps  | 41000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 5.37      |\n",
      "|    critic_loss      | 6.61      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 40750     |\n",
      "-----------------------------------\n",
      "day: 249, episode: 970\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 489328.54\n",
      "total_reward: -10671.46\n",
      "total_cost: 1317.58\n",
      "total_trades: 2596\n",
      "Sharpe: 0.144\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.09e+03 |\n",
      "|    total_reward     | -730     |\n",
      "|    total_reward_pct | -0.146   |\n",
      "|    total_trades     | 2595     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 4.53     |\n",
      "|    critic_loss      | 5.07     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 975\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 483009.89\n",
      "total_reward: -16990.11\n",
      "total_cost: 1433.81\n",
      "total_trades: 2611\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.83e+05 |\n",
      "|    total_cost       | 1.43e+03 |\n",
      "|    total_reward     | -1.7e+04 |\n",
      "|    total_reward_pct | -3.4     |\n",
      "|    total_trades     | 2611     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total timesteps  | 43000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.65     |\n",
      "|    critic_loss      | 3.97     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 42750    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.93e+05  |\n",
      "|    total_cost       | 1.31e+03  |\n",
      "|    total_reward     | -6.52e+03 |\n",
      "|    total_reward_pct | -1.3      |\n",
      "|    total_trades     | 2618      |\n",
      "| time/               |           |\n",
      "|    episodes         | 176       |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 354       |\n",
      "|    total timesteps  | 44000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.89      |\n",
      "|    critic_loss      | 4.23      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 43750     |\n",
      "-----------------------------------\n",
      "day: 249, episode: 980\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499093.35\n",
      "total_reward: -906.65\n",
      "total_cost: 953.87\n",
      "total_trades: 2620\n",
      "Sharpe: 0.189\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 951      |\n",
      "|    total_reward     | -941     |\n",
      "|    total_reward_pct | -0.188   |\n",
      "|    total_trades     | 2621     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.1      |\n",
      "|    critic_loss      | 25.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 985\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499061.89\n",
      "total_reward: -938.11\n",
      "total_cost: 1010.67\n",
      "total_trades: 2619\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.9e+05  |\n",
      "|    total_cost       | 1.33e+03 |\n",
      "|    total_reward     | -1e+04   |\n",
      "|    total_reward_pct | -2.01    |\n",
      "|    total_trades     | 2622     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 371      |\n",
      "|    total timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.41     |\n",
      "|    critic_loss      | 9.11     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 990\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498295.71\n",
      "total_reward: -1704.29\n",
      "total_cost: 1014.80\n",
      "total_trades: 2624\n",
      "Sharpe: 0.195\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -952     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 2621     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 379      |\n",
      "|    total timesteps  | 47000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.779    |\n",
      "|    critic_loss      | 3.81     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 995\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498743.30\n",
      "total_reward: -1256.70\n",
      "total_cost: 1010.51\n",
      "total_trades: 2621\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 1.01e+03  |\n",
      "|    total_reward     | -1.26e+03 |\n",
      "|    total_reward_pct | -0.251    |\n",
      "|    total_trades     | 2621      |\n",
      "| time/               |           |\n",
      "|    episodes         | 192       |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 387       |\n",
      "|    total timesteps  | 48000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.22      |\n",
      "|    critic_loss      | 7.35      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 47750     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1e+03    |\n",
      "|    total_reward     | -1.2e+03 |\n",
      "|    total_reward_pct | -0.24    |\n",
      "|    total_trades     | 2620     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 395      |\n",
      "|    total timesteps  | 49000    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.202   |\n",
      "|    critic_loss      | 29.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 48750    |\n",
      "----------------------------------\n",
      "day: 249, episode: 1000\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498280.29\n",
      "total_reward: -1719.71\n",
      "total_cost: 1008.41\n",
      "total_trades: 2620\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.88e+05  |\n",
      "|    total_cost       | 1.31e+03  |\n",
      "|    total_reward     | -1.19e+04 |\n",
      "|    total_reward_pct | -2.38     |\n",
      "|    total_trades     | 2625      |\n",
      "| time/               |           |\n",
      "|    episodes         | 200       |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 403       |\n",
      "|    total timesteps  | 50000     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -0.672    |\n",
      "|    critic_loss      | 5.39      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 49750     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-01-03 to  2019-04-04\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-04-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_126_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 1.02e+03  |\n",
      "|    total_reward     | -3.49e+03 |\n",
      "|    total_reward_pct | -0.699    |\n",
      "|    total_trades     | 2771      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 158       |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total timesteps  | 1252      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 93        |\n",
      "|    critic_loss      | 86        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 939       |\n",
      "-----------------------------------\n",
      "day: 312, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 482399.02\n",
      "total_reward: -17600.98\n",
      "total_cost: 3985.21\n",
      "total_trades: 2786\n",
      "Sharpe: 0.089\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.05e+05 |\n",
      "|    total_cost       | 1.52e+03 |\n",
      "|    total_reward     | 5.47e+03 |\n",
      "|    total_reward_pct | 1.09     |\n",
      "|    total_trades     | 2988     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total timesteps  | 2504     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 85.4     |\n",
      "|    critic_loss      | 38       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 2191     |\n",
      "----------------------------------\n",
      "day: 312, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 528989.09\n",
      "total_reward: 28989.09\n",
      "total_cost: 1559.36\n",
      "total_trades: 2987\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.04e+05 |\n",
      "|    total_cost       | 1.07e+03 |\n",
      "|    total_reward     | 3.86e+03 |\n",
      "|    total_reward_pct | 0.772    |\n",
      "|    total_trades     | 2983     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total timesteps  | 3756     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 77.5     |\n",
      "|    critic_loss      | 22       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3443     |\n",
      "----------------------------------\n",
      "day: 312, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 505816.76\n",
      "total_reward: 5816.76\n",
      "total_cost: 1898.00\n",
      "total_trades: 2992\n",
      "Sharpe: 0.212\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 967      |\n",
      "|    total_reward     | -885     |\n",
      "|    total_reward_pct | -0.177   |\n",
      "|    total_trades     | 2984     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total timesteps  | 5008     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 70.2     |\n",
      "|    critic_loss      | 13.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4695     |\n",
      "----------------------------------\n",
      "day: 312, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499812.92\n",
      "total_reward: -187.08\n",
      "total_cost: 1012.06\n",
      "total_trades: 2985\n",
      "Sharpe: 0.296\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.01e+03 |\n",
      "|    total_reward     | -187     |\n",
      "|    total_reward_pct | -0.0374  |\n",
      "|    total_trades     | 2985     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total timesteps  | 6260     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 63.9     |\n",
      "|    critic_loss      | 14       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5947     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 985       |\n",
      "|    total_reward     | -1.82e+03 |\n",
      "|    total_reward_pct | -0.364    |\n",
      "|    total_trades     | 2983      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 63        |\n",
      "|    total timesteps  | 7512      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 57.8      |\n",
      "|    critic_loss      | 7.85      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7199      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 496821.73\n",
      "total_reward: -3178.27\n",
      "total_cost: 1094.62\n",
      "total_trades: 2980\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 962       |\n",
      "|    total_reward     | -1.11e+03 |\n",
      "|    total_reward_pct | -0.222    |\n",
      "|    total_trades     | 2979      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 73        |\n",
      "|    total timesteps  | 8764      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 52.2      |\n",
      "|    critic_loss      | 27.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 8451      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498076.86\n",
      "total_reward: -1923.14\n",
      "total_cost: 990.33\n",
      "total_trades: 2988\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.03e+05 |\n",
      "|    total_cost       | 1.06e+03 |\n",
      "|    total_reward     | 2.72e+03 |\n",
      "|    total_reward_pct | 0.545    |\n",
      "|    total_trades     | 2989     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total timesteps  | 10016    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 47.1     |\n",
      "|    critic_loss      | 5.57     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 9703     |\n",
      "----------------------------------\n",
      "day: 312, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 489170.66\n",
      "total_reward: -10829.34\n",
      "total_cost: 1592.21\n",
      "total_trades: 2993\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.21e+05 |\n",
      "|    total_cost       | 1.46e+03 |\n",
      "|    total_reward     | 2.12e+04 |\n",
      "|    total_reward_pct | 4.24     |\n",
      "|    total_trades     | 2987     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total timesteps  | 11268    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 42.5     |\n",
      "|    critic_loss      | 5.93     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 10955    |\n",
      "----------------------------------\n",
      "day: 312, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499002.95\n",
      "total_reward: -997.05\n",
      "total_cost: 960.10\n",
      "total_trades: 2984\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 960      |\n",
      "|    total_reward     | -997     |\n",
      "|    total_reward_pct | -0.199   |\n",
      "|    total_trades     | 2984     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total timesteps  | 12520    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 38.5     |\n",
      "|    critic_loss      | 4.74     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 12207    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.07e+05 |\n",
      "|    total_cost       | 1.86e+03 |\n",
      "|    total_reward     | 7.04e+03 |\n",
      "|    total_reward_pct | 1.41     |\n",
      "|    total_trades     | 2995     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total timesteps  | 13772    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 34.6     |\n",
      "|    critic_loss      | 2.93     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13459    |\n",
      "----------------------------------\n",
      "day: 312, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 515765.59\n",
      "total_reward: 15765.59\n",
      "total_cost: 1849.28\n",
      "total_trades: 2995\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.24e+05 |\n",
      "|    total_cost       | 1.44e+03 |\n",
      "|    total_reward     | 2.43e+04 |\n",
      "|    total_reward_pct | 4.86     |\n",
      "|    total_trades     | 3298     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total timesteps  | 15024    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 31.2     |\n",
      "|    critic_loss      | 3.48     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 14711    |\n",
      "----------------------------------\n",
      "day: 312, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499701.08\n",
      "total_reward: -298.92\n",
      "total_cost: 1063.10\n",
      "total_trades: 3296\n",
      "Sharpe: 0.265\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 955      |\n",
      "|    total_reward     | -850     |\n",
      "|    total_reward_pct | -0.17    |\n",
      "|    total_trades     | 3294     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total timesteps  | 16276    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 28       |\n",
      "|    critic_loss      | 12       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15963    |\n",
      "----------------------------------\n",
      "day: 312, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499012.82\n",
      "total_reward: -987.18\n",
      "total_cost: 953.95\n",
      "total_trades: 3056\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 961      |\n",
      "|    total_reward     | 776      |\n",
      "|    total_reward_pct | 0.155    |\n",
      "|    total_trades     | 3056     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total timesteps  | 17528    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 25.1     |\n",
      "|    critic_loss      | 2.55     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17215    |\n",
      "----------------------------------\n",
      "day: 312, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499059.51\n",
      "total_reward: -940.49\n",
      "total_cost: 949.89\n",
      "total_trades: 3056\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 950      |\n",
      "|    total_reward     | -940     |\n",
      "|    total_reward_pct | -0.188   |\n",
      "|    total_trades     | 3056     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total timesteps  | 18780    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 22.4     |\n",
      "|    critic_loss      | 3.71     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18467    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.05e+05 |\n",
      "|    total_cost       | 1.52e+03 |\n",
      "|    total_reward     | 4.79e+03 |\n",
      "|    total_reward_pct | 0.958    |\n",
      "|    total_trades     | 3059     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total timesteps  | 20032    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 19.9     |\n",
      "|    critic_loss      | 25.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19719    |\n",
      "----------------------------------\n",
      "day: 312, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 494999.47\n",
      "total_reward: -5000.53\n",
      "total_cost: 1346.29\n",
      "total_trades: 3061\n",
      "Sharpe: 0.165\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 963      |\n",
      "|    total_reward     | 781      |\n",
      "|    total_reward_pct | 0.156    |\n",
      "|    total_trades     | 3058     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total timesteps  | 21284    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 17.9     |\n",
      "|    critic_loss      | 10       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20971    |\n",
      "----------------------------------\n",
      "day: 312, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 502144.49\n",
      "total_reward: 2144.49\n",
      "total_cost: 1529.94\n",
      "total_trades: 3064\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.11e+05 |\n",
      "|    total_cost       | 1.76e+03 |\n",
      "|    total_reward     | 1.1e+04  |\n",
      "|    total_reward_pct | 2.21     |\n",
      "|    total_trades     | 3062     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total timesteps  | 22536    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 15.8     |\n",
      "|    critic_loss      | 3.52     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 22223    |\n",
      "----------------------------------\n",
      "day: 312, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 511710.11\n",
      "total_reward: 11710.11\n",
      "total_cost: 1361.34\n",
      "total_trades: 3063\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 971       |\n",
      "|    total_reward     | -1.13e+03 |\n",
      "|    total_reward_pct | -0.226    |\n",
      "|    total_trades     | 3060      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 200       |\n",
      "|    total timesteps  | 23788     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 13.8      |\n",
      "|    critic_loss      | 1.15      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 23475     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499164.89\n",
      "total_reward: -835.11\n",
      "total_cost: 959.55\n",
      "total_trades: 3058\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 960      |\n",
      "|    total_reward     | -835     |\n",
      "|    total_reward_pct | -0.167   |\n",
      "|    total_trades     | 3058     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total timesteps  | 25040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 12.1     |\n",
      "|    critic_loss      | 2.44     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24727    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 1.02e+03 |\n",
      "|    total_reward     | 1.04e+03 |\n",
      "|    total_reward_pct | 0.209    |\n",
      "|    total_trades     | 3060     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total timesteps  | 26292    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 10.6     |\n",
      "|    critic_loss      | 2.44     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25979    |\n",
      "----------------------------------\n",
      "day: 312, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498798.66\n",
      "total_reward: -1201.34\n",
      "total_cost: 966.69\n",
      "total_trades: 3058\n",
      "Sharpe: 0.280\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 960      |\n",
      "|    total_reward     | -835     |\n",
      "|    total_reward_pct | -0.167   |\n",
      "|    total_trades     | 3059     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total timesteps  | 27544    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 9.17     |\n",
      "|    critic_loss      | 47.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27231    |\n",
      "----------------------------------\n",
      "day: 312, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498815.23\n",
      "total_reward: -1184.77\n",
      "total_cost: 974.75\n",
      "total_trades: 3061\n",
      "Sharpe: 0.196\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 1.03e+03  |\n",
      "|    total_reward     | -1.38e+03 |\n",
      "|    total_reward_pct | -0.275    |\n",
      "|    total_trades     | 3060      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 242       |\n",
      "|    total timesteps  | 28796     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 7.89      |\n",
      "|    critic_loss      | 0.87      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28483     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499058.53\n",
      "total_reward: -941.47\n",
      "total_cost: 949.59\n",
      "total_trades: 3058\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 950      |\n",
      "|    total_reward     | -991     |\n",
      "|    total_reward_pct | -0.198   |\n",
      "|    total_trades     | 3056     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total timesteps  | 30048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 6.82     |\n",
      "|    critic_loss      | 0.49     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29735    |\n",
      "----------------------------------\n",
      "day: 312, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499044.72\n",
      "total_reward: -955.28\n",
      "total_cost: 956.38\n",
      "total_trades: 3057\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 956      |\n",
      "|    total_reward     | -955     |\n",
      "|    total_reward_pct | -0.191   |\n",
      "|    total_trades     | 3057     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total timesteps  | 31300    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 5.81     |\n",
      "|    critic_loss      | 0.737    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 30987    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 1.38e+03  |\n",
      "|    total_reward     | -1.43e+03 |\n",
      "|    total_reward_pct | -0.287    |\n",
      "|    total_trades     | 3059      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 276       |\n",
      "|    total timesteps  | 32552     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 4.75      |\n",
      "|    critic_loss      | 0.839     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 32239     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499359.16\n",
      "total_reward: -640.84\n",
      "total_cost: 959.53\n",
      "total_trades: 3060\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 1.34e+03  |\n",
      "|    total_reward     | -4.14e+03 |\n",
      "|    total_reward_pct | -0.829    |\n",
      "|    total_trades     | 3058      |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 286       |\n",
      "|    total timesteps  | 33804     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 3.85      |\n",
      "|    critic_loss      | 12.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 33491     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499569.72\n",
      "total_reward: -430.28\n",
      "total_cost: 979.24\n",
      "total_trades: 3058\n",
      "Sharpe: 0.208\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 1.39e+03  |\n",
      "|    total_reward     | -3.97e+03 |\n",
      "|    total_reward_pct | -0.794    |\n",
      "|    total_trades     | 3060      |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 298       |\n",
      "|    total timesteps  | 35056     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.94      |\n",
      "|    critic_loss      | 1.85      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 34743     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 519427.96\n",
      "total_reward: 19427.96\n",
      "total_cost: 1394.94\n",
      "total_trades: 3060\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 976      |\n",
      "|    total_reward     | 986      |\n",
      "|    total_reward_pct | 0.197    |\n",
      "|    total_trades     | 3059     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total timesteps  | 36308    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.28     |\n",
      "|    critic_loss      | 0.456    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35995    |\n",
      "----------------------------------\n",
      "day: 312, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498895.64\n",
      "total_reward: -1104.36\n",
      "total_cost: 957.13\n",
      "total_trades: 3057\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 957      |\n",
      "|    total_reward     | -1.1e+03 |\n",
      "|    total_reward_pct | -0.221   |\n",
      "|    total_trades     | 3057     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 116      |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total timesteps  | 37560    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.58     |\n",
      "|    critic_loss      | 2.69     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37247    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 971      |\n",
      "|    total_reward     | -501     |\n",
      "|    total_reward_pct | -0.1     |\n",
      "|    total_trades     | 3060     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total timesteps  | 38812    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.921    |\n",
      "|    critic_loss      | 0.592    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 38499    |\n",
      "----------------------------------\n",
      "day: 312, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499536.29\n",
      "total_reward: -463.71\n",
      "total_cost: 1543.03\n",
      "total_trades: 3065\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 958       |\n",
      "|    total_reward     | -3.88e+03 |\n",
      "|    total_reward_pct | -0.776    |\n",
      "|    total_trades     | 3059      |\n",
      "| time/               |           |\n",
      "|    episodes         | 128       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 341       |\n",
      "|    total timesteps  | 40064     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.384     |\n",
      "|    critic_loss      | 0.757     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 39751     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498510.78\n",
      "total_reward: -1489.22\n",
      "total_cost: 1423.26\n",
      "total_trades: 3056\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.15e+05 |\n",
      "|    total_cost       | 1.36e+03 |\n",
      "|    total_reward     | 1.49e+04 |\n",
      "|    total_reward_pct | 2.98     |\n",
      "|    total_trades     | 3060     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total timesteps  | 41316    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.25    |\n",
      "|    critic_loss      | 0.58     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41003    |\n",
      "----------------------------------\n",
      "day: 312, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497242.85\n",
      "total_reward: -2757.15\n",
      "total_cost: 1344.94\n",
      "total_trades: 3060\n",
      "Sharpe: 0.176\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 997      |\n",
      "|    total_reward     | 1.12e+03 |\n",
      "|    total_reward_pct | 0.224    |\n",
      "|    total_trades     | 3056     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total timesteps  | 42568    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.641   |\n",
      "|    critic_loss      | 2.65     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 42255    |\n",
      "----------------------------------\n",
      "day: 312, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 503107.94\n",
      "total_reward: 3107.94\n",
      "total_cost: 1480.83\n",
      "total_trades: 3062\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.03e+05 |\n",
      "|    total_cost       | 1.48e+03 |\n",
      "|    total_reward     | 3.11e+03 |\n",
      "|    total_reward_pct | 0.622    |\n",
      "|    total_trades     | 3062     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 371      |\n",
      "|    total timesteps  | 43820    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.08    |\n",
      "|    critic_loss      | 7.12     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43507    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 955      |\n",
      "|    total_reward     | -879     |\n",
      "|    total_reward_pct | -0.176   |\n",
      "|    total_trades     | 3056     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 381      |\n",
      "|    total timesteps  | 45072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.49    |\n",
      "|    critic_loss      | 0.434    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44759    |\n",
      "----------------------------------\n",
      "day: 312, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499050.07\n",
      "total_reward: -949.93\n",
      "total_cost: 959.02\n",
      "total_trades: 3058\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 958      |\n",
      "|    total_reward     | -876     |\n",
      "|    total_reward_pct | -0.175   |\n",
      "|    total_trades     | 3059     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 392      |\n",
      "|    total timesteps  | 46324    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.89    |\n",
      "|    critic_loss      | 0.884    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46011    |\n",
      "----------------------------------\n",
      "day: 312, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499196.97\n",
      "total_reward: -803.03\n",
      "total_cost: 954.96\n",
      "total_trades: 3056\n",
      "Sharpe: 0.198\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 959      |\n",
      "|    total_reward     | -848     |\n",
      "|    total_reward_pct | -0.17    |\n",
      "|    total_trades     | 3058     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 402      |\n",
      "|    total timesteps  | 47576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.2     |\n",
      "|    critic_loss      | 123      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47263    |\n",
      "----------------------------------\n",
      "day: 312, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500887.99\n",
      "total_reward: 887.99\n",
      "total_cost: 963.56\n",
      "total_trades: 3059\n",
      "Sharpe: 0.212\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 1.34e+03  |\n",
      "|    total_reward     | -4.05e+03 |\n",
      "|    total_reward_pct | -0.81     |\n",
      "|    total_trades     | 3061      |\n",
      "| time/               |           |\n",
      "|    episodes         | 156       |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 412       |\n",
      "|    total timesteps  | 48828     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.47     |\n",
      "|    critic_loss      | 0.338     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 48515     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 494164.98\n",
      "total_reward: -5835.02\n",
      "total_cost: 1338.59\n",
      "total_trades: 3061\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.94e+05  |\n",
      "|    total_cost       | 1.34e+03  |\n",
      "|    total_reward     | -5.84e+03 |\n",
      "|    total_reward_pct | -1.17     |\n",
      "|    total_trades     | 3061      |\n",
      "| time/               |           |\n",
      "|    episodes         | 160       |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 423       |\n",
      "|    total timesteps  | 50080     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.68     |\n",
      "|    critic_loss      | 2.08      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 49767     |\n",
      "-----------------------------------\n",
      "======Trading from:  2019-04-04 to  2019-07-05\n",
      "============================================\n",
      "34.981714738922875\n",
      "turbulence_threshold:  0.0\n",
      "======Model training from:  2000-01-01 to  2019-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_1\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.83e+05  |\n",
      "|    total_cost         | 1.47e+05  |\n",
      "|    total_reward       | -1.17e+05 |\n",
      "|    total_reward_pct   | -23.4     |\n",
      "|    total_trades       | 4678      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | -1.09     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -1.1      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.0324    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.55e+05 |\n",
      "|    total_cost         | 1.54e+05 |\n",
      "|    total_reward       | 1.55e+05 |\n",
      "|    total_reward_pct   | 31.1     |\n",
      "|    total_trades       | 4588     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | 0.0979   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -31.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.85e+05  |\n",
      "|    total_cost         | 6.75e+04  |\n",
      "|    total_reward       | -2.15e+05 |\n",
      "|    total_reward_pct   | -43       |\n",
      "|    total_trades       | 4291      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -2.08     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -19.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.493     |\n",
      "-------------------------------------\n",
      "day: 312, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 385137.04\n",
      "total_reward: -114862.96\n",
      "total_cost: 95960.97\n",
      "total_trades: 4300\n",
      "Sharpe: -0.867\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.93e+05  |\n",
      "|    total_cost         | 1.24e+05  |\n",
      "|    total_reward       | -1.07e+05 |\n",
      "|    total_reward_pct   | -21.3     |\n",
      "|    total_trades       | 4449      |\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -8.68     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.104     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.57e+05  |\n",
      "|    total_cost         | 1.09e+05  |\n",
      "|    total_reward       | -1.43e+05 |\n",
      "|    total_reward_pct   | -28.6     |\n",
      "|    total_trades       | 4323      |\n",
      "| time/                 |           |\n",
      "|    fps                | 537       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.0474   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 12.3      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.389     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.33e+05 |\n",
      "|    total_cost         | 7.92e+04 |\n",
      "|    total_reward       | 1.33e+05 |\n",
      "|    total_reward_pct   | 26.7     |\n",
      "|    total_trades       | 4170     |\n",
      "| time/                 |          |\n",
      "|    fps                | 541      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | 0.141    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 23.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "day: 312, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 576724.04\n",
      "total_reward: 76724.04\n",
      "total_cost: 51184.95\n",
      "total_trades: 4073\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.2e+05  |\n",
      "|    total_cost         | 4.16e+04 |\n",
      "|    total_reward       | 1.97e+04 |\n",
      "|    total_reward_pct   | 3.95     |\n",
      "|    total_trades       | 4118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.0845  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 2.16     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.358    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.3e+05  |\n",
      "|    total_cost         | 4.79e+04 |\n",
      "|    total_reward       | 2.99e+04 |\n",
      "|    total_reward_pct   | 5.98     |\n",
      "|    total_trades       | 4126     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.238   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 20.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.802    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.09e+05  |\n",
      "|    total_cost         | 5.69e+04  |\n",
      "|    total_reward       | 8.84e+03  |\n",
      "|    total_reward_pct   | 1.77      |\n",
      "|    total_trades       | 4379      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 54.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.28      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 558382.95\n",
      "total_reward: 58382.95\n",
      "total_cost: 32494.32\n",
      "total_trades: 4267\n",
      "Sharpe: 0.457\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.58e+05 |\n",
      "|    total_cost         | 3.25e+04 |\n",
      "|    total_reward       | 5.84e+04 |\n",
      "|    total_reward_pct   | 11.7     |\n",
      "|    total_trades       | 4267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 555      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | 0.0286   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 7.81     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.01e+05 |\n",
      "|    total_cost         | 4.95e+04 |\n",
      "|    total_reward       | 1.01e+05 |\n",
      "|    total_reward_pct   | 20.1     |\n",
      "|    total_trades       | 4343     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.00228 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -69.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.49e+05 |\n",
      "|    total_cost         | 5.15e+04 |\n",
      "|    total_reward       | 2.49e+05 |\n",
      "|    total_reward_pct   | 49.9     |\n",
      "|    total_trades       | 4325     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.0185  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 15.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.554    |\n",
      "------------------------------------\n",
      "day: 312, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 723556.87\n",
      "total_reward: 223556.87\n",
      "total_cost: 40867.95\n",
      "total_trades: 4157\n",
      "Sharpe: 0.973\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.24e+05  |\n",
      "|    total_cost         | 4.09e+04  |\n",
      "|    total_reward       | 2.24e+05  |\n",
      "|    total_reward_pct   | 44.7      |\n",
      "|    total_trades       | 4157      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -38.8     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.67e+05  |\n",
      "|    total_cost         | 3e+04     |\n",
      "|    total_reward       | -1.33e+05 |\n",
      "|    total_reward_pct   | -26.7     |\n",
      "|    total_trades       | 4081      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -0.105    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.902     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.93e+05 |\n",
      "|    total_cost         | 5.58e+04 |\n",
      "|    total_reward       | 9.29e+04 |\n",
      "|    total_reward_pct   | 18.6     |\n",
      "|    total_trades       | 4109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.0321   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 11.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.267    |\n",
      "------------------------------------\n",
      "day: 312, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 537889.43\n",
      "total_reward: 37889.43\n",
      "total_cost: 80919.39\n",
      "total_trades: 4186\n",
      "Sharpe: 0.389\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.38e+05 |\n",
      "|    total_cost         | 8.09e+04 |\n",
      "|    total_reward       | 3.79e+04 |\n",
      "|    total_reward_pct   | 7.58     |\n",
      "|    total_trades       | 4186     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -13.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.776    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.57e+05 |\n",
      "|    total_cost         | 5.21e+04 |\n",
      "|    total_reward       | 5.67e+04 |\n",
      "|    total_reward_pct   | 11.3     |\n",
      "|    total_trades       | 4044     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.312    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 31.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.56e+05 |\n",
      "|    total_cost         | 5.6e+04  |\n",
      "|    total_reward       | 2.56e+05 |\n",
      "|    total_reward_pct   | 51.2     |\n",
      "|    total_trades       | 4069     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.132   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -27.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "day: 312, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 634319.76\n",
      "total_reward: 134319.76\n",
      "total_cost: 65887.08\n",
      "total_trades: 4103\n",
      "Sharpe: 1.059\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.34e+05 |\n",
      "|    total_cost         | 6.59e+04 |\n",
      "|    total_reward       | 1.34e+05 |\n",
      "|    total_reward_pct   | 26.9     |\n",
      "|    total_trades       | 4103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.0322   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 25.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.865    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.5e+05  |\n",
      "|    total_cost         | 3.35e+04 |\n",
      "|    total_reward       | -1.5e+05 |\n",
      "|    total_reward_pct   | -30      |\n",
      "|    total_trades       | 4031     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.0422  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.351    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.81e+05 |\n",
      "|    total_cost         | 4.39e+04 |\n",
      "|    total_reward       | 3.81e+05 |\n",
      "|    total_reward_pct   | 76.2     |\n",
      "|    total_trades       | 4068     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -1.37    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "day: 312, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 249485.94\n",
      "total_reward: -250514.06\n",
      "total_cost: 22114.08\n",
      "total_trades: 4132\n",
      "Sharpe: -0.965\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.49e+05  |\n",
      "|    total_cost         | 2.21e+04  |\n",
      "|    total_reward       | -2.51e+05 |\n",
      "|    total_reward_pct   | -50.1     |\n",
      "|    total_trades       | 4132      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | -0.218    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 6.66      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.191     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.17e+05  |\n",
      "|    total_cost         | 1.64e+04  |\n",
      "|    total_reward       | -1.83e+05 |\n",
      "|    total_reward_pct   | -36.6     |\n",
      "|    total_trades       | 4111      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 53.1      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.58      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.82e+05 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 3.82e+05 |\n",
      "|    total_reward_pct   | 76.5     |\n",
      "|    total_trades       | 3931     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 43.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.41e+05 |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 3.41e+05 |\n",
      "|    total_reward_pct   | 68.2     |\n",
      "|    total_trades       | 3836     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -56.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.47     |\n",
      "------------------------------------\n",
      "day: 312, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 857223.26\n",
      "total_reward: 357223.26\n",
      "total_cost: 16526.23\n",
      "total_trades: 3845\n",
      "Sharpe: 1.312\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.88e+05 |\n",
      "|    total_cost         | 9.93e+03 |\n",
      "|    total_reward       | -1.2e+04 |\n",
      "|    total_reward_pct   | -2.39    |\n",
      "|    total_trades       | 3704     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0.265    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 34.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.83e+05 |\n",
      "|    total_cost         | 1.61e+04 |\n",
      "|    total_reward       | 2.83e+05 |\n",
      "|    total_reward_pct   | 56.5     |\n",
      "|    total_trades       | 3774     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 2.23     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.036    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.01e+05  |\n",
      "|    total_cost         | 1.32e+04  |\n",
      "|    total_reward       | -9.89e+04 |\n",
      "|    total_reward_pct   | -19.8     |\n",
      "|    total_trades       | 3792      |\n",
      "| time/                 |           |\n",
      "|    fps                | 555       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0.0398    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 44.3      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.17      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 735420.31\n",
      "total_reward: 235420.31\n",
      "total_cost: 25094.86\n",
      "total_trades: 3787\n",
      "Sharpe: 1.156\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.76e+05  |\n",
      "|    total_cost         | 1.14e+04  |\n",
      "|    total_reward       | -1.24e+05 |\n",
      "|    total_reward_pct   | -24.8     |\n",
      "|    total_trades       | 3763      |\n",
      "| time/                 |           |\n",
      "|    fps                | 555       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 22.9      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.67      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.84e+05 |\n",
      "|    total_cost         | 3.34e+04 |\n",
      "|    total_reward       | 1.84e+05 |\n",
      "|    total_reward_pct   | 36.7     |\n",
      "|    total_trades       | 3891     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -1.91    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.03e+05 |\n",
      "|    total_cost         | 8.4e+03  |\n",
      "|    total_reward       | 2.54e+03 |\n",
      "|    total_reward_pct   | 0.508    |\n",
      "|    total_trades       | 3665     |\n",
      "| time/                 |          |\n",
      "|    fps                | 555      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.0538  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 25.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.997    |\n",
      "------------------------------------\n",
      "day: 312, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 810541.56\n",
      "total_reward: 310541.56\n",
      "total_cost: 21529.43\n",
      "total_trades: 3786\n",
      "Sharpe: 1.294\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.66e+05 |\n",
      "|    total_cost         | 1.65e+04 |\n",
      "|    total_reward       | 6.57e+04 |\n",
      "|    total_reward_pct   | 13.1     |\n",
      "|    total_trades       | 3849     |\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.0154  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0908   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.3e+05  |\n",
      "|    total_cost         | 2.49e+04 |\n",
      "|    total_reward       | 1.3e+05  |\n",
      "|    total_reward_pct   | 26.1     |\n",
      "|    total_trades       | 3864     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 24.4     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.86e+05 |\n",
      "|    total_cost         | 7.86e+03 |\n",
      "|    total_reward       | 8.6e+04  |\n",
      "|    total_reward_pct   | 17.2     |\n",
      "|    total_trades       | 3725     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -8.96    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.125    |\n",
      "------------------------------------\n",
      "day: 312, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 396071.44\n",
      "total_reward: -103928.56\n",
      "total_cost: 8086.11\n",
      "total_trades: 3640\n",
      "Sharpe: -0.146\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.96e+05  |\n",
      "|    total_cost         | 8.09e+03  |\n",
      "|    total_reward       | -1.04e+05 |\n",
      "|    total_reward_pct   | -20.8     |\n",
      "|    total_trades       | 3640      |\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -55.8     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.27e+05 |\n",
      "|    total_cost         | 8.18e+03 |\n",
      "|    total_reward       | 2.69e+04 |\n",
      "|    total_reward_pct   | 5.38     |\n",
      "|    total_trades       | 3715     |\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 10.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.565    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.55e+05 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 4.55e+05 |\n",
      "|    total_reward_pct   | 91.1     |\n",
      "|    total_trades       | 3847     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.0124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 3.66     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.36     |\n",
      "------------------------------------\n",
      "day: 312, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 730984.88\n",
      "total_reward: 230984.88\n",
      "total_cost: 15625.24\n",
      "total_trades: 3938\n",
      "Sharpe: 0.974\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.31e+05 |\n",
      "|    total_cost         | 1.56e+04 |\n",
      "|    total_reward       | 2.31e+05 |\n",
      "|    total_reward_pct   | 46.2     |\n",
      "|    total_trades       | 3938     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -48.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.31e+05 |\n",
      "|    total_cost         | 1.19e+04 |\n",
      "|    total_reward       | 2.31e+05 |\n",
      "|    total_reward_pct   | 46.2     |\n",
      "|    total_trades       | 4069     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.0401  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 5.13     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.685    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.13e+05 |\n",
      "|    total_cost         | 1.57e+04 |\n",
      "|    total_reward       | 3.13e+05 |\n",
      "|    total_reward_pct   | 62.6     |\n",
      "|    total_trades       | 3996     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -32.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "day: 312, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 450835.99\n",
      "total_reward: -49164.01\n",
      "total_cost: 5816.94\n",
      "total_trades: 3797\n",
      "Sharpe: 0.037\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.51e+05  |\n",
      "|    total_cost         | 5.82e+03  |\n",
      "|    total_reward       | -4.92e+04 |\n",
      "|    total_reward_pct   | -9.83     |\n",
      "|    total_trades       | 3797      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -36.2     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.03e+05 |\n",
      "|    total_cost         | 9.48e+03 |\n",
      "|    total_reward       | 3.29e+03 |\n",
      "|    total_reward_pct   | 0.659    |\n",
      "|    total_trades       | 3731     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 1.09e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -17.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.815    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.15e+05 |\n",
      "|    total_cost         | 1.73e+04 |\n",
      "|    total_reward       | 3.15e+05 |\n",
      "|    total_reward_pct   | 63       |\n",
      "|    total_trades       | 3883     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 53.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.43     |\n",
      "------------------------------------\n",
      "day: 312, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 900001.01\n",
      "total_reward: 400001.01\n",
      "total_cost: 13172.73\n",
      "total_trades: 3984\n",
      "Sharpe: 1.463\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9e+05     |\n",
      "|    total_cost         | 1.32e+04  |\n",
      "|    total_reward       | 4e+05     |\n",
      "|    total_reward_pct   | 80        |\n",
      "|    total_trades       | 3984      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 4.12      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.0653    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.62e+05  |\n",
      "|    total_cost         | 9.13e+03  |\n",
      "|    total_reward       | -3.83e+04 |\n",
      "|    total_reward_pct   | -7.67     |\n",
      "|    total_trades       | 4122      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -0.225    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 17        |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.475     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.49e+05 |\n",
      "|    total_cost         | 1.53e+04 |\n",
      "|    total_reward       | 2.49e+05 |\n",
      "|    total_reward_pct   | 49.8     |\n",
      "|    total_trades       | 4277     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.24     |\n",
      "------------------------------------\n",
      "day: 312, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 737095.29\n",
      "total_reward: 237095.29\n",
      "total_cost: 14200.78\n",
      "total_trades: 4100\n",
      "Sharpe: 1.179\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.37e+05 |\n",
      "|    total_cost         | 1.42e+04 |\n",
      "|    total_reward       | 2.37e+05 |\n",
      "|    total_reward_pct   | 47.4     |\n",
      "|    total_trades       | 4100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.56e+05 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 2.56e+05 |\n",
      "|    total_reward_pct   | 51.1     |\n",
      "|    total_trades       | 4157     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.84e+05 |\n",
      "|    total_cost         | 1.86e+04 |\n",
      "|    total_reward       | 3.84e+05 |\n",
      "|    total_reward_pct   | 76.8     |\n",
      "|    total_trades       | 4126     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.957    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.11e+05 |\n",
      "|    total_cost         | 1.4e+04  |\n",
      "|    total_reward       | 2.11e+05 |\n",
      "|    total_reward_pct   | 42.1     |\n",
      "|    total_trades       | 4155     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0.000954 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 34.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "day: 312, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 743421.09\n",
      "total_reward: 243421.09\n",
      "total_cost: 8125.44\n",
      "total_trades: 4101\n",
      "Sharpe: 1.020\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.42e+05  |\n",
      "|    total_cost         | 6.07e+03  |\n",
      "|    total_reward       | -5.81e+04 |\n",
      "|    total_reward_pct   | -11.6     |\n",
      "|    total_trades       | 4154      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -22.8     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.21      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.49e+05 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | 1.49e+05 |\n",
      "|    total_reward_pct   | 29.8     |\n",
      "|    total_trades       | 4338     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.0205  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -218     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 62.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.61e+05 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 6.07e+04 |\n",
      "|    total_reward_pct   | 12.1     |\n",
      "|    total_trades       | 4377     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -5.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -82.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "day: 312, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 771965.26\n",
      "total_reward: 271965.26\n",
      "total_cost: 14890.62\n",
      "total_trades: 4315\n",
      "Sharpe: 1.254\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.32e+05  |\n",
      "|    total_cost         | 3.88e+03  |\n",
      "|    total_reward       | -6.79e+04 |\n",
      "|    total_reward_pct   | -13.6     |\n",
      "|    total_trades       | 4293      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -0.254    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 13.7      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.466     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.09e+05 |\n",
      "|    total_cost         | 1.12e+04 |\n",
      "|    total_reward       | 8.8e+03  |\n",
      "|    total_reward_pct   | 1.76     |\n",
      "|    total_trades       | 4429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.174   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 7.41     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.41e+05 |\n",
      "|    total_cost         | 1.37e+04 |\n",
      "|    total_reward       | 4.07e+04 |\n",
      "|    total_reward_pct   | 8.14     |\n",
      "|    total_trades       | 4509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 16.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.532    |\n",
      "------------------------------------\n",
      "day: 312, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 667094.33\n",
      "total_reward: 167094.33\n",
      "total_cost: 16191.77\n",
      "total_trades: 4516\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.19e+05 |\n",
      "|    total_cost         | 1.33e+04 |\n",
      "|    total_reward       | 4.19e+05 |\n",
      "|    total_reward_pct   | 83.9     |\n",
      "|    total_trades       | 4410     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.373    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.99e+05  |\n",
      "|    total_cost         | 1.03e+04  |\n",
      "|    total_reward       | 2.99e+05  |\n",
      "|    total_reward_pct   | 59.7      |\n",
      "|    total_trades       | 4366      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -32.9     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.15e+05 |\n",
      "|    total_cost         | 5.98e+03 |\n",
      "|    total_reward       | 1.15e+05 |\n",
      "|    total_reward_pct   | 23.1     |\n",
      "|    total_trades       | 4371     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.0463   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 4.05     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.473    |\n",
      "------------------------------------\n",
      "day: 312, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 663619.04\n",
      "total_reward: 163619.04\n",
      "total_cost: 11088.02\n",
      "total_trades: 4418\n",
      "Sharpe: 1.318\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.64e+05 |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 1.64e+05 |\n",
      "|    total_reward_pct   | 32.7     |\n",
      "|    total_trades       | 4418     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.0107  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 27.3     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.34e+05 |\n",
      "|    total_cost         | 9.04e+03 |\n",
      "|    total_reward       | 3.34e+05 |\n",
      "|    total_reward_pct   | 66.7     |\n",
      "|    total_trades       | 4459     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -46.4    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.98e+05  |\n",
      "|    total_cost         | 1.1e+03   |\n",
      "|    total_reward       | -2.37e+03 |\n",
      "|    total_reward_pct   | -0.473    |\n",
      "|    total_trades       | 4316      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -51.6     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.48      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 638803.06\n",
      "total_reward: 138803.06\n",
      "total_cost: 11372.46\n",
      "total_trades: 4436\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.39e+05 |\n",
      "|    total_cost         | 1.14e+04 |\n",
      "|    total_reward       | 1.39e+05 |\n",
      "|    total_reward_pct   | 27.8     |\n",
      "|    total_trades       | 4436     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.0374  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -24.8    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.941    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.32e+05 |\n",
      "|    total_cost         | 7.44e+03 |\n",
      "|    total_reward       | 3.32e+05 |\n",
      "|    total_reward_pct   | 66.5     |\n",
      "|    total_trades       | 4404     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.0141   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 11.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.84e+05 |\n",
      "|    total_cost         | 5.98e+03 |\n",
      "|    total_reward       | 1.84e+05 |\n",
      "|    total_reward_pct   | 36.9     |\n",
      "|    total_trades       | 4525     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.0288  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -2.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.393    |\n",
      "------------------------------------\n",
      "day: 312, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 812308.93\n",
      "total_reward: 312308.93\n",
      "total_cost: 6177.15\n",
      "total_trades: 4515\n",
      "Sharpe: 1.355\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.12e+05 |\n",
      "|    total_cost         | 6.18e+03 |\n",
      "|    total_reward       | 3.12e+05 |\n",
      "|    total_reward_pct   | 62.5     |\n",
      "|    total_trades       | 4515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.602   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -3.29    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.08e+05 |\n",
      "|    total_cost         | 4.15e+03 |\n",
      "|    total_reward       | 2.08e+05 |\n",
      "|    total_reward_pct   | 41.7     |\n",
      "|    total_trades       | 4280     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.244    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 55.1     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 36.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.14e+05  |\n",
      "|    total_cost         | 7.01e+03  |\n",
      "|    total_reward       | 3.14e+05  |\n",
      "|    total_reward_pct   | 62.9      |\n",
      "|    total_trades       | 4312      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -11.7     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.438     |\n",
      "-------------------------------------\n",
      "day: 312, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 838043.68\n",
      "total_reward: 338043.68\n",
      "total_cost: 6183.44\n",
      "total_trades: 4232\n",
      "Sharpe: 1.584\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.38e+05 |\n",
      "|    total_cost         | 6.18e+03 |\n",
      "|    total_reward       | 3.38e+05 |\n",
      "|    total_reward_pct   | 67.6     |\n",
      "|    total_trades       | 4232     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.502    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 37.8     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.83e+05 |\n",
      "|    total_cost         | 6.44e+03 |\n",
      "|    total_reward       | 3.83e+05 |\n",
      "|    total_reward_pct   | 76.7     |\n",
      "|    total_trades       | 4240     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.371    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 34.3     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.39e+05 |\n",
      "|    total_cost         | 3.11e+03 |\n",
      "|    total_reward       | 3.91e+04 |\n",
      "|    total_reward_pct   | 7.83     |\n",
      "|    total_trades       | 4250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.262   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 33.8     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "day: 312, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 615651.32\n",
      "total_reward: 115651.32\n",
      "total_cost: 7451.15\n",
      "total_trades: 4430\n",
      "Sharpe: 0.877\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.16e+05  |\n",
      "|    total_cost         | 7.45e+03  |\n",
      "|    total_reward       | 1.16e+05  |\n",
      "|    total_reward_pct   | 23.1      |\n",
      "|    total_trades       | 4430      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -80.8     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.6e+05  |\n",
      "|    total_cost         | 1.39e+04 |\n",
      "|    total_reward       | 3.6e+05  |\n",
      "|    total_reward_pct   | 72       |\n",
      "|    total_trades       | 4514     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.576    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.82e+05 |\n",
      "|    total_cost         | 1.03e+04 |\n",
      "|    total_reward       | 1.82e+05 |\n",
      "|    total_reward_pct   | 36.3     |\n",
      "|    total_trades       | 4469     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -5.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 18       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.487    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.44e+05 |\n",
      "|    total_cost         | 9.66e+03 |\n",
      "|    total_reward       | 3.44e+05 |\n",
      "|    total_reward_pct   | 68.8     |\n",
      "|    total_trades       | 4456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.228   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -3.28    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.636    |\n",
      "------------------------------------\n",
      "day: 312, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 721912.31\n",
      "total_reward: 221912.31\n",
      "total_cost: 10458.78\n",
      "total_trades: 4538\n",
      "Sharpe: 1.033\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.45e+05 |\n",
      "|    total_cost         | 5.24e+03 |\n",
      "|    total_reward       | 3.45e+05 |\n",
      "|    total_reward_pct   | 69.1     |\n",
      "|    total_trades       | 4470     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 45.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.89e+05 |\n",
      "|    total_cost         | 1.31e+04 |\n",
      "|    total_reward       | 3.89e+05 |\n",
      "|    total_reward_pct   | 77.9     |\n",
      "|    total_trades       | 4612     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -27.1    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.62e+05  |\n",
      "|    total_cost         | 5e+03     |\n",
      "|    total_reward       | -3.83e+04 |\n",
      "|    total_reward_pct   | -7.65     |\n",
      "|    total_trades       | 4681      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 11.2      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.357     |\n",
      "-------------------------------------\n",
      "day: 312, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 722455.77\n",
      "total_reward: 222455.77\n",
      "total_cost: 9235.83\n",
      "total_trades: 4653\n",
      "Sharpe: 0.956\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.38e+05 |\n",
      "|    total_cost         | 7.87e+03 |\n",
      "|    total_reward       | 1.38e+05 |\n",
      "|    total_reward_pct   | 27.5     |\n",
      "|    total_trades       | 4640     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0.00557  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.878    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.36e+05 |\n",
      "|    total_cost         | 9.75e+03 |\n",
      "|    total_reward       | 4.36e+05 |\n",
      "|    total_reward_pct   | 87.1     |\n",
      "|    total_trades       | 4539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -7.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 5.88     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.11e+05 |\n",
      "|    total_cost         | 1.26e+04 |\n",
      "|    total_reward       | 4.11e+05 |\n",
      "|    total_reward_pct   | 82.2     |\n",
      "|    total_trades       | 4649     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 5.98     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.281    |\n",
      "------------------------------------\n",
      "day: 312, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 728010.58\n",
      "total_reward: 228010.58\n",
      "total_cost: 9600.38\n",
      "total_trades: 4655\n",
      "Sharpe: 1.032\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.28e+05 |\n",
      "|    total_cost         | 9.6e+03  |\n",
      "|    total_reward       | 2.28e+05 |\n",
      "|    total_reward_pct   | 45.6     |\n",
      "|    total_trades       | 4655     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.292    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.85e+05 |\n",
      "|    total_cost         | 8.38e+03 |\n",
      "|    total_reward       | 1.85e+05 |\n",
      "|    total_reward_pct   | 37.1     |\n",
      "|    total_trades       | 4688     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.183   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.513    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.13e+05 |\n",
      "|    total_cost         | 8.45e+03 |\n",
      "|    total_reward       | 1.13e+05 |\n",
      "|    total_reward_pct   | 22.5     |\n",
      "|    total_trades       | 4565     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.0119  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -27.9    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "day: 312, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 602757.12\n",
      "total_reward: 102757.12\n",
      "total_cost: 5883.63\n",
      "total_trades: 4571\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.03e+05 |\n",
      "|    total_cost         | 5.88e+03 |\n",
      "|    total_reward       | 1.03e+05 |\n",
      "|    total_reward_pct   | 20.6     |\n",
      "|    total_trades       | 4571     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 72       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 7.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.4e+05  |\n",
      "|    total_cost         | 6.02e+03 |\n",
      "|    total_reward       | 3.4e+05  |\n",
      "|    total_reward_pct   | 68       |\n",
      "|    total_trades       | 4570     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.769    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.58e+05  |\n",
      "|    total_cost         | 6.32e+03  |\n",
      "|    total_reward       | 1.58e+05  |\n",
      "|    total_reward_pct   | 31.7      |\n",
      "|    total_trades       | 4600      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 27.3      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.28      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 848360.95\n",
      "total_reward: 348360.95\n",
      "total_cost: 8445.35\n",
      "total_trades: 4452\n",
      "Sharpe: 1.757\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.48e+05 |\n",
      "|    total_cost         | 8.45e+03 |\n",
      "|    total_reward       | 3.48e+05 |\n",
      "|    total_reward_pct   | 69.7     |\n",
      "|    total_trades       | 4452     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0.0052   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -36.9    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.13e+05 |\n",
      "|    total_cost         | 6.41e+03 |\n",
      "|    total_reward       | 4.13e+05 |\n",
      "|    total_reward_pct   | 82.6     |\n",
      "|    total_trades       | 4475     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0.166    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -0.399   |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0466   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.4e+05  |\n",
      "|    total_cost         | 6.78e+03 |\n",
      "|    total_reward       | 1.4e+05  |\n",
      "|    total_reward_pct   | 28.1     |\n",
      "|    total_trades       | 4498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -0.215   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -41.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "day: 312, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 507811.84\n",
      "total_reward: 7811.84\n",
      "total_cost: 2168.54\n",
      "total_trades: 4487\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.08e+05 |\n",
      "|    total_cost         | 2.17e+03 |\n",
      "|    total_reward       | 7.81e+03 |\n",
      "|    total_reward_pct   | 1.56     |\n",
      "|    total_trades       | 4487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0.015    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 15.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.91e+05 |\n",
      "|    total_cost         | 9.05e+03 |\n",
      "|    total_reward       | 1.91e+05 |\n",
      "|    total_reward_pct   | 38.1     |\n",
      "|    total_trades       | 4393     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -52.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.62     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.7e+05   |\n",
      "|    total_cost         | 5.51e+03  |\n",
      "|    total_reward       | 2.7e+05   |\n",
      "|    total_reward_pct   | 54        |\n",
      "|    total_trades       | 4361      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 1.23      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.296     |\n",
      "-------------------------------------\n",
      "day: 312, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 765010.74\n",
      "total_reward: 265010.74\n",
      "total_cost: 6222.33\n",
      "total_trades: 4538\n",
      "Sharpe: 0.946\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.65e+05 |\n",
      "|    total_cost         | 6.22e+03 |\n",
      "|    total_reward       | 2.65e+05 |\n",
      "|    total_reward_pct   | 53       |\n",
      "|    total_trades       | 4538     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -0.222   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -2.88    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.068    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.42e+05 |\n",
      "|    total_cost         | 6.59e+03 |\n",
      "|    total_reward       | 3.42e+05 |\n",
      "|    total_reward_pct   | 68.4     |\n",
      "|    total_trades       | 4524     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0.0432   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 48.8     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.85e+05 |\n",
      "|    total_cost         | 7.88e+03 |\n",
      "|    total_reward       | 3.85e+05 |\n",
      "|    total_reward_pct   | 77.1     |\n",
      "|    total_trades       | 4548     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0.0522   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -69.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.21e+05 |\n",
      "|    total_cost         | 3.78e+03 |\n",
      "|    total_reward       | 2.07e+04 |\n",
      "|    total_reward_pct   | 4.15     |\n",
      "|    total_trades       | 4523     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -5.8     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.458    |\n",
      "------------------------------------\n",
      "day: 312, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 547724.29\n",
      "total_reward: 47724.29\n",
      "total_cost: 9453.29\n",
      "total_trades: 4528\n",
      "Sharpe: 0.363\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.82e+05 |\n",
      "|    total_cost         | 9.89e+03 |\n",
      "|    total_reward       | 2.82e+05 |\n",
      "|    total_reward_pct   | 56.5     |\n",
      "|    total_trades       | 4613     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -3.87    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0945   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.55e+05 |\n",
      "|    total_cost         | 5.83e+03 |\n",
      "|    total_reward       | 2.55e+05 |\n",
      "|    total_reward_pct   | 51       |\n",
      "|    total_trades       | 4607     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.0164  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 22.2     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.969    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.54e+05  |\n",
      "|    total_cost         | 6.46e+03  |\n",
      "|    total_reward       | -1.46e+05 |\n",
      "|    total_reward_pct   | -29.2     |\n",
      "|    total_trades       | 4571      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 28.3      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.61      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 612997.30\n",
      "total_reward: 112997.30\n",
      "total_cost: 8770.32\n",
      "total_trades: 4490\n",
      "Sharpe: 0.900\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.33e+05 |\n",
      "|    total_cost         | 7.01e+03 |\n",
      "|    total_reward       | 3.26e+04 |\n",
      "|    total_reward_pct   | 6.52     |\n",
      "|    total_trades       | 4435     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 32.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.88e+05  |\n",
      "|    total_cost         | 8.35e+03  |\n",
      "|    total_reward       | 8.81e+04  |\n",
      "|    total_reward_pct   | 17.6      |\n",
      "|    total_trades       | 4373      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -0.431    |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.228     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.43e+05 |\n",
      "|    total_cost         | 1.02e+04 |\n",
      "|    total_reward       | 3.43e+05 |\n",
      "|    total_reward_pct   | 68.5     |\n",
      "|    total_trades       | 4390     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.459    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 76       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 9.78     |\n",
      "------------------------------------\n",
      "day: 312, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 761342.46\n",
      "total_reward: 261342.46\n",
      "total_cost: 7823.74\n",
      "total_trades: 4438\n",
      "Sharpe: 1.674\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.64e+05 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 1.64e+05 |\n",
      "|    total_reward_pct   | 32.9     |\n",
      "|    total_trades       | 4410     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.2e+05  |\n",
      "|    total_cost         | 1.49e+04 |\n",
      "|    total_reward       | 2.2e+05  |\n",
      "|    total_reward_pct   | 44       |\n",
      "|    total_trades       | 4327     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -7.45    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.47e+05 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 2.47e+05 |\n",
      "|    total_reward_pct   | 49.4     |\n",
      "|    total_trades       | 4260     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 26.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "day: 312, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 821079.78\n",
      "total_reward: 321079.78\n",
      "total_cost: 11087.10\n",
      "total_trades: 4271\n",
      "Sharpe: 1.259\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.21e+05 |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 3.21e+05 |\n",
      "|    total_reward_pct   | 64.2     |\n",
      "|    total_trades       | 4271     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -0.0353  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.47e+05 |\n",
      "|    total_cost         | 1.28e+04 |\n",
      "|    total_reward       | 2.47e+05 |\n",
      "|    total_reward_pct   | 49.4     |\n",
      "|    total_trades       | 4194     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 8.17     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.468    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.49e+05  |\n",
      "|    total_cost         | 7.19e+03  |\n",
      "|    total_reward       | -5.13e+04 |\n",
      "|    total_reward_pct   | -10.3     |\n",
      "|    total_trades       | 4013      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | -0.0615   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | 50.8      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 5.63      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 533984.38\n",
      "total_reward: 33984.38\n",
      "total_cost: 5363.37\n",
      "total_trades: 3976\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.34e+05 |\n",
      "|    total_cost         | 5.36e+03 |\n",
      "|    total_reward       | 3.4e+04  |\n",
      "|    total_reward_pct   | 6.8      |\n",
      "|    total_trades       | 3976     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 3.47     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0306   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.97e+05  |\n",
      "|    total_cost         | 4.32e+03  |\n",
      "|    total_reward       | -2.65e+03 |\n",
      "|    total_reward_pct   | -0.53     |\n",
      "|    total_trades       | 3945      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 103       |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.53e+05 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 1.53e+05 |\n",
      "|    total_reward_pct   | 30.6     |\n",
      "|    total_trades       | 3995     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -5.51    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -67.9    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 7.92     |\n",
      "------------------------------------\n",
      "day: 312, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 630523.95\n",
      "total_reward: 130523.95\n",
      "total_cost: 11015.11\n",
      "total_trades: 4068\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.31e+05  |\n",
      "|    total_cost         | 1.1e+04   |\n",
      "|    total_reward       | 1.31e+05  |\n",
      "|    total_reward_pct   | 26.1      |\n",
      "|    total_trades       | 4068      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 1.32      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.571     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.8e+05   |\n",
      "|    total_cost         | 1.74e+04  |\n",
      "|    total_reward       | -2.01e+04 |\n",
      "|    total_reward_pct   | -4.01     |\n",
      "|    total_trades       | 4080      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | 0.234     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 17.9      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.95e+05  |\n",
      "|    total_cost         | 7.89e+03  |\n",
      "|    total_reward       | -1.05e+05 |\n",
      "|    total_reward_pct   | -21       |\n",
      "|    total_trades       | 3876      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | 0.147     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -27.3     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.35      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 639999.28\n",
      "total_reward: 139999.28\n",
      "total_cost: 16245.46\n",
      "total_trades: 4054\n",
      "Sharpe: 1.188\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.4e+05  |\n",
      "|    total_cost         | 1.62e+04 |\n",
      "|    total_reward       | 1.4e+05  |\n",
      "|    total_reward_pct   | 28       |\n",
      "|    total_trades       | 4054     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0.0854   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 2.48     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0577   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.85e+05 |\n",
      "|    total_cost         | 1.55e+04 |\n",
      "|    total_reward       | 2.85e+05 |\n",
      "|    total_reward_pct   | 57       |\n",
      "|    total_trades       | 4100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.77e+05  |\n",
      "|    total_cost         | 1.18e+04  |\n",
      "|    total_reward       | -2.26e+04 |\n",
      "|    total_reward_pct   | -4.52     |\n",
      "|    total_trades       | 4044      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.8     |\n",
      "|    explained_variance | -0.915    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | 34.2      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "day: 312, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 591395.68\n",
      "total_reward: 91395.68\n",
      "total_cost: 13320.91\n",
      "total_trades: 4120\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.91e+05 |\n",
      "|    total_cost         | 1.33e+04 |\n",
      "|    total_reward       | 9.14e+04 |\n",
      "|    total_reward_pct   | 18.3     |\n",
      "|    total_trades       | 4120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.000875 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -32.3    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.95e+05 |\n",
      "|    total_cost         | 1.47e+04 |\n",
      "|    total_reward       | 1.95e+05 |\n",
      "|    total_reward_pct   | 38.9     |\n",
      "|    total_trades       | 4183     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 98.2     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.04e+05  |\n",
      "|    total_cost         | 1.74e+04  |\n",
      "|    total_reward       | 4.04e+05  |\n",
      "|    total_reward_pct   | 80.8      |\n",
      "|    total_trades       | 4157      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -9.94e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 13.7      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.267     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.67e+05 |\n",
      "|    total_cost         | 1.86e+04 |\n",
      "|    total_reward       | 3.67e+05 |\n",
      "|    total_reward_pct   | 73.3     |\n",
      "|    total_trades       | 4195     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -21.7    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.586    |\n",
      "------------------------------------\n",
      "day: 312, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 820228.71\n",
      "total_reward: 320228.71\n",
      "total_cost: 10747.09\n",
      "total_trades: 4158\n",
      "Sharpe: 1.237\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.61e+05  |\n",
      "|    total_cost         | 1.27e+04  |\n",
      "|    total_reward       | 3.61e+05  |\n",
      "|    total_reward_pct   | 72.1      |\n",
      "|    total_trades       | 4104      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 10.8      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.191     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.93e+05 |\n",
      "|    total_cost         | 2.08e+04 |\n",
      "|    total_reward       | 2.93e+05 |\n",
      "|    total_reward_pct   | 58.5     |\n",
      "|    total_trades       | 4184     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0.238    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -47.2    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 3.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.5e+05  |\n",
      "|    total_cost         | 1.97e+04 |\n",
      "|    total_reward       | 1.5e+05  |\n",
      "|    total_reward_pct   | 30       |\n",
      "|    total_trades       | 4348     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 30.2     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "day: 312, episode: 200\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 648660.46\n",
      "total_reward: 148660.46\n",
      "total_cost: 13330.88\n",
      "total_trades: 4395\n",
      "Sharpe: 0.718\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.84e+05 |\n",
      "|    total_cost         | 1.33e+04 |\n",
      "|    total_reward       | 1.84e+05 |\n",
      "|    total_reward_pct   | 36.8     |\n",
      "|    total_trades       | 4361     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.607   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -16.4    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.482    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.41e+05 |\n",
      "|    total_cost         | 1.26e+04 |\n",
      "|    total_reward       | 1.41e+05 |\n",
      "|    total_reward_pct   | 28.2     |\n",
      "|    total_trades       | 4193     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 38.4     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.19e+05 |\n",
      "|    total_cost         | 1.37e+04 |\n",
      "|    total_reward       | 2.19e+05 |\n",
      "|    total_reward_pct   | 43.9     |\n",
      "|    total_trades       | 4264     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.592    |\n",
      "------------------------------------\n",
      "day: 312, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 805100.60\n",
      "total_reward: 305100.60\n",
      "total_cost: 11421.91\n",
      "total_trades: 4027\n",
      "Sharpe: 1.258\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.13e+05  |\n",
      "|    total_cost         | 9.71e+03  |\n",
      "|    total_reward       | -8.71e+04 |\n",
      "|    total_reward_pct   | -17.4     |\n",
      "|    total_trades       | 4158      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -0.408    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -2.41     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.216     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.21e+05 |\n",
      "|    total_cost         | 1.33e+04 |\n",
      "|    total_reward       | 1.21e+05 |\n",
      "|    total_reward_pct   | 24.2     |\n",
      "|    total_trades       | 4098     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -2.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 3.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.56e+05 |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 1.56e+05 |\n",
      "|    total_reward_pct   | 31.3     |\n",
      "|    total_trades       | 4178     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -0.0343  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 8.46     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.159    |\n",
      "------------------------------------\n",
      "day: 312, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 512400.63\n",
      "total_reward: 12400.63\n",
      "total_cost: 9448.45\n",
      "total_trades: 4175\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.12e+05 |\n",
      "|    total_cost         | 9.45e+03 |\n",
      "|    total_reward       | 1.24e+04 |\n",
      "|    total_reward_pct   | 2.48     |\n",
      "|    total_trades       | 4175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -0.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -8.35    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.363    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.15e+05 |\n",
      "|    total_cost         | 7.72e+03 |\n",
      "|    total_reward       | 1.15e+05 |\n",
      "|    total_reward_pct   | 23       |\n",
      "|    total_trades       | 4208     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 32.8     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.86e+05 |\n",
      "|    total_cost         | 9.16e+03 |\n",
      "|    total_reward       | 1.86e+05 |\n",
      "|    total_reward_pct   | 37.2     |\n",
      "|    total_trades       | 4228     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 14.4     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.367    |\n",
      "------------------------------------\n",
      "day: 312, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 756925.47\n",
      "total_reward: 256925.47\n",
      "total_cost: 14518.48\n",
      "total_trades: 4197\n",
      "Sharpe: 1.149\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.57e+05 |\n",
      "|    total_cost         | 1.45e+04 |\n",
      "|    total_reward       | 2.57e+05 |\n",
      "|    total_reward_pct   | 51.4     |\n",
      "|    total_trades       | 4197     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -0.352   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -186     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 42.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.32e+05 |\n",
      "|    total_cost         | 9.19e+03 |\n",
      "|    total_reward       | 1.32e+05 |\n",
      "|    total_reward_pct   | 26.4     |\n",
      "|    total_trades       | 4192     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 29.8     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.45e+05 |\n",
      "|    total_cost         | 8.52e+03 |\n",
      "|    total_reward       | 1.45e+05 |\n",
      "|    total_reward_pct   | 29.1     |\n",
      "|    total_trades       | 4127     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "day: 312, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 435322.87\n",
      "total_reward: -64677.13\n",
      "total_cost: 6697.33\n",
      "total_trades: 4003\n",
      "Sharpe: -0.243\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.35e+05  |\n",
      "|    total_cost         | 6.7e+03   |\n",
      "|    total_reward       | -6.47e+04 |\n",
      "|    total_reward_pct   | -12.9     |\n",
      "|    total_trades       | 4003      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -7.66     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.172     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.65e+05 |\n",
      "|    total_cost         | 4.49e+03 |\n",
      "|    total_reward       | 6.45e+04 |\n",
      "|    total_reward_pct   | 12.9     |\n",
      "|    total_trades       | 4082     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 3.09     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0305   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.35e+05 |\n",
      "|    total_cost         | 5.62e+03 |\n",
      "|    total_reward       | 3.53e+04 |\n",
      "|    total_reward_pct   | 7.06     |\n",
      "|    total_trades       | 4143     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -1.63    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n",
      "day: 312, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 747192.68\n",
      "total_reward: 247192.68\n",
      "total_cost: 13633.50\n",
      "total_trades: 4163\n",
      "Sharpe: 1.105\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.47e+05  |\n",
      "|    total_cost         | 1.36e+04  |\n",
      "|    total_reward       | 2.47e+05  |\n",
      "|    total_reward_pct   | 49.4      |\n",
      "|    total_trades       | 4163      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 5.78      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.67e+05 |\n",
      "|    total_cost         | 7.95e+03 |\n",
      "|    total_reward       | 2.67e+05 |\n",
      "|    total_reward_pct   | 53.5     |\n",
      "|    total_trades       | 4101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -0.331   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 20.5     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.818    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.5e+05  |\n",
      "|    total_cost         | 1.01e+04 |\n",
      "|    total_reward       | 1.5e+05  |\n",
      "|    total_reward_pct   | 30.1     |\n",
      "|    total_trades       | 4189     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -20.4    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.649    |\n",
      "------------------------------------\n",
      "day: 312, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 810437.78\n",
      "total_reward: 310437.78\n",
      "total_cost: 12538.24\n",
      "total_trades: 4123\n",
      "Sharpe: 1.199\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.1e+05  |\n",
      "|    total_cost         | 1.25e+04 |\n",
      "|    total_reward       | 3.1e+05  |\n",
      "|    total_reward_pct   | 62.1     |\n",
      "|    total_trades       | 4123     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.645    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 60.5     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 16.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.54e+05  |\n",
      "|    total_cost         | 1.12e+04  |\n",
      "|    total_reward       | 1.54e+05  |\n",
      "|    total_reward_pct   | 30.7      |\n",
      "|    total_trades       | 4133      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -20.6     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.892     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.79e+05 |\n",
      "|    total_cost         | 1.39e+04 |\n",
      "|    total_reward       | 7.93e+04 |\n",
      "|    total_reward_pct   | 15.9     |\n",
      "|    total_trades       | 3947     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.168   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 52.2     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 5.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.73e+05 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 2.73e+05 |\n",
      "|    total_reward_pct   | 54.6     |\n",
      "|    total_trades       | 4153     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.0103  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 14       |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.534    |\n",
      "------------------------------------\n",
      "day: 312, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 671664.78\n",
      "total_reward: 171664.78\n",
      "total_cost: 12608.10\n",
      "total_trades: 4158\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.68e+05 |\n",
      "|    total_cost         | 9.98e+03 |\n",
      "|    total_reward       | 6.81e+04 |\n",
      "|    total_reward_pct   | 13.6     |\n",
      "|    total_trades       | 4120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 22.3     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.926    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.9e+05  |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 2.9e+05  |\n",
      "|    total_reward_pct   | 58.1     |\n",
      "|    total_trades       | 4129     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0.477    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 75.1     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 47.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.31e+05 |\n",
      "|    total_cost         | 1.13e+04 |\n",
      "|    total_reward       | 2.31e+05 |\n",
      "|    total_reward_pct   | 46.2     |\n",
      "|    total_trades       | 4185     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 44.1     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 3.1      |\n",
      "------------------------------------\n",
      "day: 312, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 785101.81\n",
      "total_reward: 285101.81\n",
      "total_cost: 12072.29\n",
      "total_trades: 4081\n",
      "Sharpe: 1.307\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.03e+05 |\n",
      "|    total_cost         | 9.67e+03 |\n",
      "|    total_reward       | 2.03e+05 |\n",
      "|    total_reward_pct   | 40.6     |\n",
      "|    total_trades       | 4195     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.291   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 25.1     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.77e+05 |\n",
      "|    total_cost         | 1.35e+04 |\n",
      "|    total_reward       | 1.77e+05 |\n",
      "|    total_reward_pct   | 35.4     |\n",
      "|    total_trades       | 4181     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.603   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 66.7     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 5.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.34e+05 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 3.34e+05 |\n",
      "|    total_reward_pct   | 66.8     |\n",
      "|    total_trades       | 4194     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -5.77    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 42.5     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "day: 312, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 662028.14\n",
      "total_reward: 162028.14\n",
      "total_cost: 9126.81\n",
      "total_trades: 4219\n",
      "Sharpe: 1.262\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.61e+05  |\n",
      "|    total_cost         | 9.56e+03  |\n",
      "|    total_reward       | 4.61e+05  |\n",
      "|    total_reward_pct   | 92.1      |\n",
      "|    total_trades       | 4228      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -3.79     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.226     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.8e+05  |\n",
      "|    total_cost         | 7.63e+03 |\n",
      "|    total_reward       | 2.8e+05  |\n",
      "|    total_reward_pct   | 56       |\n",
      "|    total_trades       | 4191     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 51.6     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.63e+05 |\n",
      "|    total_cost         | 6.38e+03 |\n",
      "|    total_reward       | 4.63e+05 |\n",
      "|    total_reward_pct   | 92.6     |\n",
      "|    total_trades       | 3964     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.256   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -4.2     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.472    |\n",
      "------------------------------------\n",
      "day: 312, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 891969.73\n",
      "total_reward: 391969.73\n",
      "total_cost: 7407.33\n",
      "total_trades: 3886\n",
      "Sharpe: 1.549\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.92e+05 |\n",
      "|    total_cost         | 7.41e+03 |\n",
      "|    total_reward       | 3.92e+05 |\n",
      "|    total_reward_pct   | 78.4     |\n",
      "|    total_trades       | 3886     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -6.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -32      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.53e+05 |\n",
      "|    total_cost         | 4.8e+03  |\n",
      "|    total_reward       | 2.53e+05 |\n",
      "|    total_reward_pct   | 50.6     |\n",
      "|    total_trades       | 3813     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.174   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -22.6    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.723    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.08e+05 |\n",
      "|    total_cost         | 1.2e+04  |\n",
      "|    total_reward       | 4.08e+05 |\n",
      "|    total_reward_pct   | 81.5     |\n",
      "|    total_trades       | 3760     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.267    |\n",
      "------------------------------------\n",
      "day: 312, episode: 255\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 811031.68\n",
      "total_reward: 311031.68\n",
      "total_cost: 9133.87\n",
      "total_trades: 3753\n",
      "Sharpe: 1.205\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.11e+05  |\n",
      "|    total_cost         | 9.13e+03  |\n",
      "|    total_reward       | 3.11e+05  |\n",
      "|    total_reward_pct   | 62.2      |\n",
      "|    total_trades       | 3753      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 22.4      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.22      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.04e+05 |\n",
      "|    total_cost         | 1.15e+04 |\n",
      "|    total_reward       | 4.04e+05 |\n",
      "|    total_reward_pct   | 80.7     |\n",
      "|    total_trades       | 3728     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.0485   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -51.7    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 3        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.32e+05 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 2.32e+05 |\n",
      "|    total_reward_pct   | 46.4     |\n",
      "|    total_trades       | 3747     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.997   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 70.8     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 5.76     |\n",
      "------------------------------------\n",
      "day: 312, episode: 260\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 433966.51\n",
      "total_reward: -66033.49\n",
      "total_cost: 7071.84\n",
      "total_trades: 3584\n",
      "Sharpe: -0.384\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.34e+05 |\n",
      "|    total_cost         | 7.07e+03 |\n",
      "|    total_reward       | -6.6e+04 |\n",
      "|    total_reward_pct   | -13.2    |\n",
      "|    total_trades       | 3584     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -1.6     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 52.4     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.34e+05 |\n",
      "|    total_cost         | 1.19e+04 |\n",
      "|    total_reward       | 2.34e+05 |\n",
      "|    total_reward_pct   | 46.8     |\n",
      "|    total_trades       | 3686     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -4.26    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.165    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.55e+05 |\n",
      "|    total_cost         | 1.61e+04 |\n",
      "|    total_reward       | 5.52e+04 |\n",
      "|    total_reward_pct   | 11       |\n",
      "|    total_trades       | 3937     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -59.8    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 4.33     |\n",
      "------------------------------------\n",
      "day: 312, episode: 265\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 661856.49\n",
      "total_reward: 161856.49\n",
      "total_cost: 11862.64\n",
      "total_trades: 3900\n",
      "Sharpe: 0.947\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.62e+05  |\n",
      "|    total_cost         | 1.19e+04  |\n",
      "|    total_reward       | 1.62e+05  |\n",
      "|    total_reward_pct   | 32.4      |\n",
      "|    total_trades       | 3900      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 26.3      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.868     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.29e+05 |\n",
      "|    total_cost         | 7.04e+03 |\n",
      "|    total_reward       | 1.29e+05 |\n",
      "|    total_reward_pct   | 25.7     |\n",
      "|    total_trades       | 3965     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0.0832   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -10.9    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.541    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.6e+05  |\n",
      "|    total_cost         | 1.53e+04 |\n",
      "|    total_reward       | 2.6e+05  |\n",
      "|    total_reward_pct   | 52.1     |\n",
      "|    total_trades       | 3978     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -0.0862  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -30.7    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.66e+05 |\n",
      "|    total_cost         | 9e+03    |\n",
      "|    total_reward       | 1.66e+05 |\n",
      "|    total_reward_pct   | 33.1     |\n",
      "|    total_trades       | 3911     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -20.9    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.646    |\n",
      "------------------------------------\n",
      "day: 312, episode: 270\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 511581.66\n",
      "total_reward: 11581.66\n",
      "total_cost: 7688.59\n",
      "total_trades: 3978\n",
      "Sharpe: 0.212\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.71e+05 |\n",
      "|    total_cost         | 1.61e+04 |\n",
      "|    total_reward       | 2.71e+05 |\n",
      "|    total_reward_pct   | 54.1     |\n",
      "|    total_trades       | 3931     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0.0594   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -43.6    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.73e+05 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 1.73e+05 |\n",
      "|    total_reward_pct   | 34.6     |\n",
      "|    total_trades       | 3779     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0.0944   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.286    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.83e+05 |\n",
      "|    total_cost         | 1.22e+04 |\n",
      "|    total_reward       | 2.83e+05 |\n",
      "|    total_reward_pct   | 56.6     |\n",
      "|    total_trades       | 3838     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0.00758  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -52.9    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 4.12     |\n",
      "------------------------------------\n",
      "day: 312, episode: 275\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 744730.07\n",
      "total_reward: 244730.07\n",
      "total_cost: 12966.69\n",
      "total_trades: 3814\n",
      "Sharpe: 0.987\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.46e+05 |\n",
      "|    total_cost         | 1.47e+04 |\n",
      "|    total_reward       | 2.46e+05 |\n",
      "|    total_reward_pct   | 49.2     |\n",
      "|    total_trades       | 3728     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.669    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.84e+05 |\n",
      "|    total_cost         | 1.12e+04 |\n",
      "|    total_reward       | 1.84e+05 |\n",
      "|    total_reward_pct   | 36.8     |\n",
      "|    total_trades       | 3853     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -2.07    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0663   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.14e+05 |\n",
      "|    total_cost         | 1.56e+04 |\n",
      "|    total_reward       | 2.14e+05 |\n",
      "|    total_reward_pct   | 42.9     |\n",
      "|    total_trades       | 3932     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0.0468   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 2.91     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "day: 312, episode: 280\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 716834.95\n",
      "total_reward: 216834.95\n",
      "total_cost: 13482.04\n",
      "total_trades: 4067\n",
      "Sharpe: 1.024\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.7e+05  |\n",
      "|    total_cost         | 1.39e+04 |\n",
      "|    total_reward       | 3.7e+05  |\n",
      "|    total_reward_pct   | 73.9     |\n",
      "|    total_trades       | 4150     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -2.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 7.34     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.461    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.15e+05 |\n",
      "|    total_cost         | 1.64e+04 |\n",
      "|    total_reward       | 1.15e+05 |\n",
      "|    total_reward_pct   | 23       |\n",
      "|    total_trades       | 4240     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 14.9     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.8e+05  |\n",
      "|    total_cost         | 1.62e+04 |\n",
      "|    total_reward       | 1.8e+05  |\n",
      "|    total_reward_pct   | 36.1     |\n",
      "|    total_trades       | 4344     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.0133   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 8.52     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "day: 312, episode: 285\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 493277.28\n",
      "total_reward: -6722.72\n",
      "total_cost: 8499.70\n",
      "total_trades: 4277\n",
      "Sharpe: 0.075\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.93e+05  |\n",
      "|    total_cost         | 8.5e+03   |\n",
      "|    total_reward       | -6.72e+03 |\n",
      "|    total_reward_pct   | -1.34     |\n",
      "|    total_trades       | 4277      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | -0.873    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | -49.7     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 2.87      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.99e+05  |\n",
      "|    total_cost         | 1e+04     |\n",
      "|    total_reward       | -1.01e+05 |\n",
      "|    total_reward_pct   | -20.2     |\n",
      "|    total_trades       | 4168      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | 0.67      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | 24.1      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.93e+05 |\n",
      "|    total_cost         | 1.52e+04 |\n",
      "|    total_reward       | 9.27e+04 |\n",
      "|    total_reward_pct   | 18.5     |\n",
      "|    total_trades       | 4402     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -0.026   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 4.97     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.661    |\n",
      "------------------------------------\n",
      "day: 312, episode: 290\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 706223.35\n",
      "total_reward: 206223.35\n",
      "total_cost: 12153.25\n",
      "total_trades: 4320\n",
      "Sharpe: 0.877\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.06e+05 |\n",
      "|    total_cost         | 1.22e+04 |\n",
      "|    total_reward       | 2.06e+05 |\n",
      "|    total_reward_pct   | 41.2     |\n",
      "|    total_trades       | 4320     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 0.665    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.255    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.04e+05 |\n",
      "|    total_cost         | 9.02e+03 |\n",
      "|    total_reward       | 1.04e+05 |\n",
      "|    total_reward_pct   | 20.8     |\n",
      "|    total_trades       | 4195     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.0273   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 19       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.771    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.44e+05  |\n",
      "|    total_cost         | 1.27e+04  |\n",
      "|    total_reward       | 1.44e+05  |\n",
      "|    total_reward_pct   | 28.8      |\n",
      "|    total_trades       | 4373      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | 12.5      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.467     |\n",
      "-------------------------------------\n",
      "day: 312, episode: 295\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 592095.74\n",
      "total_reward: 92095.74\n",
      "total_cost: 10102.27\n",
      "total_trades: 4252\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.92e+05  |\n",
      "|    total_cost         | 1.01e+04  |\n",
      "|    total_reward       | 9.21e+04  |\n",
      "|    total_reward_pct   | 18.4      |\n",
      "|    total_trades       | 4252      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 23.9      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.779     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.6e+05  |\n",
      "|    total_cost         | 1.2e+04  |\n",
      "|    total_reward       | 2.6e+05  |\n",
      "|    total_reward_pct   | 52       |\n",
      "|    total_trades       | 4287     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.0423   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 171      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.47e+05 |\n",
      "|    total_cost         | 8.11e+03 |\n",
      "|    total_reward       | 4.73e+04 |\n",
      "|    total_reward_pct   | 9.46     |\n",
      "|    total_trades       | 4280     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 4.56     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0455   |\n",
      "------------------------------------\n",
      "day: 312, episode: 300\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 525789.50\n",
      "total_reward: 25789.50\n",
      "total_cost: 3852.61\n",
      "total_trades: 4195\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.26e+05  |\n",
      "|    total_cost         | 3.85e+03  |\n",
      "|    total_reward       | 2.58e+04  |\n",
      "|    total_reward_pct   | 5.16      |\n",
      "|    total_trades       | 4195      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | 12        |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.384     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.71e+05 |\n",
      "|    total_cost         | 6.84e+03 |\n",
      "|    total_reward       | 2.71e+05 |\n",
      "|    total_reward_pct   | 54.2     |\n",
      "|    total_trades       | 4183     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.5e+05  |\n",
      "|    total_cost         | 3.92e+03 |\n",
      "|    total_reward       | 5e+04    |\n",
      "|    total_reward_pct   | 10       |\n",
      "|    total_trades       | 4244     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "day: 312, episode: 305\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 581928.86\n",
      "total_reward: 81928.86\n",
      "total_cost: 6449.34\n",
      "total_trades: 4221\n",
      "Sharpe: 0.494\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.82e+05 |\n",
      "|    total_cost         | 6.45e+03 |\n",
      "|    total_reward       | 8.19e+04 |\n",
      "|    total_reward_pct   | 16.4     |\n",
      "|    total_trades       | 4221     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -76.5    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 6.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.08e+05 |\n",
      "|    total_cost         | 7.59e+03 |\n",
      "|    total_reward       | 1.08e+05 |\n",
      "|    total_reward_pct   | 21.6     |\n",
      "|    total_trades       | 4186     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -32.1    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.46e+05 |\n",
      "|    total_cost         | 7.72e+03 |\n",
      "|    total_reward       | 3.46e+05 |\n",
      "|    total_reward_pct   | 69.2     |\n",
      "|    total_trades       | 4313     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -9.43    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.32e+05 |\n",
      "|    total_cost         | 4.86e+03 |\n",
      "|    total_reward       | -6.8e+04 |\n",
      "|    total_reward_pct   | -13.6    |\n",
      "|    total_trades       | 4325     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -25.9    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.701    |\n",
      "------------------------------------\n",
      "day: 312, episode: 310\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 520735.39\n",
      "total_reward: 20735.39\n",
      "total_cost: 7775.84\n",
      "total_trades: 4361\n",
      "Sharpe: 0.258\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.48e+05 |\n",
      "|    total_cost         | 7.24e+03 |\n",
      "|    total_reward       | 4.82e+04 |\n",
      "|    total_reward_pct   | 9.64     |\n",
      "|    total_trades       | 4298     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -27      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.83e+05 |\n",
      "|    total_cost         | 6.96e+03 |\n",
      "|    total_reward       | 1.83e+05 |\n",
      "|    total_reward_pct   | 36.5     |\n",
      "|    total_trades       | 4279     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -1.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.234   |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.74e+05  |\n",
      "|    total_cost         | 6.92e+03  |\n",
      "|    total_reward       | -2.62e+04 |\n",
      "|    total_reward_pct   | -5.25     |\n",
      "|    total_trades       | 4300      |\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 14.6      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.743     |\n",
      "-------------------------------------\n",
      "day: 312, episode: 315\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 517605.00\n",
      "total_reward: 17605.00\n",
      "total_cost: 6751.04\n",
      "total_trades: 4448\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.97e+05 |\n",
      "|    total_cost         | 6.63e+03 |\n",
      "|    total_reward       | 1.97e+05 |\n",
      "|    total_reward_pct   | 39.4     |\n",
      "|    total_trades       | 4466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.311    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.27e+05 |\n",
      "|    total_cost         | 1.07e+04 |\n",
      "|    total_reward       | 4.27e+05 |\n",
      "|    total_reward_pct   | 85.3     |\n",
      "|    total_trades       | 4457     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -4.56    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.63e+05 |\n",
      "|    total_cost         | 7.24e+03 |\n",
      "|    total_reward       | 1.63e+05 |\n",
      "|    total_reward_pct   | 32.6     |\n",
      "|    total_trades       | 4409     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-04-04 to  2019-07-05\n",
      "A2C Sharpe Ratio:  nan\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_1\n",
      "day: 312, episode: 325\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 158138.32\n",
      "total_reward: -341861.68\n",
      "total_cost: 107339.37\n",
      "total_trades: 4362\n",
      "Sharpe: -1.784\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.55e+05  |\n",
      "|    total_cost       | 2.29e+05  |\n",
      "|    total_reward     | -4.54e+04 |\n",
      "|    total_reward_pct | -9.09     |\n",
      "|    total_trades     | 4703      |\n",
      "| time/               |           |\n",
      "|    fps              | 829       |\n",
      "|    iterations       | 1         |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 2048      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 330\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 328451.06\n",
      "total_reward: -171548.94\n",
      "total_cost: 140817.02\n",
      "total_trades: 4531\n",
      "Sharpe: -0.870\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.19e+05    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | 1.86e+04    |\n",
      "|    total_reward_pct     | 3.72        |\n",
      "|    total_trades         | 4717        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 766         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013372228 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.507       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.42        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 335\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 297450.51\n",
      "total_reward: -202549.49\n",
      "total_cost: 150839.46\n",
      "total_trades: 4394\n",
      "Sharpe: -0.844\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+05     |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | -2.1e+05    |\n",
      "|    total_reward_pct     | -42.1       |\n",
      "|    total_trades         | 4478        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 749         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008479581 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0593      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.532       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 340\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 252239.13\n",
      "total_reward: -247760.87\n",
      "total_cost: 148371.75\n",
      "total_trades: 4547\n",
      "Sharpe: -1.664\n",
      "=================================\n",
      "day: 312, episode: 345\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 288857.01\n",
      "total_reward: -211142.99\n",
      "total_cost: 144465.94\n",
      "total_trades: 4493\n",
      "Sharpe: -1.215\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.69e+05    |\n",
      "|    total_cost           | 9.01e+04    |\n",
      "|    total_reward         | -3.31e+05   |\n",
      "|    total_reward_pct     | -66.2       |\n",
      "|    total_trades         | 4364        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 740         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014000524 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 350\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 382519.74\n",
      "total_reward: -117480.26\n",
      "total_cost: 205009.35\n",
      "total_trades: 4631\n",
      "Sharpe: -0.307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+05    |\n",
      "|    total_cost           | 1.34e+05    |\n",
      "|    total_reward         | -2.13e+05   |\n",
      "|    total_reward_pct     | -42.6       |\n",
      "|    total_trades         | 4553        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011839146 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 355\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 419292.60\n",
      "total_reward: -80707.40\n",
      "total_cost: 208755.19\n",
      "total_trades: 4686\n",
      "Sharpe: -0.621\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.84e+05  |\n",
      "|    total_cost           | 1.65e+05  |\n",
      "|    total_reward         | -1.16e+05 |\n",
      "|    total_reward_pct     | -23.2     |\n",
      "|    total_trades         | 4508      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 735       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0180744 |\n",
      "|    clip_fraction        | 0.179     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27       |\n",
      "|    explained_variance   | 0.195     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.635     |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.0183   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.78      |\n",
      "---------------------------------------\n",
      "day: 312, episode: 360\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 456950.97\n",
      "total_reward: -43049.03\n",
      "total_cost: 210263.84\n",
      "total_trades: 4542\n",
      "Sharpe: -0.182\n",
      "=================================\n",
      "day: 312, episode: 365\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 609484.11\n",
      "total_reward: 109484.11\n",
      "total_cost: 230155.19\n",
      "total_trades: 4708\n",
      "Sharpe: 0.591\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.09e+05    |\n",
      "|    total_cost           | 2.3e+05     |\n",
      "|    total_reward         | 1.09e+05    |\n",
      "|    total_reward_pct     | 21.9        |\n",
      "|    total_trades         | 4708        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011967109 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.455       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 370\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 488609.76\n",
      "total_reward: -11390.24\n",
      "total_cost: 215697.02\n",
      "total_trades: 4669\n",
      "Sharpe: 0.087\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+05    |\n",
      "|    total_cost           | 1.05e+05    |\n",
      "|    total_reward         | -2.56e+05   |\n",
      "|    total_reward_pct     | -51.3       |\n",
      "|    total_trades         | 4374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022164498 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.333       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 375\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 604811.21\n",
      "total_reward: 104811.21\n",
      "total_cost: 185943.94\n",
      "total_trades: 4619\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+05    |\n",
      "|    total_cost           | 1.27e+05    |\n",
      "|    total_reward         | -2.45e+05   |\n",
      "|    total_reward_pct     | -49         |\n",
      "|    total_trades         | 4566        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 739         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022658397 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.33        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 380\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 334297.75\n",
      "total_reward: -165702.25\n",
      "total_cost: 159099.30\n",
      "total_trades: 4469\n",
      "Sharpe: -1.290\n",
      "=================================\n",
      "day: 312, episode: 385\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 360496.89\n",
      "total_reward: -139503.11\n",
      "total_cost: 149358.39\n",
      "total_trades: 4544\n",
      "Sharpe: -0.909\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.6e+05     |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | -1.4e+05    |\n",
      "|    total_reward_pct     | -27.9       |\n",
      "|    total_trades         | 4544        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 740         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026487116 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.06        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.711       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 390\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 282426.71\n",
      "total_reward: -217573.29\n",
      "total_cost: 127830.19\n",
      "total_trades: 4465\n",
      "Sharpe: -0.782\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.25e+05    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | 2.51e+04    |\n",
      "|    total_reward_pct     | 5.03        |\n",
      "|    total_trades         | 4593        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 741         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024430953 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0536      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 395\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 410146.61\n",
      "total_reward: -89853.39\n",
      "total_cost: 146454.12\n",
      "total_trades: 4450\n",
      "Sharpe: -0.399\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.96e+05    |\n",
      "|    total_cost           | 1.06e+05    |\n",
      "|    total_reward         | -2.04e+05   |\n",
      "|    total_reward_pct     | -40.8       |\n",
      "|    total_trades         | 4402        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 742         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020067897 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0685      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.807       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 400\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 537116.97\n",
      "total_reward: 37116.97\n",
      "total_cost: 146392.10\n",
      "total_trades: 4464\n",
      "Sharpe: 0.393\n",
      "=================================\n",
      "day: 312, episode: 405\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 287458.80\n",
      "total_reward: -212541.20\n",
      "total_cost: 121515.42\n",
      "total_trades: 4443\n",
      "Sharpe: -1.081\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.87e+05    |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | -2.13e+05   |\n",
      "|    total_reward_pct     | -42.5       |\n",
      "|    total_trades         | 4443        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 741         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022157565 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.404       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.34        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 410\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 401978.39\n",
      "total_reward: -98021.61\n",
      "total_cost: 148117.16\n",
      "total_trades: 4510\n",
      "Sharpe: -0.482\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.03e+05    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | 1.03e+05    |\n",
      "|    total_reward_pct     | 20.6        |\n",
      "|    total_trades         | 4659        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020936832 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 415\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 628700.09\n",
      "total_reward: 128700.09\n",
      "total_cost: 199233.59\n",
      "total_trades: 4566\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.43e+05    |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | -1.57e+05   |\n",
      "|    total_reward_pct     | -31.3       |\n",
      "|    total_trades         | 4444        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024820432 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 420\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 761176.67\n",
      "total_reward: 261176.67\n",
      "total_cost: 219894.89\n",
      "total_trades: 4787\n",
      "Sharpe: 1.222\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.75e+05    |\n",
      "|    total_cost           | 1.86e+05    |\n",
      "|    total_reward         | -2.52e+04   |\n",
      "|    total_reward_pct     | -5.04       |\n",
      "|    total_trades         | 4586        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022632305 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.513       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 425\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 578108.26\n",
      "total_reward: 78108.26\n",
      "total_cost: 194292.67\n",
      "total_trades: 4656\n",
      "Sharpe: 0.524\n",
      "=================================\n",
      "day: 312, episode: 430\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 360707.94\n",
      "total_reward: -139292.06\n",
      "total_cost: 156552.17\n",
      "total_trades: 4486\n",
      "Sharpe: -1.083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+05    |\n",
      "|    total_cost           | 1.01e+05    |\n",
      "|    total_reward         | -2.35e+05   |\n",
      "|    total_reward_pct     | -46.9       |\n",
      "|    total_trades         | 4398        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023023881 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.802       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 435\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 550330.29\n",
      "total_reward: 50330.29\n",
      "total_cost: 201148.75\n",
      "total_trades: 4512\n",
      "Sharpe: 0.390\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.11e+05    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | -8.87e+04   |\n",
      "|    total_reward_pct     | -17.7       |\n",
      "|    total_trades         | 4550        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024911117 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 440\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 444417.77\n",
      "total_reward: -55582.23\n",
      "total_cost: 145883.06\n",
      "total_trades: 4475\n",
      "Sharpe: -0.365\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.51e+05   |\n",
      "|    total_cost           | 1.9e+05    |\n",
      "|    total_reward         | 5.05e+04   |\n",
      "|    total_reward_pct     | 10.1       |\n",
      "|    total_trades         | 4567       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 737        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01624965 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.17       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 2.53       |\n",
      "----------------------------------------\n",
      "day: 312, episode: 445\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 599600.13\n",
      "total_reward: 99600.13\n",
      "total_cost: 171098.00\n",
      "total_trades: 4624\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "day: 312, episode: 450\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 439431.87\n",
      "total_reward: -60568.13\n",
      "total_cost: 129882.19\n",
      "total_trades: 4420\n",
      "Sharpe: -0.359\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.39e+05   |\n",
      "|    total_cost           | 1.3e+05    |\n",
      "|    total_reward         | -6.06e+04  |\n",
      "|    total_reward_pct     | -12.1      |\n",
      "|    total_trades         | 4420       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 736        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01968237 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.58       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 2.48       |\n",
      "----------------------------------------\n",
      "day: 312, episode: 455\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 796168.61\n",
      "total_reward: 296168.61\n",
      "total_cost: 198135.99\n",
      "total_trades: 4534\n",
      "Sharpe: 1.242\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.71e+05    |\n",
      "|    total_cost           | 8.89e+04    |\n",
      "|    total_reward         | -1.29e+05   |\n",
      "|    total_reward_pct     | -25.7       |\n",
      "|    total_trades         | 4225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026895002 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.26        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 460\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 416130.65\n",
      "total_reward: -83869.35\n",
      "total_cost: 116864.49\n",
      "total_trades: 4485\n",
      "Sharpe: -0.407\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.83e+05   |\n",
      "|    total_cost           | 1.09e+05   |\n",
      "|    total_reward         | -2.17e+05  |\n",
      "|    total_reward_pct     | -43.4      |\n",
      "|    total_trades         | 4329       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 735        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02014187 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.347      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.833      |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 2.9        |\n",
      "----------------------------------------\n",
      "day: 312, episode: 465\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 306599.80\n",
      "total_reward: -193400.20\n",
      "total_cost: 118938.74\n",
      "total_trades: 4293\n",
      "Sharpe: -0.902\n",
      "=================================\n",
      "day: 312, episode: 470\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 368874.71\n",
      "total_reward: -131125.29\n",
      "total_cost: 81102.08\n",
      "total_trades: 4309\n",
      "Sharpe: -0.275\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.69e+05    |\n",
      "|    total_cost           | 8.11e+04    |\n",
      "|    total_reward         | -1.31e+05   |\n",
      "|    total_reward_pct     | -26.2       |\n",
      "|    total_trades         | 4309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025958339 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 475\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 720826.22\n",
      "total_reward: 220826.22\n",
      "total_cost: 185558.96\n",
      "total_trades: 4630\n",
      "Sharpe: 0.966\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.95e+05    |\n",
      "|    total_cost           | 1.02e+05    |\n",
      "|    total_reward         | -4.51e+03   |\n",
      "|    total_reward_pct     | -0.902      |\n",
      "|    total_trades         | 4348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023623932 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.778       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 480\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 708527.09\n",
      "total_reward: 208527.09\n",
      "total_cost: 170968.43\n",
      "total_trades: 4521\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.4e+05     |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | 1.4e+05     |\n",
      "|    total_reward_pct     | 28          |\n",
      "|    total_trades         | 4354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025864977 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 485\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 395281.98\n",
      "total_reward: -104718.02\n",
      "total_cost: 79438.55\n",
      "total_trades: 4174\n",
      "Sharpe: -0.131\n",
      "=================================\n",
      "day: 312, episode: 490\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 912551.49\n",
      "total_reward: 412551.49\n",
      "total_cost: 138766.20\n",
      "total_trades: 4518\n",
      "Sharpe: 1.676\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.13e+05    |\n",
      "|    total_cost           | 1.39e+05    |\n",
      "|    total_reward         | 4.13e+05    |\n",
      "|    total_reward_pct     | 82.5        |\n",
      "|    total_trades         | 4518        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021974724 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.79        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 495\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 488383.28\n",
      "total_reward: -11616.72\n",
      "total_cost: 120202.11\n",
      "total_trades: 4387\n",
      "Sharpe: 0.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.72e+05    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 1.72e+05    |\n",
      "|    total_reward_pct     | 34.3        |\n",
      "|    total_trades         | 4421        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010773697 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 500\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 510185.87\n",
      "total_reward: 10185.87\n",
      "total_cost: 99760.62\n",
      "total_trades: 4283\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.46e+05   |\n",
      "|    total_cost           | 1.38e+05   |\n",
      "|    total_reward         | 2.46e+05   |\n",
      "|    total_reward_pct     | 49.1       |\n",
      "|    total_trades         | 4419       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 731        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01650915 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.52       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 3.76       |\n",
      "----------------------------------------\n",
      "day: 312, episode: 505\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 849622.49\n",
      "total_reward: 349622.49\n",
      "total_cost: 173524.41\n",
      "total_trades: 4468\n",
      "Sharpe: 1.575\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.01e+06   |\n",
      "|    total_cost           | 1.63e+05   |\n",
      "|    total_reward         | 5.07e+05   |\n",
      "|    total_reward_pct     | 101        |\n",
      "|    total_trades         | 4448       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 729        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 81         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01865574 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.264      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.952      |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 3.26       |\n",
      "----------------------------------------\n",
      "day: 312, episode: 510\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 826985.15\n",
      "total_reward: 326985.15\n",
      "total_cost: 142484.96\n",
      "total_trades: 4420\n",
      "Sharpe: 1.442\n",
      "=================================\n",
      "day: 312, episode: 515\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 433577.34\n",
      "total_reward: -66422.66\n",
      "total_cost: 60862.52\n",
      "total_trades: 4181\n",
      "Sharpe: -0.014\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.5e+05     |\n",
      "|    total_cost           | 1.11e+05    |\n",
      "|    total_reward         | -5.03e+04   |\n",
      "|    total_reward_pct     | -10.1       |\n",
      "|    total_trades         | 4396        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021906063 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.85        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 520\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 732086.28\n",
      "total_reward: 232086.28\n",
      "total_cost: 141832.98\n",
      "total_trades: 4413\n",
      "Sharpe: 0.952\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.49e+05    |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | 3.49e+05    |\n",
      "|    total_reward_pct     | 69.7        |\n",
      "|    total_trades         | 4344        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019981649 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.53        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 525\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 264317.64\n",
      "total_reward: -235682.36\n",
      "total_cost: 88411.60\n",
      "total_trades: 4238\n",
      "Sharpe: -0.815\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.23e+05   |\n",
      "|    total_cost           | 8.61e+04   |\n",
      "|    total_reward         | -7.66e+04  |\n",
      "|    total_reward_pct     | -15.3      |\n",
      "|    total_trades         | 4227       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 728        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01965071 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.474      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.18       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 4.37       |\n",
      "----------------------------------------\n",
      "day: 312, episode: 530\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 441520.09\n",
      "total_reward: -58479.91\n",
      "total_cost: 75289.51\n",
      "total_trades: 4210\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "day: 312, episode: 535\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 998571.19\n",
      "total_reward: 498571.19\n",
      "total_cost: 110516.83\n",
      "total_trades: 4397\n",
      "Sharpe: 1.799\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.99e+05   |\n",
      "|    total_cost           | 1.11e+05   |\n",
      "|    total_reward         | 4.99e+05   |\n",
      "|    total_reward_pct     | 99.7       |\n",
      "|    total_trades         | 4397       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 728        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01422139 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.62       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00993   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 5          |\n",
      "----------------------------------------\n",
      "day: 312, episode: 540\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 805727.71\n",
      "total_reward: 305727.71\n",
      "total_cost: 143884.31\n",
      "total_trades: 4444\n",
      "Sharpe: 1.239\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.32e+05    |\n",
      "|    total_cost           | 8.8e+04     |\n",
      "|    total_reward         | -6.79e+04   |\n",
      "|    total_reward_pct     | -13.6       |\n",
      "|    total_trades         | 4201        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017513286 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.07        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.25        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 545\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1083177.22\n",
      "total_reward: 583177.22\n",
      "total_cost: 145860.31\n",
      "total_trades: 4443\n",
      "Sharpe: 1.743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.96e+05    |\n",
      "|    total_cost           | 1.23e+05    |\n",
      "|    total_reward         | 4.96e+05    |\n",
      "|    total_reward_pct     | 99.2        |\n",
      "|    total_trades         | 4320        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016498677 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.15        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 550\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 636926.36\n",
      "total_reward: 136926.36\n",
      "total_cost: 106306.07\n",
      "total_trades: 4251\n",
      "Sharpe: 0.791\n",
      "=================================\n",
      "day: 312, episode: 555\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 830338.03\n",
      "total_reward: 330338.03\n",
      "total_cost: 135666.07\n",
      "total_trades: 4398\n",
      "Sharpe: 1.377\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.3e+05     |\n",
      "|    total_cost           | 1.36e+05    |\n",
      "|    total_reward         | 3.3e+05     |\n",
      "|    total_reward_pct     | 66.1        |\n",
      "|    total_trades         | 4398        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011293842 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.95        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 560\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 537160.63\n",
      "total_reward: 37160.63\n",
      "total_cost: 95087.39\n",
      "total_trades: 4263\n",
      "Sharpe: 0.359\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.36e+05    |\n",
      "|    total_cost           | 1.37e+05    |\n",
      "|    total_reward         | 4.36e+05    |\n",
      "|    total_reward_pct     | 87.3        |\n",
      "|    total_trades         | 4365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020829387 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.16        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 565\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 982888.47\n",
      "total_reward: 482888.47\n",
      "total_cost: 138279.93\n",
      "total_trades: 4414\n",
      "Sharpe: 1.919\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.85e+05   |\n",
      "|    total_cost           | 1.49e+05   |\n",
      "|    total_reward         | 3.85e+05   |\n",
      "|    total_reward_pct     | 77         |\n",
      "|    total_trades         | 4379       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 728        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02945514 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.505      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.52       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 4.43       |\n",
      "----------------------------------------\n",
      "day: 312, episode: 570\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 930646.25\n",
      "total_reward: 430646.25\n",
      "total_cost: 141593.38\n",
      "total_trades: 4300\n",
      "Sharpe: 1.831\n",
      "=================================\n",
      "day: 312, episode: 575\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1013946.86\n",
      "total_reward: 513946.86\n",
      "total_cost: 152628.38\n",
      "total_trades: 4366\n",
      "Sharpe: 2.051\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+06    |\n",
      "|    total_cost           | 1.53e+05    |\n",
      "|    total_reward         | 5.14e+05    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 4366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017980363 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.3         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 580\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 928795.22\n",
      "total_reward: 428795.22\n",
      "total_cost: 124577.68\n",
      "total_trades: 4323\n",
      "Sharpe: 1.591\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.26e+05    |\n",
      "|    total_cost           | 9.63e+04    |\n",
      "|    total_reward         | 2.26e+05    |\n",
      "|    total_reward_pct     | 45.3        |\n",
      "|    total_trades         | 4154        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018999493 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 5.61        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 585\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 742873.85\n",
      "total_reward: 242873.85\n",
      "total_cost: 111815.17\n",
      "total_trades: 4314\n",
      "Sharpe: 1.784\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.05e+06    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | 5.48e+05    |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 4363        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038469613 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.88        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 5.17        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 590\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 818733.90\n",
      "total_reward: 318733.90\n",
      "total_cost: 90758.43\n",
      "total_trades: 4301\n",
      "Sharpe: 1.974\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.38e+05   |\n",
      "|    total_cost           | 1.57e+05   |\n",
      "|    total_reward         | 4.38e+05   |\n",
      "|    total_reward_pct     | 87.5       |\n",
      "|    total_trades         | 4496       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 728        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02492881 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.56       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.47       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 6.01       |\n",
      "----------------------------------------\n",
      "day: 312, episode: 595\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1064471.18\n",
      "total_reward: 564471.18\n",
      "total_cost: 145237.38\n",
      "total_trades: 4405\n",
      "Sharpe: 1.843\n",
      "=================================\n",
      "day: 312, episode: 600\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 843806.05\n",
      "total_reward: 343806.05\n",
      "total_cost: 112712.65\n",
      "total_trades: 4207\n",
      "Sharpe: 1.291\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.91e+05    |\n",
      "|    total_cost           | 9e+04       |\n",
      "|    total_reward         | 3.91e+05    |\n",
      "|    total_reward_pct     | 78.2        |\n",
      "|    total_trades         | 4202        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028240498 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.05        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 605\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 941957.46\n",
      "total_reward: 441957.46\n",
      "total_cost: 129519.97\n",
      "total_trades: 4467\n",
      "Sharpe: 1.614\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.93e+05    |\n",
      "|    total_cost           | 1.11e+05    |\n",
      "|    total_reward         | 4.93e+05    |\n",
      "|    total_reward_pct     | 98.7        |\n",
      "|    total_trades         | 4423        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027734146 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.03        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 610\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 533044.21\n",
      "total_reward: 33044.21\n",
      "total_cost: 149256.32\n",
      "total_trades: 4500\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+06    |\n",
      "|    total_cost           | 1.13e+05    |\n",
      "|    total_reward         | 5.38e+05    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 4291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018467892 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 5.67        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 615\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 976918.05\n",
      "total_reward: 476918.05\n",
      "total_cost: 152396.50\n",
      "total_trades: 4385\n",
      "Sharpe: 1.624\n",
      "=================================\n",
      "day: 312, episode: 620\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1001817.43\n",
      "total_reward: 501817.43\n",
      "total_cost: 130515.71\n",
      "total_trades: 4480\n",
      "Sharpe: 1.541\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+06       |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 5.02e+05    |\n",
      "|    total_reward_pct     | 100         |\n",
      "|    total_trades         | 4480        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016404621 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.77        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.67        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 625\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 861755.96\n",
      "total_reward: 361755.96\n",
      "total_cost: 131530.62\n",
      "total_trades: 4455\n",
      "Sharpe: 1.484\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+06    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 5.41e+05    |\n",
      "|    total_reward_pct     | 108         |\n",
      "|    total_trades         | 4377        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028886601 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.18        |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 630\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 967449.58\n",
      "total_reward: 467449.58\n",
      "total_cost: 122374.38\n",
      "total_trades: 4332\n",
      "Sharpe: 1.732\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.93e+05    |\n",
      "|    total_cost           | 1.04e+05    |\n",
      "|    total_reward         | 3.93e+05    |\n",
      "|    total_reward_pct     | 78.5        |\n",
      "|    total_trades         | 4273        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034748033 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.19        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 7           |\n",
      "-----------------------------------------\n",
      "day: 312, episode: 635\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 973754.34\n",
      "total_reward: 473754.34\n",
      "total_cost: 94657.99\n",
      "total_trades: 4164\n",
      "Sharpe: 1.564\n",
      "=================================\n",
      "day: 312, episode: 640\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1007162.68\n",
      "total_reward: 507162.68\n",
      "total_cost: 93708.03\n",
      "total_trades: 4230\n",
      "Sharpe: 2.421\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+06    |\n",
      "|    total_cost           | 9.37e+04    |\n",
      "|    total_reward         | 5.07e+05    |\n",
      "|    total_reward_pct     | 101         |\n",
      "|    total_trades         | 4230        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021238476 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.61        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.4         |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-04-04 to  2019-07-05\n",
      "PPO Sharpe Ratio:  nan\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
      "day: 312, episode: 645\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499012.31\n",
      "total_reward: -987.69\n",
      "total_cost: 949.31\n",
      "total_trades: 3522\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -988     |\n",
      "|    total_reward_pct | -0.198   |\n",
      "|    total_trades     | 3522     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total timesteps  | 1252     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -184     |\n",
      "|    critic_loss      | 6.93e+03 |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 939      |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 964       |\n",
      "|    total_reward     | -1.81e+03 |\n",
      "|    total_reward_pct | -0.362    |\n",
      "|    total_trades     | 3450      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total timesteps  | 2504      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -170      |\n",
      "|    critic_loss      | 3.83e+03  |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 2191      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 650\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 503728.92\n",
      "total_reward: 3728.92\n",
      "total_cost: 1098.54\n",
      "total_trades: 3459\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.58e+05  |\n",
      "|    total_cost       | 1.79e+03  |\n",
      "|    total_reward     | -4.19e+04 |\n",
      "|    total_reward_pct | -8.37     |\n",
      "|    total_trades     | 3449      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total timesteps  | 3756      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -154      |\n",
      "|    critic_loss      | 1.89e+03  |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 3443      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 655\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 452519.58\n",
      "total_reward: -47480.42\n",
      "total_cost: 1867.11\n",
      "total_trades: 3383\n",
      "Sharpe: -0.006\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 978       |\n",
      "|    total_reward     | -1.93e+03 |\n",
      "|    total_reward_pct | -0.387    |\n",
      "|    total_trades     | 3434      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 121       |\n",
      "|    time_elapsed     | 41        |\n",
      "|    total timesteps  | 5008      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -146      |\n",
      "|    critic_loss      | 1.09e+03  |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 4695      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 660\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 597443.11\n",
      "total_reward: 97443.11\n",
      "total_cost: 2696.07\n",
      "total_trades: 3396\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.15e+05  |\n",
      "|    total_cost       | 2.65e+03  |\n",
      "|    total_reward     | -8.46e+04 |\n",
      "|    total_reward_pct | -16.9     |\n",
      "|    total_trades     | 3405      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 121       |\n",
      "|    time_elapsed     | 51        |\n",
      "|    total timesteps  | 6260      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -137      |\n",
      "|    critic_loss      | 575       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 5947      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 665\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 529653.38\n",
      "total_reward: 29653.38\n",
      "total_cost: 1777.71\n",
      "total_trades: 3645\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.3e+05  |\n",
      "|    total_cost       | 1.78e+03 |\n",
      "|    total_reward     | 2.97e+04 |\n",
      "|    total_reward_pct | 5.93     |\n",
      "|    total_trades     | 3645     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total timesteps  | 7512     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -128     |\n",
      "|    critic_loss      | 304      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7199     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.31e+05 |\n",
      "|    total_cost       | 2.53e+03 |\n",
      "|    total_reward     | 3.12e+04 |\n",
      "|    total_reward_pct | 6.24     |\n",
      "|    total_trades     | 3689     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total timesteps  | 8764     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -119     |\n",
      "|    critic_loss      | 175      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8451     |\n",
      "----------------------------------\n",
      "day: 312, episode: 670\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 466670.95\n",
      "total_reward: -33329.05\n",
      "total_cost: 1545.15\n",
      "total_trades: 3717\n",
      "Sharpe: -0.070\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.84e+05  |\n",
      "|    total_cost       | 2.66e+03  |\n",
      "|    total_reward     | -1.63e+04 |\n",
      "|    total_reward_pct | -3.26     |\n",
      "|    total_trades     | 3697      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 120       |\n",
      "|    time_elapsed     | 82        |\n",
      "|    total timesteps  | 10016     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -111      |\n",
      "|    critic_loss      | 106       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 9703      |\n",
      "-----------------------------------\n",
      "day: 312, episode: 675\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499049.93\n",
      "total_reward: -950.07\n",
      "total_cost: 949.10\n",
      "total_trades: 3691\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.15e+05 |\n",
      "|    total_cost       | 2.73e+03 |\n",
      "|    total_reward     | 1.5e+04  |\n",
      "|    total_reward_pct | 2.99     |\n",
      "|    total_trades     | 3706     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total timesteps  | 11268    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -104     |\n",
      "|    critic_loss      | 72.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 10955    |\n",
      "----------------------------------\n",
      "day: 312, episode: 680\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 584123.31\n",
      "total_reward: 84123.31\n",
      "total_cost: 2775.46\n",
      "total_trades: 3731\n",
      "Sharpe: 0.573\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 1.05e+03  |\n",
      "|    total_reward     | -1.78e+03 |\n",
      "|    total_reward_pct | -0.357    |\n",
      "|    total_trades     | 3731      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 104       |\n",
      "|    total timesteps  | 12520     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -98       |\n",
      "|    critic_loss      | 51.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 12207     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 685\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 406570.33\n",
      "total_reward: -93429.67\n",
      "total_cost: 2717.03\n",
      "total_trades: 3729\n",
      "Sharpe: -0.293\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.07e+05  |\n",
      "|    total_cost       | 2.72e+03  |\n",
      "|    total_reward     | -9.34e+04 |\n",
      "|    total_reward_pct | -18.7     |\n",
      "|    total_trades     | 3729      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 114       |\n",
      "|    total timesteps  | 13772     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -91.5     |\n",
      "|    critic_loss      | 44.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 13459     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 973       |\n",
      "|    total_reward     | -1.83e+03 |\n",
      "|    total_reward_pct | -0.365    |\n",
      "|    total_trades     | 3688      |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 125       |\n",
      "|    total timesteps  | 15024     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -85.5     |\n",
      "|    critic_loss      | 34.5      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 14711     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 690\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499332.69\n",
      "total_reward: -667.31\n",
      "total_cost: 955.74\n",
      "total_trades: 3686\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -947     |\n",
      "|    total_reward_pct | -0.189   |\n",
      "|    total_trades     | 3683     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total timesteps  | 16276    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -79.6    |\n",
      "|    critic_loss      | 26.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15963    |\n",
      "----------------------------------\n",
      "day: 312, episode: 695\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 598969.45\n",
      "total_reward: 98969.45\n",
      "total_cost: 2249.33\n",
      "total_trades: 3693\n",
      "Sharpe: 0.670\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.09e+05  |\n",
      "|    total_cost       | 2.78e+03  |\n",
      "|    total_reward     | -9.06e+04 |\n",
      "|    total_reward_pct | -18.1     |\n",
      "|    total_trades     | 3695      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 120       |\n",
      "|    time_elapsed     | 146       |\n",
      "|    total timesteps  | 17528     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -74.1     |\n",
      "|    critic_loss      | 20        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17215     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 700\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 496548.66\n",
      "total_reward: -3451.34\n",
      "total_cost: 1087.06\n",
      "total_trades: 3695\n",
      "Sharpe: 0.257\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.68e+05  |\n",
      "|    total_cost       | 1.87e+03  |\n",
      "|    total_reward     | -3.23e+04 |\n",
      "|    total_reward_pct | -6.47     |\n",
      "|    total_trades     | 3707      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 156       |\n",
      "|    total timesteps  | 18780     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -69.2     |\n",
      "|    critic_loss      | 21        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 18467     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 705\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498777.00\n",
      "total_reward: -1223.00\n",
      "total_cost: 958.92\n",
      "total_trades: 3666\n",
      "Sharpe: 0.199\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 959       |\n",
      "|    total_reward     | -1.22e+03 |\n",
      "|    total_reward_pct | -0.245    |\n",
      "|    total_trades     | 3666      |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 167       |\n",
      "|    total timesteps  | 20032     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -64.6     |\n",
      "|    critic_loss      | 19.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 19719     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.64e+05 |\n",
      "|    total_cost       | 1.65e+03 |\n",
      "|    total_reward     | -3.6e+04 |\n",
      "|    total_reward_pct | -7.2     |\n",
      "|    total_trades     | 3680     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total timesteps  | 21284    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -59.9    |\n",
      "|    critic_loss      | 14       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20971    |\n",
      "----------------------------------\n",
      "day: 312, episode: 710\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499059.20\n",
      "total_reward: -940.80\n",
      "total_cost: 948.43\n",
      "total_trades: 3672\n",
      "Sharpe: 0.199\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.37e+05 |\n",
      "|    total_cost       | 1.67e+03 |\n",
      "|    total_reward     | 3.66e+04 |\n",
      "|    total_reward_pct | 7.33     |\n",
      "|    total_trades     | 3681     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total timesteps  | 22536    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -54.9    |\n",
      "|    critic_loss      | 11.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 22223    |\n",
      "----------------------------------\n",
      "day: 312, episode: 715\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 450455.15\n",
      "total_reward: -49544.85\n",
      "total_cost: 1880.79\n",
      "total_trades: 3664\n",
      "Sharpe: 0.004\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.64e+05  |\n",
      "|    total_cost       | 1.7e+03   |\n",
      "|    total_reward     | -3.63e+04 |\n",
      "|    total_reward_pct | -7.25     |\n",
      "|    total_trades     | 3674      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 198       |\n",
      "|    total timesteps  | 23788     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -51.2     |\n",
      "|    critic_loss      | 10        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 23475     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 720\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 460952.98\n",
      "total_reward: -39047.02\n",
      "total_cost: 1738.64\n",
      "total_trades: 3677\n",
      "Sharpe: 0.001\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.04e+03 |\n",
      "|    total_reward     | -538     |\n",
      "|    total_reward_pct | -0.108   |\n",
      "|    total_trades     | 3674     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total timesteps  | 25040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -47.2    |\n",
      "|    critic_loss      | 10       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24727    |\n",
      "----------------------------------\n",
      "day: 312, episode: 725\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500188.53\n",
      "total_reward: 188.53\n",
      "total_cost: 1060.10\n",
      "total_trades: 3678\n",
      "Sharpe: 0.165\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.06e+03 |\n",
      "|    total_reward     | 189      |\n",
      "|    total_reward_pct | 0.0377   |\n",
      "|    total_trades     | 3678     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total timesteps  | 26292    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -43.7    |\n",
      "|    critic_loss      | 9.04     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25979    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.74e+05  |\n",
      "|    total_cost       | 1.65e+03  |\n",
      "|    total_reward     | -2.55e+04 |\n",
      "|    total_reward_pct | -5.1      |\n",
      "|    total_trades     | 3699      |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 230       |\n",
      "|    total timesteps  | 27544     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -40.6     |\n",
      "|    critic_loss      | 7.73      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 27231     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 730\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 476626.47\n",
      "total_reward: -23373.53\n",
      "total_cost: 1499.94\n",
      "total_trades: 3685\n",
      "Sharpe: 0.041\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 959      |\n",
      "|    total_reward     | -893     |\n",
      "|    total_reward_pct | -0.179   |\n",
      "|    total_trades     | 3683     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total timesteps  | 28796    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -37.6    |\n",
      "|    critic_loss      | 5.7      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28483    |\n",
      "----------------------------------\n",
      "day: 312, episode: 735\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 603767.13\n",
      "total_reward: 103767.13\n",
      "total_cost: 2616.36\n",
      "total_trades: 3694\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1e+03    |\n",
      "|    total_reward     | -894     |\n",
      "|    total_reward_pct | -0.179   |\n",
      "|    total_trades     | 3689     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total timesteps  | 30048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -34.5    |\n",
      "|    critic_loss      | 7.37     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29735    |\n",
      "----------------------------------\n",
      "day: 312, episode: 740\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 496537.95\n",
      "total_reward: -3462.05\n",
      "total_cost: 1126.69\n",
      "total_trades: 3682\n",
      "Sharpe: 0.133\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -947     |\n",
      "|    total_reward_pct | -0.189   |\n",
      "|    total_trades     | 3661     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total timesteps  | 31300    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -32      |\n",
      "|    critic_loss      | 3.67     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 30987    |\n",
      "----------------------------------\n",
      "day: 312, episode: 745\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 464070.09\n",
      "total_reward: -35929.91\n",
      "total_cost: 1704.39\n",
      "total_trades: 3639\n",
      "Sharpe: 0.016\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.64e+05  |\n",
      "|    total_cost       | 1.7e+03   |\n",
      "|    total_reward     | -3.59e+04 |\n",
      "|    total_reward_pct | -7.19     |\n",
      "|    total_trades     | 3639      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 273       |\n",
      "|    total timesteps  | 32552     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -29.8     |\n",
      "|    critic_loss      | 10.7      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 32239     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.92e+05 |\n",
      "|    total_cost       | 2.9e+03  |\n",
      "|    total_reward     | 9.2e+04  |\n",
      "|    total_reward_pct | 18.4     |\n",
      "|    total_trades     | 3649     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total timesteps  | 33804    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -27.5    |\n",
      "|    critic_loss      | 4.38     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33491    |\n",
      "----------------------------------\n",
      "day: 312, episode: 750\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 609940.02\n",
      "total_reward: 109940.02\n",
      "total_cost: 2632.17\n",
      "total_trades: 3641\n",
      "Sharpe: 0.691\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.01e+03 |\n",
      "|    total_reward     | -178     |\n",
      "|    total_reward_pct | -0.0356  |\n",
      "|    total_trades     | 3609     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total timesteps  | 35056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -25.5    |\n",
      "|    critic_loss      | 8.47     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34743    |\n",
      "----------------------------------\n",
      "day: 312, episode: 755\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 402705.18\n",
      "total_reward: -97294.82\n",
      "total_cost: 2922.18\n",
      "total_trades: 3627\n",
      "Sharpe: -0.308\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.98e+05 |\n",
      "|    total_cost       | 970      |\n",
      "|    total_reward     | -1.5e+03 |\n",
      "|    total_reward_pct | -0.3     |\n",
      "|    total_trades     | 3606     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total timesteps  | 36308    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -23.8    |\n",
      "|    critic_loss      | 31.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35995    |\n",
      "----------------------------------\n",
      "day: 312, episode: 760\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 465057.86\n",
      "total_reward: -34942.14\n",
      "total_cost: 1721.20\n",
      "total_trades: 3611\n",
      "Sharpe: 0.024\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.61e+05  |\n",
      "|    total_cost       | 1.54e+03  |\n",
      "|    total_reward     | -3.92e+04 |\n",
      "|    total_reward_pct | -7.84     |\n",
      "|    total_trades     | 3613      |\n",
      "| time/               |           |\n",
      "|    episodes         | 120       |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 317       |\n",
      "|    total timesteps  | 37560     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -21.8     |\n",
      "|    critic_loss      | 6.19      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37247     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 765\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 467364.37\n",
      "total_reward: -32635.63\n",
      "total_cost: 1737.96\n",
      "total_trades: 3620\n",
      "Sharpe: -0.000\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.67e+05  |\n",
      "|    total_cost       | 1.74e+03  |\n",
      "|    total_reward     | -3.26e+04 |\n",
      "|    total_reward_pct | -6.53     |\n",
      "|    total_trades     | 3620      |\n",
      "| time/               |           |\n",
      "|    episodes         | 124       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 329       |\n",
      "|    total timesteps  | 38812     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -20.3     |\n",
      "|    critic_loss      | 3.08      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 38499     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.85e+05 |\n",
      "|    total_cost       | 1.59e+03 |\n",
      "|    total_reward     | -1.5e+04 |\n",
      "|    total_reward_pct | -3       |\n",
      "|    total_trades     | 3612     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total timesteps  | 40064    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -18.7    |\n",
      "|    critic_loss      | 6.14     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39751    |\n",
      "----------------------------------\n",
      "day: 312, episode: 770\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 501876.26\n",
      "total_reward: 1876.26\n",
      "total_cost: 2529.17\n",
      "total_trades: 3604\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.18e+05 |\n",
      "|    total_cost       | 2.49e+03 |\n",
      "|    total_reward     | 1.8e+04  |\n",
      "|    total_reward_pct | 3.6      |\n",
      "|    total_trades     | 3574     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total timesteps  | 41316    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -17.5    |\n",
      "|    critic_loss      | 2.8      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41003    |\n",
      "----------------------------------\n",
      "day: 312, episode: 775\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 475009.24\n",
      "total_reward: -24990.76\n",
      "total_cost: 1527.67\n",
      "total_trades: 3572\n",
      "Sharpe: 0.021\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 959       |\n",
      "|    total_reward     | -1.31e+03 |\n",
      "|    total_reward_pct | -0.262    |\n",
      "|    total_trades     | 3569      |\n",
      "| time/               |           |\n",
      "|    episodes         | 136       |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 360       |\n",
      "|    total timesteps  | 42568     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -16.2     |\n",
      "|    critic_loss      | 6.56      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 42255     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 780\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499052.23\n",
      "total_reward: -947.77\n",
      "total_cost: 948.27\n",
      "total_trades: 3567\n",
      "Sharpe: 0.290\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.78e+05  |\n",
      "|    total_cost       | 1.5e+03   |\n",
      "|    total_reward     | -2.21e+04 |\n",
      "|    total_reward_pct | -4.42     |\n",
      "|    total_trades     | 3571      |\n",
      "| time/               |           |\n",
      "|    episodes         | 140       |\n",
      "|    fps              | 118       |\n",
      "|    time_elapsed     | 370       |\n",
      "|    total timesteps  | 43820     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -15       |\n",
      "|    critic_loss      | 5.61      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 43507     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 785\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 495509.70\n",
      "total_reward: -4490.30\n",
      "total_cost: 1064.91\n",
      "total_trades: 3571\n",
      "Sharpe: 0.125\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 1.06e+03  |\n",
      "|    total_reward     | -4.49e+03 |\n",
      "|    total_reward_pct | -0.898    |\n",
      "|    total_trades     | 3571      |\n",
      "| time/               |           |\n",
      "|    episodes         | 144       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 381       |\n",
      "|    total timesteps  | 45072     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -14       |\n",
      "|    critic_loss      | 4.62      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 44759     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 1.05e+03  |\n",
      "|    total_reward     | -2.46e+03 |\n",
      "|    total_reward_pct | -0.492    |\n",
      "|    total_trades     | 3574      |\n",
      "| time/               |           |\n",
      "|    episodes         | 148       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 393       |\n",
      "|    total timesteps  | 46324     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -13       |\n",
      "|    critic_loss      | 1.53      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 46011     |\n",
      "-----------------------------------\n",
      "day: 312, episode: 790\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 474936.10\n",
      "total_reward: -25063.90\n",
      "total_cost: 2306.78\n",
      "total_trades: 3570\n",
      "Sharpe: 0.037\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.02e+05 |\n",
      "|    total_cost       | 1.05e+03 |\n",
      "|    total_reward     | 2.17e+03 |\n",
      "|    total_reward_pct | 0.434    |\n",
      "|    total_trades     | 3569     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 403      |\n",
      "|    total timesteps  | 47576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -12.1    |\n",
      "|    critic_loss      | 1.15     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47263    |\n",
      "----------------------------------\n",
      "day: 312, episode: 795\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499018.69\n",
      "total_reward: -981.31\n",
      "total_cost: 951.08\n",
      "total_trades: 3565\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.02e+05 |\n",
      "|    total_cost       | 1.05e+03 |\n",
      "|    total_reward     | 1.54e+03 |\n",
      "|    total_reward_pct | 0.309    |\n",
      "|    total_trades     | 3570     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 414      |\n",
      "|    total timesteps  | 48828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -11.3    |\n",
      "|    critic_loss      | 1.42     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 48515    |\n",
      "----------------------------------\n",
      "day: 312, episode: 800\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 480635.99\n",
      "total_reward: -19364.01\n",
      "total_cost: 1400.51\n",
      "total_trades: 3575\n",
      "Sharpe: 0.052\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.78e+05  |\n",
      "|    total_cost       | 1.44e+03  |\n",
      "|    total_reward     | -2.21e+04 |\n",
      "|    total_reward_pct | -4.42     |\n",
      "|    total_trades     | 3575      |\n",
      "| time/               |           |\n",
      "|    episodes         | 160       |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 424       |\n",
      "|    total timesteps  | 50080     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -10.6     |\n",
      "|    critic_loss      | 16.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 49767     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-04-04 to  2019-07-05\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-07-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_189_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.65e+05  |\n",
      "|    total_cost       | 2.04e+03  |\n",
      "|    total_reward     | -3.48e+04 |\n",
      "|    total_reward_pct | -6.96     |\n",
      "|    total_trades     | 5009      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 157       |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total timesteps  | 1504      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 66.5      |\n",
      "|    critic_loss      | 74.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 1128      |\n",
      "-----------------------------------\n",
      "day: 375, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 748955.29\n",
      "total_reward: 248955.29\n",
      "total_cost: 5367.55\n",
      "total_trades: 5016\n",
      "Sharpe: 0.978\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.12e+05 |\n",
      "|    total_cost       | 1.01e+04 |\n",
      "|    total_reward     | 1.12e+05 |\n",
      "|    total_reward_pct | 22.3     |\n",
      "|    total_trades     | 5022     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total timesteps  | 3008     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 60       |\n",
      "|    critic_loss      | 34.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 2632     |\n",
      "----------------------------------\n",
      "day: 375, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 492080.34\n",
      "total_reward: -7919.66\n",
      "total_cost: 1467.09\n",
      "total_trades: 5018\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.91e+05 |\n",
      "|    total_cost       | 4.03e+03 |\n",
      "|    total_reward     | 3.91e+05 |\n",
      "|    total_reward_pct | 78.2     |\n",
      "|    total_trades     | 5051     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 126      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total timesteps  | 4512     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 53.9     |\n",
      "|    critic_loss      | 19.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4136     |\n",
      "----------------------------------\n",
      "day: 375, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 495569.53\n",
      "total_reward: -4430.47\n",
      "total_cost: 1003.16\n",
      "total_trades: 5047\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.56e+05  |\n",
      "|    total_cost       | 3e+03     |\n",
      "|    total_reward     | -4.37e+04 |\n",
      "|    total_reward_pct | -8.73     |\n",
      "|    total_trades     | 5063      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 125       |\n",
      "|    time_elapsed     | 47        |\n",
      "|    total timesteps  | 6016      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 47.6      |\n",
      "|    critic_loss      | 13.4      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 5640      |\n",
      "-----------------------------------\n",
      "day: 375, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 460325.73\n",
      "total_reward: -39674.27\n",
      "total_cost: 1812.13\n",
      "total_trades: 5044\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.6e+05   |\n",
      "|    total_cost       | 1.81e+03  |\n",
      "|    total_reward     | -3.97e+04 |\n",
      "|    total_reward_pct | -7.93     |\n",
      "|    total_trades     | 5044      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 60        |\n",
      "|    total timesteps  | 7520      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 42.6      |\n",
      "|    critic_loss      | 8.45      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7144      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.48e+05  |\n",
      "|    total_cost       | 2.69e+03  |\n",
      "|    total_reward     | -5.24e+04 |\n",
      "|    total_reward_pct | -10.5     |\n",
      "|    total_trades     | 5086      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 72        |\n",
      "|    total timesteps  | 9024      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 37.7      |\n",
      "|    critic_loss      | 8.19      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 8648      |\n",
      "-----------------------------------\n",
      "day: 375, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499336.62\n",
      "total_reward: -663.38\n",
      "total_cost: 1073.41\n",
      "total_trades: 5082\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.44e+05  |\n",
      "|    total_cost       | 5.06e+03  |\n",
      "|    total_reward     | -5.55e+04 |\n",
      "|    total_reward_pct | -11.1     |\n",
      "|    total_trades     | 5084      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 85        |\n",
      "|    total timesteps  | 10528     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 33.7      |\n",
      "|    critic_loss      | 16        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 10152     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 836015.35\n",
      "total_reward: 336015.35\n",
      "total_cost: 8725.27\n",
      "total_trades: 5094\n",
      "Sharpe: 1.226\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.6e+05   |\n",
      "|    total_cost       | 2.31e+03  |\n",
      "|    total_reward     | -4.04e+04 |\n",
      "|    total_reward_pct | -8.08     |\n",
      "|    total_trades     | 5082      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 97        |\n",
      "|    total timesteps  | 12032     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 30.1      |\n",
      "|    critic_loss      | 5.87      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 11656     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 740189.38\n",
      "total_reward: 240189.38\n",
      "total_cost: 7064.28\n",
      "total_trades: 4932\n",
      "Sharpe: 0.998\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.21e+03 |\n",
      "|    total_reward     | -158     |\n",
      "|    total_reward_pct | -0.0317  |\n",
      "|    total_trades     | 4924     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total timesteps  | 13536    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 26.7     |\n",
      "|    critic_loss      | 11.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13160    |\n",
      "----------------------------------\n",
      "day: 375, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 630653.92\n",
      "total_reward: 130653.92\n",
      "total_cost: 4809.34\n",
      "total_trades: 4924\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.31e+05 |\n",
      "|    total_cost       | 4.81e+03 |\n",
      "|    total_reward     | 1.31e+05 |\n",
      "|    total_reward_pct | 26.1     |\n",
      "|    total_trades     | 4924     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total timesteps  | 15040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 23.8     |\n",
      "|    critic_loss      | 8.59     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 14664    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.55e+05  |\n",
      "|    total_cost       | 2.41e+03  |\n",
      "|    total_reward     | -4.47e+04 |\n",
      "|    total_reward_pct | -8.93     |\n",
      "|    total_trades     | 4920      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 132       |\n",
      "|    total timesteps  | 16544     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 21.4      |\n",
      "|    critic_loss      | 21        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16168     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 929828.79\n",
      "total_reward: 429828.79\n",
      "total_cost: 4401.30\n",
      "total_trades: 4919\n",
      "Sharpe: 1.547\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.2e+03  |\n",
      "|    total_reward     | -556     |\n",
      "|    total_reward_pct | -0.111   |\n",
      "|    total_trades     | 4921     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 125      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total timesteps  | 18048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 18.8     |\n",
      "|    critic_loss      | 6.23     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17672    |\n",
      "----------------------------------\n",
      "day: 375, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 631140.61\n",
      "total_reward: 131140.61\n",
      "total_cost: 4769.62\n",
      "total_trades: 4925\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.41e+05  |\n",
      "|    total_cost       | 2.65e+03  |\n",
      "|    total_reward     | -5.88e+04 |\n",
      "|    total_reward_pct | -11.8     |\n",
      "|    total_trades     | 4919      |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 156       |\n",
      "|    total timesteps  | 19552     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 16.8      |\n",
      "|    critic_loss      | 2.86      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 19176     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 462956.07\n",
      "total_reward: -37043.93\n",
      "total_cost: 2256.94\n",
      "total_trades: 4922\n",
      "Sharpe: -0.051\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.22e+05 |\n",
      "|    total_cost       | 3.88e+03 |\n",
      "|    total_reward     | 4.22e+05 |\n",
      "|    total_reward_pct | 84.4     |\n",
      "|    total_trades     | 4922     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total timesteps  | 21056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 15       |\n",
      "|    critic_loss      | 25.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20680    |\n",
      "----------------------------------\n",
      "day: 375, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498040.27\n",
      "total_reward: -1959.73\n",
      "total_cost: 1039.69\n",
      "total_trades: 5131\n",
      "Sharpe: 0.194\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 1.04e+03  |\n",
      "|    total_reward     | -1.96e+03 |\n",
      "|    total_reward_pct | -0.392    |\n",
      "|    total_trades     | 5131      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 181       |\n",
      "|    total timesteps  | 22560     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 13.2      |\n",
      "|    critic_loss      | 11.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 22184     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.37e+05  |\n",
      "|    total_cost       | 2.66e+03  |\n",
      "|    total_reward     | -6.32e+04 |\n",
      "|    total_reward_pct | -12.6     |\n",
      "|    total_trades     | 5132      |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 193       |\n",
      "|    total timesteps  | 24064     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 11.7      |\n",
      "|    critic_loss      | 3.34      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 23688     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497075.06\n",
      "total_reward: -2924.94\n",
      "total_cost: 1025.06\n",
      "total_trades: 5129\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 1.04e+03  |\n",
      "|    total_reward     | -2.22e+03 |\n",
      "|    total_reward_pct | -0.444    |\n",
      "|    total_trades     | 5128      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 205       |\n",
      "|    total timesteps  | 25568     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 10.2      |\n",
      "|    critic_loss      | 9.63      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 25192     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 876930.67\n",
      "total_reward: 376930.67\n",
      "total_cost: 5909.40\n",
      "total_trades: 5095\n",
      "Sharpe: 1.375\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.13e+05 |\n",
      "|    total_cost       | 2.09e+03 |\n",
      "|    total_reward     | 1.3e+04  |\n",
      "|    total_reward_pct | 2.59     |\n",
      "|    total_trades     | 5088     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total timesteps  | 27072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 8.79     |\n",
      "|    critic_loss      | 3.33     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 26696    |\n",
      "----------------------------------\n",
      "day: 375, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 736897.15\n",
      "total_reward: 236897.15\n",
      "total_cost: 3940.57\n",
      "total_trades: 5089\n",
      "Sharpe: 1.332\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 1.01e+03  |\n",
      "|    total_reward     | -3.76e+03 |\n",
      "|    total_reward_pct | -0.751    |\n",
      "|    total_trades     | 5086      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 230       |\n",
      "|    total timesteps  | 28576     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 7.61      |\n",
      "|    critic_loss      | 1.75      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28200     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 890966.63\n",
      "total_reward: 390966.63\n",
      "total_cost: 4578.08\n",
      "total_trades: 5093\n",
      "Sharpe: 1.473\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.91e+05 |\n",
      "|    total_cost       | 4.58e+03 |\n",
      "|    total_reward     | 3.91e+05 |\n",
      "|    total_reward_pct | 78.2     |\n",
      "|    total_trades     | 5093     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 123      |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total timesteps  | 30080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 6.6      |\n",
      "|    critic_loss      | 3.81     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29704    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -946     |\n",
      "|    total_reward_pct | -0.189   |\n",
      "|    total_trades     | 5084     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total timesteps  | 31584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 5.67     |\n",
      "|    critic_loss      | 2.73     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31208    |\n",
      "----------------------------------\n",
      "day: 375, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 819041.30\n",
      "total_reward: 319041.30\n",
      "total_cost: 5664.58\n",
      "total_trades: 5091\n",
      "Sharpe: 1.221\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -970     |\n",
      "|    total_reward_pct | -0.194   |\n",
      "|    total_trades     | 5177     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total timesteps  | 33088    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 4.7      |\n",
      "|    critic_loss      | 4.78     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32712    |\n",
      "----------------------------------\n",
      "day: 375, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 515359.02\n",
      "total_reward: 15359.02\n",
      "total_cost: 2144.08\n",
      "total_trades: 5183\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.65e+05  |\n",
      "|    total_cost       | 3.05e+03  |\n",
      "|    total_reward     | -3.48e+04 |\n",
      "|    total_reward_pct | -6.96     |\n",
      "|    total_trades     | 5181      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 277       |\n",
      "|    total timesteps  | 34592     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 3.82      |\n",
      "|    critic_loss      | 9.11      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 34216     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 813153.90\n",
      "total_reward: 313153.90\n",
      "total_cost: 5021.96\n",
      "total_trades: 5182\n",
      "Sharpe: 1.261\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.25e+05  |\n",
      "|    total_cost       | 3.38e+03  |\n",
      "|    total_reward     | -7.53e+04 |\n",
      "|    total_reward_pct | -15.1     |\n",
      "|    total_trades     | 5181      |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 289       |\n",
      "|    total timesteps  | 36096     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 3.01      |\n",
      "|    critic_loss      | 5.39      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 35720     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 487716.50\n",
      "total_reward: -12283.50\n",
      "total_cost: 2402.60\n",
      "total_trades: 5181\n",
      "Sharpe: 0.103\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.88e+05  |\n",
      "|    total_cost       | 2.4e+03   |\n",
      "|    total_reward     | -1.23e+04 |\n",
      "|    total_reward_pct | -2.46     |\n",
      "|    total_trades     | 5181      |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 124       |\n",
      "|    time_elapsed     | 301       |\n",
      "|    total timesteps  | 37600     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.34      |\n",
      "|    critic_loss      | 1.6       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.65e+05 |\n",
      "|    total_cost       | 5.23e+03 |\n",
      "|    total_reward     | 1.65e+05 |\n",
      "|    total_reward_pct | 33       |\n",
      "|    total_trades     | 5184     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total timesteps  | 39104    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.71     |\n",
      "|    critic_loss      | 3.55     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 38728    |\n",
      "----------------------------------\n",
      "day: 375, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 477333.52\n",
      "total_reward: -22666.48\n",
      "total_cost: 2684.86\n",
      "total_trades: 5180\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.45e+05 |\n",
      "|    total_cost       | 5.12e+03 |\n",
      "|    total_reward     | 3.45e+05 |\n",
      "|    total_reward_pct | 68.9     |\n",
      "|    total_trades     | 5185     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total timesteps  | 40608    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.16     |\n",
      "|    critic_loss      | 2.18     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 40232    |\n",
      "----------------------------------\n",
      "day: 375, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 947506.66\n",
      "total_reward: 447506.66\n",
      "total_cost: 3721.26\n",
      "total_trades: 5181\n",
      "Sharpe: 1.703\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.57e+05 |\n",
      "|    total_cost       | 4.17e+03 |\n",
      "|    total_reward     | 1.57e+05 |\n",
      "|    total_reward_pct | 31.4     |\n",
      "|    total_trades     | 5183     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total timesteps  | 42112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.641    |\n",
      "|    critic_loss      | 13.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41736    |\n",
      "----------------------------------\n",
      "day: 375, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 802709.61\n",
      "total_reward: 302709.61\n",
      "total_cost: 4978.19\n",
      "total_trades: 5182\n",
      "Sharpe: 1.447\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.36e+05 |\n",
      "|    total_cost       | 4.86e+03 |\n",
      "|    total_reward     | 3.36e+05 |\n",
      "|    total_reward_pct | 67.2     |\n",
      "|    total_trades     | 5181     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 125      |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total timesteps  | 43616    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.206    |\n",
      "|    critic_loss      | 3.52     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43240    |\n",
      "----------------------------------\n",
      "day: 375, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 407048.11\n",
      "total_reward: -92951.89\n",
      "total_cost: 3498.24\n",
      "total_trades: 5179\n",
      "Sharpe: -0.196\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.07e+05 |\n",
      "|    total_cost       | 3.5e+03  |\n",
      "|    total_reward     | -9.3e+04 |\n",
      "|    total_reward_pct | -18.6    |\n",
      "|    total_trades     | 5179     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 125      |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total timesteps  | 45120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.197   |\n",
      "|    critic_loss      | 2.29     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44744    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.13e+05 |\n",
      "|    total_cost       | 1.95e+03 |\n",
      "|    total_reward     | 1.35e+04 |\n",
      "|    total_reward_pct | 2.69     |\n",
      "|    total_trades     | 5181     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 125      |\n",
      "|    time_elapsed     | 372      |\n",
      "|    total timesteps  | 46624    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.523   |\n",
      "|    critic_loss      | 11.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46248    |\n",
      "----------------------------------\n",
      "day: 375, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 433001.15\n",
      "total_reward: -66998.85\n",
      "total_cost: 2802.14\n",
      "total_trades: 5182\n",
      "Sharpe: -0.187\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.34e+05 |\n",
      "|    total_cost       | 4.72e+03 |\n",
      "|    total_reward     | 2.34e+05 |\n",
      "|    total_reward_pct | 46.8     |\n",
      "|    total_trades     | 5184     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 385      |\n",
      "|    total timesteps  | 48128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.891   |\n",
      "|    critic_loss      | 4.53     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47752    |\n",
      "----------------------------------\n",
      "day: 375, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 898873.03\n",
      "total_reward: 398873.03\n",
      "total_cost: 3440.60\n",
      "total_trades: 5182\n",
      "Sharpe: 1.585\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.1e+05  |\n",
      "|    total_cost       | 2.03e+03 |\n",
      "|    total_reward     | 9.77e+03 |\n",
      "|    total_reward_pct | 1.95     |\n",
      "|    total_trades     | 5181     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 397      |\n",
      "|    total timesteps  | 49632    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.23    |\n",
      "|    critic_loss      | 20.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49256    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-07-05 to  2019-10-02\n",
      "============================================\n",
      "276.0917352069127\n",
      "turbulence_threshold:  0.0\n",
      "======Model training from:  2000-01-01 to  2019-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_1\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.5e+05   |\n",
      "|    total_cost         | 2.23e+05  |\n",
      "|    total_reward       | -4.98e+04 |\n",
      "|    total_reward_pct   | -9.96     |\n",
      "|    total_trades       | 5375      |\n",
      "| time/                 |           |\n",
      "|    fps                | 555       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | -0.0474   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -7.58     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.119     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.75e+05 |\n",
      "|    total_cost         | 2.32e+05 |\n",
      "|    total_reward       | 7.52e+04 |\n",
      "|    total_reward_pct   | 15       |\n",
      "|    total_trades       | 5613     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -14      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -7.94    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.201    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.93e+05  |\n",
      "|    total_cost         | 9.97e+04  |\n",
      "|    total_reward       | -2.07e+05 |\n",
      "|    total_reward_pct   | -41.3     |\n",
      "|    total_trades       | 5227      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | 0.297     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 3.28      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.0574    |\n",
      "-------------------------------------\n",
      "day: 375, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 378860.76\n",
      "total_reward: -121139.24\n",
      "total_cost: 93379.22\n",
      "total_trades: 5160\n",
      "Sharpe: -0.421\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.79e+05  |\n",
      "|    total_cost         | 9.34e+04  |\n",
      "|    total_reward       | -1.21e+05 |\n",
      "|    total_reward_pct   | -24.2     |\n",
      "|    total_trades       | 5160      |\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 14.4      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.333     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.74e+05  |\n",
      "|    total_cost         | 9.11e+04  |\n",
      "|    total_reward       | -2.57e+04 |\n",
      "|    total_reward_pct   | -5.14     |\n",
      "|    total_trades       | 5050      |\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -0.322    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.409     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.83e+05  |\n",
      "|    total_cost         | 8.15e+04  |\n",
      "|    total_reward       | -1.73e+04 |\n",
      "|    total_reward_pct   | -3.46     |\n",
      "|    total_trades       | 5003      |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -2.44     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 19.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.92e+05  |\n",
      "|    total_cost         | 3.11e+04  |\n",
      "|    total_reward       | -2.08e+05 |\n",
      "|    total_reward_pct   | -41.6     |\n",
      "|    total_trades       | 4701      |\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -9.95     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.201     |\n",
      "-------------------------------------\n",
      "day: 375, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 402677.37\n",
      "total_reward: -97322.63\n",
      "total_cost: 51439.72\n",
      "total_trades: 4981\n",
      "Sharpe: -0.563\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.03e+05  |\n",
      "|    total_cost         | 5.14e+04  |\n",
      "|    total_reward       | -9.73e+04 |\n",
      "|    total_reward_pct   | -19.5     |\n",
      "|    total_trades       | 4981      |\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -38.5     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.32e+05 |\n",
      "|    total_cost         | 4.09e+04 |\n",
      "|    total_reward       | 3.16e+04 |\n",
      "|    total_reward_pct   | 6.32     |\n",
      "|    total_trades       | 4659     |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.232    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.823    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.79e+05 |\n",
      "|    total_cost         | 4.86e+04 |\n",
      "|    total_reward       | 7.85e+04 |\n",
      "|    total_reward_pct   | 15.7     |\n",
      "|    total_trades       | 4878     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.0531  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -51      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.95e+05 |\n",
      "|    total_cost         | 5.71e+04 |\n",
      "|    total_reward       | 9.53e+04 |\n",
      "|    total_reward_pct   | 19.1     |\n",
      "|    total_trades       | 4814     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 14.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.334    |\n",
      "------------------------------------\n",
      "day: 375, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 616454.16\n",
      "total_reward: 116454.16\n",
      "total_cost: 32461.97\n",
      "total_trades: 4550\n",
      "Sharpe: 0.603\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.16e+05 |\n",
      "|    total_cost         | 3.25e+04 |\n",
      "|    total_reward       | 1.16e+05 |\n",
      "|    total_reward_pct   | 23.3     |\n",
      "|    total_trades       | 4550     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.255   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.655    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.36e+05  |\n",
      "|    total_cost         | 1.75e+04  |\n",
      "|    total_reward       | -1.64e+05 |\n",
      "|    total_reward_pct   | -32.8     |\n",
      "|    total_trades       | 4647      |\n",
      "| time/                 |           |\n",
      "|    fps                | 572       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -0.181    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -2.12     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.132     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.45e+05  |\n",
      "|    total_cost         | 1.85e+04  |\n",
      "|    total_reward       | -1.55e+05 |\n",
      "|    total_reward_pct   | -31       |\n",
      "|    total_trades       | 4466      |\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 4.01      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.109     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.11e+05  |\n",
      "|    total_cost         | 2.18e+04  |\n",
      "|    total_reward       | -8.94e+04 |\n",
      "|    total_reward_pct   | -17.9     |\n",
      "|    total_trades       | 4385      |\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 9.39      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.126     |\n",
      "-------------------------------------\n",
      "day: 375, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 308132.09\n",
      "total_reward: -191867.91\n",
      "total_cost: 17149.75\n",
      "total_trades: 4311\n",
      "Sharpe: -0.819\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.35e+05  |\n",
      "|    total_cost         | 2.85e+04  |\n",
      "|    total_reward       | -1.65e+05 |\n",
      "|    total_reward_pct   | -33       |\n",
      "|    total_trades       | 4408      |\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -13.2     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.282     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.55e+05 |\n",
      "|    total_cost         | 3.98e+04 |\n",
      "|    total_reward       | 5.51e+04 |\n",
      "|    total_reward_pct   | 11       |\n",
      "|    total_trades       | 4364     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.632    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.45e+05 |\n",
      "|    total_cost         | 3.43e+04 |\n",
      "|    total_reward       | 1.45e+05 |\n",
      "|    total_reward_pct   | 28.9     |\n",
      "|    total_trades       | 4391     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 13.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.442    |\n",
      "------------------------------------\n",
      "day: 375, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 473633.75\n",
      "total_reward: -26366.25\n",
      "total_cost: 30635.85\n",
      "total_trades: 4291\n",
      "Sharpe: -0.012\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.74e+05  |\n",
      "|    total_cost         | 3.06e+04  |\n",
      "|    total_reward       | -2.64e+04 |\n",
      "|    total_reward_pct   | -5.27     |\n",
      "|    total_trades       | 4291      |\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | -0.00343  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -17.1     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.42      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.73e+05  |\n",
      "|    total_cost         | 6.3e+04   |\n",
      "|    total_reward       | -2.72e+04 |\n",
      "|    total_reward_pct   | -5.44     |\n",
      "|    total_trades       | 4515      |\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 6.57      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.211     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.29e+05  |\n",
      "|    total_cost         | 3.64e+04  |\n",
      "|    total_reward       | -1.71e+05 |\n",
      "|    total_reward_pct   | -34.2     |\n",
      "|    total_trades       | 4312      |\n",
      "| time/                 |           |\n",
      "|    fps                | 572       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -1.03     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.0258    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.14e+05 |\n",
      "|    total_cost         | 3.4e+04  |\n",
      "|    total_reward       | 1.14e+05 |\n",
      "|    total_reward_pct   | 22.9     |\n",
      "|    total_trades       | 4249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.0106  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -34.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n",
      "day: 375, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 667219.64\n",
      "total_reward: 167219.64\n",
      "total_cost: 29620.50\n",
      "total_trades: 4289\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.67e+05  |\n",
      "|    total_cost         | 2.96e+04  |\n",
      "|    total_reward       | 1.67e+05  |\n",
      "|    total_reward_pct   | 33.4      |\n",
      "|    total_trades       | 4289      |\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -23.9     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.61      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.8e+05  |\n",
      "|    total_cost         | 2.69e+04 |\n",
      "|    total_reward       | 7.95e+04 |\n",
      "|    total_reward_pct   | 15.9     |\n",
      "|    total_trades       | 4290     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.734    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -4.38    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0506   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.41e+05  |\n",
      "|    total_cost         | 2.17e+04  |\n",
      "|    total_reward       | -1.59e+05 |\n",
      "|    total_reward_pct   | -31.7     |\n",
      "|    total_trades       | 4200      |\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -0.324    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 25.8      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.97e+05  |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -2.03e+05 |\n",
      "|    total_reward_pct   | -40.6     |\n",
      "|    total_trades       | 3992      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | 0.065     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 56        |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.18      |\n",
      "-------------------------------------\n",
      "day: 375, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 592233.79\n",
      "total_reward: 92233.79\n",
      "total_cost: 20063.82\n",
      "total_trades: 4263\n",
      "Sharpe: 0.501\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.92e+05 |\n",
      "|    total_cost         | 2.01e+04 |\n",
      "|    total_reward       | 9.22e+04 |\n",
      "|    total_reward_pct   | 18.4     |\n",
      "|    total_trades       | 4263     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0.0656   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 25.2     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.843    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.11e+05 |\n",
      "|    total_cost         | 2.54e+04 |\n",
      "|    total_reward       | 1.1e+04  |\n",
      "|    total_reward_pct   | 2.19     |\n",
      "|    total_trades       | 4333     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0217   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.6e+05  |\n",
      "|    total_cost         | 1.76e+04 |\n",
      "|    total_reward       | -1.4e+05 |\n",
      "|    total_reward_pct   | -28.1    |\n",
      "|    total_trades       | 4302     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 6.2      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.78e+05 |\n",
      "|    total_cost         | 2.54e+04 |\n",
      "|    total_reward       | 7.78e+04 |\n",
      "|    total_reward_pct   | 15.6     |\n",
      "|    total_trades       | 4316     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.292   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0346   |\n",
      "------------------------------------\n",
      "day: 375, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 503482.83\n",
      "total_reward: 3482.83\n",
      "total_cost: 32681.28\n",
      "total_trades: 4554\n",
      "Sharpe: 0.130\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.29e+05 |\n",
      "|    total_cost         | 5.48e+04 |\n",
      "|    total_reward       | 2.29e+05 |\n",
      "|    total_reward_pct   | 45.8     |\n",
      "|    total_trades       | 4642     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.0362  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 51.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.25e+05 |\n",
      "|    total_cost         | 2.96e+04 |\n",
      "|    total_reward       | 2.48e+04 |\n",
      "|    total_reward_pct   | 4.96     |\n",
      "|    total_trades       | 4418     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0837  |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.393    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.95e+05  |\n",
      "|    total_cost         | 1.52e+04  |\n",
      "|    total_reward       | -2.05e+05 |\n",
      "|    total_reward_pct   | -40.9     |\n",
      "|    total_trades       | 4144      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -2.1      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.0173    |\n",
      "-------------------------------------\n",
      "day: 375, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 328212.44\n",
      "total_reward: -171787.56\n",
      "total_cost: 11742.64\n",
      "total_trades: 3756\n",
      "Sharpe: -0.796\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.28e+05  |\n",
      "|    total_cost         | 1.17e+04  |\n",
      "|    total_reward       | -1.72e+05 |\n",
      "|    total_reward_pct   | -34.4     |\n",
      "|    total_trades       | 3756      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -0.0616   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 12        |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.296     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.96e+05  |\n",
      "|    total_cost         | 1.33e+04  |\n",
      "|    total_reward       | -1.04e+05 |\n",
      "|    total_reward_pct   | -20.8     |\n",
      "|    total_trades       | 3866      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -0.00845  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 1.99      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.047     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.65e+05  |\n",
      "|    total_cost         | 6.22e+03  |\n",
      "|    total_reward       | -2.35e+05 |\n",
      "|    total_reward_pct   | -47       |\n",
      "|    total_trades       | 3634      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -2.94     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.0337    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.29e+05  |\n",
      "|    total_cost         | 1.99e+04  |\n",
      "|    total_reward       | -7.07e+04 |\n",
      "|    total_reward_pct   | -14.1     |\n",
      "|    total_trades       | 4134      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.49     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 32.8      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.36      |\n",
      "-------------------------------------\n",
      "day: 375, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 382293.47\n",
      "total_reward: -117706.53\n",
      "total_cost: 21455.91\n",
      "total_trades: 4247\n",
      "Sharpe: -0.642\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.82e+05  |\n",
      "|    total_cost         | 2.15e+04  |\n",
      "|    total_reward       | -1.18e+05 |\n",
      "|    total_reward_pct   | -23.5     |\n",
      "|    total_trades       | 4247      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -7.34     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.704     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.71e+05 |\n",
      "|    total_cost         | 2.61e+04 |\n",
      "|    total_reward       | 7.13e+04 |\n",
      "|    total_reward_pct   | 14.3     |\n",
      "|    total_trades       | 4234     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -6.32    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.168    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.16e+05 |\n",
      "|    total_cost         | 2.63e+04 |\n",
      "|    total_reward       | 1.16e+05 |\n",
      "|    total_reward_pct   | 23.3     |\n",
      "|    total_trades       | 4279     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -2.67    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.303    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.55e+05  |\n",
      "|    total_cost         | 9.38e+03  |\n",
      "|    total_reward       | -1.45e+05 |\n",
      "|    total_reward_pct   | -29.1     |\n",
      "|    total_trades       | 4128      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | 0.138     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -9.26     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.186     |\n",
      "-------------------------------------\n",
      "day: 375, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 559993.94\n",
      "total_reward: 59993.94\n",
      "total_cost: 22728.77\n",
      "total_trades: 4370\n",
      "Sharpe: 0.470\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.6e+05   |\n",
      "|    total_cost         | 2.27e+04  |\n",
      "|    total_reward       | 6e+04     |\n",
      "|    total_reward_pct   | 12        |\n",
      "|    total_trades       | 4370      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 3         |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.0395    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.63e+05  |\n",
      "|    total_cost         | 2.22e+04  |\n",
      "|    total_reward       | -3.75e+04 |\n",
      "|    total_reward_pct   | -7.49     |\n",
      "|    total_trades       | 4325      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | 0.41      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 3.64      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.0749    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+05  |\n",
      "|    total_cost         | 1.77e+04  |\n",
      "|    total_reward       | -1.58e+05 |\n",
      "|    total_reward_pct   | -31.6     |\n",
      "|    total_trades       | 4375      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | 0.0108    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -27.1     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.97e+05 |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | 9.66e+04 |\n",
      "|    total_reward_pct   | 19.3     |\n",
      "|    total_trades       | 4215     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -0.993   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.22     |\n",
      "------------------------------------\n",
      "day: 375, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 296496.89\n",
      "total_reward: -203503.11\n",
      "total_cost: 10076.83\n",
      "total_trades: 4249\n",
      "Sharpe: -0.772\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.56e+05  |\n",
      "|    total_cost         | 1.51e+04  |\n",
      "|    total_reward       | -4.38e+04 |\n",
      "|    total_reward_pct   | -8.75     |\n",
      "|    total_trades       | 4261      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 0.114     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -8.91     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.158     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.18e+05 |\n",
      "|    total_cost         | 2.15e+04 |\n",
      "|    total_reward       | 1.77e+04 |\n",
      "|    total_reward_pct   | 3.53     |\n",
      "|    total_trades       | 4421     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0.602    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -2.14    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0601   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.12e+05  |\n",
      "|    total_cost         | 3.29e+04  |\n",
      "|    total_reward       | 1.12e+05  |\n",
      "|    total_reward_pct   | 22.4      |\n",
      "|    total_trades       | 4290      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -0.0959   |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.0492    |\n",
      "-------------------------------------\n",
      "day: 375, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 719481.08\n",
      "total_reward: 219481.08\n",
      "total_cost: 30697.83\n",
      "total_trades: 4329\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.19e+05  |\n",
      "|    total_cost         | 3.07e+04  |\n",
      "|    total_reward       | 2.19e+05  |\n",
      "|    total_reward_pct   | 43.9      |\n",
      "|    total_trades       | 4329      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -4.8      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.126     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.08e+05  |\n",
      "|    total_cost         | 1.05e+04  |\n",
      "|    total_reward       | -1.92e+05 |\n",
      "|    total_reward_pct   | -38.4     |\n",
      "|    total_trades       | 4104      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 35.6      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.36      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.01e+05 |\n",
      "|    total_cost         | 2.37e+04 |\n",
      "|    total_reward       | 2.01e+05 |\n",
      "|    total_reward_pct   | 40.3     |\n",
      "|    total_trades       | 4281     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 8.74     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.46e+05 |\n",
      "|    total_cost         | 1.87e+04 |\n",
      "|    total_reward       | 2.46e+05 |\n",
      "|    total_reward_pct   | 49.2     |\n",
      "|    total_trades       | 4032     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0.204    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 18       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.377    |\n",
      "------------------------------------\n",
      "day: 375, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 295129.87\n",
      "total_reward: -204870.13\n",
      "total_cost: 8004.77\n",
      "total_trades: 3898\n",
      "Sharpe: -0.722\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.95e+05  |\n",
      "|    total_cost         | 8e+03     |\n",
      "|    total_reward       | -2.05e+05 |\n",
      "|    total_reward_pct   | -41       |\n",
      "|    total_trades       | 3898      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 38.7      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.46      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.64e+05 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 1.64e+05 |\n",
      "|    total_reward_pct   | 32.9     |\n",
      "|    total_trades       | 4036     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.89e+05 |\n",
      "|    total_cost         | 1.12e+04 |\n",
      "|    total_reward       | 1.89e+05 |\n",
      "|    total_reward_pct   | 37.8     |\n",
      "|    total_trades       | 3908     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -0.212   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -36.7    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.11     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.15e+05  |\n",
      "|    total_cost         | 9.17e+03  |\n",
      "|    total_reward       | -8.49e+04 |\n",
      "|    total_reward_pct   | -17       |\n",
      "|    total_trades       | 3863      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | 0.277     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -26.9     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.05      |\n",
      "-------------------------------------\n",
      "day: 375, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 394896.95\n",
      "total_reward: -105103.05\n",
      "total_cost: 8245.26\n",
      "total_trades: 3837\n",
      "Sharpe: -0.429\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.95e+05  |\n",
      "|    total_cost         | 8.25e+03  |\n",
      "|    total_reward       | -1.05e+05 |\n",
      "|    total_reward_pct   | -21       |\n",
      "|    total_trades       | 3837      |\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 2         |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.0143    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.01e+05 |\n",
      "|    total_cost         | 1.75e+04 |\n",
      "|    total_reward       | 1.01e+05 |\n",
      "|    total_reward_pct   | 20.1     |\n",
      "|    total_trades       | 3876     |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -2.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -19.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.437    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.61e+05  |\n",
      "|    total_cost         | 1.35e+04  |\n",
      "|    total_reward       | -3.93e+04 |\n",
      "|    total_reward_pct   | -7.87     |\n",
      "|    total_trades       | 3931      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | 0.103     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -3.12     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.38e+05  |\n",
      "|    total_cost         | 2.16e+04  |\n",
      "|    total_reward       | 1.38e+05  |\n",
      "|    total_reward_pct   | 27.6      |\n",
      "|    total_trades       | 3956      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 13.7      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.255     |\n",
      "-------------------------------------\n",
      "day: 375, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 666391.45\n",
      "total_reward: 166391.45\n",
      "total_cost: 25313.32\n",
      "total_trades: 3987\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.84e+05 |\n",
      "|    total_cost         | 2.48e+04 |\n",
      "|    total_reward       | 1.84e+05 |\n",
      "|    total_reward_pct   | 36.9     |\n",
      "|    total_trades       | 3980     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -12.8    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.566    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.77e+05  |\n",
      "|    total_cost         | 2.05e+04  |\n",
      "|    total_reward       | -2.33e+04 |\n",
      "|    total_reward_pct   | -4.65     |\n",
      "|    total_trades       | 4039      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -3.62     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -1.58     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.382     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.22e+05  |\n",
      "|    total_cost         | 1.57e+04  |\n",
      "|    total_reward       | -1.78e+05 |\n",
      "|    total_reward_pct   | -35.6     |\n",
      "|    total_trades       | 4046      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 9.76      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.216     |\n",
      "-------------------------------------\n",
      "day: 375, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 689251.02\n",
      "total_reward: 189251.02\n",
      "total_cost: 39066.02\n",
      "total_trades: 4187\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.89e+05 |\n",
      "|    total_cost         | 3.91e+04 |\n",
      "|    total_reward       | 1.89e+05 |\n",
      "|    total_reward_pct   | 37.9     |\n",
      "|    total_trades       | 4187     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -0.208   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 18.4     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.589    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.84e+05  |\n",
      "|    total_cost         | 1.53e+04  |\n",
      "|    total_reward       | -1.16e+05 |\n",
      "|    total_reward_pct   | -23.2     |\n",
      "|    total_trades       | 4091      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -21.5     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.584     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.05e+05  |\n",
      "|    total_cost         | 1.24e+04  |\n",
      "|    total_reward       | -9.54e+04 |\n",
      "|    total_reward_pct   | -19.1     |\n",
      "|    total_trades       | 4040      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | 0.305     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 36.3      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.43      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.16e+05 |\n",
      "|    total_cost         | 3.01e+04 |\n",
      "|    total_reward       | 1.16e+05 |\n",
      "|    total_reward_pct   | 23.3     |\n",
      "|    total_trades       | 4155     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.00407 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -24      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 3.72     |\n",
      "------------------------------------\n",
      "day: 375, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 823317.17\n",
      "total_reward: 323317.17\n",
      "total_cost: 25385.18\n",
      "total_trades: 3993\n",
      "Sharpe: 1.091\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.23e+05  |\n",
      "|    total_cost         | 2.54e+04  |\n",
      "|    total_reward       | 3.23e+05  |\n",
      "|    total_reward_pct   | 64.7      |\n",
      "|    total_trades       | 3993      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -1.76     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0672    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.65e+05  |\n",
      "|    total_cost         | 1.12e+04  |\n",
      "|    total_reward       | -1.35e+05 |\n",
      "|    total_reward_pct   | -27.1     |\n",
      "|    total_trades       | 3867      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -0.436    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -71.1     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 7.32      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.83e+05  |\n",
      "|    total_cost         | 1.81e+04  |\n",
      "|    total_reward       | -1.17e+05 |\n",
      "|    total_reward_pct   | -23.5     |\n",
      "|    total_trades       | 4047      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -0.0753   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 46.9      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.07e+05 |\n",
      "|    total_cost         | 3.52e+04 |\n",
      "|    total_reward       | 3.07e+05 |\n",
      "|    total_reward_pct   | 61.4     |\n",
      "|    total_trades       | 4171     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0.0846   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -3.74    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.557    |\n",
      "------------------------------------\n",
      "day: 375, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 786484.48\n",
      "total_reward: 286484.48\n",
      "total_cost: 33984.40\n",
      "total_trades: 4108\n",
      "Sharpe: 1.133\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.86e+05 |\n",
      "|    total_cost         | 3.4e+04  |\n",
      "|    total_reward       | 2.86e+05 |\n",
      "|    total_reward_pct   | 57.3     |\n",
      "|    total_trades       | 4108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -1.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.412    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.54e+05 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 2.54e+05 |\n",
      "|    total_reward_pct   | 50.8     |\n",
      "|    total_trades       | 4000     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.00222  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -85.7    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.69e+05 |\n",
      "|    total_cost         | 1.38e+04 |\n",
      "|    total_reward       | 1.69e+05 |\n",
      "|    total_reward_pct   | 33.8     |\n",
      "|    total_trades       | 3850     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.0223   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.473    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.75e+05 |\n",
      "|    total_cost         | 2.13e+04 |\n",
      "|    total_reward       | 2.75e+05 |\n",
      "|    total_reward_pct   | 55       |\n",
      "|    total_trades       | 3969     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 28.6     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "day: 375, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 545189.71\n",
      "total_reward: 45189.71\n",
      "total_cost: 15832.46\n",
      "total_trades: 3980\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.18e+05 |\n",
      "|    total_cost         | 3.09e+04 |\n",
      "|    total_reward       | 3.18e+05 |\n",
      "|    total_reward_pct   | 63.7     |\n",
      "|    total_trades       | 4012     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -2.5     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 23.8     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.675    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.21e+05  |\n",
      "|    total_cost         | 1.39e+04  |\n",
      "|    total_reward       | -7.94e+04 |\n",
      "|    total_reward_pct   | -15.9     |\n",
      "|    total_trades       | 3853      |\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | -3.5      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.444     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.15e+05 |\n",
      "|    total_cost         | 2.87e+04 |\n",
      "|    total_reward       | 2.15e+05 |\n",
      "|    total_reward_pct   | 43       |\n",
      "|    total_trades       | 3890     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 14.1     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.315    |\n",
      "------------------------------------\n",
      "day: 375, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 789460.59\n",
      "total_reward: 289460.59\n",
      "total_cost: 27921.17\n",
      "total_trades: 3882\n",
      "Sharpe: 1.096\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.89e+05 |\n",
      "|    total_cost         | 2.79e+04 |\n",
      "|    total_reward       | 2.89e+05 |\n",
      "|    total_reward_pct   | 57.9     |\n",
      "|    total_trades       | 3882     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -41.2    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.17e+05 |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | 2.17e+05 |\n",
      "|    total_reward_pct   | 43.4     |\n",
      "|    total_trades       | 4083     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 25.4     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.27e+05 |\n",
      "|    total_cost         | 1.56e+04 |\n",
      "|    total_reward       | 2.27e+05 |\n",
      "|    total_reward_pct   | 45.3     |\n",
      "|    total_trades       | 4016     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0.167    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 11.2     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.277    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.96e+05 |\n",
      "|    total_cost         | 2.66e+04 |\n",
      "|    total_reward       | 1.96e+05 |\n",
      "|    total_reward_pct   | 39.2     |\n",
      "|    total_trades       | 4124     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -27      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "day: 375, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 809141.50\n",
      "total_reward: 309141.50\n",
      "total_cost: 30147.70\n",
      "total_trades: 4361\n",
      "Sharpe: 1.258\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.09e+05 |\n",
      "|    total_cost         | 3.01e+04 |\n",
      "|    total_reward       | 3.09e+05 |\n",
      "|    total_reward_pct   | 61.8     |\n",
      "|    total_trades       | 4361     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -60.6    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 5.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.1e+05   |\n",
      "|    total_cost         | 4.19e+04  |\n",
      "|    total_reward       | 4.1e+05   |\n",
      "|    total_reward_pct   | 82.1      |\n",
      "|    total_trades       | 4427      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | -1.07e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 15.1      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.433     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 3.27e+04 |\n",
      "|    total_reward       | 5.37e+05 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 4348     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.121   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.279    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.77e+05 |\n",
      "|    total_cost         | 2.33e+04 |\n",
      "|    total_reward       | 3.77e+05 |\n",
      "|    total_reward_pct   | 75.3     |\n",
      "|    total_trades       | 4254     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.00562 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -36.3    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "day: 375, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 812896.28\n",
      "total_reward: 312896.28\n",
      "total_cost: 22207.19\n",
      "total_trades: 4354\n",
      "Sharpe: 1.211\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.13e+05 |\n",
      "|    total_cost         | 2.22e+04 |\n",
      "|    total_reward       | 3.13e+05 |\n",
      "|    total_reward_pct   | 62.6     |\n",
      "|    total_trades       | 4354     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 23.6     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.628    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.47e+05  |\n",
      "|    total_cost         | 1.64e+04  |\n",
      "|    total_reward       | -5.33e+04 |\n",
      "|    total_reward_pct   | -10.7     |\n",
      "|    total_trades       | 4008      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 0.0127    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 81.7      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 50.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.49e+05 |\n",
      "|    total_cost         | 3.05e+04 |\n",
      "|    total_reward       | 3.49e+05 |\n",
      "|    total_reward_pct   | 69.8     |\n",
      "|    total_trades       | 3914     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 13.7     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.78e+05  |\n",
      "|    total_cost         | 1.5e+04   |\n",
      "|    total_reward       | -2.16e+04 |\n",
      "|    total_reward_pct   | -4.32     |\n",
      "|    total_trades       | 3833      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 46.9      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 3.52      |\n",
      "-------------------------------------\n",
      "day: 375, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 831457.27\n",
      "total_reward: 331457.27\n",
      "total_cost: 23604.05\n",
      "total_trades: 3753\n",
      "Sharpe: 1.228\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.08e+05 |\n",
      "|    total_cost         | 1.47e+04 |\n",
      "|    total_reward       | 3.08e+05 |\n",
      "|    total_reward_pct   | 61.6     |\n",
      "|    total_trades       | 3798     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 54.3     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 3.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.38e+05 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 1.38e+05 |\n",
      "|    total_reward_pct   | 27.6     |\n",
      "|    total_trades       | 3696     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -1.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 9.19     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.646    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.94e+05 |\n",
      "|    total_cost         | 2.45e+04 |\n",
      "|    total_reward       | 3.94e+05 |\n",
      "|    total_reward_pct   | 78.8     |\n",
      "|    total_trades       | 3692     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -42.8    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "day: 375, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 941280.99\n",
      "total_reward: 441280.99\n",
      "total_cost: 20027.77\n",
      "total_trades: 3718\n",
      "Sharpe: 1.478\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.41e+05 |\n",
      "|    total_cost         | 2e+04    |\n",
      "|    total_reward       | 4.41e+05 |\n",
      "|    total_reward_pct   | 88.3     |\n",
      "|    total_trades       | 3718     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.192    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 27.1     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.49e+05 |\n",
      "|    total_cost         | 1.36e+04 |\n",
      "|    total_reward       | 1.49e+05 |\n",
      "|    total_reward_pct   | 29.7     |\n",
      "|    total_trades       | 3530     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.0792  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -8.04    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9e+05    |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 4e+05    |\n",
      "|    total_reward_pct   | 79.9     |\n",
      "|    total_trades       | 3363     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.137   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 3.46     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0575   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.73e+05  |\n",
      "|    total_cost         | 9.79e+03  |\n",
      "|    total_reward       | 4.73e+05  |\n",
      "|    total_reward_pct   | 94.6      |\n",
      "|    total_trades       | 3392      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 2.72      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.422     |\n",
      "-------------------------------------\n",
      "day: 375, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 793706.96\n",
      "total_reward: 293706.96\n",
      "total_cost: 11210.48\n",
      "total_trades: 3464\n",
      "Sharpe: 1.429\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.94e+05 |\n",
      "|    total_cost         | 1.12e+04 |\n",
      "|    total_reward       | 2.94e+05 |\n",
      "|    total_reward_pct   | 58.7     |\n",
      "|    total_trades       | 3464     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.0109  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 34.6     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.8e+05  |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 4.8e+05  |\n",
      "|    total_reward_pct   | 96.1     |\n",
      "|    total_trades       | 3274     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 18.3     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.627    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.35e+05 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | 4.35e+05 |\n",
      "|    total_reward_pct   | 87       |\n",
      "|    total_trades       | 3348     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -10.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -39.4    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 3.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.12e+05 |\n",
      "|    total_cost         | 9.71e+03 |\n",
      "|    total_reward       | 1.12e+05 |\n",
      "|    total_reward_pct   | 22.4     |\n",
      "|    total_trades       | 3296     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -38.5    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 2.13     |\n",
      "------------------------------------\n",
      "day: 375, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1007727.62\n",
      "total_reward: 507727.62\n",
      "total_cost: 8530.71\n",
      "total_trades: 3457\n",
      "Sharpe: 1.652\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 8.53e+03 |\n",
      "|    total_reward       | 5.08e+05 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 3457     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -57.8    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 4.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+06 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 6.12e+05 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 3488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 63.2     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 4.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 1.25e+04 |\n",
      "|    total_reward       | 5.22e+05 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 3430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -0.0145  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -41.2    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.17e+06 |\n",
      "|    total_cost         | 9.38e+03 |\n",
      "|    total_reward       | 6.74e+05 |\n",
      "|    total_reward_pct   | 135      |\n",
      "|    total_trades       | 3357     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -29      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.66     |\n",
      "------------------------------------\n",
      "day: 375, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1141800.74\n",
      "total_reward: 641800.74\n",
      "total_cost: 10532.57\n",
      "total_trades: 3260\n",
      "Sharpe: 1.878\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+06 |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 6.42e+05 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 3260     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -0.157   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.264    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 6.11e+03 |\n",
      "|    total_reward       | 5.11e+05 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 3318     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 34.1     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 7.34e+03 |\n",
      "|    total_reward       | 5.52e+05 |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 3298     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 98.9     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.7e+05  |\n",
      "|    total_cost         | 4.11e+03 |\n",
      "|    total_reward       | 2.7e+05  |\n",
      "|    total_reward_pct   | 54.1     |\n",
      "|    total_trades       | 3142     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -4.47    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "day: 375, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 539608.90\n",
      "total_reward: 39608.90\n",
      "total_cost: 4884.53\n",
      "total_trades: 3103\n",
      "Sharpe: 0.372\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+06 |\n",
      "|    total_cost         | 8.53e+03 |\n",
      "|    total_reward       | 6.41e+05 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 2948     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0.0311   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 27.6     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 4.95e+03 |\n",
      "|    total_reward       | 5.25e+05 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 2846     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -2.75    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0744   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.49e+05 |\n",
      "|    total_cost         | 6.03e+03 |\n",
      "|    total_reward       | 3.49e+05 |\n",
      "|    total_reward_pct   | 69.7     |\n",
      "|    total_trades       | 2928     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0.014    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 43.4     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 5.43     |\n",
      "------------------------------------\n",
      "day: 375, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1068739.00\n",
      "total_reward: 568739.00\n",
      "total_cost: 6593.68\n",
      "total_trades: 2843\n",
      "Sharpe: 1.819\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 6.59e+03 |\n",
      "|    total_reward       | 5.69e+05 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 2843     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.275    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.77e+05 |\n",
      "|    total_cost         | 4.57e+03 |\n",
      "|    total_reward       | 4.77e+05 |\n",
      "|    total_reward_pct   | 95.3     |\n",
      "|    total_trades       | 2710     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 8.37     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.175    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.56e+05 |\n",
      "|    total_cost         | 4.85e+03 |\n",
      "|    total_reward       | 4.56e+05 |\n",
      "|    total_reward_pct   | 91.2     |\n",
      "|    total_trades       | 2544     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -24.9    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 6.2e+03  |\n",
      "|    total_reward       | 5.03e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 2550     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0.24     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -12.3    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.223    |\n",
      "------------------------------------\n",
      "day: 375, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 951816.41\n",
      "total_reward: 451816.41\n",
      "total_cost: 5512.88\n",
      "total_trades: 2626\n",
      "Sharpe: 1.467\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.52e+05 |\n",
      "|    total_cost         | 5.51e+03 |\n",
      "|    total_reward       | 4.52e+05 |\n",
      "|    total_reward_pct   | 90.4     |\n",
      "|    total_trades       | 2626     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -26.3    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.92e+05 |\n",
      "|    total_cost         | 8.73e+03 |\n",
      "|    total_reward       | 4.92e+05 |\n",
      "|    total_reward_pct   | 98.3     |\n",
      "|    total_trades       | 2633     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -36.5    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 5.4e+03  |\n",
      "|    total_reward       | 5.4e+05  |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 2668     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 5.07e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 2787     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 37.1     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "day: 375, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 740330.03\n",
      "total_reward: 240330.03\n",
      "total_cost: 7432.27\n",
      "total_trades: 2911\n",
      "Sharpe: 1.150\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.4e+05  |\n",
      "|    total_cost         | 7.43e+03 |\n",
      "|    total_reward       | 2.4e+05  |\n",
      "|    total_reward_pct   | 48.1     |\n",
      "|    total_trades       | 2911     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0486   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 1.5e+04  |\n",
      "|    total_reward       | 6.47e+05 |\n",
      "|    total_reward_pct   | 129      |\n",
      "|    total_trades       | 3104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.00237  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 20.5     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.672    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+06 |\n",
      "|    total_cost         | 1.64e+04 |\n",
      "|    total_reward       | 5.8e+05  |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 3148     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -52.6    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 4.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.81e+05 |\n",
      "|    total_cost         | 1.3e+04  |\n",
      "|    total_reward       | 4.81e+05 |\n",
      "|    total_reward_pct   | 96.2     |\n",
      "|    total_trades       | 3238     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -4.61    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "day: 375, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1074036.18\n",
      "total_reward: 574036.18\n",
      "total_cost: 8962.62\n",
      "total_trades: 3276\n",
      "Sharpe: 1.784\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.4e+05  |\n",
      "|    total_cost         | 1.78e+04 |\n",
      "|    total_reward       | 4.4e+05  |\n",
      "|    total_reward_pct   | 88       |\n",
      "|    total_trades       | 3459     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.0555   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 27       |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.36e+05 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 3.36e+05 |\n",
      "|    total_reward_pct   | 67.2     |\n",
      "|    total_trades       | 3557     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.709    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -31.9    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.63e+05 |\n",
      "|    total_cost         | 9.17e+03 |\n",
      "|    total_reward       | 2.63e+05 |\n",
      "|    total_reward_pct   | 52.7     |\n",
      "|    total_trades       | 3363     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -0.195   |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.266    |\n",
      "------------------------------------\n",
      "day: 375, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 547302.19\n",
      "total_reward: 47302.19\n",
      "total_cost: 8442.84\n",
      "total_trades: 3200\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.47e+05 |\n",
      "|    total_cost         | 8.44e+03 |\n",
      "|    total_reward       | 4.73e+04 |\n",
      "|    total_reward_pct   | 9.46     |\n",
      "|    total_trades       | 3200     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 35.6     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 2.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.76e+05 |\n",
      "|    total_cost         | 7.92e+03 |\n",
      "|    total_reward       | 4.76e+05 |\n",
      "|    total_reward_pct   | 95.2     |\n",
      "|    total_trades       | 3154     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -59.5    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 4.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 1e+04    |\n",
      "|    total_reward       | 5.13e+05 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 3189     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 10.3     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.538    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 6.59e+03 |\n",
      "|    total_reward       | 5.63e+05 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 3008     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.00242  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 66       |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 5.5      |\n",
      "------------------------------------\n",
      "day: 375, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1259860.01\n",
      "total_reward: 759860.01\n",
      "total_cost: 8758.47\n",
      "total_trades: 3078\n",
      "Sharpe: 2.041\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.26e+06 |\n",
      "|    total_cost         | 8.76e+03 |\n",
      "|    total_reward       | 7.6e+05  |\n",
      "|    total_reward_pct   | 152      |\n",
      "|    total_trades       | 3078     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -0.138   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -18.7    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.747    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.03e+06  |\n",
      "|    total_cost         | 6.82e+03  |\n",
      "|    total_reward       | 5.25e+05  |\n",
      "|    total_reward_pct   | 105       |\n",
      "|    total_trades       | 3241      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | 24.8      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.74      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.5e+05  |\n",
      "|    total_cost         | 5.79e+03 |\n",
      "|    total_reward       | 4.5e+05  |\n",
      "|    total_reward_pct   | 90       |\n",
      "|    total_trades       | 3051     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.00153  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 2.41     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 7.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 9.19e+03 |\n",
      "|    total_reward       | 5.94e+05 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 3147     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.267    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -9.49    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.341    |\n",
      "------------------------------------\n",
      "day: 375, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 981020.84\n",
      "total_reward: 481020.84\n",
      "total_cost: 5404.26\n",
      "total_trades: 3151\n",
      "Sharpe: 1.726\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.81e+05 |\n",
      "|    total_cost         | 5.4e+03  |\n",
      "|    total_reward       | 4.81e+05 |\n",
      "|    total_reward_pct   | 96.2     |\n",
      "|    total_trades       | 3151     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.171    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+06  |\n",
      "|    total_cost         | 1.21e+04 |\n",
      "|    total_reward       | 6.02e+05 |\n",
      "|    total_reward_pct   | 120      |\n",
      "|    total_trades       | 3294     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.161    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.91e+05 |\n",
      "|    total_cost         | 5.89e+03 |\n",
      "|    total_reward       | 4.91e+05 |\n",
      "|    total_reward_pct   | 98.2     |\n",
      "|    total_trades       | 3325     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 4.17     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.294    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.69e+05 |\n",
      "|    total_cost         | 1.82e+03 |\n",
      "|    total_reward       | 6.88e+04 |\n",
      "|    total_reward_pct   | 13.8     |\n",
      "|    total_trades       | 3247     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 31       |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 4.3      |\n",
      "------------------------------------\n",
      "day: 375, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1008377.99\n",
      "total_reward: 508377.99\n",
      "total_cost: 5698.34\n",
      "total_trades: 3299\n",
      "Sharpe: 1.592\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+06 |\n",
      "|    total_cost         | 7.04e+03 |\n",
      "|    total_reward       | 6.92e+05 |\n",
      "|    total_reward_pct   | 138      |\n",
      "|    total_trades       | 3250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -30.3    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 7.29e+03 |\n",
      "|    total_reward       | 5.68e+05 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 3158     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.363    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.05e+06  |\n",
      "|    total_cost         | 7.65e+03  |\n",
      "|    total_reward       | 5.54e+05  |\n",
      "|    total_reward_pct   | 111       |\n",
      "|    total_trades       | 3180      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | -87.3     |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 7.5       |\n",
      "-------------------------------------\n",
      "day: 375, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1096330.32\n",
      "total_reward: 596330.32\n",
      "total_cost: 6785.15\n",
      "total_trades: 3336\n",
      "Sharpe: 1.844\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+06  |\n",
      "|    total_cost         | 6.79e+03 |\n",
      "|    total_reward       | 5.96e+05 |\n",
      "|    total_reward_pct   | 119      |\n",
      "|    total_trades       | 3336     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -35      |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 2.97     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.28e+05  |\n",
      "|    total_cost         | 4.09e+03  |\n",
      "|    total_reward       | 1.28e+05  |\n",
      "|    total_reward_pct   | 25.6      |\n",
      "|    total_trades       | 3359      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 29.1      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.994     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.28e+05  |\n",
      "|    total_cost         | 7.59e+03  |\n",
      "|    total_reward       | 4.28e+05  |\n",
      "|    total_reward_pct   | 85.5      |\n",
      "|    total_trades       | 3431      |\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 27.1      |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.814     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.83e+05 |\n",
      "|    total_cost         | 7.22e+03 |\n",
      "|    total_reward       | 1.83e+05 |\n",
      "|    total_reward_pct   | 36.6     |\n",
      "|    total_trades       | 3279     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 26.9     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.854    |\n",
      "------------------------------------\n",
      "day: 375, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 896590.56\n",
      "total_reward: 396590.56\n",
      "total_cost: 4913.15\n",
      "total_trades: 3265\n",
      "Sharpe: 1.301\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.97e+05 |\n",
      "|    total_cost         | 4.91e+03 |\n",
      "|    total_reward       | 3.97e+05 |\n",
      "|    total_reward_pct   | 79.3     |\n",
      "|    total_trades       | 3265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 7.32     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0847   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+05 |\n",
      "|    total_cost         | 6.27e+03 |\n",
      "|    total_reward       | 4.97e+05 |\n",
      "|    total_reward_pct   | 99.4     |\n",
      "|    total_trades       | 3353     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -9.51    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.544    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.45e+05 |\n",
      "|    total_cost         | 8.52e+03 |\n",
      "|    total_reward       | 3.45e+05 |\n",
      "|    total_reward_pct   | 69.1     |\n",
      "|    total_trades       | 3414     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -11.6    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.459    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.53e+05 |\n",
      "|    total_cost         | 7.23e+03 |\n",
      "|    total_reward       | 2.53e+05 |\n",
      "|    total_reward_pct   | 50.6     |\n",
      "|    total_trades       | 3306     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.651    |\n",
      "------------------------------------\n",
      "day: 375, episode: 200\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1052420.17\n",
      "total_reward: 552420.17\n",
      "total_cost: 6434.71\n",
      "total_trades: 3113\n",
      "Sharpe: 1.782\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 6.43e+03 |\n",
      "|    total_reward       | 5.52e+05 |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 3113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -0.322   |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 7.1e+03  |\n",
      "|    total_reward       | 5.36e+05 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 3271     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 38.2     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+06 |\n",
      "|    total_cost         | 8.11e+03 |\n",
      "|    total_reward       | 6.21e+05 |\n",
      "|    total_reward_pct   | 124      |\n",
      "|    total_trades       | 3280     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -6.34    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 4.29e+03 |\n",
      "|    total_reward       | 5.03e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 3221     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -45      |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 3.55     |\n",
      "------------------------------------\n",
      "day: 375, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 896474.48\n",
      "total_reward: 396474.48\n",
      "total_cost: 6620.06\n",
      "total_trades: 3335\n",
      "Sharpe: 1.336\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 8.88e+03 |\n",
      "|    total_reward       | 5.04e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 3342     |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -58.7    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 5.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 8.16e+03 |\n",
      "|    total_reward       | 5.65e+05 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 3439     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.485    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 23.2     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.721    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.79e+05 |\n",
      "|    total_cost         | 8.15e+03 |\n",
      "|    total_reward       | 4.79e+05 |\n",
      "|    total_reward_pct   | 95.7     |\n",
      "|    total_trades       | 3474     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 28.6     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "day: 375, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 875796.34\n",
      "total_reward: 375796.34\n",
      "total_cost: 4213.82\n",
      "total_trades: 3400\n",
      "Sharpe: 1.358\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.76e+05  |\n",
      "|    total_cost         | 4.21e+03  |\n",
      "|    total_reward       | 3.76e+05  |\n",
      "|    total_reward_pct   | 75.2      |\n",
      "|    total_trades       | 3400      |\n",
      "| time/                 |           |\n",
      "|    fps                | 572       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | 41.7      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 2.55      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+05 |\n",
      "|    total_cost         | 5.42e+03 |\n",
      "|    total_reward       | 4.99e+05 |\n",
      "|    total_reward_pct   | 99.8     |\n",
      "|    total_trades       | 3294     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.782   |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.297    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.15e+05 |\n",
      "|    total_cost         | 7e+03    |\n",
      "|    total_reward       | 4.15e+05 |\n",
      "|    total_reward_pct   | 82.9     |\n",
      "|    total_trades       | 3358     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.868    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 30.1     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.19e+05 |\n",
      "|    total_cost         | 5.81e+03 |\n",
      "|    total_reward       | 4.19e+05 |\n",
      "|    total_reward_pct   | 83.7     |\n",
      "|    total_trades       | 3279     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 72.2     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 8.01     |\n",
      "------------------------------------\n",
      "day: 375, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 870480.37\n",
      "total_reward: 370480.37\n",
      "total_cost: 6837.31\n",
      "total_trades: 3387\n",
      "Sharpe: 1.258\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.7e+05   |\n",
      "|    total_cost         | 6.84e+03  |\n",
      "|    total_reward       | 3.7e+05   |\n",
      "|    total_reward_pct   | 74.1      |\n",
      "|    total_trades       | 3387      |\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -26.5     |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8e+05    |\n",
      "|    total_cost         | 6.77e+03 |\n",
      "|    total_reward       | 3e+05    |\n",
      "|    total_reward_pct   | 60.1     |\n",
      "|    total_trades       | 3538     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 37.9     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 7.02e+03 |\n",
      "|    total_reward       | 5.3e+05  |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 3584     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 24.5     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.13e+05 |\n",
      "|    total_cost         | 4.96e+03 |\n",
      "|    total_reward       | 4.13e+05 |\n",
      "|    total_reward_pct   | 82.6     |\n",
      "|    total_trades       | 3581     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -26.5    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 3.1      |\n",
      "------------------------------------\n",
      "day: 375, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 892239.77\n",
      "total_reward: 392239.77\n",
      "total_cost: 5695.74\n",
      "total_trades: 3594\n",
      "Sharpe: 1.200\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.92e+05  |\n",
      "|    total_cost         | 5.7e+03   |\n",
      "|    total_reward       | 3.92e+05  |\n",
      "|    total_reward_pct   | 78.4      |\n",
      "|    total_trades       | 3594      |\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 6.46      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.111     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 5.29e+05 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 3701     |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -20.4    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 9.12e+03 |\n",
      "|    total_reward       | 6.53e+05 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 3655     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 6.91     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.201    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.54e+05 |\n",
      "|    total_cost         | 1.45e+04 |\n",
      "|    total_reward       | 4.54e+05 |\n",
      "|    total_reward_pct   | 90.9     |\n",
      "|    total_trades       | 3578     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0.00624  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 5.91     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.778    |\n",
      "------------------------------------\n",
      "day: 375, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 894175.57\n",
      "total_reward: 394175.57\n",
      "total_cost: 10137.16\n",
      "total_trades: 3658\n",
      "Sharpe: 1.979\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 9.71e+03 |\n",
      "|    total_reward       | 5.57e+05 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 3770     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 26.1     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.87e+05 |\n",
      "|    total_cost         | 7.47e+03 |\n",
      "|    total_reward       | 2.87e+05 |\n",
      "|    total_reward_pct   | 57.5     |\n",
      "|    total_trades       | 3802     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -41.5    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.13e+05 |\n",
      "|    total_cost         | 5.96e+03 |\n",
      "|    total_reward       | 4.13e+05 |\n",
      "|    total_reward_pct   | 82.7     |\n",
      "|    total_trades       | 3756     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -0.00214 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 13.3     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.343    |\n",
      "------------------------------------\n",
      "day: 375, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 779023.46\n",
      "total_reward: 279023.46\n",
      "total_cost: 4985.25\n",
      "total_trades: 3715\n",
      "Sharpe: 1.259\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.79e+05 |\n",
      "|    total_cost         | 4.99e+03 |\n",
      "|    total_reward       | 2.79e+05 |\n",
      "|    total_reward_pct   | 55.8     |\n",
      "|    total_trades       | 3715     |\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -0.0383  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 32.6     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.71e+05 |\n",
      "|    total_cost         | 9.33e+03 |\n",
      "|    total_reward       | 3.71e+05 |\n",
      "|    total_reward_pct   | 74.2     |\n",
      "|    total_trades       | 3958     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 59.4     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 4.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.49e+05 |\n",
      "|    total_cost         | 5.25e+03 |\n",
      "|    total_reward       | 4.49e+05 |\n",
      "|    total_reward_pct   | 89.7     |\n",
      "|    total_trades       | 4147     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 18.8     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.649    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.01e+05 |\n",
      "|    total_cost         | 1.09e+04 |\n",
      "|    total_reward       | 4.01e+05 |\n",
      "|    total_reward_pct   | 80.2     |\n",
      "|    total_trades       | 4269     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0.00393  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 20.4     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.756    |\n",
      "------------------------------------\n",
      "day: 375, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1123766.80\n",
      "total_reward: 623766.80\n",
      "total_cost: 11874.57\n",
      "total_trades: 4248\n",
      "Sharpe: 1.806\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+06 |\n",
      "|    total_cost         | 1.19e+04 |\n",
      "|    total_reward       | 6.24e+05 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 4248     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -54.9    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 3.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.86e+05 |\n",
      "|    total_cost         | 1.08e+04 |\n",
      "|    total_reward       | 4.86e+05 |\n",
      "|    total_reward_pct   | 97.1     |\n",
      "|    total_trades       | 4236     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -12.4    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.424    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.84e+05 |\n",
      "|    total_cost         | 8.81e+03 |\n",
      "|    total_reward       | 2.84e+05 |\n",
      "|    total_reward_pct   | 56.8     |\n",
      "|    total_trades       | 4176     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 5.15     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0849   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.43e+05 |\n",
      "|    total_cost         | 8.09e+03 |\n",
      "|    total_reward       | 4.43e+05 |\n",
      "|    total_reward_pct   | 88.6     |\n",
      "|    total_trades       | 4118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -28      |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 1.42     |\n",
      "------------------------------------\n",
      "day: 375, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 853182.36\n",
      "total_reward: 353182.36\n",
      "total_cost: 9358.54\n",
      "total_trades: 4131\n",
      "Sharpe: 1.869\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.53e+05 |\n",
      "|    total_cost         | 9.36e+03 |\n",
      "|    total_reward       | 3.53e+05 |\n",
      "|    total_reward_pct   | 70.6     |\n",
      "|    total_trades       | 4131     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 51.7     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 3.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 6.85e+03 |\n",
      "|    total_reward       | 5.15e+05 |\n",
      "|    total_reward_pct   | 103      |\n",
      "|    total_trades       | 4141     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0.156    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -61.6    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 31.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 5.05e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 4290     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 18.4     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.717    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.45e+05 |\n",
      "|    total_cost         | 6.5e+03  |\n",
      "|    total_reward       | 3.45e+05 |\n",
      "|    total_reward_pct   | 69       |\n",
      "|    total_trades       | 4287     |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 60       |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 4.29     |\n",
      "------------------------------------\n",
      "day: 375, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 895068.12\n",
      "total_reward: 395068.12\n",
      "total_cost: 9075.15\n",
      "total_trades: 4280\n",
      "Sharpe: 1.880\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.42e+05  |\n",
      "|    total_cost         | 8.74e+03  |\n",
      "|    total_reward       | 4.42e+05  |\n",
      "|    total_reward_pct   | 88.5      |\n",
      "|    total_trades       | 4241      |\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -9.24     |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.215     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 5.73e+03 |\n",
      "|    total_reward       | 5.68e+05 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 4249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.267   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 12.8     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.64e+05 |\n",
      "|    total_cost         | 5.12e+03 |\n",
      "|    total_reward       | 4.64e+05 |\n",
      "|    total_reward_pct   | 92.8     |\n",
      "|    total_trades       | 4331     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -20.4    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1        |\n",
      "------------------------------------\n",
      "day: 375, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 909980.55\n",
      "total_reward: 409980.55\n",
      "total_cost: 4658.34\n",
      "total_trades: 4367\n",
      "Sharpe: 1.345\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+05  |\n",
      "|    total_cost         | 4.66e+03 |\n",
      "|    total_reward       | 4.1e+05  |\n",
      "|    total_reward_pct   | 82       |\n",
      "|    total_trades       | 4367     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.485    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.15e+05 |\n",
      "|    total_cost         | 4.58e+03 |\n",
      "|    total_reward       | 4.15e+05 |\n",
      "|    total_reward_pct   | 83.1     |\n",
      "|    total_trades       | 4432     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -3.48    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0826   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.18e+05 |\n",
      "|    total_cost         | 5.2e+03  |\n",
      "|    total_reward       | 3.18e+05 |\n",
      "|    total_reward_pct   | 63.7     |\n",
      "|    total_trades       | 4356     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.803   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.845    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.51e+05 |\n",
      "|    total_cost         | 4.56e+03 |\n",
      "|    total_reward       | 2.51e+05 |\n",
      "|    total_reward_pct   | 50.2     |\n",
      "|    total_trades       | 4434     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 9.96     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.668    |\n",
      "------------------------------------\n",
      "day: 375, episode: 255\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 819671.11\n",
      "total_reward: 319671.11\n",
      "total_cost: 6543.93\n",
      "total_trades: 4526\n",
      "Sharpe: 1.181\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.2e+05  |\n",
      "|    total_cost         | 6.54e+03 |\n",
      "|    total_reward       | 3.2e+05  |\n",
      "|    total_reward_pct   | 63.9     |\n",
      "|    total_trades       | 4526     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 25.7     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.881    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.59e+05 |\n",
      "|    total_cost         | 4.29e+03 |\n",
      "|    total_reward       | 4.59e+05 |\n",
      "|    total_reward_pct   | 91.8     |\n",
      "|    total_trades       | 4584     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -29.5    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.91e+05 |\n",
      "|    total_cost         | 5.4e+03  |\n",
      "|    total_reward       | 3.91e+05 |\n",
      "|    total_reward_pct   | 78.1     |\n",
      "|    total_trades       | 4610     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.723   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 36.9     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 4.79e+03 |\n",
      "|    total_reward       | 5.61e+05 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 4513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -38.3    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "day: 375, episode: 260\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 751202.59\n",
      "total_reward: 251202.59\n",
      "total_cost: 4673.72\n",
      "total_trades: 4659\n",
      "Sharpe: 1.045\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.51e+05 |\n",
      "|    total_cost         | 4.67e+03 |\n",
      "|    total_reward       | 2.51e+05 |\n",
      "|    total_reward_pct   | 50.2     |\n",
      "|    total_trades       | 4659     |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -31.8    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.72e+05  |\n",
      "|    total_cost         | 5.77e+03  |\n",
      "|    total_reward       | 4.72e+05  |\n",
      "|    total_reward_pct   | 94.5      |\n",
      "|    total_trades       | 4449      |\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 51.2      |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 3.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 5.45e+03 |\n",
      "|    total_reward       | 5.61e+05 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 4242     |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -43.3    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 6.92e+03 |\n",
      "|    total_reward       | 5.52e+05 |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 4494     |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -0.00999 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 134      |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 19.2     |\n",
      "------------------------------------\n",
      "day: 375, episode: 265\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 903638.78\n",
      "total_reward: 403638.78\n",
      "total_cost: 7133.30\n",
      "total_trades: 4561\n",
      "Sharpe: 1.409\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.04e+05 |\n",
      "|    total_cost         | 7.13e+03 |\n",
      "|    total_reward       | 4.04e+05 |\n",
      "|    total_reward_pct   | 80.7     |\n",
      "|    total_trades       | 4561     |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -34.7    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-07-05 to  2019-10-02\n",
      "A2C Sharpe Ratio:  nan\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_1\n",
      "day: 375, episode: 270\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 217226.59\n",
      "total_reward: -282773.41\n",
      "total_cost: 157260.35\n",
      "total_trades: 5324\n",
      "Sharpe: -1.590\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.63e+05  |\n",
      "|    total_cost       | 2e+05     |\n",
      "|    total_reward     | -1.37e+05 |\n",
      "|    total_reward_pct | -27.5     |\n",
      "|    total_trades     | 5449      |\n",
      "| time/               |           |\n",
      "|    fps              | 808       |\n",
      "|    iterations       | 1         |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 2048      |\n",
      "-----------------------------------\n",
      "day: 375, episode: 275\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 251128.64\n",
      "total_reward: -248871.36\n",
      "total_cost: 142335.18\n",
      "total_trades: 5509\n",
      "Sharpe: -1.079\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.13e+05     |\n",
      "|    total_cost           | 1.54e+05     |\n",
      "|    total_reward         | -1.87e+05    |\n",
      "|    total_reward_pct     | -37.4        |\n",
      "|    total_trades         | 5346         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 756          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004997626 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | -0.173       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "day: 375, episode: 280\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 348826.92\n",
      "total_reward: -151173.08\n",
      "total_cost: 215711.77\n",
      "total_trades: 5499\n",
      "Sharpe: -1.023\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.48e+05    |\n",
      "|    total_cost           | 2.32e+05    |\n",
      "|    total_reward         | -5.18e+04   |\n",
      "|    total_reward_pct     | -10.4       |\n",
      "|    total_trades         | 5510        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 741         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011969863 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0826      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.648       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 285\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 658847.42\n",
      "total_reward: 158847.42\n",
      "total_cost: 270249.70\n",
      "total_trades: 5652\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.83e+05    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | -2.17e+05   |\n",
      "|    total_reward_pct     | -43.4       |\n",
      "|    total_trades         | 5433        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 737         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008829195 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0727      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.92        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.51        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 290\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 430923.03\n",
      "total_reward: -69076.97\n",
      "total_cost: 229104.45\n",
      "total_trades: 5573\n",
      "Sharpe: -0.423\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.19e+05    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | 1.87e+04    |\n",
      "|    total_reward_pct     | 3.74        |\n",
      "|    total_trades         | 5639        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015768323 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0699      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 295\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 187261.32\n",
      "total_reward: -312738.68\n",
      "total_cost: 133423.37\n",
      "total_trades: 5270\n",
      "Sharpe: -1.838\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.52e+05   |\n",
      "|    total_cost           | 1.92e+05   |\n",
      "|    total_reward         | -4.8e+04   |\n",
      "|    total_reward_pct     | -9.6       |\n",
      "|    total_trades         | 5531       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 733        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01522102 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.143      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.4        |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0208    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.85       |\n",
      "----------------------------------------\n",
      "day: 375, episode: 300\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 426367.74\n",
      "total_reward: -73632.26\n",
      "total_cost: 201986.51\n",
      "total_trades: 5510\n",
      "Sharpe: -0.525\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+05    |\n",
      "|    total_cost           | 1.4e+05     |\n",
      "|    total_reward         | -2.67e+05   |\n",
      "|    total_reward_pct     | -53.3       |\n",
      "|    total_trades         | 5383        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015708935 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.482       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.94        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 305\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 487128.36\n",
      "total_reward: -12871.64\n",
      "total_cost: 201786.07\n",
      "total_trades: 5367\n",
      "Sharpe: 0.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.94e+05    |\n",
      "|    total_cost           | 2.77e+05    |\n",
      "|    total_reward         | 9.42e+04    |\n",
      "|    total_reward_pct     | 18.8        |\n",
      "|    total_trades         | 5664        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013851641 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.934       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 310\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 553686.44\n",
      "total_reward: 53686.44\n",
      "total_cost: 254961.09\n",
      "total_trades: 5609\n",
      "Sharpe: 0.362\n",
      "=================================\n",
      "day: 375, episode: 315\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 247753.80\n",
      "total_reward: -252246.20\n",
      "total_cost: 144866.20\n",
      "total_trades: 5337\n",
      "Sharpe: -1.332\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+05    |\n",
      "|    total_cost           | 1.45e+05    |\n",
      "|    total_reward         | -2.52e+05   |\n",
      "|    total_reward_pct     | -50.4       |\n",
      "|    total_trades         | 5337        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014377809 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.504       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.44        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 320\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 404820.86\n",
      "total_reward: -95179.14\n",
      "total_cost: 181671.80\n",
      "total_trades: 5442\n",
      "Sharpe: -0.570\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.05e+05   |\n",
      "|    total_cost           | 1.82e+05   |\n",
      "|    total_reward         | -9.52e+04  |\n",
      "|    total_reward_pct     | -19        |\n",
      "|    total_trades         | 5442       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 726        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02232107 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.224      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.363      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 1.75       |\n",
      "----------------------------------------\n",
      "day: 375, episode: 325\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 254514.45\n",
      "total_reward: -245485.55\n",
      "total_cost: 150330.43\n",
      "total_trades: 5387\n",
      "Sharpe: -0.995\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.55e+05     |\n",
      "|    total_cost           | 1.5e+05      |\n",
      "|    total_reward         | -2.45e+05    |\n",
      "|    total_reward_pct     | -49.1        |\n",
      "|    total_trades         | 5387         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130430665 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.188        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0214      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "day: 375, episode: 330\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 419969.37\n",
      "total_reward: -80030.63\n",
      "total_cost: 230560.31\n",
      "total_trades: 5558\n",
      "Sharpe: -0.225\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 4.98e+05  |\n",
      "|    total_cost           | 2.64e+05  |\n",
      "|    total_reward         | -2.13e+03 |\n",
      "|    total_reward_pct     | -0.425    |\n",
      "|    total_trades         | 5429      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 724       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0226669 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.4     |\n",
      "|    explained_variance   | 0.193     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.753     |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -0.0169   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 2.23      |\n",
      "---------------------------------------\n",
      "day: 375, episode: 335\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 680291.85\n",
      "total_reward: 180291.85\n",
      "total_cost: 247778.59\n",
      "total_trades: 5632\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.4e+05     |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 4e+04       |\n",
      "|    total_reward_pct     | 8           |\n",
      "|    total_trades         | 5566        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025160816 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.13        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 340\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 511994.11\n",
      "total_reward: 11994.11\n",
      "total_cost: 222133.01\n",
      "total_trades: 5495\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.34e+05    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | -1.66e+05   |\n",
      "|    total_reward_pct     | -33.2       |\n",
      "|    total_trades         | 5376        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016953535 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.503       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.44        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 345\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 515653.23\n",
      "total_reward: 15653.23\n",
      "total_cost: 246953.98\n",
      "total_trades: 5556\n",
      "Sharpe: 0.203\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.87e+05   |\n",
      "|    total_cost           | 2.6e+05    |\n",
      "|    total_reward         | 2.87e+05   |\n",
      "|    total_reward_pct     | 57.5       |\n",
      "|    total_trades         | 5699       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 723        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02238258 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.09       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 2.93       |\n",
      "----------------------------------------\n",
      "day: 375, episode: 350\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 325810.69\n",
      "total_reward: -174189.31\n",
      "total_cost: 144766.01\n",
      "total_trades: 5311\n",
      "Sharpe: -0.570\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.58e+05    |\n",
      "|    total_cost           | 2.21e+05    |\n",
      "|    total_reward         | 1.58e+05    |\n",
      "|    total_reward_pct     | 31.7        |\n",
      "|    total_trades         | 5490        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019595236 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 355\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 703483.93\n",
      "total_reward: 203483.93\n",
      "total_cost: 265470.75\n",
      "total_trades: 5692\n",
      "Sharpe: 1.025\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.81e+05    |\n",
      "|    total_cost           | 1.71e+05    |\n",
      "|    total_reward         | -1.9e+04    |\n",
      "|    total_reward_pct     | -3.81       |\n",
      "|    total_trades         | 5454        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020280384 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.558       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 360\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 567563.85\n",
      "total_reward: 67563.85\n",
      "total_cost: 202305.76\n",
      "total_trades: 5655\n",
      "Sharpe: 0.448\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.29e+05    |\n",
      "|    total_cost           | 2.19e+05    |\n",
      "|    total_reward         | 1.29e+05    |\n",
      "|    total_reward_pct     | 25.8        |\n",
      "|    total_trades         | 5568        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020504178 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.464       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 365\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 772337.64\n",
      "total_reward: 272337.64\n",
      "total_cost: 237097.43\n",
      "total_trades: 5623\n",
      "Sharpe: 1.262\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.12e+05    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 1.12e+05    |\n",
      "|    total_reward_pct     | 22.4        |\n",
      "|    total_trades         | 5495        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015906641 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.29        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 370\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 286598.18\n",
      "total_reward: -213401.82\n",
      "total_cost: 127377.77\n",
      "total_trades: 5309\n",
      "Sharpe: -0.802\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.9e+05     |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 1.9e+05     |\n",
      "|    total_reward_pct     | 38.1        |\n",
      "|    total_trades         | 5685        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040893115 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.624       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.28        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 375\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 427192.54\n",
      "total_reward: -72807.46\n",
      "total_cost: 135348.70\n",
      "total_trades: 5293\n",
      "Sharpe: -0.086\n",
      "=================================\n",
      "day: 375, episode: 380\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 606201.98\n",
      "total_reward: 106201.98\n",
      "total_cost: 219922.61\n",
      "total_trades: 5609\n",
      "Sharpe: 0.758\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.06e+05    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | 1.06e+05    |\n",
      "|    total_reward_pct     | 21.2        |\n",
      "|    total_trades         | 5609        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017614854 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.531       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 385\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 562515.01\n",
      "total_reward: 62515.01\n",
      "total_cost: 217796.24\n",
      "total_trades: 5552\n",
      "Sharpe: 0.522\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.63e+05    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | 6.25e+04    |\n",
      "|    total_reward_pct     | 12.5        |\n",
      "|    total_trades         | 5552        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008285316 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 390\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 782077.92\n",
      "total_reward: 282077.92\n",
      "total_cost: 209521.09\n",
      "total_trades: 5490\n",
      "Sharpe: 1.306\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.04e+05    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 4.41e+03    |\n",
      "|    total_reward_pct     | 0.882       |\n",
      "|    total_trades         | 5487        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028972395 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.72        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.17        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 395\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 719200.53\n",
      "total_reward: 219200.53\n",
      "total_cost: 203896.28\n",
      "total_trades: 5529\n",
      "Sharpe: 1.060\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.07e+05   |\n",
      "|    total_cost           | 2.11e+05   |\n",
      "|    total_reward         | 2.07e+05   |\n",
      "|    total_reward_pct     | 41.3       |\n",
      "|    total_trades         | 5520       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 721        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02477276 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.243      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.48       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 3.28       |\n",
      "----------------------------------------\n",
      "day: 375, episode: 400\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 515357.43\n",
      "total_reward: 15357.43\n",
      "total_cost: 160684.70\n",
      "total_trades: 5401\n",
      "Sharpe: 0.254\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.16e+05    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 3.16e+05    |\n",
      "|    total_reward_pct     | 63.2        |\n",
      "|    total_trades         | 5527        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033366013 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 405\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 847480.76\n",
      "total_reward: 347480.76\n",
      "total_cost: 222200.13\n",
      "total_trades: 5581\n",
      "Sharpe: 1.397\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.9e+05     |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 3.9e+05     |\n",
      "|    total_reward_pct     | 78.1        |\n",
      "|    total_trades         | 5595        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029786535 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.571       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 410\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 349614.27\n",
      "total_reward: -150385.73\n",
      "total_cost: 126122.97\n",
      "total_trades: 5312\n",
      "Sharpe: -0.584\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.52e+05    |\n",
      "|    total_cost           | 1.5e+05     |\n",
      "|    total_reward         | 5.24e+04    |\n",
      "|    total_reward_pct     | 10.5        |\n",
      "|    total_trades         | 5378        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012202352 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 415\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 457737.31\n",
      "total_reward: -42262.69\n",
      "total_cost: 148832.95\n",
      "total_trades: 5347\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+06    |\n",
      "|    total_cost           | 2.07e+05    |\n",
      "|    total_reward         | 5.56e+05    |\n",
      "|    total_reward_pct     | 111         |\n",
      "|    total_trades         | 5441        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024513926 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.739       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 420\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 808523.00\n",
      "total_reward: 308523.00\n",
      "total_cost: 225684.60\n",
      "total_trades: 5574\n",
      "Sharpe: 1.570\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.46e+05    |\n",
      "|    total_cost           | 1.04e+05    |\n",
      "|    total_reward         | -5.39e+04   |\n",
      "|    total_reward_pct     | -10.8       |\n",
      "|    total_trades         | 5196        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041356467 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 425\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 715409.81\n",
      "total_reward: 215409.81\n",
      "total_cost: 142322.21\n",
      "total_trades: 5254\n",
      "Sharpe: 1.341\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.09e+06    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | 5.93e+05    |\n",
      "|    total_reward_pct     | 119         |\n",
      "|    total_trades         | 5345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027683688 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.894       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 430\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1169820.93\n",
      "total_reward: 669820.93\n",
      "total_cost: 186562.97\n",
      "total_trades: 5406\n",
      "Sharpe: 2.002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.9e+05     |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | -9.62e+03   |\n",
      "|    total_reward_pct     | -1.92       |\n",
      "|    total_trades         | 5291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039414495 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 435\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 952101.25\n",
      "total_reward: 452101.25\n",
      "total_cost: 239348.37\n",
      "total_trades: 5619\n",
      "Sharpe: 1.441\n",
      "=================================\n",
      "day: 375, episode: 440\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 748344.13\n",
      "total_reward: 248344.13\n",
      "total_cost: 130346.95\n",
      "total_trades: 5205\n",
      "Sharpe: 1.435\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.48e+05    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 2.48e+05    |\n",
      "|    total_reward_pct     | 49.7        |\n",
      "|    total_trades         | 5205        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015739292 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.36        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4           |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 445\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1047828.17\n",
      "total_reward: 547828.17\n",
      "total_cost: 148844.70\n",
      "total_trades: 5339\n",
      "Sharpe: 2.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.05e+06    |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | 5.48e+05    |\n",
      "|    total_reward_pct     | 110         |\n",
      "|    total_trades         | 5339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021359451 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.971       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 450\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 818260.03\n",
      "total_reward: 318260.03\n",
      "total_cost: 137583.28\n",
      "total_trades: 5302\n",
      "Sharpe: 1.890\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.98e+05    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 4.98e+05    |\n",
      "|    total_reward_pct     | 99.6        |\n",
      "|    total_trades         | 5409        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024852712 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.84        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 455\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 942137.29\n",
      "total_reward: 442137.29\n",
      "total_cost: 151125.05\n",
      "total_trades: 5201\n",
      "Sharpe: 1.563\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+06    |\n",
      "|    total_cost           | 1.92e+05    |\n",
      "|    total_reward         | 5.08e+05    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 5435        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026499202 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.99        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 460\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 481102.86\n",
      "total_reward: -18897.14\n",
      "total_cost: 106359.31\n",
      "total_trades: 5175\n",
      "Sharpe: 0.159\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.59e+05    |\n",
      "|    total_cost           | 1.27e+05    |\n",
      "|    total_reward         | 4.59e+05    |\n",
      "|    total_reward_pct     | 91.7        |\n",
      "|    total_trades         | 5250        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020967532 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.53        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 465\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 820203.64\n",
      "total_reward: 320203.64\n",
      "total_cost: 127626.38\n",
      "total_trades: 5198\n",
      "Sharpe: 1.966\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+06    |\n",
      "|    total_cost           | 1.28e+05    |\n",
      "|    total_reward         | 5.08e+05    |\n",
      "|    total_reward_pct     | 102         |\n",
      "|    total_trades         | 5212        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029385163 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.53        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 470\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1224625.30\n",
      "total_reward: 724625.30\n",
      "total_cost: 116788.22\n",
      "total_trades: 5207\n",
      "Sharpe: 1.892\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+06    |\n",
      "|    total_cost           | 1.16e+05    |\n",
      "|    total_reward         | 5.32e+05    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 4986        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021782985 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.09        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.17        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 475\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 946919.04\n",
      "total_reward: 446919.04\n",
      "total_cost: 107266.49\n",
      "total_trades: 5096\n",
      "Sharpe: 2.063\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.25e+05    |\n",
      "|    total_cost           | 9.43e+04    |\n",
      "|    total_reward         | 4.25e+05    |\n",
      "|    total_reward_pct     | 84.9        |\n",
      "|    total_trades         | 5038        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026656676 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.58        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.91        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 480\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 929340.92\n",
      "total_reward: 429340.92\n",
      "total_cost: 129509.04\n",
      "total_trades: 5256\n",
      "Sharpe: 2.200\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.58e+05    |\n",
      "|    total_cost           | 9.39e+04    |\n",
      "|    total_reward         | 2.58e+05    |\n",
      "|    total_reward_pct     | 51.6        |\n",
      "|    total_trades         | 5036        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019300796 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.84        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 485\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 998282.09\n",
      "total_reward: 498282.09\n",
      "total_cost: 120396.58\n",
      "total_trades: 5229\n",
      "Sharpe: 1.774\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.91e+05    |\n",
      "|    total_cost           | 9.29e+04    |\n",
      "|    total_reward         | 3.91e+05    |\n",
      "|    total_reward_pct     | 78.3        |\n",
      "|    total_trades         | 5094        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033265255 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.94        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.5         |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 490\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1101904.28\n",
      "total_reward: 601904.28\n",
      "total_cost: 113602.92\n",
      "total_trades: 5129\n",
      "Sharpe: 2.013\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.94e+05   |\n",
      "|    total_cost           | 8.96e+04   |\n",
      "|    total_reward         | 1.94e+05   |\n",
      "|    total_reward_pct     | 38.8       |\n",
      "|    total_trades         | 5047       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 726        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01821291 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.55       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 4.59       |\n",
      "----------------------------------------\n",
      "day: 375, episode: 495\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 848881.68\n",
      "total_reward: 348881.68\n",
      "total_cost: 101023.83\n",
      "total_trades: 5044\n",
      "Sharpe: 1.938\n",
      "=================================\n",
      "day: 375, episode: 500\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1048179.50\n",
      "total_reward: 548179.50\n",
      "total_cost: 126690.72\n",
      "total_trades: 5074\n",
      "Sharpe: 2.025\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.05e+06   |\n",
      "|    total_cost           | 1.27e+05   |\n",
      "|    total_reward         | 5.48e+05   |\n",
      "|    total_reward_pct     | 110        |\n",
      "|    total_trades         | 5074       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 727        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 121        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03287901 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.81       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 3.23       |\n",
      "----------------------------------------\n",
      "day: 375, episode: 505\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1122131.61\n",
      "total_reward: 622131.61\n",
      "total_cost: 128557.42\n",
      "total_trades: 5106\n",
      "Sharpe: 1.794\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+06    |\n",
      "|    total_cost           | 1.29e+05    |\n",
      "|    total_reward         | 6.22e+05    |\n",
      "|    total_reward_pct     | 124         |\n",
      "|    total_trades         | 5106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018195454 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.9         |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 510\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1040501.40\n",
      "total_reward: 540501.40\n",
      "total_cost: 123601.25\n",
      "total_trades: 5042\n",
      "Sharpe: 1.892\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+06    |\n",
      "|    total_cost           | 1.22e+05    |\n",
      "|    total_reward         | 6.06e+05    |\n",
      "|    total_reward_pct     | 121         |\n",
      "|    total_trades         | 5093        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028216934 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 4.58        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 515\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1094658.00\n",
      "total_reward: 594658.00\n",
      "total_cost: 129339.21\n",
      "total_trades: 5060\n",
      "Sharpe: 2.124\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.01e+05    |\n",
      "|    total_cost           | 1.48e+05    |\n",
      "|    total_reward         | 4.01e+05    |\n",
      "|    total_reward_pct     | 80.2        |\n",
      "|    total_trades         | 5224        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015979901 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 4.46        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 520\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 864357.72\n",
      "total_reward: 364357.72\n",
      "total_cost: 94405.67\n",
      "total_trades: 4933\n",
      "Sharpe: 1.895\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+06    |\n",
      "|    total_cost           | 1.17e+05    |\n",
      "|    total_reward         | 5.6e+05     |\n",
      "|    total_reward_pct     | 112         |\n",
      "|    total_trades         | 4974        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025250899 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 4.81        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 525\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 814454.03\n",
      "total_reward: 314454.03\n",
      "total_cost: 98385.43\n",
      "total_trades: 5033\n",
      "Sharpe: 1.682\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+06    |\n",
      "|    total_cost           | 1.21e+05    |\n",
      "|    total_reward         | 6.56e+05    |\n",
      "|    total_reward_pct     | 131         |\n",
      "|    total_trades         | 4964        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024851274 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "day: 375, episode: 530\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1016004.96\n",
      "total_reward: 516004.96\n",
      "total_cost: 127067.52\n",
      "total_trades: 5108\n",
      "Sharpe: 1.945\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.99e+05   |\n",
      "|    total_cost           | 7.06e+04   |\n",
      "|    total_reward         | 9.95e+04   |\n",
      "|    total_reward_pct     | 19.9       |\n",
      "|    total_trades         | 4875       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 727        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03133056 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.71       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00839   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 4.48       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2019-07-05 to  2019-10-02\n",
      "PPO Sharpe Ratio:  nan\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
      "day: 375, episode: 535\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 386133.44\n",
      "total_reward: -113866.56\n",
      "total_cost: 3959.75\n",
      "total_trades: 4861\n",
      "Sharpe: -0.245\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.66e+05  |\n",
      "|    total_cost       | 1.87e+03  |\n",
      "|    total_reward     | -3.36e+04 |\n",
      "|    total_reward_pct | -6.71     |\n",
      "|    total_trades     | 4672      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total timesteps  | 1504      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 67.6      |\n",
      "|    critic_loss      | 918       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 1128      |\n",
      "-----------------------------------\n",
      "day: 375, episode: 540\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500343.38\n",
      "total_reward: 343.38\n",
      "total_cost: 1041.94\n",
      "total_trades: 4672\n",
      "Sharpe: 0.148\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 1.18e+03  |\n",
      "|    total_reward     | -2.64e+03 |\n",
      "|    total_reward_pct | -0.529    |\n",
      "|    total_trades     | 4675      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 145       |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total timesteps  | 3008      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 61.4      |\n",
      "|    critic_loss      | 461       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 2632      |\n",
      "-----------------------------------\n",
      "day: 375, episode: 545\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499557.20\n",
      "total_reward: -442.80\n",
      "total_cost: 991.16\n",
      "total_trades: 4667\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 991      |\n",
      "|    total_reward     | -443     |\n",
      "|    total_reward_pct | -0.0886  |\n",
      "|    total_trades     | 4667     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total timesteps  | 4512     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 54.9     |\n",
      "|    critic_loss      | 230      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.03e+03 |\n",
      "|    total_reward     | -114     |\n",
      "|    total_reward_pct | -0.0228  |\n",
      "|    total_trades     | 4458     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total timesteps  | 6016     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 50.3     |\n",
      "|    critic_loss      | 117      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5640     |\n",
      "----------------------------------\n",
      "day: 375, episode: 550\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499914.73\n",
      "total_reward: -85.27\n",
      "total_cost: 1013.26\n",
      "total_trades: 4458\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.03e+05 |\n",
      "|    total_cost       | 985      |\n",
      "|    total_reward     | 2.51e+03 |\n",
      "|    total_reward_pct | 0.502    |\n",
      "|    total_trades     | 4455     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 135      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total timesteps  | 7520     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 45.5     |\n",
      "|    critic_loss      | 60.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7144     |\n",
      "----------------------------------\n",
      "day: 375, episode: 555\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 496963.86\n",
      "total_reward: -3036.14\n",
      "total_cost: 988.61\n",
      "total_trades: 4445\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.03e+05 |\n",
      "|    total_cost       | 989      |\n",
      "|    total_reward     | 2.5e+03  |\n",
      "|    total_reward_pct | 0.501    |\n",
      "|    total_trades     | 4444     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 133      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total timesteps  | 9024     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 41.8     |\n",
      "|    critic_loss      | 33.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 8648     |\n",
      "----------------------------------\n",
      "day: 375, episode: 560\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 474573.38\n",
      "total_reward: -25426.62\n",
      "total_cost: 1249.01\n",
      "total_trades: 4447\n",
      "Sharpe: 0.039\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 998       |\n",
      "|    total_reward     | -2.12e+03 |\n",
      "|    total_reward_pct | -0.423    |\n",
      "|    total_trades     | 4444      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 133       |\n",
      "|    time_elapsed     | 79        |\n",
      "|    total timesteps  | 10528     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 38.3      |\n",
      "|    critic_loss      | 18.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 10152     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 565\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498507.23\n",
      "total_reward: -1492.77\n",
      "total_cost: 982.71\n",
      "total_trades: 4441\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 983       |\n",
      "|    total_reward     | -1.49e+03 |\n",
      "|    total_reward_pct | -0.299    |\n",
      "|    total_trades     | 4441      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 90        |\n",
      "|    total timesteps  | 12032     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 35.1      |\n",
      "|    critic_loss      | 14.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 11656     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.94e+05  |\n",
      "|    total_cost       | 1.14e+03  |\n",
      "|    total_reward     | -6.34e+03 |\n",
      "|    total_reward_pct | -1.27     |\n",
      "|    total_trades     | 4446      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 102       |\n",
      "|    total timesteps  | 13536     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 32.3      |\n",
      "|    critic_loss      | 10        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 13160     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 570\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499067.99\n",
      "total_reward: -932.01\n",
      "total_cost: 949.19\n",
      "total_trades: 4441\n",
      "Sharpe: 0.238\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.63e+05  |\n",
      "|    total_cost       | 1.13e+03  |\n",
      "|    total_reward     | -3.71e+04 |\n",
      "|    total_reward_pct | -7.42     |\n",
      "|    total_trades     | 4446      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 114       |\n",
      "|    total timesteps  | 15040     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 29.6      |\n",
      "|    critic_loss      | 11.5      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 14664     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 575\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 489544.34\n",
      "total_reward: -10455.66\n",
      "total_cost: 1157.74\n",
      "total_trades: 4323\n",
      "Sharpe: 0.038\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.62e+05  |\n",
      "|    total_cost       | 1.2e+03   |\n",
      "|    total_reward     | -3.77e+04 |\n",
      "|    total_reward_pct | -7.53     |\n",
      "|    total_trades     | 4253      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 125       |\n",
      "|    total timesteps  | 16544     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 27.1      |\n",
      "|    critic_loss      | 7.08      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16168     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 580\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 496795.56\n",
      "total_reward: -3204.44\n",
      "total_cost: 1037.03\n",
      "total_trades: 4283\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.91e+05  |\n",
      "|    total_cost       | 1.16e+03  |\n",
      "|    total_reward     | -8.64e+03 |\n",
      "|    total_reward_pct | -1.73     |\n",
      "|    total_trades     | 4283      |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 137       |\n",
      "|    total timesteps  | 18048     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 24.8      |\n",
      "|    critic_loss      | 14        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17672     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 585\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 463966.87\n",
      "total_reward: -36033.13\n",
      "total_cost: 1123.59\n",
      "total_trades: 4096\n",
      "Sharpe: -0.003\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.64e+05 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | -3.6e+04 |\n",
      "|    total_reward_pct | -7.21    |\n",
      "|    total_trades     | 4096     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total timesteps  | 19552    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 22.4     |\n",
      "|    critic_loss      | 8.33     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19176    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 1.08e+03  |\n",
      "|    total_reward     | -1.93e+03 |\n",
      "|    total_reward_pct | -0.386    |\n",
      "|    total_trades     | 4095      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 160       |\n",
      "|    total timesteps  | 21056     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 20.4      |\n",
      "|    critic_loss      | 11.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 20680     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 590\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498956.21\n",
      "total_reward: -1043.79\n",
      "total_cost: 989.01\n",
      "total_trades: 4095\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 957       |\n",
      "|    total_reward     | -1.09e+03 |\n",
      "|    total_reward_pct | -0.218    |\n",
      "|    total_trades     | 4095      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 172       |\n",
      "|    total timesteps  | 22560     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 18.3      |\n",
      "|    critic_loss      | 4.51      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 22184     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 595\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 486755.56\n",
      "total_reward: -13244.44\n",
      "total_cost: 1132.90\n",
      "total_trades: 4088\n",
      "Sharpe: 0.086\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 962       |\n",
      "|    total_reward     | -1.35e+03 |\n",
      "|    total_reward_pct | -0.269    |\n",
      "|    total_trades     | 4100      |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 183       |\n",
      "|    total timesteps  | 24064     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 16.6      |\n",
      "|    critic_loss      | 3.19      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 23688     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 600\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 495411.56\n",
      "total_reward: -4588.44\n",
      "total_cost: 1227.25\n",
      "total_trades: 4094\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.82e+05 |\n",
      "|    total_cost       | 1.21e+03 |\n",
      "|    total_reward     | -1.8e+04 |\n",
      "|    total_reward_pct | -3.61    |\n",
      "|    total_trades     | 4098     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total timesteps  | 25568    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 14.8     |\n",
      "|    critic_loss      | 5.53     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25192    |\n",
      "----------------------------------\n",
      "day: 375, episode: 605\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497294.47\n",
      "total_reward: -2705.53\n",
      "total_cost: 1037.05\n",
      "total_trades: 4098\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 1.04e+03  |\n",
      "|    total_reward     | -2.71e+03 |\n",
      "|    total_reward_pct | -0.541    |\n",
      "|    total_trades     | 4098      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 207       |\n",
      "|    total timesteps  | 27072     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 13.3      |\n",
      "|    critic_loss      | 3.91      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 26696     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.06e+03 |\n",
      "|    total_reward     | -58.6    |\n",
      "|    total_reward_pct | -0.0117  |\n",
      "|    total_trades     | 4102     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total timesteps  | 28576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 11.9     |\n",
      "|    critic_loss      | 7.84     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28200    |\n",
      "----------------------------------\n",
      "day: 375, episode: 610\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 482609.34\n",
      "total_reward: -17390.66\n",
      "total_cost: 1314.03\n",
      "total_trades: 4103\n",
      "Sharpe: 0.190\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.77e+05  |\n",
      "|    total_cost       | 1.28e+03  |\n",
      "|    total_reward     | -2.32e+04 |\n",
      "|    total_reward_pct | -4.64     |\n",
      "|    total_trades     | 4100      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 230       |\n",
      "|    total timesteps  | 30080     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 10.6      |\n",
      "|    critic_loss      | 15.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 29704     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 615\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 448079.12\n",
      "total_reward: -51920.88\n",
      "total_cost: 1262.59\n",
      "total_trades: 4102\n",
      "Sharpe: -0.065\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.29e+03 |\n",
      "|    total_reward     | -591     |\n",
      "|    total_reward_pct | -0.118   |\n",
      "|    total_trades     | 4102     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total timesteps  | 31584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 9.45     |\n",
      "|    critic_loss      | 10       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31208    |\n",
      "----------------------------------\n",
      "day: 375, episode: 620\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 476105.50\n",
      "total_reward: -23894.50\n",
      "total_cost: 1354.23\n",
      "total_trades: 4107\n",
      "Sharpe: 0.148\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.87e+05  |\n",
      "|    total_cost       | 1.11e+03  |\n",
      "|    total_reward     | -1.31e+04 |\n",
      "|    total_reward_pct | -2.62     |\n",
      "|    total_trades     | 4101      |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 254       |\n",
      "|    total timesteps  | 33088     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 8.34      |\n",
      "|    critic_loss      | 33.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 32712     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 625\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498954.98\n",
      "total_reward: -1045.02\n",
      "total_cost: 954.76\n",
      "total_trades: 4098\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 955       |\n",
      "|    total_reward     | -1.05e+03 |\n",
      "|    total_reward_pct | -0.209    |\n",
      "|    total_trades     | 4098      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 265       |\n",
      "|    total timesteps  | 34592     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 7.34      |\n",
      "|    critic_loss      | 7.49      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 34216     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.62e+05 |\n",
      "|    total_cost       | 1.24e+03 |\n",
      "|    total_reward     | -3.8e+04 |\n",
      "|    total_reward_pct | -7.59    |\n",
      "|    total_trades     | 4102     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total timesteps  | 36096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 6.46     |\n",
      "|    critic_loss      | 4.1      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35720    |\n",
      "----------------------------------\n",
      "day: 375, episode: 630\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497375.62\n",
      "total_reward: -2624.38\n",
      "total_cost: 989.95\n",
      "total_trades: 4099\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.81e+05  |\n",
      "|    total_cost       | 1.2e+03   |\n",
      "|    total_reward     | -1.93e+04 |\n",
      "|    total_reward_pct | -3.86     |\n",
      "|    total_trades     | 4154      |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 289       |\n",
      "|    total timesteps  | 37600     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 5.63      |\n",
      "|    critic_loss      | 2.92      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37224     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 635\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 488458.58\n",
      "total_reward: -11541.42\n",
      "total_cost: 1132.68\n",
      "total_trades: 4139\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.88e+05  |\n",
      "|    total_cost       | 1.13e+03  |\n",
      "|    total_reward     | -1.25e+04 |\n",
      "|    total_reward_pct | -2.5      |\n",
      "|    total_trades     | 4151      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 300       |\n",
      "|    total timesteps  | 39104     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 4.85      |\n",
      "|    critic_loss      | 1.8       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 38728     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 640\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 447161.69\n",
      "total_reward: -52838.31\n",
      "total_cost: 1191.88\n",
      "total_trades: 4154\n",
      "Sharpe: 0.046\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.7e+05  |\n",
      "|    total_cost       | 1.29e+03 |\n",
      "|    total_reward     | -3e+04   |\n",
      "|    total_reward_pct | -6       |\n",
      "|    total_trades     | 4151     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total timesteps  | 40608    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 4.15     |\n",
      "|    critic_loss      | 4.34     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 40232    |\n",
      "----------------------------------\n",
      "day: 375, episode: 645\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 445029.71\n",
      "total_reward: -54970.29\n",
      "total_cost: 1246.37\n",
      "total_trades: 4150\n",
      "Sharpe: -0.260\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.45e+05 |\n",
      "|    total_cost       | 1.25e+03 |\n",
      "|    total_reward     | -5.5e+04 |\n",
      "|    total_reward_pct | -11      |\n",
      "|    total_trades     | 4150     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total timesteps  | 42112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.53     |\n",
      "|    critic_loss      | 3.41     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41736    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.48e+05  |\n",
      "|    total_cost       | 1.22e+03  |\n",
      "|    total_reward     | -5.24e+04 |\n",
      "|    total_reward_pct | -10.5     |\n",
      "|    total_trades     | 3948      |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 335       |\n",
      "|    total timesteps  | 43616     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.95      |\n",
      "|    critic_loss      | 4.11      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 43240     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 650\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 507231.34\n",
      "total_reward: 7231.34\n",
      "total_cost: 1297.84\n",
      "total_trades: 3945\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.81e+05  |\n",
      "|    total_cost       | 1.2e+03   |\n",
      "|    total_reward     | -1.86e+04 |\n",
      "|    total_reward_pct | -3.73     |\n",
      "|    total_trades     | 3943      |\n",
      "| time/               |           |\n",
      "|    episodes         | 120       |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 347       |\n",
      "|    total timesteps  | 45120     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.4       |\n",
      "|    critic_loss      | 8.05      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 44744     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 655\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 493184.34\n",
      "total_reward: -6815.66\n",
      "total_cost: 1053.58\n",
      "total_trades: 3940\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.87e+05  |\n",
      "|    total_cost       | 1.16e+03  |\n",
      "|    total_reward     | -1.34e+04 |\n",
      "|    total_reward_pct | -2.68     |\n",
      "|    total_trades     | 3944      |\n",
      "| time/               |           |\n",
      "|    episodes         | 124       |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 358       |\n",
      "|    total timesteps  | 46624     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 1.93      |\n",
      "|    critic_loss      | 94.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 46248     |\n",
      "-----------------------------------\n",
      "day: 375, episode: 660\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497539.46\n",
      "total_reward: -2460.54\n",
      "total_cost: 1009.62\n",
      "total_trades: 3950\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 1.06e+03 |\n",
      "|    total_reward     | 1.38e+03 |\n",
      "|    total_reward_pct | 0.277    |\n",
      "|    total_trades     | 3947     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total timesteps  | 48128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.42     |\n",
      "|    critic_loss      | 7.54     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47752    |\n",
      "----------------------------------\n",
      "day: 375, episode: 665\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 493730.27\n",
      "total_reward: -6269.73\n",
      "total_cost: 1117.81\n",
      "total_trades: 3947\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.94e+05  |\n",
      "|    total_cost       | 1.12e+03  |\n",
      "|    total_reward     | -6.27e+03 |\n",
      "|    total_reward_pct | -1.25     |\n",
      "|    total_trades     | 3947      |\n",
      "| time/               |           |\n",
      "|    episodes         | 132       |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 382       |\n",
      "|    total timesteps  | 49632     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 1.06      |\n",
      "|    critic_loss      | 5.4       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 49256     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-07-05 to  2019-10-02\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-10-02\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_252_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.29e+05  |\n",
      "|    total_cost       | 1.89e+03  |\n",
      "|    total_reward     | -7.13e+04 |\n",
      "|    total_reward_pct | -14.3     |\n",
      "|    total_trades     | 4711      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 163       |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total timesteps  | 1756      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 257       |\n",
      "|    critic_loss      | 5.12e+03  |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 1317      |\n",
      "-----------------------------------\n",
      "day: 438, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 444640.41\n",
      "total_reward: -55359.59\n",
      "total_cost: 1919.84\n",
      "total_trades: 4435\n",
      "Sharpe: -0.060\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.67e+05  |\n",
      "|    total_cost       | 2.38e+03  |\n",
      "|    total_reward     | -1.33e+05 |\n",
      "|    total_reward_pct | -26.7     |\n",
      "|    total_trades     | 4429      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 143       |\n",
      "|    time_elapsed     | 24        |\n",
      "|    total timesteps  | 3512      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 229       |\n",
      "|    critic_loss      | 2.1e+03   |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 3073      |\n",
      "-----------------------------------\n",
      "day: 438, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 394962.65\n",
      "total_reward: -105037.35\n",
      "total_cost: 2631.78\n",
      "total_trades: 4436\n",
      "Sharpe: -0.203\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.62e+05  |\n",
      "|    total_cost       | 2.4e+03   |\n",
      "|    total_reward     | -1.38e+05 |\n",
      "|    total_reward_pct | -27.5     |\n",
      "|    total_trades     | 4429      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 138       |\n",
      "|    time_elapsed     | 38        |\n",
      "|    total timesteps  | 5268      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 203       |\n",
      "|    critic_loss      | 927       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 4829      |\n",
      "-----------------------------------\n",
      "day: 438, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 336448.47\n",
      "total_reward: -163551.53\n",
      "total_cost: 2758.02\n",
      "total_trades: 4393\n",
      "Sharpe: -0.331\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.32e+05  |\n",
      "|    total_cost       | 1.53e+03  |\n",
      "|    total_reward     | -6.75e+04 |\n",
      "|    total_reward_pct | -13.5     |\n",
      "|    total_trades     | 4354      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 135       |\n",
      "|    time_elapsed     | 51        |\n",
      "|    total timesteps  | 7024      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 182       |\n",
      "|    critic_loss      | 467       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6585      |\n",
      "-----------------------------------\n",
      "day: 438, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 443283.72\n",
      "total_reward: -56716.28\n",
      "total_cost: 1473.45\n",
      "total_trades: 4354\n",
      "Sharpe: -0.031\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.43e+05  |\n",
      "|    total_cost       | 1.47e+03  |\n",
      "|    total_reward     | -5.67e+04 |\n",
      "|    total_reward_pct | -11.3     |\n",
      "|    total_trades     | 4354      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 134       |\n",
      "|    time_elapsed     | 65        |\n",
      "|    total timesteps  | 8780      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 163       |\n",
      "|    critic_loss      | 195       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 8341      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.82e+05  |\n",
      "|    total_cost       | 2.18e+03  |\n",
      "|    total_reward     | -1.79e+04 |\n",
      "|    total_reward_pct | -3.57     |\n",
      "|    total_trades     | 4029      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 133       |\n",
      "|    time_elapsed     | 79        |\n",
      "|    total timesteps  | 10536     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 147       |\n",
      "|    critic_loss      | 95.1      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 10097     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 374650.47\n",
      "total_reward: -125349.53\n",
      "total_cost: 2362.38\n",
      "total_trades: 4031\n",
      "Sharpe: -0.168\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.46e+05  |\n",
      "|    total_cost       | 1.67e+03  |\n",
      "|    total_reward     | -5.35e+04 |\n",
      "|    total_reward_pct | -10.7     |\n",
      "|    total_trades     | 4034      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 92        |\n",
      "|    total timesteps  | 12292     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 132       |\n",
      "|    critic_loss      | 51.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 11853     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 411591.23\n",
      "total_reward: -88408.77\n",
      "total_cost: 1704.39\n",
      "total_trades: 4028\n",
      "Sharpe: -0.074\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.37e+05  |\n",
      "|    total_cost       | 2.66e+03  |\n",
      "|    total_reward     | -6.33e+04 |\n",
      "|    total_reward_pct | -12.7     |\n",
      "|    total_trades     | 4038      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 106       |\n",
      "|    total timesteps  | 14048     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 119       |\n",
      "|    critic_loss      | 30.5      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 13609     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497883.78\n",
      "total_reward: -2116.22\n",
      "total_cost: 962.85\n",
      "total_trades: 4029\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.8e+05   |\n",
      "|    total_cost       | 1.28e+03  |\n",
      "|    total_reward     | -2.02e+04 |\n",
      "|    total_reward_pct | -4.05     |\n",
      "|    total_trades     | 4034      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 121       |\n",
      "|    total timesteps  | 15804     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 107       |\n",
      "|    critic_loss      | 21.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 15365     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 486205.95\n",
      "total_reward: -13794.05\n",
      "total_cost: 1279.09\n",
      "total_trades: 4023\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.86e+05  |\n",
      "|    total_cost       | 1.28e+03  |\n",
      "|    total_reward     | -1.38e+04 |\n",
      "|    total_reward_pct | -2.76     |\n",
      "|    total_trades     | 4023      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 135       |\n",
      "|    total timesteps  | 17560     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 95.5      |\n",
      "|    critic_loss      | 60.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17121     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.72e+05  |\n",
      "|    total_cost       | 1.6e+03   |\n",
      "|    total_reward     | -2.85e+04 |\n",
      "|    total_reward_pct | -5.69     |\n",
      "|    total_trades     | 4033      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 148       |\n",
      "|    total timesteps  | 19316     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 85.6      |\n",
      "|    critic_loss      | 44        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 18877     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 446903.00\n",
      "total_reward: -53097.00\n",
      "total_cost: 1268.05\n",
      "total_trades: 4007\n",
      "Sharpe: 0.095\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.35e+05 |\n",
      "|    total_cost       | 1.8e+03  |\n",
      "|    total_reward     | -6.5e+04 |\n",
      "|    total_reward_pct | -13      |\n",
      "|    total_trades     | 3995     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total timesteps  | 21072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 76.9     |\n",
      "|    critic_loss      | 12.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20633    |\n",
      "----------------------------------\n",
      "day: 438, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 461483.03\n",
      "total_reward: -38516.97\n",
      "total_cost: 1287.61\n",
      "total_trades: 3990\n",
      "Sharpe: 0.052\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.4e+05   |\n",
      "|    total_cost       | 1.59e+03  |\n",
      "|    total_reward     | -6.02e+04 |\n",
      "|    total_reward_pct | -12       |\n",
      "|    total_trades     | 3992      |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 176       |\n",
      "|    total timesteps  | 22828     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 68.9      |\n",
      "|    critic_loss      | 8.2       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 22389     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 425581.94\n",
      "total_reward: -74418.06\n",
      "total_cost: 1692.88\n",
      "total_trades: 3988\n",
      "Sharpe: -0.067\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.57e+05  |\n",
      "|    total_cost       | 1.88e+03  |\n",
      "|    total_reward     | -4.33e+04 |\n",
      "|    total_reward_pct | -8.66     |\n",
      "|    total_trades     | 3990      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 190       |\n",
      "|    total timesteps  | 24584     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 61.6      |\n",
      "|    critic_loss      | 7.64      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 24145     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 486541.68\n",
      "total_reward: -13458.32\n",
      "total_cost: 1276.71\n",
      "total_trades: 3990\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.87e+05  |\n",
      "|    total_cost       | 1.28e+03  |\n",
      "|    total_reward     | -1.35e+04 |\n",
      "|    total_reward_pct | -2.69     |\n",
      "|    total_trades     | 3990      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 204       |\n",
      "|    total timesteps  | 26340     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 55.1      |\n",
      "|    critic_loss      | 6.84      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 25901     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 974       |\n",
      "|    total_reward     | -3.55e+03 |\n",
      "|    total_reward_pct | -0.711    |\n",
      "|    total_trades     | 3980      |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 218       |\n",
      "|    total timesteps  | 28096     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 49.1      |\n",
      "|    critic_loss      | 4.94      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 27657     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498366.24\n",
      "total_reward: -1633.76\n",
      "total_cost: 963.08\n",
      "total_trades: 3986\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.62e+05  |\n",
      "|    total_cost       | 2.43e+03  |\n",
      "|    total_reward     | -1.38e+05 |\n",
      "|    total_reward_pct | -27.5     |\n",
      "|    total_trades     | 3985      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 231       |\n",
      "|    total timesteps  | 29852     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 43.8      |\n",
      "|    critic_loss      | 18.4      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 29413     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497968.86\n",
      "total_reward: -2031.14\n",
      "total_cost: 975.51\n",
      "total_trades: 3980\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.54e+05  |\n",
      "|    total_cost       | 1.6e+03   |\n",
      "|    total_reward     | -4.64e+04 |\n",
      "|    total_reward_pct | -9.29     |\n",
      "|    total_trades     | 4024      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 245       |\n",
      "|    total timesteps  | 31608     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 38.8      |\n",
      "|    critic_loss      | 11.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 31169     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 383925.11\n",
      "total_reward: -116074.89\n",
      "total_cost: 2191.48\n",
      "total_trades: 4012\n",
      "Sharpe: -0.140\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.38e+05  |\n",
      "|    total_cost       | 2.14e+03  |\n",
      "|    total_reward     | -6.17e+04 |\n",
      "|    total_reward_pct | -12.3     |\n",
      "|    total_trades     | 4015      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 259       |\n",
      "|    total timesteps  | 33364     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 34.6      |\n",
      "|    critic_loss      | 3.1       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 32925     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 411533.11\n",
      "total_reward: -88466.89\n",
      "total_cost: 1702.44\n",
      "total_trades: 4013\n",
      "Sharpe: -0.074\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.12e+05  |\n",
      "|    total_cost       | 1.7e+03   |\n",
      "|    total_reward     | -8.85e+04 |\n",
      "|    total_reward_pct | -17.7     |\n",
      "|    total_trades     | 4013      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 273       |\n",
      "|    total timesteps  | 35120     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 30.6      |\n",
      "|    critic_loss      | 6.85      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 34681     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.43e+05 |\n",
      "|    total_cost       | 1.73e+03 |\n",
      "|    total_reward     | -5.7e+04 |\n",
      "|    total_reward_pct | -11.4    |\n",
      "|    total_trades     | 4015     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total timesteps  | 36876    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 27.3     |\n",
      "|    critic_loss      | 15.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 36437    |\n",
      "----------------------------------\n",
      "day: 438, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 451914.84\n",
      "total_reward: -48085.16\n",
      "total_cost: 1747.30\n",
      "total_trades: 3994\n",
      "Sharpe: -0.023\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.06e+05  |\n",
      "|    total_cost       | 1.71e+03  |\n",
      "|    total_reward     | -9.41e+04 |\n",
      "|    total_reward_pct | -18.8     |\n",
      "|    total_trades     | 3987      |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 300       |\n",
      "|    total timesteps  | 38632     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 24.1      |\n",
      "|    critic_loss      | 2.89      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 38193     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498922.29\n",
      "total_reward: -1077.71\n",
      "total_cost: 959.11\n",
      "total_trades: 3990\n",
      "Sharpe: 0.245\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 976       |\n",
      "|    total_reward     | -3.34e+03 |\n",
      "|    total_reward_pct | -0.668    |\n",
      "|    total_trades     | 3987      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 314       |\n",
      "|    total timesteps  | 40388     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 21.2      |\n",
      "|    critic_loss      | 54.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 39949     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 430681.88\n",
      "total_reward: -69318.12\n",
      "total_cost: 2425.79\n",
      "total_trades: 3991\n",
      "Sharpe: -0.008\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 983       |\n",
      "|    total_reward     | -1.26e+03 |\n",
      "|    total_reward_pct | -0.252    |\n",
      "|    total_trades     | 3978      |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 328       |\n",
      "|    total timesteps  | 42144     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 18.6      |\n",
      "|    critic_loss      | 10.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 41705     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 436406.37\n",
      "total_reward: -63593.63\n",
      "total_cost: 2481.44\n",
      "total_trades: 3967\n",
      "Sharpe: 0.039\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.36e+05  |\n",
      "|    total_cost       | 2.48e+03  |\n",
      "|    total_reward     | -6.36e+04 |\n",
      "|    total_reward_pct | -12.7     |\n",
      "|    total_trades     | 3967      |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 341       |\n",
      "|    total timesteps  | 43900     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 16.4      |\n",
      "|    critic_loss      | 3.3       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 43461     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.31e+05  |\n",
      "|    total_cost       | 2.05e+03  |\n",
      "|    total_reward     | -6.89e+04 |\n",
      "|    total_reward_pct | -13.8     |\n",
      "|    total_trades     | 3958      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 355       |\n",
      "|    total timesteps  | 45656     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 14.3      |\n",
      "|    critic_loss      | 1.67      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 45217     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 347950.76\n",
      "total_reward: -152049.24\n",
      "total_cost: 2691.21\n",
      "total_trades: 3961\n",
      "Sharpe: -0.262\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.34e+05  |\n",
      "|    total_cost       | 1.82e+03  |\n",
      "|    total_reward     | -6.56e+04 |\n",
      "|    total_reward_pct | -13.1     |\n",
      "|    total_trades     | 3946      |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 369       |\n",
      "|    total timesteps  | 47412     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 12.5      |\n",
      "|    critic_loss      | 99.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 46973     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 411984.34\n",
      "total_reward: -88015.66\n",
      "total_cost: 1702.00\n",
      "total_trades: 3936\n",
      "Sharpe: -0.073\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.25e+05  |\n",
      "|    total_cost       | 1.73e+03  |\n",
      "|    total_reward     | -7.52e+04 |\n",
      "|    total_reward_pct | -15       |\n",
      "|    total_trades     | 3904      |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 383       |\n",
      "|    total timesteps  | 49168     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 10.9      |\n",
      "|    critic_loss      | 6.66      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 48729     |\n",
      "-----------------------------------\n",
      "======Trading from:  2019-10-02 to  2020-01-03\n",
      "============================================\n",
      "18.44636893135484\n",
      "turbulence_threshold:  0.0\n",
      "======Model training from:  2000-01-01 to  2019-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_1\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.25e+05  |\n",
      "|    total_cost         | 1.22e+05  |\n",
      "|    total_reward       | -7.48e+04 |\n",
      "|    total_reward_pct   | -15       |\n",
      "|    total_trades       | 5858      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | -0.133    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -22.5     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.888     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.17e+05  |\n",
      "|    total_cost         | 8.88e+04  |\n",
      "|    total_reward       | -1.83e+05 |\n",
      "|    total_reward_pct   | -36.6     |\n",
      "|    total_trades       | 5904      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | -0.235    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -11.8     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.66e+05 |\n",
      "|    total_cost         | 1.78e+05 |\n",
      "|    total_reward       | 2.66e+05 |\n",
      "|    total_reward_pct   | 53.1     |\n",
      "|    total_trades       | 6205     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -0.625   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 6.71     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.15e+05  |\n",
      "|    total_cost         | 1.26e+05  |\n",
      "|    total_reward       | -8.47e+04 |\n",
      "|    total_reward_pct   | -16.9     |\n",
      "|    total_trades       | 6042      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | 0.161     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.83      |\n",
      "-------------------------------------\n",
      "day: 438, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 737716.78\n",
      "total_reward: 237716.78\n",
      "total_cost: 147233.78\n",
      "total_trades: 6017\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.38e+05 |\n",
      "|    total_cost         | 1.47e+05 |\n",
      "|    total_reward       | 2.38e+05 |\n",
      "|    total_reward_pct   | 47.5     |\n",
      "|    total_trades       | 6017     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -1.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -1.11    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0753   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.29e+05 |\n",
      "|    total_cost         | 1.18e+05 |\n",
      "|    total_reward       | 2.89e+04 |\n",
      "|    total_reward_pct   | 5.79     |\n",
      "|    total_trades       | 5930     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | 0.188    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 42.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.91e+05 |\n",
      "|    total_cost         | 8.98e+04 |\n",
      "|    total_reward       | 9.06e+04 |\n",
      "|    total_reward_pct   | 18.1     |\n",
      "|    total_trades       | 5835     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | 0.138    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 7.87     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.189    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.88e+05  |\n",
      "|    total_cost         | 3.49e+04  |\n",
      "|    total_reward       | -1.12e+05 |\n",
      "|    total_reward_pct   | -22.4     |\n",
      "|    total_trades       | 5610      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.0495   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -1.47     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.0543    |\n",
      "-------------------------------------\n",
      "day: 438, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500975.80\n",
      "total_reward: 975.80\n",
      "total_cost: 23186.82\n",
      "total_trades: 5537\n",
      "Sharpe: 0.141\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.01e+05 |\n",
      "|    total_cost         | 2.32e+04 |\n",
      "|    total_reward       | 976      |\n",
      "|    total_reward_pct   | 0.195    |\n",
      "|    total_trades       | 5537     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -6.99    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0675   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.39e+05  |\n",
      "|    total_cost         | 2.35e+04  |\n",
      "|    total_reward       | -1.61e+05 |\n",
      "|    total_reward_pct   | -32.1     |\n",
      "|    total_trades       | 5478      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | 0.013     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 3.92      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.132     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.91e+05 |\n",
      "|    total_cost         | 3.14e+04 |\n",
      "|    total_reward       | 2.91e+05 |\n",
      "|    total_reward_pct   | 58.3     |\n",
      "|    total_trades       | 5629     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 11.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.246    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.64e+05  |\n",
      "|    total_cost         | 1.05e+04  |\n",
      "|    total_reward       | -1.36e+05 |\n",
      "|    total_reward_pct   | -27.3     |\n",
      "|    total_trades       | 5465      |\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -1.58     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.078     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.53e+05 |\n",
      "|    total_cost         | 1.83e+04 |\n",
      "|    total_reward       | 5.25e+04 |\n",
      "|    total_reward_pct   | 10.5     |\n",
      "|    total_trades       | 5551     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 3.28     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.188    |\n",
      "------------------------------------\n",
      "day: 438, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 555366.31\n",
      "total_reward: 55366.31\n",
      "total_cost: 25242.14\n",
      "total_trades: 5703\n",
      "Sharpe: 0.396\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.55e+05 |\n",
      "|    total_cost         | 2.52e+04 |\n",
      "|    total_reward       | 5.54e+04 |\n",
      "|    total_reward_pct   | 11.1     |\n",
      "|    total_trades       | 5703     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.365    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 4.35     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0562   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.11e+05 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 1.11e+05 |\n",
      "|    total_reward_pct   | 22.2     |\n",
      "|    total_trades       | 5906     |\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.731   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -2.92    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0726   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.51e+05  |\n",
      "|    total_cost         | 1.18e+04  |\n",
      "|    total_reward       | -1.49e+05 |\n",
      "|    total_reward_pct   | -29.7     |\n",
      "|    total_trades       | 5887      |\n",
      "| time/                 |           |\n",
      "|    fps                | 555       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0.0873    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -8.92     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.163     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.17e+05 |\n",
      "|    total_cost         | 2.13e+04 |\n",
      "|    total_reward       | 1.17e+05 |\n",
      "|    total_reward_pct   | 23.5     |\n",
      "|    total_trades       | 5893     |\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.309    |\n",
      "------------------------------------\n",
      "day: 438, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 390595.61\n",
      "total_reward: -109404.39\n",
      "total_cost: 9915.69\n",
      "total_trades: 5638\n",
      "Sharpe: -0.156\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.91e+05  |\n",
      "|    total_cost         | 9.92e+03  |\n",
      "|    total_reward       | -1.09e+05 |\n",
      "|    total_reward_pct   | -21.9     |\n",
      "|    total_trades       | 5638      |\n",
      "| time/                 |           |\n",
      "|    fps                | 556       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -9.48     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.212     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.88e+05  |\n",
      "|    total_cost         | 9.81e+03  |\n",
      "|    total_reward       | -1.23e+04 |\n",
      "|    total_reward_pct   | -2.46     |\n",
      "|    total_trades       | 5646      |\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0.0416    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.369     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.63e+05 |\n",
      "|    total_cost         | 1.81e+04 |\n",
      "|    total_reward       | 1.63e+05 |\n",
      "|    total_reward_pct   | 32.5     |\n",
      "|    total_trades       | 5831     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -23.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.672    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.76e+05  |\n",
      "|    total_cost         | 1.24e+04  |\n",
      "|    total_reward       | -2.37e+04 |\n",
      "|    total_reward_pct   | -4.74     |\n",
      "|    total_trades       | 5567      |\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0.233     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.389     |\n",
      "-------------------------------------\n",
      "day: 438, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1139281.76\n",
      "total_reward: 639281.76\n",
      "total_cost: 12195.65\n",
      "total_trades: 5183\n",
      "Sharpe: 1.467\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+06 |\n",
      "|    total_cost         | 1.22e+04 |\n",
      "|    total_reward       | 6.39e+05 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 5183     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.0114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -6.78    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0796   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.15e+05 |\n",
      "|    total_cost         | 8.16e+03 |\n",
      "|    total_reward       | 1.15e+05 |\n",
      "|    total_reward_pct   | 23       |\n",
      "|    total_trades       | 5091     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.198   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.451   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.374    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.54e+05 |\n",
      "|    total_cost         | 8.55e+03 |\n",
      "|    total_reward       | 1.54e+05 |\n",
      "|    total_reward_pct   | 30.9     |\n",
      "|    total_trades       | 5206     |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 13       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.55e+05 |\n",
      "|    total_cost         | 1.57e+04 |\n",
      "|    total_reward       | 4.55e+05 |\n",
      "|    total_reward_pct   | 91       |\n",
      "|    total_trades       | 5093     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.431    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.43e+05 |\n",
      "|    total_cost         | 1.15e+04 |\n",
      "|    total_reward       | 1.43e+05 |\n",
      "|    total_reward_pct   | 28.5     |\n",
      "|    total_trades       | 5035     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.312    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 4.44     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0791   |\n",
      "------------------------------------\n",
      "day: 438, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1025490.47\n",
      "total_reward: 525490.47\n",
      "total_cost: 13318.06\n",
      "total_trades: 4950\n",
      "Sharpe: 1.347\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.03e+06  |\n",
      "|    total_cost         | 1.33e+04  |\n",
      "|    total_reward       | 5.25e+05  |\n",
      "|    total_reward_pct   | 105       |\n",
      "|    total_trades       | 4950      |\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -0.342    |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.0816    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.99e+05 |\n",
      "|    total_cost         | 5.19e+03 |\n",
      "|    total_reward       | 3.99e+05 |\n",
      "|    total_reward_pct   | 79.7     |\n",
      "|    total_trades       | 4989     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 2.35     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0113   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.02e+05 |\n",
      "|    total_cost         | 4.35e+03 |\n",
      "|    total_reward       | 3.02e+05 |\n",
      "|    total_reward_pct   | 60.4     |\n",
      "|    total_trades       | 4843     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.968   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.385    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.66e+05 |\n",
      "|    total_cost         | 3.27e+03 |\n",
      "|    total_reward       | -3.4e+04 |\n",
      "|    total_reward_pct   | -6.8     |\n",
      "|    total_trades       | 4865     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.0429  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -7.61    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.89     |\n",
      "------------------------------------\n",
      "day: 438, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 701177.20\n",
      "total_reward: 201177.20\n",
      "total_cost: 4846.93\n",
      "total_trades: 4913\n",
      "Sharpe: 0.860\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.01e+05 |\n",
      "|    total_cost         | 4.85e+03 |\n",
      "|    total_reward       | 2.01e+05 |\n",
      "|    total_reward_pct   | 40.2     |\n",
      "|    total_trades       | 4913     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.0452   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 4.94e+03 |\n",
      "|    total_reward       | 5.49e+05 |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 4971     |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -1.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -5.98    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.215    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.63e+05 |\n",
      "|    total_cost         | 6.5e+03  |\n",
      "|    total_reward       | 2.63e+05 |\n",
      "|    total_reward_pct   | 52.5     |\n",
      "|    total_trades       | 5153     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.033    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 1.37e+04 |\n",
      "|    total_reward       | 5.47e+05 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 5245     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.0154  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 23.8     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.08e+05 |\n",
      "|    total_cost         | 2.8e+03  |\n",
      "|    total_reward       | 1.08e+05 |\n",
      "|    total_reward_pct   | 21.5     |\n",
      "|    total_trades       | 4980     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.228   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 25.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "day: 438, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 986206.61\n",
      "total_reward: 486206.61\n",
      "total_cost: 4601.70\n",
      "total_trades: 5011\n",
      "Sharpe: 1.556\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+06  |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 6.04e+05 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 5243     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.00841  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 33.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.3e+05  |\n",
      "|    total_cost         | 2.72e+03 |\n",
      "|    total_reward       | 2.96e+04 |\n",
      "|    total_reward_pct   | 5.93     |\n",
      "|    total_trades       | 5019     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.291   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -4.21    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.336    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+05 |\n",
      "|    total_cost         | 7.83e+03 |\n",
      "|    total_reward       | 4.97e+05 |\n",
      "|    total_reward_pct   | 99.5     |\n",
      "|    total_trades       | 4975     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -1.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -21.9    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.664    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+06 |\n",
      "|    total_cost         | 4.79e+03 |\n",
      "|    total_reward       | 6.39e+05 |\n",
      "|    total_reward_pct   | 128      |\n",
      "|    total_trades       | 4936     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.563   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.765    |\n",
      "------------------------------------\n",
      "day: 438, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1069017.42\n",
      "total_reward: 569017.42\n",
      "total_cost: 7780.92\n",
      "total_trades: 5111\n",
      "Sharpe: 1.730\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 7.78e+03 |\n",
      "|    total_reward       | 5.69e+05 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 5111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -39.5    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.5e+05  |\n",
      "|    total_cost         | 5.95e+03 |\n",
      "|    total_reward       | 2.5e+05  |\n",
      "|    total_reward_pct   | 50.1     |\n",
      "|    total_trades       | 5122     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 5.72e+03 |\n",
      "|    total_reward       | 5.42e+05 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 4976     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0.18     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 15.5     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+06 |\n",
      "|    total_cost         | 7.78e+03 |\n",
      "|    total_reward       | 6.13e+05 |\n",
      "|    total_reward_pct   | 123      |\n",
      "|    total_trades       | 5003     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -7.69    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.308    |\n",
      "------------------------------------\n",
      "day: 438, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1061904.86\n",
      "total_reward: 561904.86\n",
      "total_cost: 8374.04\n",
      "total_trades: 5126\n",
      "Sharpe: 1.676\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 8.37e+03 |\n",
      "|    total_reward       | 5.62e+05 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 5126     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.506   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0982   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 6.94e+03 |\n",
      "|    total_reward       | 5.46e+05 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 5105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.191   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -18.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.935    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+06 |\n",
      "|    total_cost         | 5.55e+03 |\n",
      "|    total_reward       | 5.78e+05 |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 4887     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0.263    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -9.3     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 7.82e+03 |\n",
      "|    total_reward       | 6.5e+05  |\n",
      "|    total_reward_pct   | 130      |\n",
      "|    total_trades       | 5047     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 30.9     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 9.63e+03 |\n",
      "|    total_reward       | 5.18e+05 |\n",
      "|    total_reward_pct   | 104      |\n",
      "|    total_trades       | 5089     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.342    |\n",
      "------------------------------------\n",
      "day: 438, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 638637.80\n",
      "total_reward: 138637.80\n",
      "total_cost: 6939.08\n",
      "total_trades: 4722\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.39e+05  |\n",
      "|    total_cost         | 6.94e+03  |\n",
      "|    total_reward       | 1.39e+05  |\n",
      "|    total_reward_pct   | 27.7      |\n",
      "|    total_trades       | 4722      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 14        |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.458     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 6.49e+05 |\n",
      "|    total_reward_pct   | 130      |\n",
      "|    total_trades       | 4639     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 26.5     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+06 |\n",
      "|    total_cost         | 7.44e+03 |\n",
      "|    total_reward       | 6.2e+05  |\n",
      "|    total_reward_pct   | 124      |\n",
      "|    total_trades       | 4528     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -0.0412  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -2.69    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.239    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.89e+05 |\n",
      "|    total_cost         | 4.23e+03 |\n",
      "|    total_reward       | -1.1e+04 |\n",
      "|    total_reward_pct   | -2.2     |\n",
      "|    total_trades       | 4477     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -1.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -23      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.893    |\n",
      "------------------------------------\n",
      "day: 438, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1241015.34\n",
      "total_reward: 741015.34\n",
      "total_cost: 9238.65\n",
      "total_trades: 4579\n",
      "Sharpe: 1.680\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.24e+06 |\n",
      "|    total_cost         | 9.24e+03 |\n",
      "|    total_reward       | 7.41e+05 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 4579     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.333    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.32e+05 |\n",
      "|    total_cost         | 6.6e+03  |\n",
      "|    total_reward       | 1.32e+05 |\n",
      "|    total_reward_pct   | 26.5     |\n",
      "|    total_trades       | 4625     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -37.2    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.08e+05 |\n",
      "|    total_cost         | 5.77e+03 |\n",
      "|    total_reward       | 1.08e+05 |\n",
      "|    total_reward_pct   | 21.7     |\n",
      "|    total_trades       | 4637     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -0.00384 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.507   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.02e+05 |\n",
      "|    total_cost         | 6.51e+03 |\n",
      "|    total_reward       | 1.82e+03 |\n",
      "|    total_reward_pct   | 0.364    |\n",
      "|    total_trades       | 4515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -34.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.46e+05 |\n",
      "|    total_cost         | 1.52e+04 |\n",
      "|    total_reward       | 4.46e+05 |\n",
      "|    total_reward_pct   | 89.1     |\n",
      "|    total_trades       | 4660     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "day: 438, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 637622.24\n",
      "total_reward: 137622.24\n",
      "total_cost: 4272.71\n",
      "total_trades: 4626\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+05 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 4.97e+05 |\n",
      "|    total_reward_pct   | 99.3     |\n",
      "|    total_trades       | 4866     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.0961  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -3.04    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 1.95e+04 |\n",
      "|    total_reward       | 5.72e+05 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 4893     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.47e+05 |\n",
      "|    total_cost         | 1.25e+04 |\n",
      "|    total_reward       | 4.47e+05 |\n",
      "|    total_reward_pct   | 89.5     |\n",
      "|    total_trades       | 4729     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 12.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.4e+05  |\n",
      "|    total_cost         | 8.99e+03 |\n",
      "|    total_reward       | 4.4e+05  |\n",
      "|    total_reward_pct   | 87.9     |\n",
      "|    total_trades       | 4725     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0.741    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -2.25    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "day: 438, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 984471.14\n",
      "total_reward: 484471.14\n",
      "total_cost: 12430.11\n",
      "total_trades: 4609\n",
      "Sharpe: 1.316\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.84e+05 |\n",
      "|    total_cost         | 1.24e+04 |\n",
      "|    total_reward       | 4.84e+05 |\n",
      "|    total_reward_pct   | 96.9     |\n",
      "|    total_trades       | 4609     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 8.7      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.91e+05  |\n",
      "|    total_cost         | 1.14e+04  |\n",
      "|    total_reward       | 3.91e+05  |\n",
      "|    total_reward_pct   | 78.1      |\n",
      "|    total_trades       | 4845      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -28.1     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.17      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.42e+05  |\n",
      "|    total_cost         | 1.18e+04  |\n",
      "|    total_reward       | 4.42e+05  |\n",
      "|    total_reward_pct   | 88.5      |\n",
      "|    total_trades       | 4771      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -12.1     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.387     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.61e+05  |\n",
      "|    total_cost         | 7.95e+03  |\n",
      "|    total_reward       | 1.61e+05  |\n",
      "|    total_reward_pct   | 32.1      |\n",
      "|    total_trades       | 4629      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.768     |\n",
      "-------------------------------------\n",
      "day: 438, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 933693.97\n",
      "total_reward: 433693.97\n",
      "total_cost: 12279.18\n",
      "total_trades: 4655\n",
      "Sharpe: 1.374\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.34e+05 |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 4.34e+05 |\n",
      "|    total_reward_pct   | 86.7     |\n",
      "|    total_trades       | 4655     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.912    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.95e+05 |\n",
      "|    total_cost         | 1.13e+04 |\n",
      "|    total_reward       | 3.95e+05 |\n",
      "|    total_reward_pct   | 79.1     |\n",
      "|    total_trades       | 4732     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -0.559   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -13.7    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.395    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.46e+05 |\n",
      "|    total_cost         | 5.51e+03 |\n",
      "|    total_reward       | -5.4e+04 |\n",
      "|    total_reward_pct   | -10.8    |\n",
      "|    total_trades       | 4601     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -12.8    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.608    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.62e+05  |\n",
      "|    total_cost         | 1.81e+04  |\n",
      "|    total_reward       | 4.62e+05  |\n",
      "|    total_reward_pct   | 92.4      |\n",
      "|    total_trades       | 4628      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 18        |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.772     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.7e+05   |\n",
      "|    total_cost         | 8.72e+03  |\n",
      "|    total_reward       | 3.7e+05   |\n",
      "|    total_reward_pct   | 74        |\n",
      "|    total_trades       | 4582      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 2.77      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.143     |\n",
      "-------------------------------------\n",
      "day: 438, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 797174.86\n",
      "total_reward: 297174.86\n",
      "total_cost: 7062.34\n",
      "total_trades: 4522\n",
      "Sharpe: 1.413\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.97e+05 |\n",
      "|    total_cost         | 7.06e+03 |\n",
      "|    total_reward       | 2.97e+05 |\n",
      "|    total_reward_pct   | 59.4     |\n",
      "|    total_trades       | 4522     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 58.1     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.97e+05 |\n",
      "|    total_cost         | 9.38e+03 |\n",
      "|    total_reward       | 2.97e+05 |\n",
      "|    total_reward_pct   | 59.5     |\n",
      "|    total_trades       | 4766     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -28      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.47e+05 |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | 3.47e+05 |\n",
      "|    total_reward_pct   | 69.4     |\n",
      "|    total_trades       | 4828     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -6.39    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.77e+05 |\n",
      "|    total_cost         | 9.9e+03  |\n",
      "|    total_reward       | 3.77e+05 |\n",
      "|    total_reward_pct   | 75.5     |\n",
      "|    total_trades       | 4773     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -0.0129  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0458   |\n",
      "------------------------------------\n",
      "day: 438, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 946806.75\n",
      "total_reward: 446806.75\n",
      "total_cost: 9869.33\n",
      "total_trades: 4762\n",
      "Sharpe: 1.296\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.47e+05 |\n",
      "|    total_cost         | 9.87e+03 |\n",
      "|    total_reward       | 4.47e+05 |\n",
      "|    total_reward_pct   | 89.4     |\n",
      "|    total_trades       | 4762     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 23.4     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.767    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.58e+05 |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | 3.58e+05 |\n",
      "|    total_reward_pct   | 71.6     |\n",
      "|    total_trades       | 4776     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -0.915   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -43.6    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.42e+05  |\n",
      "|    total_cost         | 1.66e+04  |\n",
      "|    total_reward       | 3.42e+05  |\n",
      "|    total_reward_pct   | 68.3      |\n",
      "|    total_trades       | 4803      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 0.37      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.0314    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.48e+05 |\n",
      "|    total_cost         | 5.64e+03 |\n",
      "|    total_reward       | 4.83e+04 |\n",
      "|    total_reward_pct   | 9.66     |\n",
      "|    total_trades       | 4562     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -3.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -2.85    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.656    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.63e+05 |\n",
      "|    total_cost         | 9.76e+03 |\n",
      "|    total_reward       | 3.63e+05 |\n",
      "|    total_reward_pct   | 72.7     |\n",
      "|    total_trades       | 4652     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -0.636   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -5.26    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.268    |\n",
      "------------------------------------\n",
      "day: 438, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 407103.11\n",
      "total_reward: -92896.89\n",
      "total_cost: 4944.96\n",
      "total_trades: 4600\n",
      "Sharpe: -0.105\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.88e+05 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 3.88e+05 |\n",
      "|    total_reward_pct   | 77.6     |\n",
      "|    total_trades       | 4774     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.0173   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 5.31     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.228    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 5.07e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 4809     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -0.95    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0508   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.15e+05 |\n",
      "|    total_cost         | 9.62e+03 |\n",
      "|    total_reward       | 3.15e+05 |\n",
      "|    total_reward_pct   | 62.9     |\n",
      "|    total_trades       | 4666     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -31.5    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.84e+05 |\n",
      "|    total_cost         | 2.25e+04 |\n",
      "|    total_reward       | 3.84e+05 |\n",
      "|    total_reward_pct   | 76.9     |\n",
      "|    total_trades       | 4684     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0.0638   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 17.2     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.846    |\n",
      "------------------------------------\n",
      "day: 438, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 652597.85\n",
      "total_reward: 152597.85\n",
      "total_cost: 13321.58\n",
      "total_trades: 4605\n",
      "Sharpe: 0.967\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.53e+05 |\n",
      "|    total_cost         | 1.33e+04 |\n",
      "|    total_reward       | 1.53e+05 |\n",
      "|    total_reward_pct   | 30.5     |\n",
      "|    total_trades       | 4605     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -24.2    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.9e+05  |\n",
      "|    total_cost         | 1.61e+04 |\n",
      "|    total_reward       | 4.9e+05  |\n",
      "|    total_reward_pct   | 98.1     |\n",
      "|    total_trades       | 4453     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 66.5     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 5.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.66e+05 |\n",
      "|    total_cost         | 1.92e+04 |\n",
      "|    total_reward       | 4.66e+05 |\n",
      "|    total_reward_pct   | 93.2     |\n",
      "|    total_trades       | 4288     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 11.4     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.459    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.21e+05 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 4.21e+05 |\n",
      "|    total_reward_pct   | 84.3     |\n",
      "|    total_trades       | 4125     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 33.1     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "day: 438, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1062786.82\n",
      "total_reward: 562786.82\n",
      "total_cost: 24221.46\n",
      "total_trades: 4040\n",
      "Sharpe: 1.610\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 2.42e+04 |\n",
      "|    total_reward       | 5.63e+05 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 4040     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -34      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.1e+05  |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | 3.1e+05  |\n",
      "|    total_reward_pct   | 62.1     |\n",
      "|    total_trades       | 3949     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.0172   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 9.96     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.766    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 1.3e+04  |\n",
      "|    total_reward       | 5.31e+05 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 4142     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -65.3    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 7.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 1.59e+04 |\n",
      "|    total_reward       | 5.64e+05 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 4020     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.011    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -44.7    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.74e+05  |\n",
      "|    total_cost         | 1.39e+04  |\n",
      "|    total_reward       | 3.74e+05  |\n",
      "|    total_reward_pct   | 74.8      |\n",
      "|    total_trades       | 3979      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 44.5      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 2.9       |\n",
      "-------------------------------------\n",
      "day: 438, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 949687.97\n",
      "total_reward: 449687.97\n",
      "total_cost: 20030.33\n",
      "total_trades: 4125\n",
      "Sharpe: 1.289\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.5e+05  |\n",
      "|    total_cost         | 2e+04    |\n",
      "|    total_reward       | 4.5e+05  |\n",
      "|    total_reward_pct   | 89.9     |\n",
      "|    total_trades       | 4125     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0.00687  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.46e+05 |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | 3.46e+05 |\n",
      "|    total_reward_pct   | 69.3     |\n",
      "|    total_trades       | 4166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -99.2    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.83e+05 |\n",
      "|    total_cost         | 2.11e+04 |\n",
      "|    total_reward       | 2.83e+05 |\n",
      "|    total_reward_pct   | 56.6     |\n",
      "|    total_trades       | 4317     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.0117  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -1.5     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.81e+05 |\n",
      "|    total_cost         | 2.91e+04 |\n",
      "|    total_reward       | 3.81e+05 |\n",
      "|    total_reward_pct   | 76.1     |\n",
      "|    total_trades       | 4438     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 5.15     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.295    |\n",
      "------------------------------------\n",
      "day: 438, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 840189.12\n",
      "total_reward: 340189.12\n",
      "total_cost: 31939.14\n",
      "total_trades: 4312\n",
      "Sharpe: 1.063\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.4e+05  |\n",
      "|    total_cost         | 3.19e+04 |\n",
      "|    total_reward       | 3.4e+05  |\n",
      "|    total_reward_pct   | 68       |\n",
      "|    total_trades       | 4312     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 0.659    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -31.9    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.3e+05  |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | 3.3e+05  |\n",
      "|    total_reward_pct   | 66       |\n",
      "|    total_trades       | 4180     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0.000998 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -19.2    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.528    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.75e+05  |\n",
      "|    total_cost         | 9.35e+03  |\n",
      "|    total_reward       | -2.49e+04 |\n",
      "|    total_reward_pct   | -4.97     |\n",
      "|    total_trades       | 3977      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 4.24      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.186     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.58e+05 |\n",
      "|    total_cost         | 2.86e+04 |\n",
      "|    total_reward       | 3.58e+05 |\n",
      "|    total_reward_pct   | 71.5     |\n",
      "|    total_trades       | 4053     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 27.1     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "day: 438, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 444121.97\n",
      "total_reward: -55878.03\n",
      "total_cost: 10361.42\n",
      "total_trades: 4169\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.44e+05  |\n",
      "|    total_cost         | 1.04e+04  |\n",
      "|    total_reward       | -5.59e+04 |\n",
      "|    total_reward_pct   | -11.2     |\n",
      "|    total_trades       | 4169      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | -0.0216   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 96.7      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.83e+05 |\n",
      "|    total_cost         | 1.63e+04 |\n",
      "|    total_reward       | 2.83e+05 |\n",
      "|    total_reward_pct   | 56.6     |\n",
      "|    total_trades       | 4164     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 17.1     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 5.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.22e+05 |\n",
      "|    total_cost         | 1.96e+04 |\n",
      "|    total_reward       | 3.22e+05 |\n",
      "|    total_reward_pct   | 64.4     |\n",
      "|    total_trades       | 4079     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 56       |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.6e+05  |\n",
      "|    total_cost         | 1.36e+04 |\n",
      "|    total_reward       | 2.6e+05  |\n",
      "|    total_reward_pct   | 52       |\n",
      "|    total_trades       | 4045     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -0.0987  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -20.2    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.495    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+05  |\n",
      "|    total_cost         | 6.57e+03  |\n",
      "|    total_reward       | -1.58e+05 |\n",
      "|    total_reward_pct   | -31.5     |\n",
      "|    total_trades       | 4061      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | 0.0738    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 57.7      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 4.75      |\n",
      "-------------------------------------\n",
      "day: 438, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 733322.00\n",
      "total_reward: 233322.00\n",
      "total_cost: 9766.86\n",
      "total_trades: 4149\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.33e+05  |\n",
      "|    total_cost         | 9.77e+03  |\n",
      "|    total_reward       | 2.33e+05  |\n",
      "|    total_reward_pct   | 46.7      |\n",
      "|    total_trades       | 4149      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | 24.2      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.935     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.26e+05 |\n",
      "|    total_cost         | 6.91e+03 |\n",
      "|    total_reward       | 2.26e+05 |\n",
      "|    total_reward_pct   | 45.2     |\n",
      "|    total_trades       | 4115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 6.85     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.958    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.38e+05 |\n",
      "|    total_cost         | 2.04e+04 |\n",
      "|    total_reward       | 2.38e+05 |\n",
      "|    total_reward_pct   | 47.6     |\n",
      "|    total_trades       | 4233     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -45      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.05e+05 |\n",
      "|    total_cost         | 7.41e+03 |\n",
      "|    total_reward       | 3.05e+05 |\n",
      "|    total_reward_pct   | 61       |\n",
      "|    total_trades       | 4087     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -46.4    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3.19     |\n",
      "------------------------------------\n",
      "day: 438, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 759390.13\n",
      "total_reward: 259390.13\n",
      "total_cost: 10194.67\n",
      "total_trades: 4118\n",
      "Sharpe: 0.890\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.59e+05 |\n",
      "|    total_cost         | 1.02e+04 |\n",
      "|    total_reward       | 2.59e+05 |\n",
      "|    total_reward_pct   | 51.9     |\n",
      "|    total_trades       | 4118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 35.5     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.57e+05 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | 2.57e+05 |\n",
      "|    total_reward_pct   | 51.4     |\n",
      "|    total_trades       | 3921     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -0.0726  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 35.3     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.42e+05 |\n",
      "|    total_cost         | 1.64e+04 |\n",
      "|    total_reward       | 3.42e+05 |\n",
      "|    total_reward_pct   | 68.4     |\n",
      "|    total_trades       | 4010     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.00935 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 22.7     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.696    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.28e+05 |\n",
      "|    total_cost         | 5.43e+03 |\n",
      "|    total_reward       | 2.28e+05 |\n",
      "|    total_reward_pct   | 45.5     |\n",
      "|    total_trades       | 3954     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -19.2    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.492    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.46e+05  |\n",
      "|    total_cost         | 3.42e+03  |\n",
      "|    total_reward       | -1.54e+05 |\n",
      "|    total_reward_pct   | -30.8     |\n",
      "|    total_trades       | 3917      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.9     |\n",
      "|    explained_variance | -0.5      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -9.78     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.482     |\n",
      "-------------------------------------\n",
      "day: 438, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 743936.69\n",
      "total_reward: 243936.69\n",
      "total_cost: 13240.29\n",
      "total_trades: 3798\n",
      "Sharpe: 0.803\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.44e+05 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 2.44e+05 |\n",
      "|    total_reward_pct   | 48.8     |\n",
      "|    total_trades       | 3798     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -21.2    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.825    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.12e+05 |\n",
      "|    total_cost         | 2.27e+04 |\n",
      "|    total_reward       | 2.12e+05 |\n",
      "|    total_reward_pct   | 42.3     |\n",
      "|    total_trades       | 3908     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -9.4     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.805    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.71e+05 |\n",
      "|    total_cost         | 1.86e+04 |\n",
      "|    total_reward       | 3.71e+05 |\n",
      "|    total_reward_pct   | 74.2     |\n",
      "|    total_trades       | 3826     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 46.2     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.74e+05 |\n",
      "|    total_cost         | 2.16e+04 |\n",
      "|    total_reward       | 2.74e+05 |\n",
      "|    total_reward_pct   | 54.8     |\n",
      "|    total_trades       | 3863     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -41.7    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.37     |\n",
      "------------------------------------\n",
      "day: 438, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 783890.71\n",
      "total_reward: 283890.71\n",
      "total_cost: 19432.85\n",
      "total_trades: 3772\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.84e+05 |\n",
      "|    total_cost         | 1.94e+04 |\n",
      "|    total_reward       | 2.84e+05 |\n",
      "|    total_reward_pct   | 56.8     |\n",
      "|    total_trades       | 3772     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.0774   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 64       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.09e+05 |\n",
      "|    total_cost         | 2.64e+04 |\n",
      "|    total_reward       | 3.09e+05 |\n",
      "|    total_reward_pct   | 61.8     |\n",
      "|    total_trades       | 3830     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 64.5     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 6.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.07e+05 |\n",
      "|    total_cost         | 2.62e+04 |\n",
      "|    total_reward       | 2.07e+05 |\n",
      "|    total_reward_pct   | 41.4     |\n",
      "|    total_trades       | 3906     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 3.2      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.759    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.96e+05 |\n",
      "|    total_cost         | 1.82e+04 |\n",
      "|    total_reward       | 2.96e+05 |\n",
      "|    total_reward_pct   | 59.3     |\n",
      "|    total_trades       | 3741     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 13.6     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.638    |\n",
      "------------------------------------\n",
      "day: 438, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 689061.77\n",
      "total_reward: 189061.77\n",
      "total_cost: 27164.33\n",
      "total_trades: 3835\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.89e+05 |\n",
      "|    total_cost         | 2.72e+04 |\n",
      "|    total_reward       | 1.89e+05 |\n",
      "|    total_reward_pct   | 37.8     |\n",
      "|    total_trades       | 3835     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -6.59    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.259    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.56e+05  |\n",
      "|    total_cost         | 3.78e+03  |\n",
      "|    total_reward       | -1.44e+05 |\n",
      "|    total_reward_pct   | -28.7     |\n",
      "|    total_trades       | 3851      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -12.3     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.288     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.37e+05  |\n",
      "|    total_cost         | 2.7e+03   |\n",
      "|    total_reward       | -1.63e+05 |\n",
      "|    total_reward_pct   | -32.5     |\n",
      "|    total_trades       | 3841      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 37.5      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 2.12      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.46e+05 |\n",
      "|    total_cost         | 7.29e+03 |\n",
      "|    total_reward       | 2.46e+05 |\n",
      "|    total_reward_pct   | 49.1     |\n",
      "|    total_trades       | 3674     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -15.3    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.26e+05 |\n",
      "|    total_cost         | 1.09e+04 |\n",
      "|    total_reward       | 2.26e+05 |\n",
      "|    total_reward_pct   | 45.2     |\n",
      "|    total_trades       | 3617     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 21.6     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "day: 438, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 772662.41\n",
      "total_reward: 272662.41\n",
      "total_cost: 10605.79\n",
      "total_trades: 3683\n",
      "Sharpe: 0.885\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.73e+05 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 2.73e+05 |\n",
      "|    total_reward_pct   | 54.5     |\n",
      "|    total_trades       | 3683     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 60.3     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 5.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.22e+05 |\n",
      "|    total_cost         | 1.44e+04 |\n",
      "|    total_reward       | 3.22e+05 |\n",
      "|    total_reward_pct   | 64.5     |\n",
      "|    total_trades       | 3737     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -15.7    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.32e+05 |\n",
      "|    total_cost         | 1.3e+04  |\n",
      "|    total_reward       | 2.32e+05 |\n",
      "|    total_reward_pct   | 46.5     |\n",
      "|    total_trades       | 3804     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -12      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 2.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.65e+05 |\n",
      "|    total_cost         | 8.51e+03 |\n",
      "|    total_reward       | 2.65e+05 |\n",
      "|    total_reward_pct   | 53.1     |\n",
      "|    total_trades       | 3872     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.0327   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.38     |\n",
      "------------------------------------\n",
      "day: 438, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 378836.44\n",
      "total_reward: -121163.56\n",
      "total_cost: 7074.73\n",
      "total_trades: 3812\n",
      "Sharpe: -0.152\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.79e+05  |\n",
      "|    total_cost         | 7.07e+03  |\n",
      "|    total_reward       | -1.21e+05 |\n",
      "|    total_reward_pct   | -24.2     |\n",
      "|    total_trades       | 3812      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -21.1     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 1.49      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.39e+05 |\n",
      "|    total_cost         | 4.5e+03  |\n",
      "|    total_reward       | 3.9e+04  |\n",
      "|    total_reward_pct   | 7.81     |\n",
      "|    total_trades       | 3675     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 52.8     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.53e+05 |\n",
      "|    total_cost         | 8.96e+03 |\n",
      "|    total_reward       | 2.53e+05 |\n",
      "|    total_reward_pct   | 50.7     |\n",
      "|    total_trades       | 3764     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.108    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 9.48     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.189    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.07e+05  |\n",
      "|    total_cost         | 4.33e+03  |\n",
      "|    total_reward       | -9.28e+04 |\n",
      "|    total_reward_pct   | -18.6     |\n",
      "|    total_trades       | 3572      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -6.77     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.125     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.91e+05 |\n",
      "|    total_cost         | 5.77e+03 |\n",
      "|    total_reward       | 1.91e+05 |\n",
      "|    total_reward_pct   | 38.2     |\n",
      "|    total_trades       | 3592     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.247    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "day: 438, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 761656.93\n",
      "total_reward: 261656.93\n",
      "total_cost: 8420.94\n",
      "total_trades: 3583\n",
      "Sharpe: 0.925\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.05e+05 |\n",
      "|    total_cost         | 1.68e+03 |\n",
      "|    total_reward       | 4.72e+03 |\n",
      "|    total_reward_pct   | 0.944    |\n",
      "|    total_trades       | 3569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 50.5     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.08e+05 |\n",
      "|    total_cost         | 1.98e+03 |\n",
      "|    total_reward       | 8.37e+03 |\n",
      "|    total_reward_pct   | 1.67     |\n",
      "|    total_trades       | 3639     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.813    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.32e+05  |\n",
      "|    total_cost         | 1.63e+03  |\n",
      "|    total_reward       | -6.82e+04 |\n",
      "|    total_reward_pct   | -13.6     |\n",
      "|    total_trades       | 3721      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 17.2      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.746     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.33e+05  |\n",
      "|    total_cost         | 1.49e+03  |\n",
      "|    total_reward       | -6.69e+04 |\n",
      "|    total_reward_pct   | -13.4     |\n",
      "|    total_trades       | 3929      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | 0.00123   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -44.8     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 2.14      |\n",
      "-------------------------------------\n",
      "day: 438, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 545815.72\n",
      "total_reward: 45815.72\n",
      "total_cost: 1040.84\n",
      "total_trades: 3912\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.46e+05 |\n",
      "|    total_cost         | 1.04e+03 |\n",
      "|    total_reward       | 4.58e+04 |\n",
      "|    total_reward_pct   | 9.16     |\n",
      "|    total_trades       | 3912     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | -0.133   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 38.8     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.84e+05 |\n",
      "|    total_cost         | 3.7e+03  |\n",
      "|    total_reward       | 1.84e+05 |\n",
      "|    total_reward_pct   | 36.8     |\n",
      "|    total_trades       | 3825     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 56.9     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 3.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.94e+05 |\n",
      "|    total_cost         | 5.66e+03 |\n",
      "|    total_reward       | 2.94e+05 |\n",
      "|    total_reward_pct   | 58.8     |\n",
      "|    total_trades       | 3873     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -22.8    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.633    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.02e+05 |\n",
      "|    total_cost         | 2.11e+03 |\n",
      "|    total_reward       | 1.02e+05 |\n",
      "|    total_reward_pct   | 20.4     |\n",
      "|    total_trades       | 4160     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.0721   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.693    |\n",
      "------------------------------------\n",
      "day: 438, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 745165.57\n",
      "total_reward: 245165.57\n",
      "total_cost: 7892.55\n",
      "total_trades: 4276\n",
      "Sharpe: 0.852\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.45e+05 |\n",
      "|    total_cost         | 7.89e+03 |\n",
      "|    total_reward       | 2.45e+05 |\n",
      "|    total_reward_pct   | 49       |\n",
      "|    total_trades       | 4276     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -29.6    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.57e+05 |\n",
      "|    total_cost         | 7.17e+03 |\n",
      "|    total_reward       | 2.57e+05 |\n",
      "|    total_reward_pct   | 51.5     |\n",
      "|    total_trades       | 4415     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 43.9     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.7e+05  |\n",
      "|    total_cost         | 8.29e+03 |\n",
      "|    total_reward       | 2.7e+05  |\n",
      "|    total_reward_pct   | 53.9     |\n",
      "|    total_trades       | 4464     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 25.1     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.778    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.45e+05  |\n",
      "|    total_cost         | 2.52e+03  |\n",
      "|    total_reward       | -5.45e+04 |\n",
      "|    total_reward_pct   | -10.9     |\n",
      "|    total_trades       | 4402      |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | -0.0662   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -4.55     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.274     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.57e+05 |\n",
      "|    total_cost         | 5.6e+03  |\n",
      "|    total_reward       | 2.57e+05 |\n",
      "|    total_reward_pct   | 51.3     |\n",
      "|    total_trades       | 4351     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -32.9    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 1.86     |\n",
      "------------------------------------\n",
      "day: 438, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 758581.71\n",
      "total_reward: 258581.71\n",
      "total_cost: 4108.36\n",
      "total_trades: 4371\n",
      "Sharpe: 0.853\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.59e+05 |\n",
      "|    total_cost         | 4.11e+03 |\n",
      "|    total_reward       | 2.59e+05 |\n",
      "|    total_reward_pct   | 51.7     |\n",
      "|    total_trades       | 4371     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.255   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.731    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.98e+05 |\n",
      "|    total_cost         | 8.12e+03 |\n",
      "|    total_reward       | 2.98e+05 |\n",
      "|    total_reward_pct   | 59.6     |\n",
      "|    total_trades       | 4303     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0.0343   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.638    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.15e+05  |\n",
      "|    total_cost         | 2.69e+03  |\n",
      "|    total_reward       | -8.52e+04 |\n",
      "|    total_reward_pct   | -17       |\n",
      "|    total_trades       | 4256      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -17.6     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.951     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.55e+05 |\n",
      "|    total_cost         | 5.36e+03 |\n",
      "|    total_reward       | 2.55e+05 |\n",
      "|    total_reward_pct   | 51.1     |\n",
      "|    total_trades       | 4270     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 73.9     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 7.28     |\n",
      "------------------------------------\n",
      "day: 438, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 762786.56\n",
      "total_reward: 262786.56\n",
      "total_cost: 5153.98\n",
      "total_trades: 4318\n",
      "Sharpe: 0.856\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.63e+05 |\n",
      "|    total_cost         | 5.15e+03 |\n",
      "|    total_reward       | 2.63e+05 |\n",
      "|    total_reward_pct   | 52.6     |\n",
      "|    total_trades       | 4318     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -38.1    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.08e+05 |\n",
      "|    total_cost         | 5.85e+03 |\n",
      "|    total_reward       | 3.08e+05 |\n",
      "|    total_reward_pct   | 61.7     |\n",
      "|    total_trades       | 4516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0.156    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.443   |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.267    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.52e+05 |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 2.52e+05 |\n",
      "|    total_reward_pct   | 50.5     |\n",
      "|    total_trades       | 4564     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.323   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 5.21     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.068    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.06e+05  |\n",
      "|    total_cost         | 4.5e+03   |\n",
      "|    total_reward       | -9.35e+04 |\n",
      "|    total_reward_pct   | -18.7     |\n",
      "|    total_trades       | 4477      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -1.88     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 1.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.31e+05 |\n",
      "|    total_cost         | 6.91e+03 |\n",
      "|    total_reward       | 3.31e+05 |\n",
      "|    total_reward_pct   | 66.2     |\n",
      "|    total_trades       | 4394     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 22.3     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.843    |\n",
      "------------------------------------\n",
      "day: 438, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 766105.16\n",
      "total_reward: 266105.16\n",
      "total_cost: 5462.81\n",
      "total_trades: 4144\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.49e+05  |\n",
      "|    total_cost         | 1.86e+03  |\n",
      "|    total_reward       | -5.13e+04 |\n",
      "|    total_reward_pct   | -10.3     |\n",
      "|    total_trades       | 4028      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | -0.048    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | -17.9     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.543     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.41e+05  |\n",
      "|    total_cost         | 2.37e+03  |\n",
      "|    total_reward       | -1.59e+05 |\n",
      "|    total_reward_pct   | -31.7     |\n",
      "|    total_trades       | 3907      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | -10.2     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.726     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.43e+05 |\n",
      "|    total_cost         | 3.52e+03 |\n",
      "|    total_reward       | 2.43e+05 |\n",
      "|    total_reward_pct   | 48.6     |\n",
      "|    total_trades       | 4018     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 16.2     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.46e+05 |\n",
      "|    total_cost         | 5.62e+03 |\n",
      "|    total_reward       | 3.46e+05 |\n",
      "|    total_reward_pct   | 69.2     |\n",
      "|    total_trades       | 3990     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -12.7    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.353    |\n",
      "------------------------------------\n",
      "day: 438, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 730715.13\n",
      "total_reward: 230715.13\n",
      "total_cost: 3453.18\n",
      "total_trades: 3999\n",
      "Sharpe: 0.828\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.31e+05 |\n",
      "|    total_cost         | 3.45e+03 |\n",
      "|    total_reward       | 2.31e+05 |\n",
      "|    total_reward_pct   | 46.1     |\n",
      "|    total_trades       | 3999     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.492    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.03e+05  |\n",
      "|    total_cost         | 2.7e+03   |\n",
      "|    total_reward       | -9.72e+04 |\n",
      "|    total_reward_pct   | -19.4     |\n",
      "|    total_trades       | 3961      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 4.36      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.65e+05  |\n",
      "|    total_cost         | 5.32e+03  |\n",
      "|    total_reward       | 2.65e+05  |\n",
      "|    total_reward_pct   | 53.1      |\n",
      "|    total_trades       | 4048      |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 4.09      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.467     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.86e+05 |\n",
      "|    total_cost         | 7.17e+03 |\n",
      "|    total_reward       | 2.86e+05 |\n",
      "|    total_reward_pct   | 57.3     |\n",
      "|    total_trades       | 4025     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -9.98    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "day: 438, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 838550.38\n",
      "total_reward: 338550.38\n",
      "total_cost: 7227.51\n",
      "total_trades: 4009\n",
      "Sharpe: 1.081\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.39e+05 |\n",
      "|    total_cost         | 7.23e+03 |\n",
      "|    total_reward       | 3.39e+05 |\n",
      "|    total_reward_pct   | 67.7     |\n",
      "|    total_trades       | 4009     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 17       |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.559    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.77e+05  |\n",
      "|    total_cost         | 2.48e+03  |\n",
      "|    total_reward       | -1.23e+05 |\n",
      "|    total_reward_pct   | -24.5     |\n",
      "|    total_trades       | 3900      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -20.9     |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.558     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.69e+05 |\n",
      "|    total_cost         | 4.31e+03 |\n",
      "|    total_reward       | 2.69e+05 |\n",
      "|    total_reward_pct   | 53.8     |\n",
      "|    total_trades       | 3950     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 53.3     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 4.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.61e+05 |\n",
      "|    total_cost         | 3.92e+03 |\n",
      "|    total_reward       | 2.61e+05 |\n",
      "|    total_reward_pct   | 52.2     |\n",
      "|    total_trades       | 3917     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.0225   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 40.3     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 3.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.69e+05 |\n",
      "|    total_cost         | 5.58e+03 |\n",
      "|    total_reward       | 3.69e+05 |\n",
      "|    total_reward_pct   | 73.8     |\n",
      "|    total_trades       | 3942     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -10.7    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.147    |\n",
      "------------------------------------\n",
      "day: 438, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 342275.74\n",
      "total_reward: -157724.26\n",
      "total_cost: 2388.41\n",
      "total_trades: 3852\n",
      "Sharpe: -0.210\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+05  |\n",
      "|    total_cost         | 2.39e+03  |\n",
      "|    total_reward       | -1.58e+05 |\n",
      "|    total_reward_pct   | -31.5     |\n",
      "|    total_trades       | 3852      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -35       |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.63e+05  |\n",
      "|    total_cost         | 4.81e+03  |\n",
      "|    total_reward       | 2.63e+05  |\n",
      "|    total_reward_pct   | 52.7      |\n",
      "|    total_trades       | 4002      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 66        |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 5.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.96e+05 |\n",
      "|    total_cost         | 7.69e+03 |\n",
      "|    total_reward       | 1.96e+05 |\n",
      "|    total_reward_pct   | 39.2     |\n",
      "|    total_trades       | 4000     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -3       |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.278    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.54e+05  |\n",
      "|    total_cost         | 3.56e+03  |\n",
      "|    total_reward       | -1.46e+05 |\n",
      "|    total_reward_pct   | -29.1     |\n",
      "|    total_trades       | 3893      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | -1.44     |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.154     |\n",
      "-------------------------------------\n",
      "day: 438, episode: 200\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 362383.13\n",
      "total_reward: -137616.87\n",
      "total_cost: 5716.29\n",
      "total_trades: 3830\n",
      "Sharpe: -0.180\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.62e+05  |\n",
      "|    total_cost         | 5.72e+03  |\n",
      "|    total_reward       | -1.38e+05 |\n",
      "|    total_reward_pct   | -27.5     |\n",
      "|    total_trades       | 3830      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -18.3     |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 1.64      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.66e+05 |\n",
      "|    total_cost         | 5.72e+03 |\n",
      "|    total_reward       | 2.66e+05 |\n",
      "|    total_reward_pct   | 53.1     |\n",
      "|    total_trades       | 3782     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 37.4     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.56e+05 |\n",
      "|    total_cost         | 6.02e+03 |\n",
      "|    total_reward       | 2.56e+05 |\n",
      "|    total_reward_pct   | 51.2     |\n",
      "|    total_trades       | 3783     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 23.3     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.675    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.56e+05  |\n",
      "|    total_cost         | 2.54e+03  |\n",
      "|    total_reward       | -1.44e+05 |\n",
      "|    total_reward_pct   | -28.7     |\n",
      "|    total_trades       | 3725      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | -7.98     |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.235     |\n",
      "-------------------------------------\n",
      "day: 438, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 762003.96\n",
      "total_reward: 262003.96\n",
      "total_cost: 7195.41\n",
      "total_trades: 3876\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.62e+05 |\n",
      "|    total_cost         | 7.2e+03  |\n",
      "|    total_reward       | 2.62e+05 |\n",
      "|    total_reward_pct   | 52.4     |\n",
      "|    total_trades       | 3876     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -48.7    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.39e+05 |\n",
      "|    total_cost         | 7.91e+03 |\n",
      "|    total_reward       | 3.39e+05 |\n",
      "|    total_reward_pct   | 67.8     |\n",
      "|    total_trades       | 4019     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -0.052   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -42.8    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.5e+05  |\n",
      "|    total_cost         | 6.48e+03 |\n",
      "|    total_reward       | 3.5e+05  |\n",
      "|    total_reward_pct   | 70.1     |\n",
      "|    total_trades       | 4065     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0.238    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 12.3     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.319    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.8e+05   |\n",
      "|    total_cost         | 2.76e+03  |\n",
      "|    total_reward       | -1.2e+05  |\n",
      "|    total_reward_pct   | -24       |\n",
      "|    total_trades       | 3954      |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 16.2      |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.608     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.51e+05 |\n",
      "|    total_cost         | 1.92e+03 |\n",
      "|    total_reward       | 5.11e+04 |\n",
      "|    total_reward_pct   | 10.2     |\n",
      "|    total_trades       | 3955     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -0.879   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -6.39    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "day: 438, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 576533.13\n",
      "total_reward: 76533.13\n",
      "total_cost: 3393.03\n",
      "total_trades: 3910\n",
      "Sharpe: 0.430\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.77e+05 |\n",
      "|    total_cost         | 3.39e+03 |\n",
      "|    total_reward       | 7.65e+04 |\n",
      "|    total_reward_pct   | 15.3     |\n",
      "|    total_trades       | 3910     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -3.45    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.49e+05  |\n",
      "|    total_cost         | 1.78e+03  |\n",
      "|    total_reward       | -5.15e+04 |\n",
      "|    total_reward_pct   | -10.3     |\n",
      "|    total_trades       | 3847      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -3.41     |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 0.0721    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.37e+05  |\n",
      "|    total_cost         | 2.59e+03  |\n",
      "|    total_reward       | -6.33e+04 |\n",
      "|    total_reward_pct   | -12.7     |\n",
      "|    total_trades       | 3864      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -7.93     |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 0.0943    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.25e+05 |\n",
      "|    total_cost         | 8.78e+03 |\n",
      "|    total_reward       | 4.25e+05 |\n",
      "|    total_reward_pct   | 85.1     |\n",
      "|    total_trades       | 3934     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | -0.947   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "day: 438, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 344540.43\n",
      "total_reward: -155459.57\n",
      "total_cost: 3670.68\n",
      "total_trades: 3970\n",
      "Sharpe: -0.256\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.45e+05  |\n",
      "|    total_cost         | 3.67e+03  |\n",
      "|    total_reward       | -1.55e+05 |\n",
      "|    total_reward_pct   | -31.1     |\n",
      "|    total_trades       | 3970      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 38.9      |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 4.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.64e+05 |\n",
      "|    total_cost         | 3.82e+03 |\n",
      "|    total_reward       | 2.64e+05 |\n",
      "|    total_reward_pct   | 52.8     |\n",
      "|    total_trades       | 4013     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -2.93    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.835    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.21e+05 |\n",
      "|    total_cost         | 5.65e+03 |\n",
      "|    total_reward       | 3.21e+05 |\n",
      "|    total_reward_pct   | 64.3     |\n",
      "|    total_trades       | 4039     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -8.69    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.167    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.97e+05  |\n",
      "|    total_cost         | 2.79e+03  |\n",
      "|    total_reward       | -2.74e+03 |\n",
      "|    total_reward_pct   | -0.548    |\n",
      "|    total_trades       | 4055      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 72.2      |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 7.54      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.07e+05 |\n",
      "|    total_cost         | 4.31e+03 |\n",
      "|    total_reward       | 1.07e+05 |\n",
      "|    total_reward_pct   | 21.3     |\n",
      "|    total_trades       | 4095     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 7.08     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.533    |\n",
      "------------------------------------\n",
      "day: 438, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 488112.75\n",
      "total_reward: -11887.25\n",
      "total_cost: 1869.78\n",
      "total_trades: 4035\n",
      "Sharpe: 0.137\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.88e+05  |\n",
      "|    total_cost         | 1.87e+03  |\n",
      "|    total_reward       | -1.19e+04 |\n",
      "|    total_reward_pct   | -2.38     |\n",
      "|    total_trades       | 4035      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 29.8      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 1.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.22e+05 |\n",
      "|    total_cost         | 1.29e+04 |\n",
      "|    total_reward       | 2.22e+05 |\n",
      "|    total_reward_pct   | 44.4     |\n",
      "|    total_trades       | 4038     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -55.2    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 4.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.81e+05 |\n",
      "|    total_cost         | 6.71e+03 |\n",
      "|    total_reward       | 1.81e+05 |\n",
      "|    total_reward_pct   | 36.3     |\n",
      "|    total_trades       | 4004     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -34.1    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8e+05    |\n",
      "|    total_cost         | 5.71e+03 |\n",
      "|    total_reward       | 3e+05    |\n",
      "|    total_reward_pct   | 59.9     |\n",
      "|    total_trades       | 4000     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.0021  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -8.94    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.523    |\n",
      "------------------------------------\n",
      "day: 438, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 759657.24\n",
      "total_reward: 259657.24\n",
      "total_cost: 9229.06\n",
      "total_trades: 4007\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.6e+05  |\n",
      "|    total_cost         | 9.23e+03 |\n",
      "|    total_reward       | 2.6e+05  |\n",
      "|    total_reward_pct   | 51.9     |\n",
      "|    total_trades       | 4007     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 6.88     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.155    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.64e+05  |\n",
      "|    total_cost         | 2.14e+03  |\n",
      "|    total_reward       | -3.62e+04 |\n",
      "|    total_reward_pct   | -7.23     |\n",
      "|    total_trades       | 4037      |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -0.373    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | -35.9     |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 1.94      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.31e+05 |\n",
      "|    total_cost         | 8.13e+03 |\n",
      "|    total_reward       | 2.31e+05 |\n",
      "|    total_reward_pct   | 46.2     |\n",
      "|    total_trades       | 4012     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 64       |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 4.8      |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-10-02 to  2020-01-03\n",
      "A2C Sharpe Ratio:  nan\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_1\n",
      "day: 438, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 168662.69\n",
      "total_reward: -331337.31\n",
      "total_cost: 137593.50\n",
      "total_trades: 6113\n",
      "Sharpe: -1.460\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.31e+05  |\n",
      "|    total_cost       | 1.74e+05  |\n",
      "|    total_reward     | -2.69e+05 |\n",
      "|    total_reward_pct | -53.9     |\n",
      "|    total_trades     | 6294      |\n",
      "| time/               |           |\n",
      "|    fps              | 827       |\n",
      "|    iterations       | 1         |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 2048      |\n",
      "-----------------------------------\n",
      "day: 438, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 243468.46\n",
      "total_reward: -256531.54\n",
      "total_cost: 191514.87\n",
      "total_trades: 6219\n",
      "Sharpe: -1.016\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.4e+05     |\n",
      "|    total_cost           | 1.81e+05    |\n",
      "|    total_reward         | -2.6e+05    |\n",
      "|    total_reward_pct     | -52         |\n",
      "|    total_trades         | 6156        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 769         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018224943 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0303      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2           |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 232126.24\n",
      "total_reward: -267873.76\n",
      "total_cost: 208802.85\n",
      "total_trades: 6326\n",
      "Sharpe: -1.861\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+05    |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | -2.44e+05   |\n",
      "|    total_reward_pct     | -48.8       |\n",
      "|    total_trades         | 6061        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 750         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014353174 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0877      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 210527.49\n",
      "total_reward: -289472.51\n",
      "total_cost: 164414.12\n",
      "total_trades: 5993\n",
      "Sharpe: -1.172\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+05    |\n",
      "|    total_cost           | 1.87e+05    |\n",
      "|    total_reward         | -2.76e+05   |\n",
      "|    total_reward_pct     | -55.2       |\n",
      "|    total_trades         | 6242        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 743         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010979507 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 316274.15\n",
      "total_reward: -183725.85\n",
      "total_cost: 232025.71\n",
      "total_trades: 6325\n",
      "Sharpe: -1.198\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.49e+05    |\n",
      "|    total_cost           | 2.82e+05    |\n",
      "|    total_reward         | -1.51e+05   |\n",
      "|    total_reward_pct     | -30.1       |\n",
      "|    total_trades         | 6411        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012190463 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0979     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 255\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 313513.05\n",
      "total_reward: -186486.95\n",
      "total_cost: 197447.65\n",
      "total_trades: 6414\n",
      "Sharpe: -1.215\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.14e+05    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | -1.86e+05   |\n",
      "|    total_reward_pct     | -37.3       |\n",
      "|    total_trades         | 6414        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024791824 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0931      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.438       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 260\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 384306.27\n",
      "total_reward: -115693.73\n",
      "total_cost: 260164.16\n",
      "total_trades: 6435\n",
      "Sharpe: -0.720\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.84e+05    |\n",
      "|    total_cost           | 2.6e+05     |\n",
      "|    total_reward         | -1.16e+05   |\n",
      "|    total_reward_pct     | -23.1       |\n",
      "|    total_trades         | 6435        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016919829 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 265\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 187736.12\n",
      "total_reward: -312263.88\n",
      "total_cost: 145514.08\n",
      "total_trades: 6284\n",
      "Sharpe: -1.276\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+05    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | -3.12e+05   |\n",
      "|    total_reward_pct     | -62.5       |\n",
      "|    total_trades         | 6284        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013380253 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.452       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+05    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | -2.82e+05   |\n",
      "|    total_reward_pct     | -56.4       |\n",
      "|    total_trades         | 6211        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036222 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 270\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 373884.63\n",
      "total_reward: -126115.37\n",
      "total_cost: 259565.28\n",
      "total_trades: 6359\n",
      "Sharpe: -0.760\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+05    |\n",
      "|    total_cost           | 1.6e+05     |\n",
      "|    total_reward         | -3.05e+05   |\n",
      "|    total_reward_pct     | -61.1       |\n",
      "|    total_trades         | 6115        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018244734 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.233       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 275\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 464496.58\n",
      "total_reward: -35503.42\n",
      "total_cost: 274372.03\n",
      "total_trades: 6432\n",
      "Sharpe: 0.006\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.75e+05   |\n",
      "|    total_cost           | 3e+05      |\n",
      "|    total_reward         | -2.54e+04  |\n",
      "|    total_reward_pct     | -5.08      |\n",
      "|    total_trades         | 6600       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 719        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00958449 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.057      |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 1.82       |\n",
      "----------------------------------------\n",
      "day: 438, episode: 280\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 453771.50\n",
      "total_reward: -46228.50\n",
      "total_cost: 232902.15\n",
      "total_trades: 6502\n",
      "Sharpe: -0.213\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.69e+05   |\n",
      "|    total_cost           | 2.49e+05   |\n",
      "|    total_reward         | -3.12e+04  |\n",
      "|    total_reward_pct     | -6.25      |\n",
      "|    total_trades         | 6384       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 719        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01908775 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.0687     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.354      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 1.98       |\n",
      "----------------------------------------\n",
      "day: 438, episode: 285\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 242045.22\n",
      "total_reward: -257954.78\n",
      "total_cost: 151952.94\n",
      "total_trades: 6244\n",
      "Sharpe: -0.992\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.16e+05    |\n",
      "|    total_cost           | 1.86e+05    |\n",
      "|    total_reward         | -1.84e+05   |\n",
      "|    total_reward_pct     | -36.8       |\n",
      "|    total_trades         | 6287        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017621607 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 290\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 437159.18\n",
      "total_reward: -62840.82\n",
      "total_cost: 257426.11\n",
      "total_trades: 6452\n",
      "Sharpe: -0.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+05    |\n",
      "|    total_cost           | 1.98e+05    |\n",
      "|    total_reward         | -2.37e+05   |\n",
      "|    total_reward_pct     | -47.5       |\n",
      "|    total_trades         | 6376        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006005506 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.193       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.95        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 295\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 422457.11\n",
      "total_reward: -77542.89\n",
      "total_cost: 287389.56\n",
      "total_trades: 6452\n",
      "Sharpe: -0.417\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.94e+05    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | -2.06e+05   |\n",
      "|    total_reward_pct     | -41.2       |\n",
      "|    total_trades         | 6306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018802827 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.294       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 300\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 520497.27\n",
      "total_reward: 20497.27\n",
      "total_cost: 308603.71\n",
      "total_trades: 6578\n",
      "Sharpe: 0.211\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.39e+05    |\n",
      "|    total_cost           | 2.5e+05     |\n",
      "|    total_reward         | -6.14e+04   |\n",
      "|    total_reward_pct     | -12.3       |\n",
      "|    total_trades         | 6573        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015371724 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.332       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 305\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 285608.15\n",
      "total_reward: -214391.85\n",
      "total_cost: 176789.30\n",
      "total_trades: 6246\n",
      "Sharpe: -0.900\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.49e+05    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | -5.09e+04   |\n",
      "|    total_reward_pct     | -10.2       |\n",
      "|    total_trades         | 6328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027496487 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.34        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 310\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 265163.30\n",
      "total_reward: -234836.70\n",
      "total_cost: 154398.09\n",
      "total_trades: 6108\n",
      "Sharpe: -0.795\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.54e+05   |\n",
      "|    total_cost           | 2.35e+05   |\n",
      "|    total_reward         | -4.63e+04  |\n",
      "|    total_reward_pct     | -9.26      |\n",
      "|    total_trades         | 6485       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 716        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01718944 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.696      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 2.22       |\n",
      "----------------------------------------\n",
      "day: 438, episode: 315\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 501381.00\n",
      "total_reward: 1381.00\n",
      "total_cost: 273801.09\n",
      "total_trades: 6562\n",
      "Sharpe: 0.094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.84e+05    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | -1.16e+05   |\n",
      "|    total_reward_pct     | -23.3       |\n",
      "|    total_trades         | 6485        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018066417 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.284       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 320\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 518796.80\n",
      "total_reward: 18796.80\n",
      "total_cost: 227423.09\n",
      "total_trades: 6240\n",
      "Sharpe: 0.208\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.93e+05   |\n",
      "|    total_cost           | 2.09e+05   |\n",
      "|    total_reward         | -2.07e+05  |\n",
      "|    total_reward_pct     | -41.4      |\n",
      "|    total_trades         | 6325       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 716        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01987125 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.268      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.344      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 1.26       |\n",
      "----------------------------------------\n",
      "day: 438, episode: 325\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 595974.81\n",
      "total_reward: 95974.81\n",
      "total_cost: 266528.31\n",
      "total_trades: 6551\n",
      "Sharpe: 0.642\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.96e+05   |\n",
      "|    total_cost           | 2.67e+05   |\n",
      "|    total_reward         | 9.6e+04    |\n",
      "|    total_reward_pct     | 19.2       |\n",
      "|    total_trades         | 6551       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 716        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01825612 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.172      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.477      |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 1.71       |\n",
      "----------------------------------------\n",
      "day: 438, episode: 330\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 515130.27\n",
      "total_reward: 15130.27\n",
      "total_cost: 255173.09\n",
      "total_trades: 6509\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.15e+05   |\n",
      "|    total_cost           | 2.55e+05   |\n",
      "|    total_reward         | 1.51e+04   |\n",
      "|    total_reward_pct     | 3.03       |\n",
      "|    total_trades         | 6509       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 716        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01365166 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.161      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.386      |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 1.8        |\n",
      "----------------------------------------\n",
      "day: 438, episode: 335\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 605247.41\n",
      "total_reward: 105247.41\n",
      "total_cost: 291772.88\n",
      "total_trades: 6584\n",
      "Sharpe: 0.520\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.05e+05    |\n",
      "|    total_cost           | 2.92e+05    |\n",
      "|    total_reward         | 1.05e+05    |\n",
      "|    total_reward_pct     | 21          |\n",
      "|    total_trades         | 6584        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014165011 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.72        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.94e+05    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | -5.99e+03   |\n",
      "|    total_reward_pct     | -1.2        |\n",
      "|    total_trades         | 6388        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022659075 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.727       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 340\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 616694.49\n",
      "total_reward: 116694.49\n",
      "total_cost: 257367.95\n",
      "total_trades: 6540\n",
      "Sharpe: 0.641\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+05     |\n",
      "|    total_cost           | 1.49e+05    |\n",
      "|    total_reward         | -1.6e+05    |\n",
      "|    total_reward_pct     | -32.1       |\n",
      "|    total_trades         | 6113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026092535 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.338       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 345\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 449425.31\n",
      "total_reward: -50574.69\n",
      "total_cost: 202783.59\n",
      "total_trades: 6374\n",
      "Sharpe: -0.206\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.2e+05     |\n",
      "|    total_cost           | 2.4e+05     |\n",
      "|    total_reward         | 3.2e+05     |\n",
      "|    total_reward_pct     | 63.9        |\n",
      "|    total_trades         | 6492        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015015561 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.43        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 350\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 326964.58\n",
      "total_reward: -173035.42\n",
      "total_cost: 179632.12\n",
      "total_trades: 6362\n",
      "Sharpe: -0.885\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.87e+05    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 2.87e+05    |\n",
      "|    total_reward_pct     | 57.4        |\n",
      "|    total_trades         | 6554        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028698254 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.835       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 355\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 352283.76\n",
      "total_reward: -147716.24\n",
      "total_cost: 115946.59\n",
      "total_trades: 6041\n",
      "Sharpe: -0.465\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.47e+05    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | 2.47e+05    |\n",
      "|    total_reward_pct     | 49.3        |\n",
      "|    total_trades         | 6424        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024498649 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.875       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 360\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 289361.11\n",
      "total_reward: -210638.89\n",
      "total_cost: 128769.85\n",
      "total_trades: 6206\n",
      "Sharpe: -0.877\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.68e+05    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | -2.32e+05   |\n",
      "|    total_reward_pct     | -46.3       |\n",
      "|    total_trades         | 6309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020431086 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.364       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 365\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 758661.16\n",
      "total_reward: 258661.16\n",
      "total_cost: 213542.11\n",
      "total_trades: 6316\n",
      "Sharpe: 0.952\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.55e+05    |\n",
      "|    total_cost           | 2.37e+05    |\n",
      "|    total_reward         | 2.55e+05    |\n",
      "|    total_reward_pct     | 51.1        |\n",
      "|    total_trades         | 6299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016283609 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.4         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 370\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 537995.32\n",
      "total_reward: 37995.32\n",
      "total_cost: 133354.37\n",
      "total_trades: 6147\n",
      "Sharpe: 0.314\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.2e+05     |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | 1.2e+05     |\n",
      "|    total_reward_pct     | 23.9        |\n",
      "|    total_trades         | 6377        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018016951 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 375\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 615981.15\n",
      "total_reward: 115981.15\n",
      "total_cost: 147075.76\n",
      "total_trades: 6228\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.65e+05    |\n",
      "|    total_cost           | 1.75e+05    |\n",
      "|    total_reward         | 1.65e+05    |\n",
      "|    total_reward_pct     | 33          |\n",
      "|    total_trades         | 6212        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014271825 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.647       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 380\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 377777.17\n",
      "total_reward: -122222.83\n",
      "total_cost: 139467.77\n",
      "total_trades: 6170\n",
      "Sharpe: -0.316\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.85e+05    |\n",
      "|    total_cost           | 1.42e+05    |\n",
      "|    total_reward         | -1.52e+04   |\n",
      "|    total_reward_pct     | -3.05       |\n",
      "|    total_trades         | 6069        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007087444 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.64        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 385\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 902299.22\n",
      "total_reward: 402299.22\n",
      "total_cost: 183140.13\n",
      "total_trades: 6157\n",
      "Sharpe: 1.220\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.34e+05    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 2.34e+05    |\n",
      "|    total_reward_pct     | 46.9        |\n",
      "|    total_trades         | 6336        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009645088 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.663       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 390\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 821818.63\n",
      "total_reward: 321818.63\n",
      "total_cost: 224195.30\n",
      "total_trades: 6289\n",
      "Sharpe: 1.074\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.16e+05     |\n",
      "|    total_cost           | 1.12e+05     |\n",
      "|    total_reward         | -8.37e+04    |\n",
      "|    total_reward_pct     | -16.7        |\n",
      "|    total_trades         | 5997         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114025865 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -28.3        |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "day: 438, episode: 395\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 570923.31\n",
      "total_reward: 70923.31\n",
      "total_cost: 157366.53\n",
      "total_trades: 6064\n",
      "Sharpe: 0.520\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.71e+05   |\n",
      "|    total_cost           | 1.57e+05   |\n",
      "|    total_reward         | 7.09e+04   |\n",
      "|    total_reward_pct     | 14.2       |\n",
      "|    total_trades         | 6064       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 717        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00901268 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.476      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.963      |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 3.69       |\n",
      "----------------------------------------\n",
      "day: 438, episode: 400\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 564268.16\n",
      "total_reward: 64268.16\n",
      "total_cost: 130708.64\n",
      "total_trades: 6203\n",
      "Sharpe: 0.423\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.64e+05    |\n",
      "|    total_cost           | 1.31e+05    |\n",
      "|    total_reward         | 6.43e+04    |\n",
      "|    total_reward_pct     | 12.9        |\n",
      "|    total_trades         | 6203        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014648246 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 405\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 845421.69\n",
      "total_reward: 345421.69\n",
      "total_cost: 188343.65\n",
      "total_trades: 6278\n",
      "Sharpe: 1.247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.45e+05    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 3.45e+05    |\n",
      "|    total_reward_pct     | 69.1        |\n",
      "|    total_trades         | 6278        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025860967 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.08e+05    |\n",
      "|    total_cost           | 1.26e+05    |\n",
      "|    total_reward         | 1.08e+05    |\n",
      "|    total_reward_pct     | 21.6        |\n",
      "|    total_trades         | 6032        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018611565 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.744       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 410\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 819301.73\n",
      "total_reward: 319301.73\n",
      "total_cost: 154683.95\n",
      "total_trades: 6254\n",
      "Sharpe: 1.399\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.75e+05    |\n",
      "|    total_cost           | 1.54e+05    |\n",
      "|    total_reward         | 7.48e+04    |\n",
      "|    total_reward_pct     | 15          |\n",
      "|    total_trades         | 5993        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019799802 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.79        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 415\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 839799.15\n",
      "total_reward: 339799.15\n",
      "total_cost: 188656.08\n",
      "total_trades: 6261\n",
      "Sharpe: 1.241\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.35e+05    |\n",
      "|    total_cost           | 1.46e+05    |\n",
      "|    total_reward         | 1.35e+05    |\n",
      "|    total_reward_pct     | 26.9        |\n",
      "|    total_trades         | 6124        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022967096 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.724       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.27        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 420\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 947688.01\n",
      "total_reward: 447688.01\n",
      "total_cost: 210212.45\n",
      "total_trades: 6373\n",
      "Sharpe: 1.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.65e+05    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 4.65e+05    |\n",
      "|    total_reward_pct     | 92.9        |\n",
      "|    total_trades         | 6225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014363444 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 425\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 813459.58\n",
      "total_reward: 313459.58\n",
      "total_cost: 175560.78\n",
      "total_trades: 6156\n",
      "Sharpe: 1.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.99e+05    |\n",
      "|    total_cost           | 1.63e+05    |\n",
      "|    total_reward         | 2.99e+05    |\n",
      "|    total_reward_pct     | 59.9        |\n",
      "|    total_trades         | 6329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019892018 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 430\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 998002.31\n",
      "total_reward: 498002.31\n",
      "total_cost: 168240.99\n",
      "total_trades: 6117\n",
      "Sharpe: 1.434\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.48e+05    |\n",
      "|    total_cost           | 1.3e+05     |\n",
      "|    total_reward         | 4.8e+04     |\n",
      "|    total_reward_pct     | 9.59        |\n",
      "|    total_trades         | 6129        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014191564 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 435\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1153187.83\n",
      "total_reward: 653187.83\n",
      "total_cost: 203187.14\n",
      "total_trades: 6101\n",
      "Sharpe: 1.837\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.99e+05    |\n",
      "|    total_cost           | 8.71e+04    |\n",
      "|    total_reward         | -531        |\n",
      "|    total_reward_pct     | -0.106      |\n",
      "|    total_trades         | 5925        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016316136 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.32        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 440\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 915073.63\n",
      "total_reward: 415073.63\n",
      "total_cost: 149761.49\n",
      "total_trades: 5922\n",
      "Sharpe: 1.167\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.38e+05    |\n",
      "|    total_cost           | 1.43e+05    |\n",
      "|    total_reward         | 3.38e+05    |\n",
      "|    total_reward_pct     | 67.6        |\n",
      "|    total_trades         | 5986        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016922127 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.778       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.8         |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 445\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 684857.81\n",
      "total_reward: 184857.81\n",
      "total_cost: 174233.20\n",
      "total_trades: 5892\n",
      "Sharpe: 0.691\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+06    |\n",
      "|    total_cost           | 1.66e+05    |\n",
      "|    total_reward         | 5.18e+05    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 6100        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040600143 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 450\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 803597.78\n",
      "total_reward: 303597.78\n",
      "total_cost: 191479.42\n",
      "total_trades: 6226\n",
      "Sharpe: 1.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.31e+05    |\n",
      "|    total_cost           | 1.72e+05    |\n",
      "|    total_reward         | 4.31e+05    |\n",
      "|    total_reward_pct     | 86.2        |\n",
      "|    total_trades         | 6166        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026228253 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 3.87        |\n",
      "-----------------------------------------\n",
      "day: 438, episode: 455\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 969031.84\n",
      "total_reward: 469031.84\n",
      "total_cost: 138609.99\n",
      "total_trades: 6176\n",
      "Sharpe: 1.695\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.93e+05    |\n",
      "|    total_cost           | 1.64e+05    |\n",
      "|    total_reward         | 4.93e+05    |\n",
      "|    total_reward_pct     | 98.6        |\n",
      "|    total_trades         | 6078        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024495026 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 4.57        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-10-02 to  2020-01-03\n",
      "PPO Sharpe Ratio:  nan\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
      "day: 438, episode: 460\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 485012.87\n",
      "total_reward: -14987.13\n",
      "total_cost: 1591.05\n",
      "total_trades: 4769\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.02e+05 |\n",
      "|    total_cost       | 1.33e+03 |\n",
      "|    total_reward     | 1.64e+03 |\n",
      "|    total_reward_pct | 0.327    |\n",
      "|    total_trades     | 4799     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 160      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 1756     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 11.7     |\n",
      "|    critic_loss      | 281      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 1317     |\n",
      "----------------------------------\n",
      "day: 438, episode: 465\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 528430.28\n",
      "total_reward: 28430.28\n",
      "total_cost: 2734.51\n",
      "total_trades: 5361\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.28e+05 |\n",
      "|    total_cost       | 2.73e+03 |\n",
      "|    total_reward     | 2.84e+04 |\n",
      "|    total_reward_pct | 5.69     |\n",
      "|    total_trades     | 5361     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total timesteps  | 3512     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 11       |\n",
      "|    critic_loss      | 119      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3073     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.31e+05 |\n",
      "|    total_cost       | 2.83e+03 |\n",
      "|    total_reward     | 1.31e+05 |\n",
      "|    total_reward_pct | 26.2     |\n",
      "|    total_trades     | 5328     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total timesteps  | 5268     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 8.69     |\n",
      "|    critic_loss      | 67.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4829     |\n",
      "----------------------------------\n",
      "day: 438, episode: 470\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 594157.74\n",
      "total_reward: 94157.74\n",
      "total_cost: 2738.88\n",
      "total_trades: 5309\n",
      "Sharpe: 0.510\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.41e+05 |\n",
      "|    total_cost       | 2.5e+03  |\n",
      "|    total_reward     | 1.41e+05 |\n",
      "|    total_reward_pct | 28.3     |\n",
      "|    total_trades     | 5394     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 135      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total timesteps  | 7024     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 6.84     |\n",
      "|    critic_loss      | 19.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6585     |\n",
      "----------------------------------\n",
      "day: 438, episode: 475\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 512909.03\n",
      "total_reward: 12909.03\n",
      "total_cost: 2097.92\n",
      "total_trades: 5523\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.85e+05  |\n",
      "|    total_cost       | 1.73e+03  |\n",
      "|    total_reward     | -1.46e+04 |\n",
      "|    total_reward_pct | -2.91     |\n",
      "|    total_trades     | 5553      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 134       |\n",
      "|    time_elapsed     | 65        |\n",
      "|    total timesteps  | 8780      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 5.3       |\n",
      "|    critic_loss      | 89.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 8341      |\n",
      "-----------------------------------\n",
      "day: 438, episode: 480\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 574477.50\n",
      "total_reward: 74477.50\n",
      "total_cost: 2796.67\n",
      "total_trades: 5562\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.06e+05 |\n",
      "|    total_cost       | 1.71e+03 |\n",
      "|    total_reward     | 5.55e+03 |\n",
      "|    total_reward_pct | 1.11     |\n",
      "|    total_trades     | 5558     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 133      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total timesteps  | 10536    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.93     |\n",
      "|    critic_loss      | 11.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 10097    |\n",
      "----------------------------------\n",
      "day: 438, episode: 485\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 417786.54\n",
      "total_reward: -82213.46\n",
      "total_cost: 2356.69\n",
      "total_trades: 5616\n",
      "Sharpe: -0.206\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.18e+05  |\n",
      "|    total_cost       | 2.36e+03  |\n",
      "|    total_reward     | -8.22e+04 |\n",
      "|    total_reward_pct | -16.4     |\n",
      "|    total_trades     | 5616      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 92        |\n",
      "|    total timesteps  | 12292     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.96      |\n",
      "|    critic_loss      | 30.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 11853     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.16e+05 |\n",
      "|    total_cost       | 1.98e+03 |\n",
      "|    total_reward     | 1.16e+05 |\n",
      "|    total_reward_pct | 23.1     |\n",
      "|    total_trades     | 5588     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 132      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total timesteps  | 14048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.99     |\n",
      "|    critic_loss      | 7.25     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13609    |\n",
      "----------------------------------\n",
      "day: 438, episode: 490\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 446819.11\n",
      "total_reward: -53180.89\n",
      "total_cost: 3075.86\n",
      "total_trades: 5616\n",
      "Sharpe: -0.087\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.06e+05 |\n",
      "|    total_cost       | 1.57e+03 |\n",
      "|    total_reward     | 6.35e+03 |\n",
      "|    total_reward_pct | 1.27     |\n",
      "|    total_trades     | 5598     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total timesteps  | 15804    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.09     |\n",
      "|    critic_loss      | 5.58     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15365    |\n",
      "----------------------------------\n",
      "day: 438, episode: 495\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 462090.22\n",
      "total_reward: -37909.78\n",
      "total_cost: 2257.00\n",
      "total_trades: 5608\n",
      "Sharpe: 0.016\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.65e+05  |\n",
      "|    total_cost       | 3.94e+03  |\n",
      "|    total_reward     | -3.53e+04 |\n",
      "|    total_reward_pct | -7.06     |\n",
      "|    total_trades     | 5592      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 133       |\n",
      "|    total timesteps  | 17560     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.645     |\n",
      "|    critic_loss      | 4.07      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17121     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 500\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 567952.32\n",
      "total_reward: 67952.32\n",
      "total_cost: 2530.96\n",
      "total_trades: 5307\n",
      "Sharpe: 0.420\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.49e+05 |\n",
      "|    total_cost       | 3.23e+03 |\n",
      "|    total_reward     | 4.93e+04 |\n",
      "|    total_reward_pct | 9.85     |\n",
      "|    total_trades     | 5301     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total timesteps  | 19316    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.0788   |\n",
      "|    critic_loss      | 13.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18877    |\n",
      "----------------------------------\n",
      "day: 438, episode: 505\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 539974.80\n",
      "total_reward: 39974.80\n",
      "total_cost: 4218.82\n",
      "total_trades: 5297\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.4e+05  |\n",
      "|    total_cost       | 4.22e+03 |\n",
      "|    total_reward     | 4e+04    |\n",
      "|    total_reward_pct | 7.99     |\n",
      "|    total_trades     | 5297     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total timesteps  | 21072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.324   |\n",
      "|    critic_loss      | 3.18     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 20633    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.28e+05 |\n",
      "|    total_cost       | 1.95e+03 |\n",
      "|    total_reward     | 2.78e+04 |\n",
      "|    total_reward_pct | 5.56     |\n",
      "|    total_trades     | 5277     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total timesteps  | 22828    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.795   |\n",
      "|    critic_loss      | 13.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 22389    |\n",
      "----------------------------------\n",
      "day: 438, episode: 510\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 468725.29\n",
      "total_reward: -31274.71\n",
      "total_cost: 1413.11\n",
      "total_trades: 5267\n",
      "Sharpe: 0.068\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.07e+05 |\n",
      "|    total_cost       | 1.02e+03 |\n",
      "|    total_reward     | 6.63e+03 |\n",
      "|    total_reward_pct | 1.33     |\n",
      "|    total_trades     | 5270     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total timesteps  | 24584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.22    |\n",
      "|    critic_loss      | 8.73     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24145    |\n",
      "----------------------------------\n",
      "day: 438, episode: 515\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 610016.09\n",
      "total_reward: 110016.09\n",
      "total_cost: 1984.14\n",
      "total_trades: 5260\n",
      "Sharpe: 0.540\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 1.91e+03  |\n",
      "|    total_reward     | -3.27e+03 |\n",
      "|    total_reward_pct | -0.654    |\n",
      "|    total_trades     | 5240      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 201       |\n",
      "|    total timesteps  | 26340     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.46     |\n",
      "|    critic_loss      | 3.13      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 25901     |\n",
      "-----------------------------------\n",
      "day: 438, episode: 520\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499052.34\n",
      "total_reward: -947.66\n",
      "total_cost: 948.19\n",
      "total_trades: 5160\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.09e+05 |\n",
      "|    total_cost       | 2.01e+03 |\n",
      "|    total_reward     | 1.09e+05 |\n",
      "|    total_reward_pct | 21.8     |\n",
      "|    total_trades     | 5137     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total timesteps  | 28096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.7     |\n",
      "|    critic_loss      | 61.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27657    |\n",
      "----------------------------------\n",
      "day: 438, episode: 525\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 598225.63\n",
      "total_reward: 98225.63\n",
      "total_cost: 2600.67\n",
      "total_trades: 5119\n",
      "Sharpe: 0.521\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.98e+05 |\n",
      "|    total_cost       | 2.6e+03  |\n",
      "|    total_reward     | 9.82e+04 |\n",
      "|    total_reward_pct | 19.6     |\n",
      "|    total_trades     | 5119     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total timesteps  | 29852    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.87    |\n",
      "|    critic_loss      | 4.43     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29413    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.65e+05 |\n",
      "|    total_cost       | 2.6e+03  |\n",
      "|    total_reward     | 6.54e+04 |\n",
      "|    total_reward_pct | 13.1     |\n",
      "|    total_trades     | 5047     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total timesteps  | 31608    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.08    |\n",
      "|    critic_loss      | 37.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31169    |\n",
      "----------------------------------\n",
      "day: 438, episode: 530\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 520320.11\n",
      "total_reward: 20320.11\n",
      "total_cost: 3204.41\n",
      "total_trades: 5028\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.63e+05 |\n",
      "|    total_cost       | 2.66e+03 |\n",
      "|    total_reward     | 6.34e+04 |\n",
      "|    total_reward_pct | 12.7     |\n",
      "|    total_trades     | 5054     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total timesteps  | 33364    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.26    |\n",
      "|    critic_loss      | 5.38     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32925    |\n",
      "----------------------------------\n",
      "day: 438, episode: 535\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499721.22\n",
      "total_reward: -278.78\n",
      "total_cost: 1058.36\n",
      "total_trades: 4978\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.07e+05 |\n",
      "|    total_cost       | 2.66e+03 |\n",
      "|    total_reward     | 1.07e+05 |\n",
      "|    total_reward_pct | 21.3     |\n",
      "|    total_trades     | 4977     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total timesteps  | 35120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.46    |\n",
      "|    critic_loss      | 1.69     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34681    |\n",
      "----------------------------------\n",
      "day: 438, episode: 540\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 528622.45\n",
      "total_reward: 28622.45\n",
      "total_cost: 1893.69\n",
      "total_trades: 4993\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.23e+05 |\n",
      "|    total_cost       | 1.92e+03 |\n",
      "|    total_reward     | 2.34e+04 |\n",
      "|    total_reward_pct | 4.67     |\n",
      "|    total_trades     | 5313     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total timesteps  | 36876    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.56    |\n",
      "|    critic_loss      | 6.15     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 36437    |\n",
      "----------------------------------\n",
      "day: 438, episode: 545\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 485754.97\n",
      "total_reward: -14245.03\n",
      "total_cost: 2742.73\n",
      "total_trades: 5300\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.86e+05  |\n",
      "|    total_cost       | 2.74e+03  |\n",
      "|    total_reward     | -1.42e+04 |\n",
      "|    total_reward_pct | -2.85     |\n",
      "|    total_trades     | 5300      |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 296       |\n",
      "|    total timesteps  | 38632     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.77     |\n",
      "|    critic_loss      | 2.06      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 38193     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.28e+05 |\n",
      "|    total_cost       | 1.59e+03 |\n",
      "|    total_reward     | 2.84e+04 |\n",
      "|    total_reward_pct | 5.67     |\n",
      "|    total_trades     | 5278     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total timesteps  | 40388    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.92    |\n",
      "|    critic_loss      | 6.15     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39949    |\n",
      "----------------------------------\n",
      "day: 438, episode: 550\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 521828.64\n",
      "total_reward: 21828.64\n",
      "total_cost: 1549.06\n",
      "total_trades: 5295\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.06e+06 |\n",
      "|    total_cost       | 4.09e+03 |\n",
      "|    total_reward     | 5.59e+05 |\n",
      "|    total_reward_pct | 112      |\n",
      "|    total_trades     | 5305     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total timesteps  | 42144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.01    |\n",
      "|    critic_loss      | 3.45     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41705    |\n",
      "----------------------------------\n",
      "day: 438, episode: 555\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1010179.84\n",
      "total_reward: 510179.84\n",
      "total_cost: 3993.67\n",
      "total_trades: 5311\n",
      "Sharpe: 1.461\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.14e+05 |\n",
      "|    total_cost       | 2.05e+03 |\n",
      "|    total_reward     | 1.14e+05 |\n",
      "|    total_reward_pct | 22.7     |\n",
      "|    total_trades     | 5294     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total timesteps  | 43900    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.16    |\n",
      "|    critic_loss      | 46.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43461    |\n",
      "----------------------------------\n",
      "day: 438, episode: 560\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 606190.54\n",
      "total_reward: 106190.54\n",
      "total_cost: 1902.20\n",
      "total_trades: 5291\n",
      "Sharpe: 0.529\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.08e+05 |\n",
      "|    total_cost       | 2.61e+03 |\n",
      "|    total_reward     | 1.08e+05 |\n",
      "|    total_reward_pct | 21.7     |\n",
      "|    total_trades     | 5306     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total timesteps  | 45656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.26    |\n",
      "|    critic_loss      | 4.11     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45217    |\n",
      "----------------------------------\n",
      "day: 438, episode: 565\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 505155.04\n",
      "total_reward: 5155.04\n",
      "total_cost: 2082.78\n",
      "total_trades: 5298\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.05e+05 |\n",
      "|    total_cost       | 2.08e+03 |\n",
      "|    total_reward     | 5.16e+03 |\n",
      "|    total_reward_pct | 1.03     |\n",
      "|    total_trades     | 5298     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total timesteps  | 47412    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.39    |\n",
      "|    critic_loss      | 5.25     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46973    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6e+05    |\n",
      "|    total_cost       | 1.91e+03 |\n",
      "|    total_reward     | 9.97e+04 |\n",
      "|    total_reward_pct | 19.9     |\n",
      "|    total_trades     | 5294     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 378      |\n",
      "|    total timesteps  | 49168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.48    |\n",
      "|    critic_loss      | 3.17     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 48729    |\n",
      "----------------------------------\n",
      "day: 438, episode: 570\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 621928.33\n",
      "total_reward: 121928.33\n",
      "total_cost: 2221.01\n",
      "total_trades: 5303\n",
      "Sharpe: 0.604\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-02 to  2020-01-03\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-01-03\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_315_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.75e+05 |\n",
      "|    total_cost       | 1.35e+03 |\n",
      "|    total_reward     | -2.5e+04 |\n",
      "|    total_reward_pct | -5       |\n",
      "|    total_trades     | 5568     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 165      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 2008     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -326     |\n",
      "|    critic_loss      | 1.27e+04 |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 1506     |\n",
      "----------------------------------\n",
      "day: 501, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498191.48\n",
      "total_reward: -1808.52\n",
      "total_cost: 1259.83\n",
      "total_trades: 5618\n",
      "Sharpe: 0.305\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.15e+05 |\n",
      "|    total_cost       | 1.49e+03 |\n",
      "|    total_reward     | 1.5e+04  |\n",
      "|    total_reward_pct | 3        |\n",
      "|    total_trades     | 5686     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total timesteps  | 4016     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -285     |\n",
      "|    critic_loss      | 4.39e+03 |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3514     |\n",
      "----------------------------------\n",
      "day: 501, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 519405.04\n",
      "total_reward: 19405.04\n",
      "total_cost: 1248.67\n",
      "total_trades: 5683\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.82e+05 |\n",
      "|    total_cost       | 1.94e+03 |\n",
      "|    total_reward     | 8.18e+04 |\n",
      "|    total_reward_pct | 16.4     |\n",
      "|    total_trades     | 5278     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total timesteps  | 6024     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -248     |\n",
      "|    critic_loss      | 2.01e+03 |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 5522     |\n",
      "----------------------------------\n",
      "day: 501, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 494504.69\n",
      "total_reward: -5495.31\n",
      "total_cost: 959.93\n",
      "total_trades: 5317\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.41e+05 |\n",
      "|    total_cost       | 1.44e+03 |\n",
      "|    total_reward     | 4.1e+04  |\n",
      "|    total_reward_pct | 8.2      |\n",
      "|    total_trades     | 5321     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 136      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total timesteps  | 8032     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -219     |\n",
      "|    critic_loss      | 788      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7530     |\n",
      "----------------------------------\n",
      "day: 501, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 507735.03\n",
      "total_reward: 7735.03\n",
      "total_cost: 1417.99\n",
      "total_trades: 5449\n",
      "Sharpe: 0.278\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.08e+05 |\n",
      "|    total_cost       | 1.42e+03 |\n",
      "|    total_reward     | 7.74e+03 |\n",
      "|    total_reward_pct | 1.55     |\n",
      "|    total_trades     | 5449     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 134      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total timesteps  | 10040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -196     |\n",
      "|    critic_loss      | 368      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 9538     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.39e+05 |\n",
      "|    total_cost       | 1.84e+03 |\n",
      "|    total_reward     | 3.86e+04 |\n",
      "|    total_reward_pct | 7.71     |\n",
      "|    total_trades     | 5469     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 133      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total timesteps  | 12048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -174     |\n",
      "|    critic_loss      | 159      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11546    |\n",
      "----------------------------------\n",
      "day: 501, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 465058.50\n",
      "total_reward: -34941.50\n",
      "total_cost: 1749.61\n",
      "total_trades: 5467\n",
      "Sharpe: 0.095\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.95e+05  |\n",
      "|    total_cost       | 989       |\n",
      "|    total_reward     | -5.17e+03 |\n",
      "|    total_reward_pct | -1.03     |\n",
      "|    total_trades     | 5467      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 133       |\n",
      "|    time_elapsed     | 105       |\n",
      "|    total timesteps  | 14056     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -157      |\n",
      "|    critic_loss      | 108       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 13554     |\n",
      "-----------------------------------\n",
      "day: 501, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 551644.48\n",
      "total_reward: 51644.48\n",
      "total_cost: 1368.71\n",
      "total_trades: 5469\n",
      "Sharpe: 0.397\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.9e+05   |\n",
      "|    total_cost       | 1.33e+03  |\n",
      "|    total_reward     | -1.04e+04 |\n",
      "|    total_reward_pct | -2.08     |\n",
      "|    total_trades     | 5470      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 120       |\n",
      "|    total timesteps  | 16064     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -140      |\n",
      "|    critic_loss      | 53        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 15562     |\n",
      "-----------------------------------\n",
      "day: 501, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 468434.96\n",
      "total_reward: -31565.04\n",
      "total_cost: 1411.95\n",
      "total_trades: 5471\n",
      "Sharpe: 0.158\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.92e+05  |\n",
      "|    total_cost       | 1.74e+03  |\n",
      "|    total_reward     | -7.83e+03 |\n",
      "|    total_reward_pct | -1.57     |\n",
      "|    total_trades     | 5472      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 136       |\n",
      "|    total timesteps  | 18072     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -127      |\n",
      "|    critic_loss      | 36.4      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17570     |\n",
      "-----------------------------------\n",
      "day: 501, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 459373.03\n",
      "total_reward: -40626.97\n",
      "total_cost: 1514.39\n",
      "total_trades: 5470\n",
      "Sharpe: 0.122\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.59e+05  |\n",
      "|    total_cost       | 1.51e+03  |\n",
      "|    total_reward     | -4.06e+04 |\n",
      "|    total_reward_pct | -8.13     |\n",
      "|    total_trades     | 5470      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 152       |\n",
      "|    total timesteps  | 20080     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -113      |\n",
      "|    critic_loss      | 35.7      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 19578     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.6e+05  |\n",
      "|    total_cost       | 1.54e+03 |\n",
      "|    total_reward     | -4e+04   |\n",
      "|    total_reward_pct | -7.99    |\n",
      "|    total_trades     | 5471     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total timesteps  | 22088    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -102     |\n",
      "|    critic_loss      | 21.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 21586    |\n",
      "----------------------------------\n",
      "day: 501, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 529650.14\n",
      "total_reward: 29650.14\n",
      "total_cost: 1909.73\n",
      "total_trades: 5471\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.16e+05 |\n",
      "|    total_cost       | 2.04e+03 |\n",
      "|    total_reward     | 1.58e+04 |\n",
      "|    total_reward_pct | 3.16     |\n",
      "|    total_trades     | 5474     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total timesteps  | 24096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -91.1    |\n",
      "|    critic_loss      | 34.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 23594    |\n",
      "----------------------------------\n",
      "day: 501, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 530326.97\n",
      "total_reward: 30326.97\n",
      "total_cost: 1352.48\n",
      "total_trades: 5472\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.91e+05  |\n",
      "|    total_cost       | 1.55e+03  |\n",
      "|    total_reward     | -9.46e+03 |\n",
      "|    total_reward_pct | -1.89     |\n",
      "|    total_trades     | 5473      |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 198       |\n",
      "|    total timesteps  | 26104     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -82.1     |\n",
      "|    critic_loss      | 13        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 25602     |\n",
      "-----------------------------------\n",
      "day: 501, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 541771.14\n",
      "total_reward: 41771.14\n",
      "total_cost: 1635.21\n",
      "total_trades: 5473\n",
      "Sharpe: 0.351\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.75e+05  |\n",
      "|    total_cost       | 1.75e+03  |\n",
      "|    total_reward     | -2.54e+04 |\n",
      "|    total_reward_pct | -5.09     |\n",
      "|    total_trades     | 5473      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 214       |\n",
      "|    total timesteps  | 28112     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -73.8     |\n",
      "|    critic_loss      | 9.61      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 27610     |\n",
      "-----------------------------------\n",
      "day: 501, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 449460.23\n",
      "total_reward: -50539.77\n",
      "total_cost: 1388.94\n",
      "total_trades: 5472\n",
      "Sharpe: 0.123\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.49e+05  |\n",
      "|    total_cost       | 1.39e+03  |\n",
      "|    total_reward     | -5.05e+04 |\n",
      "|    total_reward_pct | -10.1     |\n",
      "|    total_trades     | 5472      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 229       |\n",
      "|    total timesteps  | 30120     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -66.3     |\n",
      "|    critic_loss      | 13.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 29618     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.08e+05 |\n",
      "|    total_cost       | 1.99e+03 |\n",
      "|    total_reward     | 8.18e+03 |\n",
      "|    total_reward_pct | 1.64     |\n",
      "|    total_trades     | 5473     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total timesteps  | 32128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -59.6    |\n",
      "|    critic_loss      | 8.87     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31626    |\n",
      "----------------------------------\n",
      "day: 501, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 495097.13\n",
      "total_reward: -4902.87\n",
      "total_cost: 973.46\n",
      "total_trades: 5470\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.05e+05 |\n",
      "|    total_cost       | 1.42e+03 |\n",
      "|    total_reward     | 4.65e+03 |\n",
      "|    total_reward_pct | 0.93     |\n",
      "|    total_trades     | 5471     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total timesteps  | 34136    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -53.3    |\n",
      "|    critic_loss      | 23.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33634    |\n",
      "----------------------------------\n",
      "day: 501, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 514950.82\n",
      "total_reward: 14950.82\n",
      "total_cost: 1754.57\n",
      "total_trades: 5473\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.96e+05  |\n",
      "|    total_cost       | 970       |\n",
      "|    total_reward     | -4.37e+03 |\n",
      "|    total_reward_pct | -0.874    |\n",
      "|    total_trades     | 5470      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 276       |\n",
      "|    total timesteps  | 36144     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -47.7     |\n",
      "|    critic_loss      | 4.21      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 35642     |\n",
      "-----------------------------------\n",
      "day: 501, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 485650.48\n",
      "total_reward: -14349.52\n",
      "total_cost: 1116.53\n",
      "total_trades: 5470\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.18e+05 |\n",
      "|    total_cost       | 1.97e+03 |\n",
      "|    total_reward     | 1.84e+04 |\n",
      "|    total_reward_pct | 3.68     |\n",
      "|    total_trades     | 5471     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total timesteps  | 38152    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -42.9    |\n",
      "|    critic_loss      | 15.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37650    |\n",
      "----------------------------------\n",
      "day: 501, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 448385.99\n",
      "total_reward: -51614.01\n",
      "total_cost: 1425.71\n",
      "total_trades: 5472\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.48e+05  |\n",
      "|    total_cost       | 1.43e+03  |\n",
      "|    total_reward     | -5.16e+04 |\n",
      "|    total_reward_pct | -10.3     |\n",
      "|    total_trades     | 5472      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 307       |\n",
      "|    total timesteps  | 40160     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -38.8     |\n",
      "|    critic_loss      | 5.92      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 39658     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.3e+05  |\n",
      "|    total_cost       | 1.8e+03  |\n",
      "|    total_reward     | 3.03e+04 |\n",
      "|    total_reward_pct | 6.06     |\n",
      "|    total_trades     | 5473     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total timesteps  | 42168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -34.9    |\n",
      "|    critic_loss      | 12.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41666    |\n",
      "----------------------------------\n",
      "day: 501, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 461865.95\n",
      "total_reward: -38134.05\n",
      "total_cost: 1411.19\n",
      "total_trades: 5471\n",
      "Sharpe: 0.134\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.22e+03 |\n",
      "|    total_reward     | -286     |\n",
      "|    total_reward_pct | -0.0572  |\n",
      "|    total_trades     | 5906     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total timesteps  | 44176    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -31.6    |\n",
      "|    critic_loss      | 2.73     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43674    |\n",
      "----------------------------------\n",
      "day: 501, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 548835.50\n",
      "total_reward: 48835.50\n",
      "total_cost: 2045.49\n",
      "total_trades: 5895\n",
      "Sharpe: 0.349\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.04e+05 |\n",
      "|    total_cost       | 987      |\n",
      "|    total_reward     | 3.98e+03 |\n",
      "|    total_reward_pct | 0.795    |\n",
      "|    total_trades     | 5894     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total timesteps  | 46184    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -28.6    |\n",
      "|    critic_loss      | 2.05     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45682    |\n",
      "----------------------------------\n",
      "day: 501, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 583231.64\n",
      "total_reward: 83231.64\n",
      "total_cost: 1670.45\n",
      "total_trades: 5898\n",
      "Sharpe: 0.448\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.44e+05 |\n",
      "|    total_cost       | 2.05e+03 |\n",
      "|    total_reward     | 4.4e+04  |\n",
      "|    total_reward_pct | 8.8      |\n",
      "|    total_trades     | 5904     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 369      |\n",
      "|    total timesteps  | 48192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -25.9    |\n",
      "|    critic_loss      | 12.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47690    |\n",
      "----------------------------------\n",
      "day: 501, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 654631.73\n",
      "total_reward: 154631.73\n",
      "total_cost: 2780.22\n",
      "total_trades: 5557\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.55e+05 |\n",
      "|    total_cost       | 2.78e+03 |\n",
      "|    total_reward     | 1.55e+05 |\n",
      "|    total_reward_pct | 30.9     |\n",
      "|    total_trades     | 5557     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 385      |\n",
      "|    total timesteps  | 50200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -23.8    |\n",
      "|    critic_loss      | 8.16     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49698    |\n",
      "----------------------------------\n",
      "======Trading from:  2020-01-03 to  2020-04-06\n",
      "============================================\n",
      "15.300228230562777\n",
      "turbulence_threshold:  0.0\n",
      "======Model training from:  2000-01-01 to  2020-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -0.372   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 7.08     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.163    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.55e+05 |\n",
      "|    total_cost         | 2.02e+05 |\n",
      "|    total_reward       | 1.55e+05 |\n",
      "|    total_reward_pct   | 31       |\n",
      "|    total_trades       | 7234     |\n",
      "| time/                 |          |\n",
      "|    fps                | 548      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | 0.029    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -8.81    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.89e+05  |\n",
      "|    total_cost         | 9.94e+04  |\n",
      "|    total_reward       | -2.11e+05 |\n",
      "|    total_reward_pct   | -42.2     |\n",
      "|    total_trades       | 6685      |\n",
      "| time/                 |           |\n",
      "|    fps                | 543       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 15.3      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.368     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.62e+05  |\n",
      "|    total_cost         | 6.46e+04  |\n",
      "|    total_reward       | -2.38e+05 |\n",
      "|    total_reward_pct   | -47.5     |\n",
      "|    total_trades       | 6360      |\n",
      "| time/                 |           |\n",
      "|    fps                | 545       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.054    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 8.8       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.45e+05  |\n",
      "|    total_cost         | 3.25e+04  |\n",
      "|    total_reward       | -2.55e+05 |\n",
      "|    total_reward_pct   | -50.9     |\n",
      "|    total_trades       | 5773      |\n",
      "| time/                 |           |\n",
      "|    fps                | 546       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | 0.624     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 13.1      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.292     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 373119.42\n",
      "total_reward: -126880.58\n",
      "total_cost: 47336.42\n",
      "total_trades: 6095\n",
      "Sharpe: -0.245\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.73e+05  |\n",
      "|    total_cost         | 4.73e+04  |\n",
      "|    total_reward       | -1.27e+05 |\n",
      "|    total_reward_pct   | -25.4     |\n",
      "|    total_trades       | 6095      |\n",
      "| time/                 |           |\n",
      "|    fps                | 548       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -2.47     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 4.57      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.399     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.81e+05  |\n",
      "|    total_cost         | 4.56e+04  |\n",
      "|    total_reward       | -1.19e+05 |\n",
      "|    total_reward_pct   | -23.7     |\n",
      "|    total_trades       | 5752      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -1.47     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -23.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.863     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.26e+05  |\n",
      "|    total_cost         | 2.2e+04   |\n",
      "|    total_reward       | -1.74e+05 |\n",
      "|    total_reward_pct   | -34.8     |\n",
      "|    total_trades       | 5590      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 19.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.696     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.75e+05  |\n",
      "|    total_cost         | 2.32e+04  |\n",
      "|    total_reward       | -1.25e+05 |\n",
      "|    total_reward_pct   | -25       |\n",
      "|    total_trades       | 5763      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | -2.24e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -8.39     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.348     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.59e+05 |\n",
      "|    total_cost         | 2.83e+04 |\n",
      "|    total_reward       | 5.85e+04 |\n",
      "|    total_reward_pct   | 11.7     |\n",
      "|    total_trades       | 5705     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.187    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -13.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.319    |\n",
      "------------------------------------\n",
      "day: 501, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 392051.01\n",
      "total_reward: -107948.99\n",
      "total_cost: 29139.38\n",
      "total_trades: 5466\n",
      "Sharpe: -0.078\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.92e+05  |\n",
      "|    total_cost         | 2.91e+04  |\n",
      "|    total_reward       | -1.08e+05 |\n",
      "|    total_reward_pct   | -21.6     |\n",
      "|    total_trades       | 5466      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0.0967    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 2.12      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.0788    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.24e+05  |\n",
      "|    total_cost         | 1.71e+04  |\n",
      "|    total_reward       | -1.76e+05 |\n",
      "|    total_reward_pct   | -35.1     |\n",
      "|    total_trades       | 5113      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -0.508    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.496     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.6e+05   |\n",
      "|    total_cost         | 1.44e+04  |\n",
      "|    total_reward       | -4.02e+04 |\n",
      "|    total_reward_pct   | -8.04     |\n",
      "|    total_trades       | 4994      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | -0.176    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -9.42     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.178     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.91e+05  |\n",
      "|    total_cost         | 1.4e+04   |\n",
      "|    total_reward       | -1.09e+05 |\n",
      "|    total_reward_pct   | -21.8     |\n",
      "|    total_trades       | 4861      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | -0.0347   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -14.4     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.467     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.2e+05  |\n",
      "|    total_cost         | 1.26e+04 |\n",
      "|    total_reward       | 1.98e+04 |\n",
      "|    total_reward_pct   | 3.96     |\n",
      "|    total_trades       | 4766     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.299    |\n",
      "------------------------------------\n",
      "day: 501, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 408142.66\n",
      "total_reward: -91857.34\n",
      "total_cost: 8952.74\n",
      "total_trades: 4586\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.08e+05  |\n",
      "|    total_cost         | 8.95e+03  |\n",
      "|    total_reward       | -9.19e+04 |\n",
      "|    total_reward_pct   | -18.4     |\n",
      "|    total_trades       | 4586      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0.000619  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 25.2      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.82      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.32e+05 |\n",
      "|    total_cost         | 1.2e+04  |\n",
      "|    total_reward       | 3.22e+04 |\n",
      "|    total_reward_pct   | 6.44     |\n",
      "|    total_trades       | 4807     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.0713   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 85.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.75e+05 |\n",
      "|    total_cost         | 1.53e+04 |\n",
      "|    total_reward       | 2.75e+05 |\n",
      "|    total_reward_pct   | 55       |\n",
      "|    total_trades       | 4659     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.028   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 24.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.74e+05  |\n",
      "|    total_cost         | 1.21e+04  |\n",
      "|    total_reward       | -2.64e+04 |\n",
      "|    total_reward_pct   | -5.29     |\n",
      "|    total_trades       | 4871      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | 0.128     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 23.5      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.792     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.74e+05  |\n",
      "|    total_cost         | 1.41e+04  |\n",
      "|    total_reward       | -1.26e+05 |\n",
      "|    total_reward_pct   | -25.2     |\n",
      "|    total_trades       | 4750      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -0.038    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -1.03     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0162    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 365633.59\n",
      "total_reward: -134366.41\n",
      "total_cost: 18185.30\n",
      "total_trades: 4837\n",
      "Sharpe: -0.160\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.66e+05  |\n",
      "|    total_cost         | 1.82e+04  |\n",
      "|    total_reward       | -1.34e+05 |\n",
      "|    total_reward_pct   | -26.9     |\n",
      "|    total_trades       | 4837      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -0.146    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.17      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.04e+05  |\n",
      "|    total_cost         | 1.73e+04  |\n",
      "|    total_reward       | -9.56e+04 |\n",
      "|    total_reward_pct   | -19.1     |\n",
      "|    total_trades       | 4765      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -0.0971   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 7.4       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.155     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.59e+05  |\n",
      "|    total_cost         | 1.48e+04  |\n",
      "|    total_reward       | -1.41e+05 |\n",
      "|    total_reward_pct   | -28.3     |\n",
      "|    total_trades       | 4723      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | 0.427     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 15.4      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.401     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.97e+05  |\n",
      "|    total_cost         | 1.76e+04  |\n",
      "|    total_reward       | -1.03e+05 |\n",
      "|    total_reward_pct   | -20.6     |\n",
      "|    total_trades       | 4775      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | 0.0185    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 5.58      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0557    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.82e+05  |\n",
      "|    total_cost         | 1.71e+04  |\n",
      "|    total_reward       | -1.82e+04 |\n",
      "|    total_reward_pct   | -3.65     |\n",
      "|    total_trades       | 4727      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 4.31      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0794    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 309838.44\n",
      "total_reward: -190161.56\n",
      "total_cost: 12140.37\n",
      "total_trades: 4531\n",
      "Sharpe: -0.283\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+05  |\n",
      "|    total_cost         | 1.21e+04 |\n",
      "|    total_reward       | -1.9e+05 |\n",
      "|    total_reward_pct   | -38      |\n",
      "|    total_trades       | 4531     |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.703    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.335    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.93e+05  |\n",
      "|    total_cost         | 1.53e+04  |\n",
      "|    total_reward       | -7.38e+03 |\n",
      "|    total_reward_pct   | -1.48     |\n",
      "|    total_trades       | 4498      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | 0.707     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -13.7     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.385     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.89e+05 |\n",
      "|    total_cost         | 1.8e+04  |\n",
      "|    total_reward       | 1.89e+05 |\n",
      "|    total_reward_pct   | 37.9     |\n",
      "|    total_trades       | 4453     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 5.8      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0501   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.67e+05  |\n",
      "|    total_cost         | 7.85e+03  |\n",
      "|    total_reward       | -1.33e+05 |\n",
      "|    total_reward_pct   | -26.5     |\n",
      "|    total_trades       | 4434      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -0.616    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -4.96     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.0439    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.2e+05  |\n",
      "|    total_cost         | 2.11e+04 |\n",
      "|    total_reward       | 4.2e+05  |\n",
      "|    total_reward_pct   | 84       |\n",
      "|    total_trades       | 4562     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -6.51    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "day: 501, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 450028.69\n",
      "total_reward: -49971.31\n",
      "total_cost: 12689.60\n",
      "total_trades: 4594\n",
      "Sharpe: 0.026\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.5e+05  |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | -5e+04   |\n",
      "|    total_reward_pct   | -9.99    |\n",
      "|    total_trades       | 4594     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.343    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -12.8    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.229    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.87e+05  |\n",
      "|    total_cost         | 1.54e+04  |\n",
      "|    total_reward       | -1.31e+04 |\n",
      "|    total_reward_pct   | -2.62     |\n",
      "|    total_trades       | 4751      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -0.178    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -23.1     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.768     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.24e+05  |\n",
      "|    total_cost         | 1.44e+04  |\n",
      "|    total_reward       | -1.76e+05 |\n",
      "|    total_reward_pct   | -35.1     |\n",
      "|    total_trades       | 4840      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -0.106    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -14       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.325     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.06e+05  |\n",
      "|    total_cost         | 1.77e+04  |\n",
      "|    total_reward       | -1.94e+05 |\n",
      "|    total_reward_pct   | -38.8     |\n",
      "|    total_trades       | 4624      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 6.73      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.193     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.95e+05  |\n",
      "|    total_cost         | 9.12e+03  |\n",
      "|    total_reward       | -1.05e+05 |\n",
      "|    total_reward_pct   | -20.9     |\n",
      "|    total_trades       | 4348      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 21.1      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.753     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 384769.33\n",
      "total_reward: -115230.67\n",
      "total_cost: 9335.82\n",
      "total_trades: 4350\n",
      "Sharpe: -0.008\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.85e+05  |\n",
      "|    total_cost         | 9.34e+03  |\n",
      "|    total_reward       | -1.15e+05 |\n",
      "|    total_reward_pct   | -23       |\n",
      "|    total_trades       | 4350      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -15       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.278     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.09e+05  |\n",
      "|    total_cost         | 6.89e+03  |\n",
      "|    total_reward       | -9.06e+04 |\n",
      "|    total_reward_pct   | -18.1     |\n",
      "|    total_trades       | 4143      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | 0.0281    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -6.34     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.465     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.26e+05 |\n",
      "|    total_cost         | 1.77e+04 |\n",
      "|    total_reward       | 4.26e+05 |\n",
      "|    total_reward_pct   | 85.1     |\n",
      "|    total_trades       | 4205     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 17.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.459    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.85e+05  |\n",
      "|    total_cost         | 1.22e+04  |\n",
      "|    total_reward       | -1.54e+04 |\n",
      "|    total_reward_pct   | -3.09     |\n",
      "|    total_trades       | 4140      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 2.49      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.0347    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.44e+05  |\n",
      "|    total_cost         | 9.28e+03  |\n",
      "|    total_reward       | -1.56e+05 |\n",
      "|    total_reward_pct   | -31.1     |\n",
      "|    total_trades       | 4135      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | 0.0224    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 18.9      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.573     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 526252.88\n",
      "total_reward: 26252.88\n",
      "total_cost: 7954.80\n",
      "total_trades: 4011\n",
      "Sharpe: 0.280\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.26e+05 |\n",
      "|    total_cost         | 7.95e+03 |\n",
      "|    total_reward       | 2.63e+04 |\n",
      "|    total_reward_pct   | 5.25     |\n",
      "|    total_trades       | 4011     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.309    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.36e+05  |\n",
      "|    total_cost         | 9.56e+03  |\n",
      "|    total_reward       | -6.43e+04 |\n",
      "|    total_reward_pct   | -12.9     |\n",
      "|    total_trades       | 4003      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | 0.0113    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -18.8     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.568     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.34e+05 |\n",
      "|    total_cost         | 1.3e+04  |\n",
      "|    total_reward       | 2.34e+05 |\n",
      "|    total_reward_pct   | 46.9     |\n",
      "|    total_trades       | 4058     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -3.49    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.13e+05 |\n",
      "|    total_cost         | 1.22e+04 |\n",
      "|    total_reward       | 1.3e+04  |\n",
      "|    total_reward_pct   | 2.61     |\n",
      "|    total_trades       | 4097     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 32.5     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.84e+05 |\n",
      "|    total_cost         | 1.66e+04 |\n",
      "|    total_reward       | 4.84e+05 |\n",
      "|    total_reward_pct   | 96.8     |\n",
      "|    total_trades       | 4177     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0.249    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -7.44    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "day: 501, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 470714.97\n",
      "total_reward: -29285.03\n",
      "total_cost: 9843.98\n",
      "total_trades: 4206\n",
      "Sharpe: 0.101\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.71e+05  |\n",
      "|    total_cost         | 9.84e+03  |\n",
      "|    total_reward       | -2.93e+04 |\n",
      "|    total_reward_pct   | -5.86     |\n",
      "|    total_trades       | 4206      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -0.363    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -9.99     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.241     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.88e+05  |\n",
      "|    total_cost         | 7.75e+03  |\n",
      "|    total_reward       | -1.23e+04 |\n",
      "|    total_reward_pct   | -2.46     |\n",
      "|    total_trades       | 4095      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -1.96     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -16.6     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.457     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.38e+05  |\n",
      "|    total_cost         | 7.12e+03  |\n",
      "|    total_reward       | -1.62e+05 |\n",
      "|    total_reward_pct   | -32.4     |\n",
      "|    total_trades       | 4197      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 0.0399    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -15       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.527     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.79e+05 |\n",
      "|    total_cost         | 1.63e+04 |\n",
      "|    total_reward       | 3.79e+05 |\n",
      "|    total_reward_pct   | 75.7     |\n",
      "|    total_trades       | 4207     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0.0353   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -36.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.4e+05  |\n",
      "|    total_cost         | 1.61e+04 |\n",
      "|    total_reward       | 3.4e+05  |\n",
      "|    total_reward_pct   | 68       |\n",
      "|    total_trades       | 4134     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -30.7    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "day: 501, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 398267.43\n",
      "total_reward: -101732.57\n",
      "total_cost: 6247.28\n",
      "total_trades: 4229\n",
      "Sharpe: -0.193\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.98e+05  |\n",
      "|    total_cost         | 6.25e+03  |\n",
      "|    total_reward       | -1.02e+05 |\n",
      "|    total_reward_pct   | -20.3     |\n",
      "|    total_trades       | 4229      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | 0.147     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -3.01     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.0296    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.98e+05  |\n",
      "|    total_cost         | 6.08e+03  |\n",
      "|    total_reward       | -2.02e+05 |\n",
      "|    total_reward_pct   | -40.4     |\n",
      "|    total_trades       | 4349      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | 0.157     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -20       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.455     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.49e+05  |\n",
      "|    total_cost         | 9.78e+03  |\n",
      "|    total_reward       | -5.09e+04 |\n",
      "|    total_reward_pct   | -10.2     |\n",
      "|    total_trades       | 4570      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | 0.143     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.161     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.96e+05  |\n",
      "|    total_cost         | 1.15e+04  |\n",
      "|    total_reward       | -3.68e+03 |\n",
      "|    total_reward_pct   | -0.737    |\n",
      "|    total_trades       | 4714      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | -0.203    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 3.51      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.207     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.25e+05  |\n",
      "|    total_cost         | 2.27e+04  |\n",
      "|    total_reward       | 3.25e+05  |\n",
      "|    total_reward_pct   | 65.1      |\n",
      "|    total_trades       | 4645      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | -0.000911 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 0.454     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.0144    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 428590.77\n",
      "total_reward: -71409.23\n",
      "total_cost: 7920.42\n",
      "total_trades: 4855\n",
      "Sharpe: -0.063\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.29e+05  |\n",
      "|    total_cost         | 7.92e+03  |\n",
      "|    total_reward       | -7.14e+04 |\n",
      "|    total_reward_pct   | -14.3     |\n",
      "|    total_trades       | 4855      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | 0.302     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -4.74     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.0318    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.91e+05  |\n",
      "|    total_cost         | 5.25e+03  |\n",
      "|    total_reward       | -2.09e+05 |\n",
      "|    total_reward_pct   | -41.8     |\n",
      "|    total_trades       | 4656      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -0.0215   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 0.231     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.0127    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.51e+05  |\n",
      "|    total_cost         | 5.36e+03  |\n",
      "|    total_reward       | -2.49e+05 |\n",
      "|    total_reward_pct   | -49.9     |\n",
      "|    total_trades       | 4772      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -0.396    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 1.54      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.133     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.33e+05 |\n",
      "|    total_cost         | 1.89e+04 |\n",
      "|    total_reward       | 2.33e+05 |\n",
      "|    total_reward_pct   | 46.6     |\n",
      "|    total_trades       | 4624     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0.0801   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 13.8     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.936    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.83e+05 |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | 1.83e+05 |\n",
      "|    total_reward_pct   | 36.6     |\n",
      "|    total_trades       | 4717     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.0242   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 43       |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 6.38     |\n",
      "------------------------------------\n",
      "day: 501, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 679138.19\n",
      "total_reward: 179138.19\n",
      "total_cost: 21100.80\n",
      "total_trades: 4645\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.79e+05 |\n",
      "|    total_cost         | 2.11e+04 |\n",
      "|    total_reward       | 1.79e+05 |\n",
      "|    total_reward_pct   | 35.8     |\n",
      "|    total_trades       | 4645     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.394   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 63.9     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.8      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.13e+05  |\n",
      "|    total_cost         | 6.31e+03  |\n",
      "|    total_reward       | -2.87e+05 |\n",
      "|    total_reward_pct   | -57.5     |\n",
      "|    total_trades       | 4558      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | 0.161     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -3.33     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0149    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.96e+05  |\n",
      "|    total_cost         | 8.88e+03  |\n",
      "|    total_reward       | -3.04e+05 |\n",
      "|    total_reward_pct   | -60.8     |\n",
      "|    total_trades       | 4576      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 6         |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.116     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.29e+05  |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -1.71e+05 |\n",
      "|    total_reward_pct   | -34.2     |\n",
      "|    total_trades       | 4678      |\n",
      "| time/                 |           |\n",
      "|    fps                | 554       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 9.7       |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.15      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.32e+05  |\n",
      "|    total_cost         | 9.8e+03   |\n",
      "|    total_reward       | -2.68e+05 |\n",
      "|    total_reward_pct   | -53.5     |\n",
      "|    total_trades       | 4362      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | 0.474     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 11.5      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.167     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 818850.09\n",
      "total_reward: 318850.09\n",
      "total_cost: 32568.00\n",
      "total_trades: 4518\n",
      "Sharpe: 1.121\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.19e+05 |\n",
      "|    total_cost         | 3.26e+04 |\n",
      "|    total_reward       | 3.19e+05 |\n",
      "|    total_reward_pct   | 63.8     |\n",
      "|    total_trades       | 4518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -0.175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 2.03     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0485   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.22e+05  |\n",
      "|    total_cost         | 1.34e+04  |\n",
      "|    total_reward       | -7.79e+04 |\n",
      "|    total_reward_pct   | -15.6     |\n",
      "|    total_trades       | 4474      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | -0.494    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.506     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.31e+05  |\n",
      "|    total_cost         | 1.12e+04  |\n",
      "|    total_reward       | -2.69e+05 |\n",
      "|    total_reward_pct   | -53.7     |\n",
      "|    total_trades       | 4504      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.376     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.74e+05  |\n",
      "|    total_cost         | 3.55e+04  |\n",
      "|    total_reward       | -1.26e+05 |\n",
      "|    total_reward_pct   | -25.2     |\n",
      "|    total_trades       | 4887      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 23.6      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.665     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.62e+05  |\n",
      "|    total_cost         | 6.97e+04  |\n",
      "|    total_reward       | 1.62e+05  |\n",
      "|    total_reward_pct   | 32.5      |\n",
      "|    total_trades       | 4941      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 14.2      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.222     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 437455.70\n",
      "total_reward: -62544.30\n",
      "total_cost: 49300.90\n",
      "total_trades: 4758\n",
      "Sharpe: -0.014\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.37e+05  |\n",
      "|    total_cost         | 4.93e+04  |\n",
      "|    total_reward       | -6.25e+04 |\n",
      "|    total_reward_pct   | -12.5     |\n",
      "|    total_trades       | 4758      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 7.25      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.257     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.55e+05  |\n",
      "|    total_cost         | 2.5e+04   |\n",
      "|    total_reward       | -2.45e+05 |\n",
      "|    total_reward_pct   | -49.1     |\n",
      "|    total_trades       | 4758      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 29.5      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.26e+05  |\n",
      "|    total_cost         | 2.68e+04  |\n",
      "|    total_reward       | -1.74e+05 |\n",
      "|    total_reward_pct   | -34.8     |\n",
      "|    total_trades       | 4813      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -4        |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.0248    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.38e+05  |\n",
      "|    total_cost         | 1.86e+04  |\n",
      "|    total_reward       | -1.62e+05 |\n",
      "|    total_reward_pct   | -32.4     |\n",
      "|    total_trades       | 5010      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 2.53      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.0114    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.37e+05  |\n",
      "|    total_cost         | 1.75e+04  |\n",
      "|    total_reward       | -2.63e+05 |\n",
      "|    total_reward_pct   | -52.6     |\n",
      "|    total_trades       | 4946      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 11.6      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.283     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 511466.93\n",
      "total_reward: 11466.93\n",
      "total_cost: 38169.03\n",
      "total_trades: 4904\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.11e+05  |\n",
      "|    total_cost         | 3.82e+04  |\n",
      "|    total_reward       | 1.15e+04  |\n",
      "|    total_reward_pct   | 2.29      |\n",
      "|    total_trades       | 4904      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 2.39      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.0441    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.57e+05  |\n",
      "|    total_cost         | 1.92e+04  |\n",
      "|    total_reward       | -4.32e+04 |\n",
      "|    total_reward_pct   | -8.63     |\n",
      "|    total_trades       | 5039      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -12.3     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.198     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.77e+05  |\n",
      "|    total_cost         | 1.42e+04  |\n",
      "|    total_reward       | -1.23e+05 |\n",
      "|    total_reward_pct   | -24.6     |\n",
      "|    total_trades       | 4941      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -4.18     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.0549    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.19e+05  |\n",
      "|    total_cost         | 1.45e+04  |\n",
      "|    total_reward       | -1.81e+05 |\n",
      "|    total_reward_pct   | -36.2     |\n",
      "|    total_trades       | 5157      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -24.2     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.22      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.74e+05  |\n",
      "|    total_cost         | 1.09e+04  |\n",
      "|    total_reward       | -2.65e+04 |\n",
      "|    total_reward_pct   | -5.3      |\n",
      "|    total_trades       | 4939      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -25.9     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.863     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 428097.87\n",
      "total_reward: -71902.13\n",
      "total_cost: 14823.10\n",
      "total_trades: 4745\n",
      "Sharpe: 0.039\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.28e+05  |\n",
      "|    total_cost         | 1.48e+04  |\n",
      "|    total_reward       | -7.19e+04 |\n",
      "|    total_reward_pct   | -14.4     |\n",
      "|    total_trades       | 4745      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -10.6     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.158     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.87e+05  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | -1.13e+05 |\n",
      "|    total_reward_pct   | -22.5     |\n",
      "|    total_trades       | 5132      |\n",
      "| time/                 |           |\n",
      "|    fps                | 553       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -4.58     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.0396    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.63e+05  |\n",
      "|    total_cost         | 1.44e+04  |\n",
      "|    total_reward       | -2.37e+05 |\n",
      "|    total_reward_pct   | -47.5     |\n",
      "|    total_trades       | 5133      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -14       |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.227     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.97e+05 |\n",
      "|    total_cost         | 1.64e+04 |\n",
      "|    total_reward       | 9.73e+04 |\n",
      "|    total_reward_pct   | 19.5     |\n",
      "|    total_trades       | 4969     |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 4.32     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0331   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.58e+05  |\n",
      "|    total_cost         | 1.04e+04  |\n",
      "|    total_reward       | -1.42e+05 |\n",
      "|    total_reward_pct   | -28.4     |\n",
      "|    total_trades       | 5177      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -3.05     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.0269    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 365341.52\n",
      "total_reward: -134658.48\n",
      "total_cost: 10400.41\n",
      "total_trades: 5339\n",
      "Sharpe: -0.264\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.65e+05  |\n",
      "|    total_cost         | 1.04e+04  |\n",
      "|    total_reward       | -1.35e+05 |\n",
      "|    total_reward_pct   | -26.9     |\n",
      "|    total_trades       | 5339      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -7.48     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.228     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.74e+05  |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -1.26e+05 |\n",
      "|    total_reward_pct   | -25.2     |\n",
      "|    total_trades       | 5268      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -1.59     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.0301    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.3e+05  |\n",
      "|    total_cost         | 1.43e+04 |\n",
      "|    total_reward       | -1.7e+05 |\n",
      "|    total_reward_pct   | -33.9    |\n",
      "|    total_trades       | 4834     |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 41.9     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.27e+05  |\n",
      "|    total_cost         | 6.19e+03  |\n",
      "|    total_reward       | -7.34e+04 |\n",
      "|    total_reward_pct   | -14.7     |\n",
      "|    total_trades       | 4940      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 31.6      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 1.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.63e+05  |\n",
      "|    total_cost         | 2.69e+04  |\n",
      "|    total_reward       | -1.37e+05 |\n",
      "|    total_reward_pct   | -27.4     |\n",
      "|    total_trades       | 5283      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | -0.00414  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 3.43      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.0148    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 273372.80\n",
      "total_reward: -226627.20\n",
      "total_cost: 34273.36\n",
      "total_trades: 5454\n",
      "Sharpe: -0.392\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.73e+05  |\n",
      "|    total_cost         | 3.43e+04  |\n",
      "|    total_reward       | -2.27e+05 |\n",
      "|    total_reward_pct   | -45.3     |\n",
      "|    total_trades       | 5454      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | -0.996    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 3.29      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.0715    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.45e+05  |\n",
      "|    total_cost         | 4.73e+04  |\n",
      "|    total_reward       | -1.55e+05 |\n",
      "|    total_reward_pct   | -31       |\n",
      "|    total_trades       | 5447      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 7.89      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.0952    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.11e+05  |\n",
      "|    total_cost         | 2.28e+04  |\n",
      "|    total_reward       | -1.89e+05 |\n",
      "|    total_reward_pct   | -37.8     |\n",
      "|    total_trades       | 5095      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -4.91     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.0554    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.16e+05  |\n",
      "|    total_cost         | 5.64e+04  |\n",
      "|    total_reward       | -1.84e+05 |\n",
      "|    total_reward_pct   | -36.9     |\n",
      "|    total_trades       | 5573      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 6.74      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.0896    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.22e+05 |\n",
      "|    total_cost         | 1.02e+05 |\n",
      "|    total_reward       | 2.22e+05 |\n",
      "|    total_reward_pct   | 44.4     |\n",
      "|    total_trades       | 6277     |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -11.7    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.187    |\n",
      "------------------------------------\n",
      "day: 501, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 398859.16\n",
      "total_reward: -101140.84\n",
      "total_cost: 71263.47\n",
      "total_trades: 6098\n",
      "Sharpe: -0.160\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.99e+05  |\n",
      "|    total_cost         | 7.13e+04  |\n",
      "|    total_reward       | -1.01e+05 |\n",
      "|    total_reward_pct   | -20.2     |\n",
      "|    total_trades       | 6098      |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | -2.03e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -13.6     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.225     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.11e+05  |\n",
      "|    total_cost         | 4.73e+04  |\n",
      "|    total_reward       | -1.89e+05 |\n",
      "|    total_reward_pct   | -37.9     |\n",
      "|    total_trades       | 6200      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -4.71     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.0916    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.76e+05  |\n",
      "|    total_cost         | 4.9e+04   |\n",
      "|    total_reward       | -1.24e+05 |\n",
      "|    total_reward_pct   | -24.9     |\n",
      "|    total_trades       | 6140      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.495     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.84e+05 |\n",
      "|    total_cost         | 4.1e+04  |\n",
      "|    total_reward       | 8.43e+04 |\n",
      "|    total_reward_pct   | 16.9     |\n",
      "|    total_trades       | 5852     |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.338    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.19e+05  |\n",
      "|    total_cost         | 3.03e+04  |\n",
      "|    total_reward       | -8.09e+04 |\n",
      "|    total_reward_pct   | -16.2     |\n",
      "|    total_trades       | 5741      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -11.2     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.178     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 399896.32\n",
      "total_reward: -100103.68\n",
      "total_cost: 19192.17\n",
      "total_trades: 5626\n",
      "Sharpe: -0.158\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4e+05    |\n",
      "|    total_cost         | 1.92e+04 |\n",
      "|    total_reward       | -1e+05   |\n",
      "|    total_reward_pct   | -20      |\n",
      "|    total_trades       | 5626     |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.33e+05  |\n",
      "|    total_cost         | 1.84e+04  |\n",
      "|    total_reward       | -6.68e+04 |\n",
      "|    total_reward_pct   | -13.4     |\n",
      "|    total_trades       | 5950      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -7.42     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.103     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.32e+05  |\n",
      "|    total_cost         | 1.52e+04  |\n",
      "|    total_reward       | 3.24e+04  |\n",
      "|    total_reward_pct   | 6.48      |\n",
      "|    total_trades       | 5987      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.207     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.1e+05  |\n",
      "|    total_cost         | 1.48e+04 |\n",
      "|    total_reward       | 9.62e+03 |\n",
      "|    total_reward_pct   | 1.92     |\n",
      "|    total_trades       | 5886     |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 8.79     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.375    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.85e+05  |\n",
      "|    total_cost         | 1.77e+04  |\n",
      "|    total_reward       | -1.15e+05 |\n",
      "|    total_reward_pct   | -22.9     |\n",
      "|    total_trades       | 5918      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | -0.408    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 9.44      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.116     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 448316.49\n",
      "total_reward: -51683.51\n",
      "total_cost: 21390.41\n",
      "total_trades: 6122\n",
      "Sharpe: 0.036\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.48e+05  |\n",
      "|    total_cost         | 2.14e+04  |\n",
      "|    total_reward       | -5.17e+04 |\n",
      "|    total_reward_pct   | -10.3     |\n",
      "|    total_trades       | 6122      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | 0.0634    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | 2.62      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.0661    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.07e+05 |\n",
      "|    total_cost         | 2.03e+04 |\n",
      "|    total_reward       | 7.35e+03 |\n",
      "|    total_reward_pct   | 1.47     |\n",
      "|    total_trades       | 6089     |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | -14.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 12.8     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.367    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.5e+05  |\n",
      "|    total_cost         | 1.55e+04 |\n",
      "|    total_reward       | -2.5e+05 |\n",
      "|    total_reward_pct   | -49.9    |\n",
      "|    total_trades       | 5756     |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.0539  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 9.18     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.158    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.49e+05  |\n",
      "|    total_cost         | 1.96e+04  |\n",
      "|    total_reward       | -5.15e+04 |\n",
      "|    total_reward_pct   | -10.3     |\n",
      "|    total_trades       | 5742      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -7.64     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.0977    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+05  |\n",
      "|    total_cost         | 1.38e+04  |\n",
      "|    total_reward       | -1.58e+05 |\n",
      "|    total_reward_pct   | -31.5     |\n",
      "|    total_trades       | 5645      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | 0.0946    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | 6.1       |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.0627    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 308988.73\n",
      "total_reward: -191011.27\n",
      "total_cost: 11931.44\n",
      "total_trades: 5451\n",
      "Sharpe: -0.310\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.09e+05  |\n",
      "|    total_cost         | 1.19e+04  |\n",
      "|    total_reward       | -1.91e+05 |\n",
      "|    total_reward_pct   | -38.2     |\n",
      "|    total_trades       | 5451      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -13.3     |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.212     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.91e+05  |\n",
      "|    total_cost         | 2.44e+04  |\n",
      "|    total_reward       | -1.09e+05 |\n",
      "|    total_reward_pct   | -21.9     |\n",
      "|    total_trades       | 5637      |\n",
      "| time/                 |           |\n",
      "|    fps                | 551       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | 0.115     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 5.11      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.153     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.77e+05  |\n",
      "|    total_cost         | 2.46e+04  |\n",
      "|    total_reward       | -2.29e+04 |\n",
      "|    total_reward_pct   | -4.58     |\n",
      "|    total_trades       | 5751      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | 0.626     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 7.5       |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.0572    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.46e+05  |\n",
      "|    total_cost         | 2.31e+04  |\n",
      "|    total_reward       | -1.54e+05 |\n",
      "|    total_reward_pct   | -30.7     |\n",
      "|    total_trades       | 5752      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | 0.202     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 22.6      |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.566     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.33e+05  |\n",
      "|    total_cost         | 2.77e+04  |\n",
      "|    total_reward       | -6.71e+04 |\n",
      "|    total_reward_pct   | -13.4     |\n",
      "|    total_trades       | 5616      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -0.0789   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 3.88      |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.075     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 379017.95\n",
      "total_reward: -120982.05\n",
      "total_cost: 20251.47\n",
      "total_trades: 5581\n",
      "Sharpe: -0.067\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.79e+05  |\n",
      "|    total_cost         | 2.03e+04  |\n",
      "|    total_reward       | -1.21e+05 |\n",
      "|    total_reward_pct   | -24.2     |\n",
      "|    total_trades       | 5581      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | 0.0847    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 5.85      |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.119     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.12e+05  |\n",
      "|    total_cost         | 2.54e+04  |\n",
      "|    total_reward       | -8.81e+04 |\n",
      "|    total_reward_pct   | -17.6     |\n",
      "|    total_trades       | 5624      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31       |\n",
      "|    explained_variance | -0.137    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | 0.0104    |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 0.0277    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.34e+05  |\n",
      "|    total_cost         | 3.18e+04  |\n",
      "|    total_reward       | -6.64e+04 |\n",
      "|    total_reward_pct   | -13.3     |\n",
      "|    total_trades       | 5726      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31       |\n",
      "|    explained_variance | 0.00692   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | 3.21      |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 0.0145    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.08e+05  |\n",
      "|    total_cost         | 1.73e+04  |\n",
      "|    total_reward       | -9.16e+04 |\n",
      "|    total_reward_pct   | -18.3     |\n",
      "|    total_trades       | 5353      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -7.28     |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 0.132     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.09e+05  |\n",
      "|    total_cost         | 8.14e+03  |\n",
      "|    total_reward       | -9.15e+04 |\n",
      "|    total_reward_pct   | -18.3     |\n",
      "|    total_trades       | 5159      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.1     |\n",
      "|    explained_variance | 0.0508    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -9.19     |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 0.163     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 420069.01\n",
      "total_reward: -79930.99\n",
      "total_cost: 6414.53\n",
      "total_trades: 5041\n",
      "Sharpe: -0.082\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.2e+05   |\n",
      "|    total_cost         | 6.41e+03  |\n",
      "|    total_reward       | -7.99e+04 |\n",
      "|    total_reward_pct   | -16       |\n",
      "|    total_trades       | 5041      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.1     |\n",
      "|    explained_variance | -0.024    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 23.1      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.866     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.04e+05 |\n",
      "|    total_cost         | 5.78e+03 |\n",
      "|    total_reward       | 3.61e+03 |\n",
      "|    total_reward_pct   | 0.722    |\n",
      "|    total_trades       | 5096     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0.123    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 31.3     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.12e+05  |\n",
      "|    total_cost         | 8.47e+03  |\n",
      "|    total_reward       | -8.78e+04 |\n",
      "|    total_reward_pct   | -17.6     |\n",
      "|    total_trades       | 5255      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 30.4      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 1.03      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.47e+05  |\n",
      "|    total_cost         | 8.68e+03  |\n",
      "|    total_reward       | -5.27e+04 |\n",
      "|    total_reward_pct   | -10.5     |\n",
      "|    total_trades       | 5210      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -0.254    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | 0.0234    |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.132     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.62e+05  |\n",
      "|    total_cost         | 5.01e+03  |\n",
      "|    total_reward       | -1.38e+05 |\n",
      "|    total_reward_pct   | -27.5     |\n",
      "|    total_trades       | 5013      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | 0.00584   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -51.7     |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 3.55      |\n",
      "-------------------------------------\n",
      "day: 501, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 610874.91\n",
      "total_reward: 110874.91\n",
      "total_cost: 7288.39\n",
      "total_trades: 5305\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.11e+05 |\n",
      "|    total_cost         | 7.29e+03 |\n",
      "|    total_reward       | 1.11e+05 |\n",
      "|    total_reward_pct   | 22.2     |\n",
      "|    total_trades       | 5305     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0.322    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -31.4    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.3e+05   |\n",
      "|    total_cost         | 7.48e+03  |\n",
      "|    total_reward       | -6.98e+04 |\n",
      "|    total_reward_pct   | -14       |\n",
      "|    total_trades       | 5241      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -5.58     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 22.7      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 1.46      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.02e+05  |\n",
      "|    total_cost         | 6e+03     |\n",
      "|    total_reward       | -9.75e+04 |\n",
      "|    total_reward_pct   | -19.5     |\n",
      "|    total_trades       | 5129      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -12.5     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 51.4      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.35e+05  |\n",
      "|    total_cost         | 7.27e+03  |\n",
      "|    total_reward       | -6.52e+04 |\n",
      "|    total_reward_pct   | -13       |\n",
      "|    total_trades       | 5279      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 0.204     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.22e+05  |\n",
      "|    total_cost         | 4.77e+03  |\n",
      "|    total_reward       | -7.76e+04 |\n",
      "|    total_reward_pct   | -15.5     |\n",
      "|    total_trades       | 5245      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -30.8     |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 0.978     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 632532.68\n",
      "total_reward: 132532.68\n",
      "total_cost: 21706.09\n",
      "total_trades: 5680\n",
      "Sharpe: 0.705\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.33e+05 |\n",
      "|    total_cost         | 2.17e+04 |\n",
      "|    total_reward       | 1.33e+05 |\n",
      "|    total_reward_pct   | 26.5     |\n",
      "|    total_trades       | 5680     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -16.2    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.83e+05  |\n",
      "|    total_cost         | 1.5e+04   |\n",
      "|    total_reward       | -2.17e+05 |\n",
      "|    total_reward_pct   | -43.5     |\n",
      "|    total_trades       | 5657      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.3     |\n",
      "|    explained_variance | -0.321    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -11.9     |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 0.165     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+05  |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | -1.8e+05 |\n",
      "|    total_reward_pct   | -35.9    |\n",
      "|    total_trades       | 5606     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0.195    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 5.74     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.199    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.12e+05  |\n",
      "|    total_cost         | 1.74e+04  |\n",
      "|    total_reward       | -8.78e+04 |\n",
      "|    total_reward_pct   | -17.6     |\n",
      "|    total_trades       | 5488      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 16.1      |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.298     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.22e+05  |\n",
      "|    total_cost         | 1.36e+04  |\n",
      "|    total_reward       | -1.78e+05 |\n",
      "|    total_reward_pct   | -35.6     |\n",
      "|    total_trades       | 5462      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 6.26      |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.0681    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 438918.59\n",
      "total_reward: -61081.41\n",
      "total_cost: 15361.57\n",
      "total_trades: 5571\n",
      "Sharpe: -0.114\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.39e+05  |\n",
      "|    total_cost         | 1.54e+04  |\n",
      "|    total_reward       | -6.11e+04 |\n",
      "|    total_reward_pct   | -12.2     |\n",
      "|    total_trades       | 5571      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | -0.701    |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.0652    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+05  |\n",
      "|    total_cost         | 1.08e+04 |\n",
      "|    total_reward       | -1.8e+05 |\n",
      "|    total_reward_pct   | -36      |\n",
      "|    total_trades       | 5569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.66e+05  |\n",
      "|    total_cost         | 1.56e+04  |\n",
      "|    total_reward       | -3.35e+04 |\n",
      "|    total_reward_pct   | -6.7      |\n",
      "|    total_trades       | 5538      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.7     |\n",
      "|    explained_variance | 0.264     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -24.3     |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.651     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.33e+05  |\n",
      "|    total_cost         | 1.73e+04  |\n",
      "|    total_reward       | -6.75e+04 |\n",
      "|    total_reward_pct   | -13.5     |\n",
      "|    total_trades       | 5579      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -9.56     |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.154     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.72e+05  |\n",
      "|    total_cost         | 9.57e+03  |\n",
      "|    total_reward       | -2.84e+04 |\n",
      "|    total_reward_pct   | -5.67     |\n",
      "|    total_trades       | 5457      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.202     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 393144.28\n",
      "total_reward: -106855.72\n",
      "total_cost: 4792.88\n",
      "total_trades: 5103\n",
      "Sharpe: -0.151\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.93e+05  |\n",
      "|    total_cost         | 4.79e+03  |\n",
      "|    total_reward       | -1.07e+05 |\n",
      "|    total_reward_pct   | -21.4     |\n",
      "|    total_trades       | 5103      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -5.9      |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 0.0867    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.53e+05  |\n",
      "|    total_cost         | 1.29e+04  |\n",
      "|    total_reward       | -4.69e+04 |\n",
      "|    total_reward_pct   | -9.38     |\n",
      "|    total_trades       | 5067      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.7     |\n",
      "|    explained_variance | -0.664    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | -10       |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 0.272     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.2e+05  |\n",
      "|    total_cost         | 1.42e+04 |\n",
      "|    total_reward       | -8e+04   |\n",
      "|    total_reward_pct   | -16      |\n",
      "|    total_trades       | 5052     |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 13.9     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.543    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.32e+05  |\n",
      "|    total_cost         | 1.54e+04  |\n",
      "|    total_reward       | -6.77e+04 |\n",
      "|    total_reward_pct   | -13.5     |\n",
      "|    total_trades       | 5010      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 16.2      |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 0.375     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.56e+05  |\n",
      "|    total_cost         | 1.75e+04  |\n",
      "|    total_reward       | -1.44e+05 |\n",
      "|    total_reward_pct   | -28.8     |\n",
      "|    total_trades       | 5212      |\n",
      "| time/                 |           |\n",
      "|    fps                | 550       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -6.33     |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.491     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 663938.01\n",
      "total_reward: 163938.01\n",
      "total_cost: 22015.76\n",
      "total_trades: 5336\n",
      "Sharpe: 0.916\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.64e+05 |\n",
      "|    total_cost         | 2.2e+04  |\n",
      "|    total_reward       | 1.64e+05 |\n",
      "|    total_reward_pct   | 32.8     |\n",
      "|    total_trades       | 5336     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | -0.58    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -20      |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.713    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.29e+05  |\n",
      "|    total_cost         | 1.08e+04  |\n",
      "|    total_reward       | -1.71e+05 |\n",
      "|    total_reward_pct   | -34.2     |\n",
      "|    total_trades       | 4884      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.9     |\n",
      "|    explained_variance | -2.21     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -118      |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 16.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.67e+05 |\n",
      "|    total_cost         | 1.71e+04 |\n",
      "|    total_reward       | 3.67e+05 |\n",
      "|    total_reward_pct   | 73.4     |\n",
      "|    total_trades       | 4791     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | -9.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -30.7    |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.01e+05  |\n",
      "|    total_cost         | 6.01e+03  |\n",
      "|    total_reward       | -9.88e+04 |\n",
      "|    total_reward_pct   | -19.8     |\n",
      "|    total_trades       | 4669      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.9     |\n",
      "|    explained_variance | -0.517    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | 4.23      |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.354     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.77e+05  |\n",
      "|    total_cost         | 1.42e+04  |\n",
      "|    total_reward       | -2.33e+04 |\n",
      "|    total_reward_pct   | -4.66     |\n",
      "|    total_trades       | 4751      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32       |\n",
      "|    explained_variance | -0.624    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -38       |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 2.06      |\n",
      "-------------------------------------\n",
      "day: 501, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 360637.85\n",
      "total_reward: -139362.15\n",
      "total_cost: 13828.47\n",
      "total_trades: 4785\n",
      "Sharpe: -0.116\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.61e+05  |\n",
      "|    total_cost         | 1.38e+04  |\n",
      "|    total_reward       | -1.39e+05 |\n",
      "|    total_reward_pct   | -27.9     |\n",
      "|    total_trades       | 4785      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.1     |\n",
      "|    explained_variance | -0.241    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -22.9     |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.708     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.45e+05  |\n",
      "|    total_cost         | 1.79e+04  |\n",
      "|    total_reward       | -1.55e+05 |\n",
      "|    total_reward_pct   | -30.9     |\n",
      "|    total_trades       | 4876      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.2     |\n",
      "|    explained_variance | 0.0183    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -14.5     |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 0.292     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.48e+05  |\n",
      "|    total_cost         | 5.58e+03  |\n",
      "|    total_reward       | -1.52e+05 |\n",
      "|    total_reward_pct   | -30.4     |\n",
      "|    total_trades       | 4709      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.2     |\n",
      "|    explained_variance | 0.13      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -26.7     |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 0.714     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.1e+05   |\n",
      "|    total_cost         | 9.84e+03  |\n",
      "|    total_reward       | -9.02e+04 |\n",
      "|    total_reward_pct   | -18       |\n",
      "|    total_trades       | 4647      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.2     |\n",
      "|    explained_variance | -0.122    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | 15.2      |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 0.254     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.84e+05  |\n",
      "|    total_cost         | 5.65e+03  |\n",
      "|    total_reward       | -1.16e+05 |\n",
      "|    total_reward_pct   | -23.2     |\n",
      "|    total_trades       | 4729      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.3     |\n",
      "|    explained_variance | -2.97     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | 0.343     |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.00896   |\n",
      "-------------------------------------\n",
      "day: 501, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 214304.09\n",
      "total_reward: -285695.91\n",
      "total_cost: 7090.32\n",
      "total_trades: 4700\n",
      "Sharpe: -0.749\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.14e+05  |\n",
      "|    total_cost         | 7.09e+03  |\n",
      "|    total_reward       | -2.86e+05 |\n",
      "|    total_reward_pct   | -57.1     |\n",
      "|    total_trades       | 4700      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.3     |\n",
      "|    explained_variance | -0.116    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | -8.42     |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.132     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.35e+05  |\n",
      "|    total_cost         | 9.16e+03  |\n",
      "|    total_reward       | -2.65e+05 |\n",
      "|    total_reward_pct   | -53       |\n",
      "|    total_trades       | 4917      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.4     |\n",
      "|    explained_variance | -0.0314   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -1.46     |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.259     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.33e+05 |\n",
      "|    total_cost         | 1.34e+04 |\n",
      "|    total_reward       | 3.31e+04 |\n",
      "|    total_reward_pct   | 6.63     |\n",
      "|    total_trades       | 4910     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | -0.345   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.287    |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.49e+05  |\n",
      "|    total_cost         | 7.97e+03  |\n",
      "|    total_reward       | -2.51e+05 |\n",
      "|    total_reward_pct   | -50.2     |\n",
      "|    total_trades       | 4823      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.4     |\n",
      "|    explained_variance | 0.0658    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 16.2      |\n",
      "|    std                | 1.34      |\n",
      "|    value_loss         | 0.292     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.07e+05  |\n",
      "|    total_cost         | 1.58e+04  |\n",
      "|    total_reward       | -1.93e+05 |\n",
      "|    total_reward_pct   | -38.6     |\n",
      "|    total_trades       | 4915      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 18.6      |\n",
      "|    std                | 1.34      |\n",
      "|    value_loss         | 0.362     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 300219.58\n",
      "total_reward: -199780.42\n",
      "total_cost: 17007.65\n",
      "total_trades: 4845\n",
      "Sharpe: -0.565\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3e+05    |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | -2e+05   |\n",
      "|    total_reward_pct   | -40      |\n",
      "|    total_trades       | 4845     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0.131    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 9.44     |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.132    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.14e+05  |\n",
      "|    total_cost         | 1.19e+04  |\n",
      "|    total_reward       | -1.86e+05 |\n",
      "|    total_reward_pct   | -37.2     |\n",
      "|    total_trades       | 4710      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 6         |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 0.0939    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.19e+05  |\n",
      "|    total_cost         | 1.5e+04   |\n",
      "|    total_reward       | -1.81e+05 |\n",
      "|    total_reward_pct   | -36.1     |\n",
      "|    total_trades       | 4639      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.6     |\n",
      "|    explained_variance | -0.217    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -16.2     |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 0.528     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.61e+05  |\n",
      "|    total_cost         | 1.27e+04  |\n",
      "|    total_reward       | -1.39e+05 |\n",
      "|    total_reward_pct   | -27.8     |\n",
      "|    total_trades       | 4537      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.6     |\n",
      "|    explained_variance | -0.172    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -45.6     |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 2.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.25e+05  |\n",
      "|    total_cost         | 1.54e+04  |\n",
      "|    total_reward       | -1.75e+05 |\n",
      "|    total_reward_pct   | -35.1     |\n",
      "|    total_trades       | 4558      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.7     |\n",
      "|    explained_variance | -0.431    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | -7.86     |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 0.264     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 744137.78\n",
      "total_reward: 244137.78\n",
      "total_cost: 27834.98\n",
      "total_trades: 4804\n",
      "Sharpe: 1.185\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.44e+05 |\n",
      "|    total_cost         | 2.78e+04 |\n",
      "|    total_reward       | 2.44e+05 |\n",
      "|    total_reward_pct   | 48.8     |\n",
      "|    total_trades       | 4804     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | 0.255    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.962    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.64e+05 |\n",
      "|    total_cost         | 2.36e+04 |\n",
      "|    total_reward       | 2.64e+05 |\n",
      "|    total_reward_pct   | 52.8     |\n",
      "|    total_trades       | 4694     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -0.659   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.31     |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.4e+05   |\n",
      "|    total_cost         | 1.49e+04  |\n",
      "|    total_reward       | -5.98e+04 |\n",
      "|    total_reward_pct   | -12       |\n",
      "|    total_trades       | 4598      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.8     |\n",
      "|    explained_variance | -0.142    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -11.6     |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 0.166     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.49e+05  |\n",
      "|    total_cost         | 1.02e+04  |\n",
      "|    total_reward       | -5.09e+04 |\n",
      "|    total_reward_pct   | -10.2     |\n",
      "|    total_trades       | 4505      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 1.15      |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 0.203     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.97e+05  |\n",
      "|    total_cost         | 1.14e+04  |\n",
      "|    total_reward       | -3.01e+03 |\n",
      "|    total_reward_pct   | -0.601    |\n",
      "|    total_trades       | 4593      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 15.9      |\n",
      "|    std                | 1.37      |\n",
      "|    value_loss         | 0.267     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 429746.13\n",
      "total_reward: -70253.87\n",
      "total_cost: 9208.81\n",
      "total_trades: 4453\n",
      "Sharpe: 0.005\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.3e+05   |\n",
      "|    total_cost         | 9.21e+03  |\n",
      "|    total_reward       | -7.03e+04 |\n",
      "|    total_reward_pct   | -14.1     |\n",
      "|    total_trades       | 4453      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | -6.52     |\n",
      "|    std                | 1.37      |\n",
      "|    value_loss         | 0.361     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.39e+05  |\n",
      "|    total_cost         | 1.34e+04  |\n",
      "|    total_reward       | 3.39e+05  |\n",
      "|    total_reward_pct   | 67.8      |\n",
      "|    total_trades       | 4257      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -6.86     |\n",
      "|    std                | 1.37      |\n",
      "|    value_loss         | 0.105     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.44e+05  |\n",
      "|    total_cost         | 4.02e+03  |\n",
      "|    total_reward       | -5.57e+04 |\n",
      "|    total_reward_pct   | -11.1     |\n",
      "|    total_trades       | 4114      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 3.04      |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.0968    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.23e+05  |\n",
      "|    total_cost         | 6.17e+03  |\n",
      "|    total_reward       | -7.74e+04 |\n",
      "|    total_reward_pct   | -15.5     |\n",
      "|    total_trades       | 4008      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -2.3      |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.0299    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.53e+05  |\n",
      "|    total_cost         | 3.64e+03  |\n",
      "|    total_reward       | -1.47e+05 |\n",
      "|    total_reward_pct   | -29.5     |\n",
      "|    total_trades       | 4075      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 6.99      |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.0957    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 351635.51\n",
      "total_reward: -148364.49\n",
      "total_cost: 5437.56\n",
      "total_trades: 4168\n",
      "Sharpe: -0.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.52e+05  |\n",
      "|    total_cost         | 5.44e+03  |\n",
      "|    total_reward       | -1.48e+05 |\n",
      "|    total_reward_pct   | -29.7     |\n",
      "|    total_trades       | 4168      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -8.85     |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.137     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.12e+05  |\n",
      "|    total_cost         | 5.13e+03  |\n",
      "|    total_reward       | -1.88e+05 |\n",
      "|    total_reward_pct   | -37.5     |\n",
      "|    total_trades       | 4203      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | 10.9      |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.19e+05  |\n",
      "|    total_cost         | 4.39e+03  |\n",
      "|    total_reward       | -8.09e+04 |\n",
      "|    total_reward_pct   | -16.2     |\n",
      "|    total_trades       | 4362      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 19.1      |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 0.43      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.27e+05 |\n",
      "|    total_cost         | 9.08e+03 |\n",
      "|    total_reward       | 1.27e+05 |\n",
      "|    total_reward_pct   | 25.3     |\n",
      "|    total_trades       | 4278     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 14.5     |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.265    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.73e+05  |\n",
      "|    total_cost         | 1.67e+04  |\n",
      "|    total_reward       | 2.73e+05  |\n",
      "|    total_reward_pct   | 54.6      |\n",
      "|    total_trades       | 4300      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -1.8      |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 0.111     |\n",
      "-------------------------------------\n",
      "day: 501, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 745327.53\n",
      "total_reward: 245327.53\n",
      "total_cost: 10923.93\n",
      "total_trades: 4317\n",
      "Sharpe: 0.992\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.45e+05 |\n",
      "|    total_cost         | 1.09e+04 |\n",
      "|    total_reward       | 2.45e+05 |\n",
      "|    total_reward_pct   | 49.1     |\n",
      "|    total_trades       | 4317     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -0.461   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -24.4    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.699    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.62e+05  |\n",
      "|    total_cost         | 4.37e+03  |\n",
      "|    total_reward       | -1.38e+05 |\n",
      "|    total_reward_pct   | -27.6     |\n",
      "|    total_trades       | 4218      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.4     |\n",
      "|    explained_variance | -0.492    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | -16.1     |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.265     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.57e+05  |\n",
      "|    total_cost         | 5.2e+03   |\n",
      "|    total_reward       | -1.43e+05 |\n",
      "|    total_reward_pct   | -28.5     |\n",
      "|    total_trades       | 4232      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.261     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.17e+05  |\n",
      "|    total_cost         | 5.36e+03  |\n",
      "|    total_reward       | -1.83e+05 |\n",
      "|    total_reward_pct   | -36.7     |\n",
      "|    total_trades       | 4219      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 0.172     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.49e+05  |\n",
      "|    total_cost         | 3.99e+03  |\n",
      "|    total_reward       | -1.51e+05 |\n",
      "|    total_reward_pct   | -30.1     |\n",
      "|    total_trades       | 4163      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 14.6      |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 0.3       |\n",
      "-------------------------------------\n",
      "day: 501, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 361691.84\n",
      "total_reward: -138308.16\n",
      "total_cost: 4015.98\n",
      "total_trades: 4122\n",
      "Sharpe: -0.351\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.62e+05  |\n",
      "|    total_cost         | 4.02e+03  |\n",
      "|    total_reward       | -1.38e+05 |\n",
      "|    total_reward_pct   | -27.7     |\n",
      "|    total_trades       | 4122      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | 8.44      |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 0.0965    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.54e+05  |\n",
      "|    total_cost         | 6.16e+03  |\n",
      "|    total_reward       | -1.46e+05 |\n",
      "|    total_reward_pct   | -29.3     |\n",
      "|    total_trades       | 4197      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.7     |\n",
      "|    explained_variance | -4.11     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 19.5      |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 1.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.29e+05 |\n",
      "|    total_cost         | 1.42e+04 |\n",
      "|    total_reward       | 2.29e+05 |\n",
      "|    total_reward_pct   | 45.7     |\n",
      "|    total_trades       | 4197     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | -40.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 57.9     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 3.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.84e+05  |\n",
      "|    total_cost         | 5.14e+03  |\n",
      "|    total_reward       | -2.16e+05 |\n",
      "|    total_reward_pct   | -43.3     |\n",
      "|    total_trades       | 4064      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.8     |\n",
      "|    explained_variance | 0.182     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | -2.13     |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 0.0285    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.26e+05  |\n",
      "|    total_cost         | 7.31e+03  |\n",
      "|    total_reward       | -7.44e+04 |\n",
      "|    total_reward_pct   | -14.9     |\n",
      "|    total_trades       | 4084      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.8     |\n",
      "|    explained_variance | -0.0874   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -7.5      |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 0.0611    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 279894.83\n",
      "total_reward: -220105.17\n",
      "total_cost: 8261.81\n",
      "total_trades: 4235\n",
      "Sharpe: -0.489\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+05  |\n",
      "|    total_cost         | 8.26e+03 |\n",
      "|    total_reward       | -2.2e+05 |\n",
      "|    total_reward_pct   | -44      |\n",
      "|    total_trades       | 4235     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0.0804   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.89e+05 |\n",
      "|    total_cost         | 1.55e+04 |\n",
      "|    total_reward       | 1.89e+05 |\n",
      "|    total_reward_pct   | 37.7     |\n",
      "|    total_trades       | 4168     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | -0.383   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 11.2     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.92e+05  |\n",
      "|    total_cost         | 7.53e+03  |\n",
      "|    total_reward       | -7.95e+03 |\n",
      "|    total_reward_pct   | -1.59     |\n",
      "|    total_trades       | 4298      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.9     |\n",
      "|    explained_variance | -0.115    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.119     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.33e+05  |\n",
      "|    total_cost         | 1.03e+04  |\n",
      "|    total_reward       | -6.74e+04 |\n",
      "|    total_reward_pct   | -13.5     |\n",
      "|    total_trades       | 4346      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34       |\n",
      "|    explained_variance | 0.0294    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -2.41     |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.0184    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.93e+05  |\n",
      "|    total_cost         | 8.21e+03  |\n",
      "|    total_reward       | -1.07e+05 |\n",
      "|    total_reward_pct   | -21.4     |\n",
      "|    total_trades       | 4246      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34       |\n",
      "|    explained_variance | 0.215     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 6.88      |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.0768    |\n",
      "-------------------------------------\n",
      "day: 501, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 441677.26\n",
      "total_reward: -58322.74\n",
      "total_cost: 7694.59\n",
      "total_trades: 4197\n",
      "Sharpe: -0.062\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.42e+05  |\n",
      "|    total_cost         | 7.69e+03  |\n",
      "|    total_reward       | -5.83e+04 |\n",
      "|    total_reward_pct   | -11.7     |\n",
      "|    total_trades       | 4197      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34       |\n",
      "|    explained_variance | -0.000255 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | 16        |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.369     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.4e+05  |\n",
      "|    total_cost         | 2.59e+04 |\n",
      "|    total_reward       | 3.4e+05  |\n",
      "|    total_reward_pct   | 67.9     |\n",
      "|    total_trades       | 4359     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -9.78    |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.184    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.7e+05  |\n",
      "|    total_cost         | 1.55e+04 |\n",
      "|    total_reward       | 7.04e+04 |\n",
      "|    total_reward_pct   | 14.1     |\n",
      "|    total_trades       | 4386     |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0.00466  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.74     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.99e+05  |\n",
      "|    total_cost         | 1.02e+04  |\n",
      "|    total_reward       | -1.01e+05 |\n",
      "|    total_reward_pct   | -20.2     |\n",
      "|    total_trades       | 4437      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 181       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 25.6      |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 0.575     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.83e+05  |\n",
      "|    total_cost         | 5.99e+03  |\n",
      "|    total_reward       | -2.17e+05 |\n",
      "|    total_reward_pct   | -43.4     |\n",
      "|    total_trades       | 4354      |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.2     |\n",
      "|    explained_variance | 0.076     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -11.4     |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 0.307     |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-01-03 to  2020-04-06\n",
      "A2C Sharpe Ratio:  nan\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.1e+05  |\n",
      "|    total_cost       | 1.79e+05 |\n",
      "|    total_reward     | -2.9e+05 |\n",
      "|    total_reward_pct | -58      |\n",
      "|    total_trades     | 7112     |\n",
      "| time/               |          |\n",
      "|    fps              | 767      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "day: 501, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 225097.16\n",
      "total_reward: -274902.84\n",
      "total_cost: 231521.84\n",
      "total_trades: 7313\n",
      "Sharpe: -1.557\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.91e+05   |\n",
      "|    total_cost           | 3.97e+05   |\n",
      "|    total_reward         | 9.08e+04   |\n",
      "|    total_reward_pct     | 18.2       |\n",
      "|    total_trades         | 7581       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 716        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02068267 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | -0.104     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.226      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.39       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 249761.27\n",
      "total_reward: -250238.73\n",
      "total_cost: 196947.66\n",
      "total_trades: 6981\n",
      "Sharpe: -0.812\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2e+05       |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | -3e+05      |\n",
      "|    total_reward_pct     | -60.1       |\n",
      "|    total_trades         | 6993        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009706734 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0224      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.623       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 202619.15\n",
      "total_reward: -297380.85\n",
      "total_cost: 185290.89\n",
      "total_trades: 7040\n",
      "Sharpe: -1.037\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.51e+05   |\n",
      "|    total_cost           | 1.54e+05   |\n",
      "|    total_reward         | -3.49e+05  |\n",
      "|    total_reward_pct     | -69.9      |\n",
      "|    total_trades         | 6953       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 694        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01314097 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0928    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.32       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 489640.18\n",
      "total_reward: -10359.82\n",
      "total_cost: 392724.60\n",
      "total_trades: 7613\n",
      "Sharpe: 0.076\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.9e+05    |\n",
      "|    total_cost           | 3.93e+05   |\n",
      "|    total_reward         | -1.04e+04  |\n",
      "|    total_reward_pct     | -2.07      |\n",
      "|    total_trades         | 7613       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 689        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01254435 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0077    |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.46       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.14e+05    |\n",
      "|    total_cost           | 3.08e+05    |\n",
      "|    total_reward         | -8.55e+04   |\n",
      "|    total_reward_pct     | -17.1       |\n",
      "|    total_trades         | 7373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008856183 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 275509.94\n",
      "total_reward: -224490.06\n",
      "total_cost: 224141.52\n",
      "total_trades: 7134\n",
      "Sharpe: -0.617\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.42e+05    |\n",
      "|    total_cost           | 3.64e+05    |\n",
      "|    total_reward         | -5.8e+04    |\n",
      "|    total_reward_pct     | -11.6       |\n",
      "|    total_trades         | 7466        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015729921 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.377       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 387324.36\n",
      "total_reward: -112675.64\n",
      "total_cost: 276840.91\n",
      "total_trades: 7404\n",
      "Sharpe: -0.457\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.23e+05    |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | -1.77e+05   |\n",
      "|    total_reward_pct     | -35.4       |\n",
      "|    total_trades         | 7227        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014248728 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 562123.29\n",
      "total_reward: 62123.29\n",
      "total_cost: 347784.53\n",
      "total_trades: 7183\n",
      "Sharpe: 0.340\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+05    |\n",
      "|    total_cost           | 1.82e+05    |\n",
      "|    total_reward         | -3.18e+05   |\n",
      "|    total_reward_pct     | -63.6       |\n",
      "|    total_trades         | 7114        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021135569 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.674       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.67        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 218071.69\n",
      "total_reward: -281928.31\n",
      "total_cost: 187923.37\n",
      "total_trades: 6978\n",
      "Sharpe: -1.100\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+05    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | -2.82e+05   |\n",
      "|    total_reward_pct     | -56.4       |\n",
      "|    total_trades         | 6978        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014479544 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.491       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.14e+05     |\n",
      "|    total_cost           | 2.6e+05      |\n",
      "|    total_reward         | -1.86e+05    |\n",
      "|    total_reward_pct     | -37.2        |\n",
      "|    total_trades         | 7092         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 680          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118827745 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.189        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0202      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "day: 501, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 151810.89\n",
      "total_reward: -348189.11\n",
      "total_cost: 160262.50\n",
      "total_trades: 7055\n",
      "Sharpe: -1.099\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 6.24e+05     |\n",
      "|    total_cost           | 3.69e+05     |\n",
      "|    total_reward         | 1.24e+05     |\n",
      "|    total_reward_pct     | 24.8         |\n",
      "|    total_trades         | 7570         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 680          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104898345 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.352        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.19         |\n",
      "------------------------------------------\n",
      "day: 501, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 367518.67\n",
      "total_reward: -132481.33\n",
      "total_cost: 274345.33\n",
      "total_trades: 7144\n",
      "Sharpe: -0.677\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.85e+05  |\n",
      "|    total_cost           | 2.96e+05  |\n",
      "|    total_reward         | -1.15e+05 |\n",
      "|    total_reward_pct     | -22.9     |\n",
      "|    total_trades         | 7326      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 679       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0217803 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.3     |\n",
      "|    explained_variance   | 0.191     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.363     |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -0.0159   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 1.81      |\n",
      "---------------------------------------\n",
      "day: 501, episode: 255\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 308353.94\n",
      "total_reward: -191646.06\n",
      "total_cost: 197825.16\n",
      "total_trades: 7218\n",
      "Sharpe: -0.412\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.25e+05    |\n",
      "|    total_cost           | 3.05e+05    |\n",
      "|    total_reward         | -7.49e+04   |\n",
      "|    total_reward_pct     | -15         |\n",
      "|    total_trades         | 7390        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017184291 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.825       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 260\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 319631.40\n",
      "total_reward: -180368.60\n",
      "total_cost: 205014.48\n",
      "total_trades: 7231\n",
      "Sharpe: -0.441\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.1e+05     |\n",
      "|    total_cost           | 3.28e+05    |\n",
      "|    total_reward         | 1.1e+05     |\n",
      "|    total_reward_pct     | 22.1        |\n",
      "|    total_trades         | 7259        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016112395 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 265\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 550229.60\n",
      "total_reward: 50229.60\n",
      "total_cost: 325303.73\n",
      "total_trades: 7406\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.5e+05     |\n",
      "|    total_cost           | 3.25e+05    |\n",
      "|    total_reward         | 5.02e+04    |\n",
      "|    total_reward_pct     | 10          |\n",
      "|    total_trades         | 7406        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 679         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019343019 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.561       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.31        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.9e+05    |\n",
      "|    total_cost           | 3.87e+05   |\n",
      "|    total_reward         | 1.9e+05    |\n",
      "|    total_reward_pct     | 37.9       |\n",
      "|    total_trades         | 7448       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 679        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02439937 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.19       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.32       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 2.48       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 270\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 225834.61\n",
      "total_reward: -274165.39\n",
      "total_cost: 155934.99\n",
      "total_trades: 6796\n",
      "Sharpe: -0.840\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.9e+05    |\n",
      "|    total_cost           | 2.23e+05   |\n",
      "|    total_reward         | -2.1e+05   |\n",
      "|    total_reward_pct     | -42.1      |\n",
      "|    total_trades         | 7152       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 678        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02342876 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.09       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 3.08       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 275\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 177837.50\n",
      "total_reward: -322162.50\n",
      "total_cost: 142237.64\n",
      "total_trades: 6878\n",
      "Sharpe: -0.977\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.98e+05    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | -1.02e+05   |\n",
      "|    total_reward_pct     | -20.5       |\n",
      "|    total_trades         | 6941        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020649973 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 280\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 229785.35\n",
      "total_reward: -270214.65\n",
      "total_cost: 147967.53\n",
      "total_trades: 6878\n",
      "Sharpe: -0.593\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.85e+05   |\n",
      "|    total_cost           | 2.29e+05   |\n",
      "|    total_reward         | -1.15e+05  |\n",
      "|    total_reward_pct     | -23        |\n",
      "|    total_trades         | 7083       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 677        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02089503 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.313      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.71       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.34       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 285\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 353091.35\n",
      "total_reward: -146908.65\n",
      "total_cost: 197143.60\n",
      "total_trades: 7119\n",
      "Sharpe: -0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.53e+05    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | -1.47e+05   |\n",
      "|    total_reward_pct     | -29.4       |\n",
      "|    total_trades         | 7119        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021331765 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.26        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.09e+05    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | -1.91e+05   |\n",
      "|    total_reward_pct     | -38.3       |\n",
      "|    total_trades         | 6937        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020699851 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.382       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 290\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 348499.41\n",
      "total_reward: -151500.59\n",
      "total_cost: 210910.52\n",
      "total_trades: 6959\n",
      "Sharpe: -0.459\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.1e+05    |\n",
      "|    total_cost           | 2.26e+05   |\n",
      "|    total_reward         | -1.9e+05   |\n",
      "|    total_reward_pct     | -38.1      |\n",
      "|    total_trades         | 7092       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 676        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02345509 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.577      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.75       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 295\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 440129.94\n",
      "total_reward: -59870.06\n",
      "total_cost: 228756.37\n",
      "total_trades: 6902\n",
      "Sharpe: -0.026\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.28e+05    |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | -7.16e+04   |\n",
      "|    total_reward_pct     | -14.3       |\n",
      "|    total_trades         | 7001        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018583454 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.285       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 300\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 268120.92\n",
      "total_reward: -231879.08\n",
      "total_cost: 155762.46\n",
      "total_trades: 6980\n",
      "Sharpe: -0.510\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+05    |\n",
      "|    total_cost           | 1.59e+05    |\n",
      "|    total_reward         | -2.94e+05   |\n",
      "|    total_reward_pct     | -58.8       |\n",
      "|    total_trades         | 6758        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027767606 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.95        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 305\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 442563.78\n",
      "total_reward: -57436.22\n",
      "total_cost: 216815.02\n",
      "total_trades: 7095\n",
      "Sharpe: -0.007\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.73e+05   |\n",
      "|    total_cost           | 3.08e+05   |\n",
      "|    total_reward         | 1.73e+05   |\n",
      "|    total_reward_pct     | 34.6       |\n",
      "|    total_trades         | 7283       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 676        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01634255 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.4        |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 2.51       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 310\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 585815.41\n",
      "total_reward: 85815.41\n",
      "total_cost: 277973.06\n",
      "total_trades: 7297\n",
      "Sharpe: 0.501\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.86e+05    |\n",
      "|    total_cost           | 2.78e+05    |\n",
      "|    total_reward         | 8.58e+04    |\n",
      "|    total_reward_pct     | 17.2        |\n",
      "|    total_trades         | 7297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022866521 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.67e+05    |\n",
      "|    total_cost           | 2.42e+05    |\n",
      "|    total_reward         | -3.3e+04    |\n",
      "|    total_reward_pct     | -6.59       |\n",
      "|    total_trades         | 7025        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018320408 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.64        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.34        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 315\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 310039.17\n",
      "total_reward: -189960.83\n",
      "total_cost: 206161.07\n",
      "total_trades: 7056\n",
      "Sharpe: -0.610\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.29e+05    |\n",
      "|    total_cost           | 2.54e+05    |\n",
      "|    total_reward         | 2.88e+04    |\n",
      "|    total_reward_pct     | 5.77        |\n",
      "|    total_trades         | 7156        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021063004 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.408       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 320\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 943554.21\n",
      "total_reward: 443554.21\n",
      "total_cost: 316228.80\n",
      "total_trades: 7303\n",
      "Sharpe: 1.181\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.95e+05    |\n",
      "|    total_cost           | 2.87e+05    |\n",
      "|    total_reward         | 1.95e+05    |\n",
      "|    total_reward_pct     | 38.9        |\n",
      "|    total_trades         | 7247        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018046197 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.266       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 325\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 581029.18\n",
      "total_reward: 81029.18\n",
      "total_cost: 212061.38\n",
      "total_trades: 7047\n",
      "Sharpe: 0.455\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.94e+05    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | -6.39e+03   |\n",
      "|    total_reward_pct     | -1.28       |\n",
      "|    total_trades         | 7159        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020732427 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 330\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 550864.13\n",
      "total_reward: 50864.13\n",
      "total_cost: 210831.33\n",
      "total_trades: 7185\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.51e+05   |\n",
      "|    total_cost           | 2.11e+05   |\n",
      "|    total_reward         | 5.09e+04   |\n",
      "|    total_reward_pct     | 10.2       |\n",
      "|    total_trades         | 7185       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 675        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02149627 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.282      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.865      |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 2.71       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.66e+05    |\n",
      "|    total_cost           | 3.34e+05    |\n",
      "|    total_reward         | 2.66e+05    |\n",
      "|    total_reward_pct     | 53.3        |\n",
      "|    total_trades         | 7090        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017230727 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.906       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 335\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 329779.92\n",
      "total_reward: -170220.08\n",
      "total_cost: 198690.71\n",
      "total_trades: 6967\n",
      "Sharpe: -0.502\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.9e+05    |\n",
      "|    total_cost           | 1.94e+05   |\n",
      "|    total_reward         | -1.1e+05   |\n",
      "|    total_reward_pct     | -22        |\n",
      "|    total_trades         | 7107       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 674        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01695434 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.317      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.08       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00895   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 2.99       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 340\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 691499.27\n",
      "total_reward: 191499.27\n",
      "total_cost: 277150.22\n",
      "total_trades: 7175\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.83e+05    |\n",
      "|    total_cost           | 2.01e+05    |\n",
      "|    total_reward         | 8.3e+04     |\n",
      "|    total_reward_pct     | 16.6        |\n",
      "|    total_trades         | 6994        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032696024 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.829       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 2.88        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 345\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 443705.35\n",
      "total_reward: -56294.65\n",
      "total_cost: 200377.66\n",
      "total_trades: 6982\n",
      "Sharpe: -0.041\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.73e+05   |\n",
      "|    total_cost           | 2.63e+05   |\n",
      "|    total_reward         | 2.73e+05   |\n",
      "|    total_reward_pct     | 54.6       |\n",
      "|    total_trades         | 7051       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 675        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 109        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02460711 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.375      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.7        |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 5.29       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 350\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 725218.74\n",
      "total_reward: 225218.74\n",
      "total_cost: 209899.41\n",
      "total_trades: 7045\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.25e+05    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | 2.25e+05    |\n",
      "|    total_reward_pct     | 45          |\n",
      "|    total_trades         | 7045        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022306845 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.06        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 355\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 763991.82\n",
      "total_reward: 263991.82\n",
      "total_cost: 253094.32\n",
      "total_trades: 7173\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.64e+05    |\n",
      "|    total_cost           | 2.53e+05    |\n",
      "|    total_reward         | 2.64e+05    |\n",
      "|    total_reward_pct     | 52.8        |\n",
      "|    total_trades         | 7173        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018148843 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+06    |\n",
      "|    total_cost           | 3.07e+05    |\n",
      "|    total_reward         | 5.29e+05    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 7340        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012553393 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 360\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 628238.92\n",
      "total_reward: 128238.92\n",
      "total_cost: 229430.33\n",
      "total_trades: 7052\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.56e+05    |\n",
      "|    total_cost           | 2.33e+05    |\n",
      "|    total_reward         | 1.56e+05    |\n",
      "|    total_reward_pct     | 31.2        |\n",
      "|    total_trades         | 6983        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025471829 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.02        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.79        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 365\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 330634.71\n",
      "total_reward: -169365.29\n",
      "total_cost: 171715.29\n",
      "total_trades: 6988\n",
      "Sharpe: -0.397\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.05e+05    |\n",
      "|    total_cost           | 2.35e+05    |\n",
      "|    total_reward         | -9.54e+04   |\n",
      "|    total_reward_pct     | -19.1       |\n",
      "|    total_trades         | 7108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023777917 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.68        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 370\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 929116.44\n",
      "total_reward: 429116.44\n",
      "total_cost: 308043.13\n",
      "total_trades: 7207\n",
      "Sharpe: 1.212\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.58e+05   |\n",
      "|    total_cost           | 2.77e+05   |\n",
      "|    total_reward         | 2.58e+05   |\n",
      "|    total_reward_pct     | 51.6       |\n",
      "|    total_trades         | 7119       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 674        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02517436 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.529      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.99       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 3.31       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 375\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 737706.84\n",
      "total_reward: 237706.84\n",
      "total_cost: 297990.32\n",
      "total_trades: 7131\n",
      "Sharpe: 0.799\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.38e+05    |\n",
      "|    total_cost           | 2.98e+05    |\n",
      "|    total_reward         | 2.38e+05    |\n",
      "|    total_reward_pct     | 47.5        |\n",
      "|    total_trades         | 7131        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020704526 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.11e+06    |\n",
      "|    total_cost           | 2.8e+05     |\n",
      "|    total_reward         | 6.1e+05     |\n",
      "|    total_reward_pct     | 122         |\n",
      "|    total_trades         | 7212        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026992435 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.84        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 380\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 729397.84\n",
      "total_reward: 229397.84\n",
      "total_cost: 228271.92\n",
      "total_trades: 6996\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.36e+05    |\n",
      "|    total_cost           | 2.66e+05    |\n",
      "|    total_reward         | 2.36e+05    |\n",
      "|    total_reward_pct     | 47.2        |\n",
      "|    total_trades         | 6964        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026412107 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.51        |\n",
      "-----------------------------------------\n",
      "day: 501, episode: 385\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 477751.01\n",
      "total_reward: -22248.99\n",
      "total_cost: 182797.42\n",
      "total_trades: 6847\n",
      "Sharpe: 0.128\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.11e+06   |\n",
      "|    total_cost           | 2.39e+05   |\n",
      "|    total_reward         | 6.08e+05   |\n",
      "|    total_reward_pct     | 122        |\n",
      "|    total_trades         | 7033       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 675        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 139        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02223258 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.43       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 3.9        |\n",
      "----------------------------------------\n",
      "day: 501, episode: 390\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 349221.35\n",
      "total_reward: -150778.65\n",
      "total_cost: 144797.63\n",
      "total_trades: 6618\n",
      "Sharpe: -0.210\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.73e+05   |\n",
      "|    total_cost           | 2.32e+05   |\n",
      "|    total_reward         | 4.73e+05   |\n",
      "|    total_reward_pct     | 94.6       |\n",
      "|    total_trades         | 6928       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 675        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02402639 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.47       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00694   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 5.21       |\n",
      "----------------------------------------\n",
      "day: 501, episode: 395\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 945934.44\n",
      "total_reward: 445934.44\n",
      "total_cost: 290210.76\n",
      "total_trades: 7171\n",
      "Sharpe: 1.217\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.46e+05   |\n",
      "|    total_cost           | 2.9e+05    |\n",
      "|    total_reward         | 4.46e+05   |\n",
      "|    total_reward_pct     | 89.2       |\n",
      "|    total_trades         | 7171       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 675        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 145        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02746949 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.48       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00342   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 5.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.18e+05    |\n",
      "|    total_cost           | 2.51e+05    |\n",
      "|    total_reward         | 3.18e+05    |\n",
      "|    total_reward_pct     | 63.6        |\n",
      "|    total_trades         | 7123        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023692694 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.3         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.98        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-01-03 to  2020-04-06\n",
      "PPO Sharpe Ratio:  nan\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.26e+05 |\n",
      "|    total_cost       | 5.17e+03 |\n",
      "|    total_reward     | 2.6e+04  |\n",
      "|    total_reward_pct | 5.2      |\n",
      "|    total_trades     | 4360     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 162      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 2008     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -76.3    |\n",
      "|    critic_loss      | 594      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 1506     |\n",
      "----------------------------------\n",
      "day: 501, episode: 405\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 525344.35\n",
      "total_reward: 25344.35\n",
      "total_cost: 2902.59\n",
      "total_trades: 4355\n",
      "Sharpe: 0.248\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.4e+05  |\n",
      "|    total_cost       | 2.99e+03 |\n",
      "|    total_reward     | 4e+04    |\n",
      "|    total_reward_pct | 7.99     |\n",
      "|    total_trades     | 4357     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total timesteps  | 4016     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -65.8    |\n",
      "|    critic_loss      | 221      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 3514     |\n",
      "----------------------------------\n",
      "day: 501, episode: 410\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 485897.22\n",
      "total_reward: -14102.78\n",
      "total_cost: 2885.28\n",
      "total_trades: 4357\n",
      "Sharpe: 0.099\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.74e+05  |\n",
      "|    total_cost       | 5.13e+03  |\n",
      "|    total_reward     | -2.59e+04 |\n",
      "|    total_reward_pct | -5.19     |\n",
      "|    total_trades     | 4361      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 137       |\n",
      "|    time_elapsed     | 43        |\n",
      "|    total timesteps  | 6024      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -59.7     |\n",
      "|    critic_loss      | 86.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 5522      |\n",
      "-----------------------------------\n",
      "day: 501, episode: 415\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 526787.47\n",
      "total_reward: 26787.47\n",
      "total_cost: 4109.09\n",
      "total_trades: 4357\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.27e+05 |\n",
      "|    total_cost       | 3e+03    |\n",
      "|    total_reward     | 2.68e+04 |\n",
      "|    total_reward_pct | 5.37     |\n",
      "|    total_trades     | 4356     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 134      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total timesteps  | 8032     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -53.8    |\n",
      "|    critic_loss      | 32       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7530     |\n",
      "----------------------------------\n",
      "day: 501, episode: 420\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 507486.98\n",
      "total_reward: 7486.98\n",
      "total_cost: 3305.95\n",
      "total_trades: 4353\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.07e+05 |\n",
      "|    total_cost       | 3.31e+03 |\n",
      "|    total_reward     | 7.49e+03 |\n",
      "|    total_reward_pct | 1.5      |\n",
      "|    total_trades     | 4353     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 133      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total timesteps  | 10040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -48.5    |\n",
      "|    critic_loss      | 19.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 9538     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.98e+05 |\n",
      "|    total_cost       | 2.16e+03 |\n",
      "|    total_reward     | 9.78e+04 |\n",
      "|    total_reward_pct | 19.6     |\n",
      "|    total_trades     | 4398     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 132      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total timesteps  | 12048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -43.7    |\n",
      "|    critic_loss      | 60.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11546    |\n",
      "----------------------------------\n",
      "day: 501, episode: 425\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 615573.45\n",
      "total_reward: 115573.45\n",
      "total_cost: 2108.27\n",
      "total_trades: 4394\n",
      "Sharpe: 0.520\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -940     |\n",
      "|    total_reward_pct | -0.188   |\n",
      "|    total_trades     | 4388     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total timesteps  | 14056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -39.5    |\n",
      "|    critic_loss      | 11.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13554    |\n",
      "----------------------------------\n",
      "day: 501, episode: 430\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 526106.82\n",
      "total_reward: 26106.82\n",
      "total_cost: 2226.76\n",
      "total_trades: 4396\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.57e+05 |\n",
      "|    total_cost       | 2.18e+03 |\n",
      "|    total_reward     | 5.69e+04 |\n",
      "|    total_reward_pct | 11.4     |\n",
      "|    total_trades     | 4398     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total timesteps  | 16064    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -35.6    |\n",
      "|    critic_loss      | 9.3      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15562    |\n",
      "----------------------------------\n",
      "day: 501, episode: 435\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 610692.93\n",
      "total_reward: 110692.93\n",
      "total_cost: 1967.75\n",
      "total_trades: 4390\n",
      "Sharpe: 0.514\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.42e+05 |\n",
      "|    total_cost       | 2.2e+03  |\n",
      "|    total_reward     | 4.15e+04 |\n",
      "|    total_reward_pct | 8.3      |\n",
      "|    total_trades     | 4396     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total timesteps  | 18072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -32.2    |\n",
      "|    critic_loss      | 5.73     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17570    |\n",
      "----------------------------------\n",
      "day: 501, episode: 440\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499160.07\n",
      "total_reward: -839.93\n",
      "total_cost: 1077.75\n",
      "total_trades: 4393\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 1.08e+03 |\n",
      "|    total_reward     | -840     |\n",
      "|    total_reward_pct | -0.168   |\n",
      "|    total_trades     | 4393     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total timesteps  | 20080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -29.2    |\n",
      "|    critic_loss      | 4.8      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19578    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -940     |\n",
      "|    total_reward_pct | -0.188   |\n",
      "|    total_trades     | 4389     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total timesteps  | 22088    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -26.4    |\n",
      "|    critic_loss      | 13       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 21586    |\n",
      "----------------------------------\n",
      "day: 501, episode: 445\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 525298.25\n",
      "total_reward: 25298.25\n",
      "total_cost: 2123.52\n",
      "total_trades: 4395\n",
      "Sharpe: 0.246\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.2e+05  |\n",
      "|    total_cost       | 2.11e+03 |\n",
      "|    total_reward     | 1.2e+05  |\n",
      "|    total_reward_pct | 24       |\n",
      "|    total_trades     | 4395     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total timesteps  | 24096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -23.9    |\n",
      "|    critic_loss      | 25.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 23594    |\n",
      "----------------------------------\n",
      "day: 501, episode: 450\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 525827.56\n",
      "total_reward: 25827.56\n",
      "total_cost: 2254.68\n",
      "total_trades: 4396\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -927     |\n",
      "|    total_reward_pct | -0.185   |\n",
      "|    total_trades     | 4389     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total timesteps  | 26104    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -21.6    |\n",
      "|    critic_loss      | 44.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25602    |\n",
      "----------------------------------\n",
      "day: 501, episode: 455\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 534059.35\n",
      "total_reward: 34059.35\n",
      "total_cost: 2194.78\n",
      "total_trades: 4394\n",
      "Sharpe: 0.277\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.14e+05 |\n",
      "|    total_cost       | 1.9e+03  |\n",
      "|    total_reward     | 1.14e+05 |\n",
      "|    total_reward_pct | 22.9     |\n",
      "|    total_trades     | 4390     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total timesteps  | 28112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -19.6    |\n",
      "|    critic_loss      | 49.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27610    |\n",
      "----------------------------------\n",
      "day: 501, episode: 460\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 480926.78\n",
      "total_reward: -19073.22\n",
      "total_cost: 1206.83\n",
      "total_trades: 4393\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.81e+05  |\n",
      "|    total_cost       | 1.21e+03  |\n",
      "|    total_reward     | -1.91e+04 |\n",
      "|    total_reward_pct | -3.81     |\n",
      "|    total_trades     | 4393      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 231       |\n",
      "|    total timesteps  | 30120     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -17.8     |\n",
      "|    critic_loss      | 4.85      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 29618     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -924     |\n",
      "|    total_reward_pct | -0.185   |\n",
      "|    total_trades     | 4389     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total timesteps  | 32128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -16.2    |\n",
      "|    critic_loss      | 1.62     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31626    |\n",
      "----------------------------------\n",
      "day: 501, episode: 465\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 614285.57\n",
      "total_reward: 114285.57\n",
      "total_cost: 1902.58\n",
      "total_trades: 4391\n",
      "Sharpe: 0.508\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.93e+05 |\n",
      "|    total_cost       | 2.17e+03 |\n",
      "|    total_reward     | 9.33e+04 |\n",
      "|    total_reward_pct | 18.7     |\n",
      "|    total_trades     | 4396     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total timesteps  | 34136    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -14.9    |\n",
      "|    critic_loss      | 14.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33634    |\n",
      "----------------------------------\n",
      "day: 501, episode: 470\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 594772.77\n",
      "total_reward: 94772.77\n",
      "total_cost: 2229.88\n",
      "total_trades: 4396\n",
      "Sharpe: 0.464\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.33e+05 |\n",
      "|    total_cost       | 2.17e+03 |\n",
      "|    total_reward     | 3.29e+04 |\n",
      "|    total_reward_pct | 6.59     |\n",
      "|    total_trades     | 4242     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total timesteps  | 36144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -13.7    |\n",
      "|    critic_loss      | 2.09     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35642    |\n",
      "----------------------------------\n",
      "day: 501, episode: 475\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 482686.60\n",
      "total_reward: -17313.40\n",
      "total_cost: 1343.85\n",
      "total_trades: 4391\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.9e+05  |\n",
      "|    total_cost       | 2.21e+03 |\n",
      "|    total_reward     | 8.98e+04 |\n",
      "|    total_reward_pct | 18       |\n",
      "|    total_trades     | 4392     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total timesteps  | 38152    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -12.6    |\n",
      "|    critic_loss      | 3.95     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37650    |\n",
      "----------------------------------\n",
      "day: 501, episode: 480\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 601590.83\n",
      "total_reward: 101590.83\n",
      "total_cost: 2238.04\n",
      "total_trades: 4394\n",
      "Sharpe: 0.481\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.02e+05 |\n",
      "|    total_cost       | 2.24e+03 |\n",
      "|    total_reward     | 1.02e+05 |\n",
      "|    total_reward_pct | 20.3     |\n",
      "|    total_trades     | 4394     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total timesteps  | 40160    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -11.6    |\n",
      "|    critic_loss      | 1.57     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39658    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.21e+05 |\n",
      "|    total_cost       | 2.2e+03  |\n",
      "|    total_reward     | 2.1e+04  |\n",
      "|    total_reward_pct | 4.2      |\n",
      "|    total_trades     | 4394     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total timesteps  | 42168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -10.8    |\n",
      "|    critic_loss      | 0.747    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41666    |\n",
      "----------------------------------\n",
      "day: 501, episode: 485\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 519764.02\n",
      "total_reward: 19764.02\n",
      "total_cost: 2251.23\n",
      "total_trades: 4392\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.03e+05 |\n",
      "|    total_cost       | 2.19e+03 |\n",
      "|    total_reward     | 1.03e+05 |\n",
      "|    total_reward_pct | 20.6     |\n",
      "|    total_trades     | 4393     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total timesteps  | 44176    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -10.1    |\n",
      "|    critic_loss      | 21.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43674    |\n",
      "----------------------------------\n",
      "day: 501, episode: 490\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 608955.36\n",
      "total_reward: 108955.36\n",
      "total_cost: 1948.13\n",
      "total_trades: 4391\n",
      "Sharpe: 0.502\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.08e+05 |\n",
      "|    total_cost       | 1.96e+03 |\n",
      "|    total_reward     | 1.08e+05 |\n",
      "|    total_reward_pct | 21.6     |\n",
      "|    total_trades     | 4392     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total timesteps  | 46184    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -9.38    |\n",
      "|    critic_loss      | 0.65     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45682    |\n",
      "----------------------------------\n",
      "day: 501, episode: 495\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 479285.83\n",
      "total_reward: -20714.17\n",
      "total_cost: 1247.84\n",
      "total_trades: 4394\n",
      "Sharpe: 0.150\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.08e+05 |\n",
      "|    total_cost       | 2.07e+03 |\n",
      "|    total_reward     | 1.08e+05 |\n",
      "|    total_reward_pct | 21.5     |\n",
      "|    total_trades     | 4391     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 372      |\n",
      "|    total timesteps  | 48192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.81    |\n",
      "|    critic_loss      | 1.36     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47690    |\n",
      "----------------------------------\n",
      "day: 501, episode: 500\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 609755.94\n",
      "total_reward: 109755.94\n",
      "total_cost: 2011.57\n",
      "total_trades: 4392\n",
      "Sharpe: 0.522\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.1e+05  |\n",
      "|    total_cost       | 2.01e+03 |\n",
      "|    total_reward     | 1.1e+05  |\n",
      "|    total_reward_pct | 22       |\n",
      "|    total_trades     | 4392     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 388      |\n",
      "|    total timesteps  | 50200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.32    |\n",
      "|    critic_loss      | 1.54     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49698    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-01-03 to  2020-04-06\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-04-06\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_378_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.64e+05  |\n",
      "|    total_cost       | 1.7e+03   |\n",
      "|    total_reward     | -3.56e+04 |\n",
      "|    total_reward_pct | -7.12     |\n",
      "|    total_trades     | 6041      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 160       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total timesteps  | 2260      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 136       |\n",
      "|    critic_loss      | 344       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 1695      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 466611.63\n",
      "total_reward: -33388.37\n",
      "total_cost: 1407.10\n",
      "total_trades: 6052\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.7e+05   |\n",
      "|    total_cost       | 1.38e+03  |\n",
      "|    total_reward     | -3.05e+04 |\n",
      "|    total_reward_pct | -6.09     |\n",
      "|    total_trades     | 6360      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 142       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total timesteps  | 4520      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 123       |\n",
      "|    critic_loss      | 123       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 3955      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 467270.06\n",
      "total_reward: -32729.94\n",
      "total_cost: 1750.86\n",
      "total_trades: 6368\n",
      "Sharpe: 0.067\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.55e+05  |\n",
      "|    total_cost       | 1.5e+03   |\n",
      "|    total_reward     | -4.52e+04 |\n",
      "|    total_reward_pct | -9.05     |\n",
      "|    total_trades     | 6364      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 136       |\n",
      "|    time_elapsed     | 49        |\n",
      "|    total timesteps  | 6780      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 108       |\n",
      "|    critic_loss      | 50.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6215      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 486566.55\n",
      "total_reward: -13433.45\n",
      "total_cost: 1631.26\n",
      "total_trades: 6323\n",
      "Sharpe: 0.134\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.81e+05  |\n",
      "|    total_cost       | 1.45e+03  |\n",
      "|    total_reward     | -1.93e+04 |\n",
      "|    total_reward_pct | -3.85     |\n",
      "|    total_trades     | 6324      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 134       |\n",
      "|    time_elapsed     | 67        |\n",
      "|    total timesteps  | 9040      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 94.7      |\n",
      "|    critic_loss      | 38.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 8475      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 471212.81\n",
      "total_reward: -28787.19\n",
      "total_cost: 1194.24\n",
      "total_trades: 6320\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.71e+05  |\n",
      "|    total_cost       | 1.19e+03  |\n",
      "|    total_reward     | -2.88e+04 |\n",
      "|    total_reward_pct | -5.76     |\n",
      "|    total_trades     | 6320      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 85        |\n",
      "|    total timesteps  | 11300     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 82.6      |\n",
      "|    critic_loss      | 13.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 10735     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.6e+05   |\n",
      "|    total_cost       | 1.29e+03  |\n",
      "|    total_reward     | -3.97e+04 |\n",
      "|    total_reward_pct | -7.93     |\n",
      "|    total_trades     | 6618      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 102       |\n",
      "|    total timesteps  | 13560     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 72        |\n",
      "|    critic_loss      | 9.24      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 12995     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 464167.97\n",
      "total_reward: -35832.03\n",
      "total_cost: 1221.55\n",
      "total_trades: 6616\n",
      "Sharpe: 0.051\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.61e+05  |\n",
      "|    total_cost       | 1.29e+03  |\n",
      "|    total_reward     | -3.86e+04 |\n",
      "|    total_reward_pct | -7.72     |\n",
      "|    total_trades     | 6611      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 120       |\n",
      "|    total timesteps  | 15820     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 62.7      |\n",
      "|    critic_loss      | 6.79      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 15255     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 448255.52\n",
      "total_reward: -51744.48\n",
      "total_cost: 1337.30\n",
      "total_trades: 6613\n",
      "Sharpe: 0.003\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.6e+05   |\n",
      "|    total_cost       | 1.29e+03  |\n",
      "|    total_reward     | -3.98e+04 |\n",
      "|    total_reward_pct | -7.95     |\n",
      "|    total_trades     | 6612      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 138       |\n",
      "|    total timesteps  | 18080     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 54.7      |\n",
      "|    critic_loss      | 4.86      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17515     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 455128.58\n",
      "total_reward: -44871.42\n",
      "total_cost: 1298.96\n",
      "total_trades: 6613\n",
      "Sharpe: 0.030\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.71e+05  |\n",
      "|    total_cost       | 1.19e+03  |\n",
      "|    total_reward     | -2.89e+04 |\n",
      "|    total_reward_pct | -5.78     |\n",
      "|    total_trades     | 6610      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 155       |\n",
      "|    total timesteps  | 20340     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 47.6      |\n",
      "|    critic_loss      | 12.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 19775     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499051.80\n",
      "total_reward: -948.20\n",
      "total_cost: 948.20\n",
      "total_trades: 6628\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -948     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 6628     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total timesteps  | 22600    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 41.5     |\n",
      "|    critic_loss      | 1.99     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 22035    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -949     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 6663     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total timesteps  | 24860    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 36.2     |\n",
      "|    critic_loss      | 1.7      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24295    |\n",
      "----------------------------------\n",
      "day: 564, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 459826.20\n",
      "total_reward: -40173.80\n",
      "total_cost: 1290.85\n",
      "total_trades: 6605\n",
      "Sharpe: 0.012\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.6e+05   |\n",
      "|    total_cost       | 1.29e+03  |\n",
      "|    total_reward     | -4.01e+04 |\n",
      "|    total_reward_pct | -8.01     |\n",
      "|    total_trades     | 6707      |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 209       |\n",
      "|    total timesteps  | 27120     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 31.5      |\n",
      "|    critic_loss      | 6.92      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 26555     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499112.90\n",
      "total_reward: -887.10\n",
      "total_cost: 948.20\n",
      "total_trades: 6704\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -948     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 7261     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total timesteps  | 29380    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 27.4     |\n",
      "|    critic_loss      | 14.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28815    |\n",
      "----------------------------------\n",
      "day: 564, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 465822.46\n",
      "total_reward: -34177.54\n",
      "total_cost: 1328.86\n",
      "total_trades: 7278\n",
      "Sharpe: 0.005\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.06e+05 |\n",
      "|    total_cost       | 998      |\n",
      "|    total_reward     | 6.35e+03 |\n",
      "|    total_reward_pct | 1.27     |\n",
      "|    total_trades     | 7270     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total timesteps  | 31640    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 23.8     |\n",
      "|    critic_loss      | 5.16     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 31075    |\n",
      "----------------------------------\n",
      "day: 564, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 453530.90\n",
      "total_reward: -46469.10\n",
      "total_cost: 1334.05\n",
      "total_trades: 7283\n",
      "Sharpe: 0.021\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.54e+05  |\n",
      "|    total_cost       | 1.33e+03  |\n",
      "|    total_reward     | -4.65e+04 |\n",
      "|    total_reward_pct | -9.29     |\n",
      "|    total_trades     | 7283      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 262       |\n",
      "|    total timesteps  | 33900     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 20.6      |\n",
      "|    critic_loss      | 2.61      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 33335     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 952       |\n",
      "|    total_reward     | -1.42e+03 |\n",
      "|    total_reward_pct | -0.285    |\n",
      "|    total_trades     | 7278      |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 280       |\n",
      "|    total timesteps  | 36160     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 17.9      |\n",
      "|    critic_loss      | 12        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 35595     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499944.63\n",
      "total_reward: -55.37\n",
      "total_cost: 968.09\n",
      "total_trades: 7278\n",
      "Sharpe: 0.154\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 952       |\n",
      "|    total_reward     | -1.34e+03 |\n",
      "|    total_reward_pct | -0.269    |\n",
      "|    total_trades     | 7285      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 297       |\n",
      "|    total timesteps  | 38420     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 15.5      |\n",
      "|    critic_loss      | 55.5      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37855     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 505594.70\n",
      "total_reward: 5594.70\n",
      "total_cost: 999.47\n",
      "total_trades: 7278\n",
      "Sharpe: 0.163\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.45e+05  |\n",
      "|    total_cost       | 1.3e+03   |\n",
      "|    total_reward     | -5.52e+04 |\n",
      "|    total_reward_pct | -11       |\n",
      "|    total_trades     | 7283      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 315       |\n",
      "|    total timesteps  | 40680     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 13.5      |\n",
      "|    critic_loss      | 2.96      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 40115     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 503528.49\n",
      "total_reward: 3528.49\n",
      "total_cost: 989.43\n",
      "total_trades: 6891\n",
      "Sharpe: 0.128\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.06e+05 |\n",
      "|    total_cost       | 998      |\n",
      "|    total_reward     | 6.11e+03 |\n",
      "|    total_reward_pct | 1.22     |\n",
      "|    total_trades     | 7276     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total timesteps  | 42940    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 12       |\n",
      "|    critic_loss      | 2.65     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 42375    |\n",
      "----------------------------------\n",
      "day: 564, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500079.90\n",
      "total_reward: 79.90\n",
      "total_cost: 963.82\n",
      "total_trades: 7276\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 964      |\n",
      "|    total_reward     | 79.9     |\n",
      "|    total_reward_pct | 0.016    |\n",
      "|    total_trades     | 7276     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total timesteps  | 45200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 10.2     |\n",
      "|    critic_loss      | 9.99     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.66e+05 |\n",
      "|    total_cost       | 1.34e+03 |\n",
      "|    total_reward     | -3.4e+04 |\n",
      "|    total_reward_pct | -6.8     |\n",
      "|    total_trades     | 7267     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total timesteps  | 47460    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 8.92     |\n",
      "|    critic_loss      | 6.31     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46895    |\n",
      "----------------------------------\n",
      "day: 564, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 504960.11\n",
      "total_reward: 4960.11\n",
      "total_cost: 995.21\n",
      "total_trades: 7244\n",
      "Sharpe: 0.170\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.06e+05 |\n",
      "|    total_cost       | 999      |\n",
      "|    total_reward     | 6.33e+03 |\n",
      "|    total_reward_pct | 1.27     |\n",
      "|    total_trades     | 7253     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 386      |\n",
      "|    total timesteps  | 49720    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 7.7      |\n",
      "|    critic_loss      | 15.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49155    |\n",
      "----------------------------------\n",
      "======Trading from:  2020-04-06 to  2020-07-09\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  0.0\n",
      "======Model training from:  2000-01-01 to  2020-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -6.03    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0587   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.67e+05  |\n",
      "|    total_cost         | 3e+05     |\n",
      "|    total_reward       | -2.33e+05 |\n",
      "|    total_reward_pct   | -46.5     |\n",
      "|    total_trades       | 7971      |\n",
      "| time/                 |           |\n",
      "|    fps                | 535       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27       |\n",
      "|    explained_variance | -0.104    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -4.69     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.0564    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.83e+05  |\n",
      "|    total_cost         | 1.74e+05  |\n",
      "|    total_reward       | -3.17e+05 |\n",
      "|    total_reward_pct   | -63.3     |\n",
      "|    total_trades       | 7540      |\n",
      "| time/                 |           |\n",
      "|    fps                | 535       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.924    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 16.2      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.388     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.91e+05  |\n",
      "|    total_cost         | 1.84e+05  |\n",
      "|    total_reward       | -3.09e+05 |\n",
      "|    total_reward_pct   | -61.8     |\n",
      "|    total_trades       | 7426      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.621    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 9.39      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.134     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.09e+05  |\n",
      "|    total_cost         | 2.19e+05  |\n",
      "|    total_reward       | -1.91e+05 |\n",
      "|    total_reward_pct   | -38.2     |\n",
      "|    total_trades       | 7512      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -29.9     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "day: 564, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500082.21\n",
      "total_reward: 82.21\n",
      "total_cost: 123363.40\n",
      "total_trades: 7305\n",
      "Sharpe: 0.100\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5e+05    |\n",
      "|    total_cost         | 1.23e+05 |\n",
      "|    total_reward       | 82.2     |\n",
      "|    total_reward_pct   | 0.0164   |\n",
      "|    total_trades       | 7305     |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.0771   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -15.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.462    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.16e+05  |\n",
      "|    total_cost         | 5.21e+04  |\n",
      "|    total_reward       | -2.84e+05 |\n",
      "|    total_reward_pct   | -56.7     |\n",
      "|    total_trades       | 7051      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0.104     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 18        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.692     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5e+05    |\n",
      "|    total_cost         | 3.49e+04 |\n",
      "|    total_reward       | -28.8    |\n",
      "|    total_reward_pct   | -0.00576 |\n",
      "|    total_trades       | 6880     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.879    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 532       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -153      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 30.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.17e+05  |\n",
      "|    total_cost         | 2.83e+04  |\n",
      "|    total_reward       | 1.17e+05  |\n",
      "|    total_reward_pct   | 23.4      |\n",
      "|    total_trades       | 6641      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 11.4      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.53      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.16e+05 |\n",
      "|    total_cost         | 3.58e+04 |\n",
      "|    total_reward       | 1.63e+04 |\n",
      "|    total_reward_pct   | 3.26     |\n",
      "|    total_trades       | 6906     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.00166  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 2.5      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.84     |\n",
      "------------------------------------\n",
      "day: 564, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 800114.41\n",
      "total_reward: 300114.41\n",
      "total_cost: 33020.16\n",
      "total_trades: 6894\n",
      "Sharpe: 0.817\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8e+05     |\n",
      "|    total_cost         | 3.3e+04   |\n",
      "|    total_reward       | 3e+05     |\n",
      "|    total_reward_pct   | 60        |\n",
      "|    total_trades       | 6894      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 68        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.04      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.98e+05 |\n",
      "|    total_cost         | 3.28e+04 |\n",
      "|    total_reward       | 2.98e+05 |\n",
      "|    total_reward_pct   | 59.6     |\n",
      "|    total_trades       | 6395     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0.0704   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.619    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.79e+05  |\n",
      "|    total_cost         | 3.76e+04  |\n",
      "|    total_reward       | -2.21e+05 |\n",
      "|    total_reward_pct   | -44.3     |\n",
      "|    total_trades       | 6274      |\n",
      "| time/                 |           |\n",
      "|    fps                | 534       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -5.59     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.124     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.72e+05  |\n",
      "|    total_cost         | 3.07e+04  |\n",
      "|    total_reward       | -2.8e+04  |\n",
      "|    total_reward_pct   | -5.61     |\n",
      "|    total_trades       | 6255      |\n",
      "| time/                 |           |\n",
      "|    fps                | 534       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -77.4     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 9.7       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+05  |\n",
      "|    total_cost         | 3.37e+04 |\n",
      "|    total_reward       | 4.1e+05  |\n",
      "|    total_reward_pct   | 82       |\n",
      "|    total_trades       | 6558     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -8.42    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.411    |\n",
      "------------------------------------\n",
      "day: 564, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 628904.94\n",
      "total_reward: 128904.94\n",
      "total_cost: 56810.22\n",
      "total_trades: 6795\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.29e+05 |\n",
      "|    total_cost         | 5.68e+04 |\n",
      "|    total_reward       | 1.29e+05 |\n",
      "|    total_reward_pct   | 25.8     |\n",
      "|    total_trades       | 6795     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.177   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -29.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.0294   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -30.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.85e+05 |\n",
      "|    total_cost         | 4.15e+04 |\n",
      "|    total_reward       | 1.85e+05 |\n",
      "|    total_reward_pct   | 37       |\n",
      "|    total_trades       | 6597     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -4.89    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.304    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.49e+05 |\n",
      "|    total_cost         | 4.07e+04 |\n",
      "|    total_reward       | 2.49e+05 |\n",
      "|    total_reward_pct   | 49.9     |\n",
      "|    total_trades       | 6513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -17.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.737    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.33e+05 |\n",
      "|    total_cost         | 2.22e+04 |\n",
      "|    total_reward       | 3.35e+04 |\n",
      "|    total_reward_pct   | 6.69     |\n",
      "|    total_trades       | 6095     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.283    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 19.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.597    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.81e+05 |\n",
      "|    total_cost         | 1.91e+04 |\n",
      "|    total_reward       | 1.81e+05 |\n",
      "|    total_reward_pct   | 36.2     |\n",
      "|    total_trades       | 5920     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.0379  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -8.82    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.363    |\n",
      "------------------------------------\n",
      "day: 564, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 629191.44\n",
      "total_reward: 129191.44\n",
      "total_cost: 23348.36\n",
      "total_trades: 6207\n",
      "Sharpe: 0.613\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.29e+05 |\n",
      "|    total_cost         | 2.33e+04 |\n",
      "|    total_reward       | 1.29e+05 |\n",
      "|    total_reward_pct   | 25.8     |\n",
      "|    total_trades       | 6207     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.00933 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -68.3    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.09e+05 |\n",
      "|    total_cost         | 2.46e+04 |\n",
      "|    total_reward       | 4.09e+05 |\n",
      "|    total_reward_pct   | 81.8     |\n",
      "|    total_trades       | 6001     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.021   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -1.28    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.5e+05  |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | -1.5e+05 |\n",
      "|    total_reward_pct   | -29.9    |\n",
      "|    total_trades       | 5989     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 10.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.924    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.25e+05  |\n",
      "|    total_cost         | 2.99e+04  |\n",
      "|    total_reward       | -1.75e+05 |\n",
      "|    total_reward_pct   | -35.1     |\n",
      "|    total_trades       | 5956      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | 0.261     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 41.3      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -1.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 14.1     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.6e+05  |\n",
      "|    total_cost         | 2.93e+04 |\n",
      "|    total_reward       | 2.6e+05  |\n",
      "|    total_reward_pct   | 52       |\n",
      "|    total_trades       | 5865     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -11.2    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.557    |\n",
      "------------------------------------\n",
      "day: 564, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 613968.42\n",
      "total_reward: 113968.42\n",
      "total_cost: 23213.16\n",
      "total_trades: 5907\n",
      "Sharpe: 0.544\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.14e+05 |\n",
      "|    total_cost         | 2.32e+04 |\n",
      "|    total_reward       | 1.14e+05 |\n",
      "|    total_reward_pct   | 22.8     |\n",
      "|    total_trades       | 5907     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.0417  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.446    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.92e+05 |\n",
      "|    total_cost         | 2.93e+04 |\n",
      "|    total_reward       | 9.17e+04 |\n",
      "|    total_reward_pct   | 18.3     |\n",
      "|    total_trades       | 5955     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -6.41    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.589    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.31e+05 |\n",
      "|    total_cost         | 1.84e+04 |\n",
      "|    total_reward       | 3.31e+05 |\n",
      "|    total_reward_pct   | 66.2     |\n",
      "|    total_trades       | 5807     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -30.4    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.76e+05 |\n",
      "|    total_cost         | 1.72e+04 |\n",
      "|    total_reward       | 3.76e+05 |\n",
      "|    total_reward_pct   | 75.1     |\n",
      "|    total_trades       | 5701     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 43.1     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.79e+05 |\n",
      "|    total_cost         | 2.24e+04 |\n",
      "|    total_reward       | 2.79e+05 |\n",
      "|    total_reward_pct   | 55.7     |\n",
      "|    total_trades       | 5866     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.308   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 32.5     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 5.31     |\n",
      "------------------------------------\n",
      "day: 564, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 858788.80\n",
      "total_reward: 358788.80\n",
      "total_cost: 10205.60\n",
      "total_trades: 5820\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.59e+05 |\n",
      "|    total_cost         | 1.02e+04 |\n",
      "|    total_reward       | 3.59e+05 |\n",
      "|    total_reward_pct   | 71.8     |\n",
      "|    total_trades       | 5820     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.00394  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -14.4    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -29.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.22e+05 |\n",
      "|    total_cost         | 1.37e+04 |\n",
      "|    total_reward       | 3.22e+05 |\n",
      "|    total_reward_pct   | 64.3     |\n",
      "|    total_trades       | 6078     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 4.19     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.243    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.68e+05 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 2.68e+05 |\n",
      "|    total_reward_pct   | 53.5     |\n",
      "|    total_trades       | 5787     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.339   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 60.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 4.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.2e+05  |\n",
      "|    total_cost         | 1.34e+04 |\n",
      "|    total_reward       | 3.2e+05  |\n",
      "|    total_reward_pct   | 64       |\n",
      "|    total_trades       | 5852     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 24.7     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.865    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.03e+05  |\n",
      "|    total_cost         | 6.61e+03  |\n",
      "|    total_reward       | -1.97e+05 |\n",
      "|    total_reward_pct   | -39.4     |\n",
      "|    total_trades       | 6090      |\n",
      "| time/                 |           |\n",
      "|    fps                | 532       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | 0.399     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -2.17     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.11      |\n",
      "-------------------------------------\n",
      "day: 564, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 354197.80\n",
      "total_reward: -145802.20\n",
      "total_cost: 6272.51\n",
      "total_trades: 6066\n",
      "Sharpe: -0.277\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.54e+05  |\n",
      "|    total_cost         | 6.27e+03  |\n",
      "|    total_reward       | -1.46e+05 |\n",
      "|    total_reward_pct   | -29.2     |\n",
      "|    total_trades       | 6066      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -20.2     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.622     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.92e+05 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | 1.92e+05 |\n",
      "|    total_reward_pct   | 38.4     |\n",
      "|    total_trades       | 6261     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -15      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.98e+05  |\n",
      "|    total_cost         | 1.45e+04  |\n",
      "|    total_reward       | 2.98e+05  |\n",
      "|    total_reward_pct   | 59.6      |\n",
      "|    total_trades       | 6286      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -15.4     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.558     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.7e+05  |\n",
      "|    total_cost         | 8.1e+03  |\n",
      "|    total_reward       | 1.7e+05  |\n",
      "|    total_reward_pct   | 33.9     |\n",
      "|    total_trades       | 6303     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -30.5    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -0.443   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 18.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.949    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.35e+05 |\n",
      "|    total_cost         | 1.72e+04 |\n",
      "|    total_reward       | 3.49e+04 |\n",
      "|    total_reward_pct   | 6.99     |\n",
      "|    total_trades       | 6360     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -9.16    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.786    |\n",
      "------------------------------------\n",
      "day: 564, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 754025.63\n",
      "total_reward: 254025.63\n",
      "total_cost: 15668.89\n",
      "total_trades: 6631\n",
      "Sharpe: 0.711\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.54e+05 |\n",
      "|    total_cost         | 1.57e+04 |\n",
      "|    total_reward       | 2.54e+05 |\n",
      "|    total_reward_pct   | 50.8     |\n",
      "|    total_trades       | 6631     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 29.9     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.27e+05 |\n",
      "|    total_cost         | 8.47e+03 |\n",
      "|    total_reward       | 1.27e+05 |\n",
      "|    total_reward_pct   | 25.4     |\n",
      "|    total_trades       | 6659     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 4.54     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0315   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.76e+05  |\n",
      "|    total_cost         | 6.07e+03  |\n",
      "|    total_reward       | -2.44e+04 |\n",
      "|    total_reward_pct   | -4.87     |\n",
      "|    total_trades       | 6534      |\n",
      "| time/                 |           |\n",
      "|    fps                | 532       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 40.5      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.83e+05  |\n",
      "|    total_cost         | 3.01e+03  |\n",
      "|    total_reward       | -1.69e+04 |\n",
      "|    total_reward_pct   | -3.38     |\n",
      "|    total_trades       | 6810      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -375      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 181       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.14e+05 |\n",
      "|    total_cost         | 7.41e+03 |\n",
      "|    total_reward       | 3.14e+05 |\n",
      "|    total_reward_pct   | 62.8     |\n",
      "|    total_trades       | 6644     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.0127  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -18.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.716    |\n",
      "------------------------------------\n",
      "day: 564, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 348820.71\n",
      "total_reward: -151179.29\n",
      "total_cost: 6823.78\n",
      "total_trades: 6628\n",
      "Sharpe: -0.250\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.49e+05  |\n",
      "|    total_cost         | 6.82e+03  |\n",
      "|    total_reward       | -1.51e+05 |\n",
      "|    total_reward_pct   | -30.2     |\n",
      "|    total_trades       | 6628      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -0.156    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -24.2     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.77      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.46e+05  |\n",
      "|    total_cost         | 8.55e+03  |\n",
      "|    total_reward       | -1.54e+05 |\n",
      "|    total_reward_pct   | -30.7     |\n",
      "|    total_trades       | 6560      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -0.436    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -1.3      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.076     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0.504    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 38.2     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.77e+05 |\n",
      "|    total_cost         | 1.38e+04 |\n",
      "|    total_reward       | 7.67e+04 |\n",
      "|    total_reward_pct   | 15.3     |\n",
      "|    total_trades       | 6832     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -50.1    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.47e+05 |\n",
      "|    total_cost         | 9.71e+03 |\n",
      "|    total_reward       | 2.47e+05 |\n",
      "|    total_reward_pct   | 49.4     |\n",
      "|    total_trades       | 6629     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0.0668   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 24       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.82e+05 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 3.82e+05 |\n",
      "|    total_reward_pct   | 76.4     |\n",
      "|    total_trades       | 6699     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 11.3     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.199    |\n",
      "------------------------------------\n",
      "day: 564, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 349941.48\n",
      "total_reward: -150058.52\n",
      "total_cost: 7373.37\n",
      "total_trades: 6593\n",
      "Sharpe: -0.241\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.5e+05  |\n",
      "|    total_cost         | 7.37e+03 |\n",
      "|    total_reward       | -1.5e+05 |\n",
      "|    total_reward_pct   | -30      |\n",
      "|    total_trades       | 6593     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.222   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.468    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.01e+05  |\n",
      "|    total_cost         | 9.71e+03  |\n",
      "|    total_reward       | -9.92e+04 |\n",
      "|    total_reward_pct   | -19.8     |\n",
      "|    total_trades       | 6699      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -0.948    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 46.1      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 4.16      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.72e+05 |\n",
      "|    total_cost         | 1.31e+04 |\n",
      "|    total_reward       | 3.72e+05 |\n",
      "|    total_reward_pct   | 74.3     |\n",
      "|    total_trades       | 6891     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -22.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.895    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.19e+05 |\n",
      "|    total_cost         | 1.34e+04 |\n",
      "|    total_reward       | 1.19e+05 |\n",
      "|    total_reward_pct   | 23.8     |\n",
      "|    total_trades       | 6905     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -1.39    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0492   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0.378    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -65.6    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 6.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.76e+05  |\n",
      "|    total_cost         | 1.4e+04   |\n",
      "|    total_reward       | -2.35e+04 |\n",
      "|    total_reward_pct   | -4.71     |\n",
      "|    total_trades       | 7218      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | -8.63     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -17.6     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.991     |\n",
      "-------------------------------------\n",
      "day: 564, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 411377.17\n",
      "total_reward: -88622.83\n",
      "total_cost: 12832.39\n",
      "total_trades: 7389\n",
      "Sharpe: -0.173\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.11e+05  |\n",
      "|    total_cost         | 1.28e+04  |\n",
      "|    total_reward       | -8.86e+04 |\n",
      "|    total_reward_pct   | -17.7     |\n",
      "|    total_trades       | 7389      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 15.7      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.404     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.64e+05 |\n",
      "|    total_cost         | 1.07e+04 |\n",
      "|    total_reward       | -3.6e+04 |\n",
      "|    total_reward_pct   | -7.19    |\n",
      "|    total_trades       | 7219     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -7.49    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.223    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.46e+05  |\n",
      "|    total_cost         | 1.33e+04  |\n",
      "|    total_reward       | 2.46e+05  |\n",
      "|    total_reward_pct   | 49.3      |\n",
      "|    total_trades       | 7549      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 19.1      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.488     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.3e+05  |\n",
      "|    total_cost         | 5.45e+03 |\n",
      "|    total_reward       | 3e+04    |\n",
      "|    total_reward_pct   | 6.01     |\n",
      "|    total_trades       | 7643     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.249    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.11e+05  |\n",
      "|    total_cost         | 5.4e+03   |\n",
      "|    total_reward       | -8.86e+04 |\n",
      "|    total_reward_pct   | -17.7     |\n",
      "|    total_trades       | 7682      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.548     |\n",
      "-------------------------------------\n",
      "day: 564, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 746730.31\n",
      "total_reward: 246730.31\n",
      "total_cost: 9519.81\n",
      "total_trades: 7725\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.47e+05 |\n",
      "|    total_cost         | 9.52e+03 |\n",
      "|    total_reward       | 2.47e+05 |\n",
      "|    total_reward_pct   | 49.3     |\n",
      "|    total_trades       | 7725     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.0297  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.215    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.32e+05  |\n",
      "|    total_cost         | 2.54e+03  |\n",
      "|    total_reward       | -1.68e+05 |\n",
      "|    total_reward_pct   | -33.7     |\n",
      "|    total_trades       | 7624      |\n",
      "| time/                 |           |\n",
      "|    fps                | 533       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 101       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.000258 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.517    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.39e+05 |\n",
      "|    total_cost         | 6.6e+03  |\n",
      "|    total_reward       | 1.39e+05 |\n",
      "|    total_reward_pct   | 27.8     |\n",
      "|    total_trades       | 7487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 13.7     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.898    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.12e+05 |\n",
      "|    total_cost         | 7.03e+03 |\n",
      "|    total_reward       | 3.12e+05 |\n",
      "|    total_reward_pct   | 62.4     |\n",
      "|    total_trades       | 7528     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -20.6    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.91e+05  |\n",
      "|    total_cost         | 2.81e+03  |\n",
      "|    total_reward       | 9.13e+04  |\n",
      "|    total_reward_pct   | 18.3      |\n",
      "|    total_trades       | 7672      |\n",
      "| time/                 |           |\n",
      "|    fps                | 532       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -13.2     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.266     |\n",
      "-------------------------------------\n",
      "day: 564, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 611264.59\n",
      "total_reward: 111264.59\n",
      "total_cost: 2673.58\n",
      "total_trades: 7539\n",
      "Sharpe: 0.439\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.11e+05 |\n",
      "|    total_cost         | 2.67e+03 |\n",
      "|    total_reward       | 1.11e+05 |\n",
      "|    total_reward_pct   | 22.3     |\n",
      "|    total_trades       | 7539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -0.382   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.582    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.84e+05 |\n",
      "|    total_cost         | 2.32e+03 |\n",
      "|    total_reward       | -1.6e+04 |\n",
      "|    total_reward_pct   | -3.2     |\n",
      "|    total_trades       | 7411     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.181    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -10.9    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.205    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.18e+05 |\n",
      "|    total_cost         | 2.16e+03 |\n",
      "|    total_reward       | 1.82e+04 |\n",
      "|    total_reward_pct   | 3.63     |\n",
      "|    total_trades       | 7346     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 28.5     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.11e+05 |\n",
      "|    total_cost         | 6.3e+03  |\n",
      "|    total_reward       | 4.11e+05 |\n",
      "|    total_reward_pct   | 82.1     |\n",
      "|    total_trades       | 7350     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.61     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -0.123   |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0286   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.04e+05  |\n",
      "|    total_cost         | 2.37e+03  |\n",
      "|    total_reward       | -1.96e+05 |\n",
      "|    total_reward_pct   | -39.3     |\n",
      "|    total_trades       | 7211      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.5     |\n",
      "|    explained_variance | 0.0351    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -22.1     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.56      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -15.4    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "day: 564, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 833389.89\n",
      "total_reward: 333389.89\n",
      "total_cost: 4105.45\n",
      "total_trades: 7315\n",
      "Sharpe: 0.788\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.33e+05 |\n",
      "|    total_cost         | 4.11e+03 |\n",
      "|    total_reward       | 3.33e+05 |\n",
      "|    total_reward_pct   | 66.7     |\n",
      "|    total_trades       | 7315     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -5.62    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 82.6     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.51e+05 |\n",
      "|    total_cost         | 4.24e+03 |\n",
      "|    total_reward       | 4.51e+05 |\n",
      "|    total_reward_pct   | 90.3     |\n",
      "|    total_trades       | 7225     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 8.13     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.244    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.52e+05  |\n",
      "|    total_cost         | 5.13e+03  |\n",
      "|    total_reward       | 3.52e+05  |\n",
      "|    total_reward_pct   | 70.4      |\n",
      "|    total_trades       | 7111      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 9.76      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.198     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.32e+05  |\n",
      "|    total_cost         | 2.5e+03   |\n",
      "|    total_reward       | -1.68e+05 |\n",
      "|    total_reward_pct   | -33.5     |\n",
      "|    total_trades       | 7252      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 0.605     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.02      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.1e+05  |\n",
      "|    total_cost         | 4.47e+03 |\n",
      "|    total_reward       | 3.1e+05  |\n",
      "|    total_reward_pct   | 61.9     |\n",
      "|    total_trades       | 7537     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.268    |\n",
      "------------------------------------\n",
      "day: 564, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 726849.97\n",
      "total_reward: 226849.97\n",
      "total_cost: 3807.21\n",
      "total_trades: 7476\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.27e+05 |\n",
      "|    total_cost         | 3.81e+03 |\n",
      "|    total_reward       | 2.27e+05 |\n",
      "|    total_reward_pct   | 45.4     |\n",
      "|    total_trades       | 7476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0.0572   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 80.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 8.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.45e+05 |\n",
      "|    total_cost         | 3.51e+03 |\n",
      "|    total_reward       | 2.45e+05 |\n",
      "|    total_reward_pct   | 48.9     |\n",
      "|    total_trades       | 7535     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0.0782   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -25.5    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -0.0624  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -54.6    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.58e+05 |\n",
      "|    total_cost         | 3.43e+03 |\n",
      "|    total_reward       | 1.58e+05 |\n",
      "|    total_reward_pct   | 31.6     |\n",
      "|    total_trades       | 7441     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -3.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 28       |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.94e+05 |\n",
      "|    total_cost         | 5.07e+03 |\n",
      "|    total_reward       | 3.94e+05 |\n",
      "|    total_reward_pct   | 78.8     |\n",
      "|    total_trades       | 7274     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -17.7    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.649    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.06e+05  |\n",
      "|    total_cost         | 2.31e+03  |\n",
      "|    total_reward       | -9.38e+04 |\n",
      "|    total_reward_pct   | -18.8     |\n",
      "|    total_trades       | 7123      |\n",
      "| time/                 |           |\n",
      "|    fps                | 530       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 44.1      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "day: 564, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 833498.20\n",
      "total_reward: 333498.20\n",
      "total_cost: 4109.43\n",
      "total_trades: 7254\n",
      "Sharpe: 0.820\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.33e+05 |\n",
      "|    total_cost         | 4.11e+03 |\n",
      "|    total_reward       | 3.33e+05 |\n",
      "|    total_reward_pct   | 66.7     |\n",
      "|    total_trades       | 7254     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 16.7     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.827    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.58e+05  |\n",
      "|    total_cost         | 1.88e+03  |\n",
      "|    total_reward       | -4.23e+04 |\n",
      "|    total_reward_pct   | -8.46     |\n",
      "|    total_trades       | 7403      |\n",
      "| time/                 |           |\n",
      "|    fps                | 530       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 34.3      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 2.09      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.15e+05 |\n",
      "|    total_cost         | 3.98e+03 |\n",
      "|    total_reward       | 3.15e+05 |\n",
      "|    total_reward_pct   | 63       |\n",
      "|    total_trades       | 7443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0.716    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -7.87    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.25e+05 |\n",
      "|    total_cost         | 2.38e+03 |\n",
      "|    total_reward       | 1.25e+05 |\n",
      "|    total_reward_pct   | 25       |\n",
      "|    total_trades       | 7232     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.0507   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 12.8     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.358    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.77e+05 |\n",
      "|    total_cost         | 4.79e+03 |\n",
      "|    total_reward       | 3.77e+05 |\n",
      "|    total_reward_pct   | 75.4     |\n",
      "|    total_trades       | 7203     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -0.129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -18.6    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.208   |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.641    |\n",
      "------------------------------------\n",
      "day: 564, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 541528.45\n",
      "total_reward: 41528.45\n",
      "total_cost: 1757.49\n",
      "total_trades: 6973\n",
      "Sharpe: 0.275\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.42e+05 |\n",
      "|    total_cost         | 1.76e+03 |\n",
      "|    total_reward       | 4.15e+04 |\n",
      "|    total_reward_pct   | 8.31     |\n",
      "|    total_trades       | 6973     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 48.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.58e+05 |\n",
      "|    total_cost         | 3.93e+03 |\n",
      "|    total_reward       | 3.58e+05 |\n",
      "|    total_reward_pct   | 71.6     |\n",
      "|    total_trades       | 7010     |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -57.2    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.51e+05 |\n",
      "|    total_cost         | 3.26e+03 |\n",
      "|    total_reward       | 2.51e+05 |\n",
      "|    total_reward_pct   | 50.2     |\n",
      "|    total_trades       | 7094     |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -20.9    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.38e+05 |\n",
      "|    total_cost         | 3.38e+03 |\n",
      "|    total_reward       | 1.38e+05 |\n",
      "|    total_reward_pct   | 27.5     |\n",
      "|    total_trades       | 6969     |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -35.2    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.77e+05 |\n",
      "|    total_cost         | 2.5e+03  |\n",
      "|    total_reward       | 1.77e+05 |\n",
      "|    total_reward_pct   | 35.5     |\n",
      "|    total_trades       | 7034     |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 62.1     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 5.98     |\n",
      "------------------------------------\n",
      "day: 564, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 461064.63\n",
      "total_reward: -38935.37\n",
      "total_cost: 1776.90\n",
      "total_trades: 7071\n",
      "Sharpe: 0.112\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.61e+05  |\n",
      "|    total_cost         | 1.78e+03  |\n",
      "|    total_reward       | -3.89e+04 |\n",
      "|    total_reward_pct   | -7.79     |\n",
      "|    total_trades       | 7071      |\n",
      "| time/                 |           |\n",
      "|    fps                | 529       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -21.9     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.8e+05   |\n",
      "|    total_cost         | 4.32e+03  |\n",
      "|    total_reward       | 3.8e+05   |\n",
      "|    total_reward_pct   | 76.1      |\n",
      "|    total_trades       | 7061      |\n",
      "| time/                 |           |\n",
      "|    fps                | 529       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 112       |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 15.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.92e+05 |\n",
      "|    total_cost         | 5.29e+03 |\n",
      "|    total_reward       | 3.92e+05 |\n",
      "|    total_reward_pct   | 78.4     |\n",
      "|    total_trades       | 7237     |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.324   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 28.5     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -4.87    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 45.5     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 5.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.2e+05  |\n",
      "|    total_cost         | 5.46e+03 |\n",
      "|    total_reward       | 4.2e+05  |\n",
      "|    total_reward_pct   | 84       |\n",
      "|    total_trades       | 7190     |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.00601 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -34      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 5.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.94e+05  |\n",
      "|    total_cost         | 3.49e+03  |\n",
      "|    total_reward       | 9.44e+04  |\n",
      "|    total_reward_pct   | 18.9      |\n",
      "|    total_trades       | 7151      |\n",
      "| time/                 |           |\n",
      "|    fps                | 528       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -38.8     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.08      |\n",
      "-------------------------------------\n",
      "day: 564, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 787468.80\n",
      "total_reward: 287468.80\n",
      "total_cost: 3561.00\n",
      "total_trades: 7082\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.87e+05 |\n",
      "|    total_cost         | 3.56e+03 |\n",
      "|    total_reward       | 2.87e+05 |\n",
      "|    total_reward_pct   | 57.5     |\n",
      "|    total_trades       | 7082     |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 60.8     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 7.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.72e+05 |\n",
      "|    total_cost         | 4.3e+03  |\n",
      "|    total_reward       | 3.72e+05 |\n",
      "|    total_reward_pct   | 74.3     |\n",
      "|    total_trades       | 6938     |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 42.9     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.99e+05 |\n",
      "|    total_cost         | 6.28e+03 |\n",
      "|    total_reward       | 3.99e+05 |\n",
      "|    total_reward_pct   | 79.8     |\n",
      "|    total_trades       | 6787     |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.00833  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -11.2    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.449    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.54e+05 |\n",
      "|    total_cost         | 4.68e+03 |\n",
      "|    total_reward       | 3.54e+05 |\n",
      "|    total_reward_pct   | 70.8     |\n",
      "|    total_trades       | 6637     |\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -0.338   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 52.7     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.5e+05  |\n",
      "|    total_cost         | 5.64e+03 |\n",
      "|    total_reward       | 3.5e+05  |\n",
      "|    total_reward_pct   | 70       |\n",
      "|    total_trades       | 6653     |\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -18.1    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "day: 564, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 866408.98\n",
      "total_reward: 366408.98\n",
      "total_cost: 4748.39\n",
      "total_trades: 6712\n",
      "Sharpe: 0.975\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.66e+05 |\n",
      "|    total_cost         | 4.75e+03 |\n",
      "|    total_reward       | 3.66e+05 |\n",
      "|    total_reward_pct   | 73.3     |\n",
      "|    total_trades       | 6712     |\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 56.8     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 14.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -3.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 30.2     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.9e+05   |\n",
      "|    total_cost         | 2e+03     |\n",
      "|    total_reward       | -9.77e+03 |\n",
      "|    total_reward_pct   | -1.95     |\n",
      "|    total_trades       | 6672      |\n",
      "| time/                 |           |\n",
      "|    fps                | 527       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -22.9     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.876     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.65e+05 |\n",
      "|    total_cost         | 4.66e+03 |\n",
      "|    total_reward       | 3.65e+05 |\n",
      "|    total_reward_pct   | 73       |\n",
      "|    total_trades       | 6565     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0.292    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.655    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.18e+05 |\n",
      "|    total_cost         | 6.05e+03 |\n",
      "|    total_reward       | 3.18e+05 |\n",
      "|    total_reward_pct   | 63.6     |\n",
      "|    total_trades       | 6587     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -27.1    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.46e+05 |\n",
      "|    total_cost         | 7.18e+03 |\n",
      "|    total_reward       | 2.46e+05 |\n",
      "|    total_reward_pct   | 49.2     |\n",
      "|    total_trades       | 6489     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -58.5    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n",
      "day: 564, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 827448.22\n",
      "total_reward: 327448.22\n",
      "total_cost: 7897.42\n",
      "total_trades: 6515\n",
      "Sharpe: 0.769\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.27e+05 |\n",
      "|    total_cost         | 7.9e+03  |\n",
      "|    total_reward       | 3.27e+05 |\n",
      "|    total_reward_pct   | 65.5     |\n",
      "|    total_trades       | 6515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -9.44    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.75e+05  |\n",
      "|    total_cost         | 4.37e+03  |\n",
      "|    total_reward       | -1.25e+05 |\n",
      "|    total_reward_pct   | -24.9     |\n",
      "|    total_trades       | 6454      |\n",
      "| time/                 |           |\n",
      "|    fps                | 526       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | 4.13      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.677     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.49e+05 |\n",
      "|    total_cost         | 5.62e+03 |\n",
      "|    total_reward       | 4.92e+04 |\n",
      "|    total_reward_pct   | 9.84     |\n",
      "|    total_trades       | 6614     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 8.68     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 526       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -195      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 58.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.39e+05 |\n",
      "|    total_cost         | 1.13e+04 |\n",
      "|    total_reward       | 2.39e+05 |\n",
      "|    total_reward_pct   | 47.7     |\n",
      "|    total_trades       | 6601     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 7.21     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0984   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.72e+05  |\n",
      "|    total_cost         | 5.7e+03   |\n",
      "|    total_reward       | -1.28e+05 |\n",
      "|    total_reward_pct   | -25.7     |\n",
      "|    total_trades       | 6597      |\n",
      "| time/                 |           |\n",
      "|    fps                | 527       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | -1.44     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | 7.44      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "day: 564, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 267826.85\n",
      "total_reward: -232173.15\n",
      "total_cost: 5709.28\n",
      "total_trades: 6573\n",
      "Sharpe: -0.378\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.68e+05  |\n",
      "|    total_cost         | 5.71e+03  |\n",
      "|    total_reward       | -2.32e+05 |\n",
      "|    total_reward_pct   | -46.4     |\n",
      "|    total_trades       | 6573      |\n",
      "| time/                 |           |\n",
      "|    fps                | 526       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | -0.104    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 68        |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 5.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.87e+05  |\n",
      "|    total_cost         | 5e+03     |\n",
      "|    total_reward       | -1.13e+05 |\n",
      "|    total_reward_pct   | -22.6     |\n",
      "|    total_trades       | 6453      |\n",
      "| time/                 |           |\n",
      "|    fps                | 526       |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.364     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.85e+05  |\n",
      "|    total_cost         | 3.88e+03  |\n",
      "|    total_reward       | -1.15e+05 |\n",
      "|    total_reward_pct   | -22.9     |\n",
      "|    total_trades       | 6450      |\n",
      "| time/                 |           |\n",
      "|    fps                | 526       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -78.3     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 7.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.21e+05 |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 2.21e+05 |\n",
      "|    total_reward_pct   | 44.2     |\n",
      "|    total_trades       | 6424     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.00871 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -46.6    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.09e+05 |\n",
      "|    total_cost         | 7.75e+03 |\n",
      "|    total_reward       | 9.16e+03 |\n",
      "|    total_reward_pct   | 1.83     |\n",
      "|    total_trades       | 6473     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.0128   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 30       |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "day: 564, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 682609.19\n",
      "total_reward: 182609.19\n",
      "total_cost: 4518.21\n",
      "total_trades: 6432\n",
      "Sharpe: 0.611\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.83e+05 |\n",
      "|    total_cost         | 4.52e+03 |\n",
      "|    total_reward       | 1.83e+05 |\n",
      "|    total_reward_pct   | 36.5     |\n",
      "|    total_trades       | 6432     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.0346   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -12.4    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.479    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -17.4    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.39e+05 |\n",
      "|    total_cost         | 1.1e+04  |\n",
      "|    total_reward       | 3.39e+05 |\n",
      "|    total_reward_pct   | 67.8     |\n",
      "|    total_trades       | 6361     |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -10.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -4.12    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+05  |\n",
      "|    total_cost         | 3.55e+03 |\n",
      "|    total_reward       | -2.2e+05 |\n",
      "|    total_reward_pct   | -43.9    |\n",
      "|    total_trades       | 6267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.016   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 8.2      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.78e+05  |\n",
      "|    total_cost         | 9.27e+03  |\n",
      "|    total_reward       | -1.22e+05 |\n",
      "|    total_reward_pct   | -24.5     |\n",
      "|    total_trades       | 6372      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.6     |\n",
      "|    explained_variance | -0.0316   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 64.7      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 4.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.59e+05 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 2.59e+05 |\n",
      "|    total_reward_pct   | 51.9     |\n",
      "|    total_trades       | 6002     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -1.33    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 43.5     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 2.11     |\n",
      "------------------------------------\n",
      "day: 564, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 811802.27\n",
      "total_reward: 311802.27\n",
      "total_cost: 12831.94\n",
      "total_trades: 5951\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.12e+05 |\n",
      "|    total_cost         | 1.28e+04 |\n",
      "|    total_reward       | 3.12e+05 |\n",
      "|    total_reward_pct   | 62.4     |\n",
      "|    total_trades       | 5951     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 0.124    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -12      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.602    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.06e+05 |\n",
      "|    total_cost         | 5.97e+03 |\n",
      "|    total_reward       | 5.56e+03 |\n",
      "|    total_reward_pct   | 1.11     |\n",
      "|    total_trades       | 5997     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.0168  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 18.3     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.34e+05 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 2.34e+05 |\n",
      "|    total_reward_pct   | 46.8     |\n",
      "|    total_trades       | 6010     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.0778  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -54.6    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 7.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.89e+05 |\n",
      "|    total_cost         | 5.92e+03 |\n",
      "|    total_reward       | 8.91e+04 |\n",
      "|    total_reward_pct   | 17.8     |\n",
      "|    total_trades       | 5947     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.00858 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 40       |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 6.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0.0136   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 3.43     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0725   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.13e+05 |\n",
      "|    total_cost         | 6e+03    |\n",
      "|    total_reward       | 1.26e+04 |\n",
      "|    total_reward_pct   | 2.51     |\n",
      "|    total_trades       | 5951     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 0.364    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "day: 564, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 543480.74\n",
      "total_reward: 43480.74\n",
      "total_cost: 4509.91\n",
      "total_trades: 5854\n",
      "Sharpe: 0.275\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.43e+05 |\n",
      "|    total_cost         | 4.51e+03 |\n",
      "|    total_reward       | 4.35e+04 |\n",
      "|    total_reward_pct   | 8.7      |\n",
      "|    total_trades       | 5854     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0.182    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -7.56    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.827    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.7e+05   |\n",
      "|    total_cost         | 4.76e+03  |\n",
      "|    total_reward       | 3.7e+05   |\n",
      "|    total_reward_pct   | 73.9      |\n",
      "|    total_trades       | 5731      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | 2.45      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.0143    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.8e+05   |\n",
      "|    total_cost         | 1.24e+04  |\n",
      "|    total_reward       | -1.95e+04 |\n",
      "|    total_reward_pct   | -3.91     |\n",
      "|    total_trades       | 5864      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -32.8     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.99e+05 |\n",
      "|    total_cost         | 2.32e+04 |\n",
      "|    total_reward       | 3.99e+05 |\n",
      "|    total_reward_pct   | 79.7     |\n",
      "|    total_trades       | 6051     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0.258    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -7.91    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.426    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.76e+05 |\n",
      "|    total_cost         | 1.97e+04 |\n",
      "|    total_reward       | 2.76e+05 |\n",
      "|    total_reward_pct   | 55.1     |\n",
      "|    total_trades       | 5929     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -0.211   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -21.7    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.877    |\n",
      "------------------------------------\n",
      "day: 564, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 670868.95\n",
      "total_reward: 170868.95\n",
      "total_cost: 6737.94\n",
      "total_trades: 5852\n",
      "Sharpe: 0.655\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.71e+05 |\n",
      "|    total_cost         | 6.74e+03 |\n",
      "|    total_reward       | 1.71e+05 |\n",
      "|    total_reward_pct   | 34.2     |\n",
      "|    total_trades       | 5852     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -0.071   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0.000553 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.63e+05 |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 2.63e+05 |\n",
      "|    total_reward_pct   | 52.6     |\n",
      "|    total_trades       | 5793     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -39.1    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.24e+05 |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | 2.24e+05 |\n",
      "|    total_reward_pct   | 44.8     |\n",
      "|    total_trades       | 5799     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 14.9     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.315    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.39e+05 |\n",
      "|    total_cost         | 1.15e+04 |\n",
      "|    total_reward       | 3.9e+04  |\n",
      "|    total_reward_pct   | 7.81     |\n",
      "|    total_trades       | 5816     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 3.5      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0992   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.24e+05 |\n",
      "|    total_cost         | 1.26e+04 |\n",
      "|    total_reward       | 1.24e+05 |\n",
      "|    total_reward_pct   | 24.8     |\n",
      "|    total_trades       | 5879     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.398   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 32.1     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "day: 564, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 788442.36\n",
      "total_reward: 288442.36\n",
      "total_cost: 19504.89\n",
      "total_trades: 6014\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.88e+05 |\n",
      "|    total_cost         | 1.95e+04 |\n",
      "|    total_reward       | 2.88e+05 |\n",
      "|    total_reward_pct   | 57.7     |\n",
      "|    total_trades       | 6014     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 10       |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.72e+05 |\n",
      "|    total_cost         | 1.76e+04 |\n",
      "|    total_reward       | 1.72e+05 |\n",
      "|    total_reward_pct   | 34.4     |\n",
      "|    total_trades       | 6059     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -18.4    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.661    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.47e+05 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | 1.47e+05 |\n",
      "|    total_reward_pct   | 29.3     |\n",
      "|    total_trades       | 6055     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -17.5    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.6      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.46e+05  |\n",
      "|    total_cost         | 7.79e+03  |\n",
      "|    total_reward       | -2.54e+05 |\n",
      "|    total_reward_pct   | -50.9     |\n",
      "|    total_trades       | 6225      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.9     |\n",
      "|    explained_variance | 0.0151    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | -48.8     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 3.65      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -0.0769  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 100      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 15.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.85e+05 |\n",
      "|    total_cost         | 1.7e+04  |\n",
      "|    total_reward       | 2.85e+05 |\n",
      "|    total_reward_pct   | 56.9     |\n",
      "|    total_trades       | 6386     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 26.4     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "day: 564, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 699276.52\n",
      "total_reward: 199276.52\n",
      "total_cost: 17405.72\n",
      "total_trades: 6276\n",
      "Sharpe: 0.598\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.99e+05 |\n",
      "|    total_cost         | 1.74e+04 |\n",
      "|    total_reward       | 1.99e+05 |\n",
      "|    total_reward_pct   | 39.9     |\n",
      "|    total_trades       | 6276     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.758   |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00371  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.9e+05  |\n",
      "|    total_cost         | 1.58e+04 |\n",
      "|    total_reward       | 9.03e+04 |\n",
      "|    total_reward_pct   | 18.1     |\n",
      "|    total_trades       | 6187     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0.0582   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 30.4     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.74e+05 |\n",
      "|    total_cost         | 2.19e+04 |\n",
      "|    total_reward       | 3.74e+05 |\n",
      "|    total_reward_pct   | 74.7     |\n",
      "|    total_trades       | 6292     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -0.00498 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -9.22    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.252    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.72e+05  |\n",
      "|    total_cost         | 9.33e+03  |\n",
      "|    total_reward       | -2.76e+04 |\n",
      "|    total_reward_pct   | -5.51     |\n",
      "|    total_trades       | 6395      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | -0.0143   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -445      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 197       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.24e+05 |\n",
      "|    total_cost         | 1.03e+04 |\n",
      "|    total_reward       | 3.24e+05 |\n",
      "|    total_reward_pct   | 64.8     |\n",
      "|    total_trades       | 6567     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -32.5    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "day: 564, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 591343.22\n",
      "total_reward: 91343.22\n",
      "total_cost: 5344.43\n",
      "total_trades: 6657\n",
      "Sharpe: 0.419\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.91e+05 |\n",
      "|    total_cost         | 5.34e+03 |\n",
      "|    total_reward       | 9.13e+04 |\n",
      "|    total_reward_pct   | 18.3     |\n",
      "|    total_trades       | 6657     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.0187   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -30.5    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 6.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.9e+05  |\n",
      "|    total_cost         | 6.48e+03 |\n",
      "|    total_reward       | 3.9e+05  |\n",
      "|    total_reward_pct   | 78.1     |\n",
      "|    total_trades       | 6557     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0.0194   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 123      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 77       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 74.4     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 7.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.72e+05 |\n",
      "|    total_cost         | 8.65e+03 |\n",
      "|    total_reward       | 2.72e+05 |\n",
      "|    total_reward_pct   | 54.4     |\n",
      "|    total_trades       | 6563     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -49      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.61e+05  |\n",
      "|    total_cost         | 5.01e+03  |\n",
      "|    total_reward       | 3.61e+05  |\n",
      "|    total_reward_pct   | 72.1      |\n",
      "|    total_trades       | 6301      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | 22.3      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.544     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.01e+05 |\n",
      "|    total_cost         | 8.7e+03  |\n",
      "|    total_reward       | 3.01e+05 |\n",
      "|    total_reward_pct   | 60.3     |\n",
      "|    total_trades       | 6338     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -0.846   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -14.1    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.679    |\n",
      "------------------------------------\n",
      "day: 564, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 761786.68\n",
      "total_reward: 261786.68\n",
      "total_cost: 8343.15\n",
      "total_trades: 6335\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.62e+05 |\n",
      "|    total_cost         | 8.34e+03 |\n",
      "|    total_reward       | 2.62e+05 |\n",
      "|    total_reward_pct   | 52.4     |\n",
      "|    total_trades       | 6335     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -2.3     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -29      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+05  |\n",
      "|    total_cost         | 7.01e+03 |\n",
      "|    total_reward       | 4.1e+05  |\n",
      "|    total_reward_pct   | 82       |\n",
      "|    total_trades       | 6325     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.000111 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 21.5     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.597    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.42e+05 |\n",
      "|    total_cost         | 2.24e+03 |\n",
      "|    total_reward       | 4.19e+04 |\n",
      "|    total_reward_pct   | 8.37     |\n",
      "|    total_trades       | 6193     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.392    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -37.5    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.38e+05 |\n",
      "|    total_cost         | 3.74e+03 |\n",
      "|    total_reward       | 3.8e+04  |\n",
      "|    total_reward_pct   | 7.61     |\n",
      "|    total_trades       | 6100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0.662    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 16.4     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.305    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.0118   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -140     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 38       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.58e+05 |\n",
      "|    total_cost         | 7.31e+03 |\n",
      "|    total_reward       | 2.58e+05 |\n",
      "|    total_reward_pct   | 51.6     |\n",
      "|    total_trades       | 6028     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -0.201   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -34.4    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "day: 564, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 821199.98\n",
      "total_reward: 321199.98\n",
      "total_cost: 7640.71\n",
      "total_trades: 6000\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.21e+05  |\n",
      "|    total_cost         | 7.64e+03  |\n",
      "|    total_reward       | 3.21e+05  |\n",
      "|    total_reward_pct   | 64.2      |\n",
      "|    total_trades       | 6000      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 25.5      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.982     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.62e+05 |\n",
      "|    total_cost         | 8.56e+03 |\n",
      "|    total_reward       | 2.62e+05 |\n",
      "|    total_reward_pct   | 52.4     |\n",
      "|    total_trades       | 6118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -15.2    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.322    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.36e+05  |\n",
      "|    total_cost         | 4.79e+03  |\n",
      "|    total_reward       | 3.36e+05  |\n",
      "|    total_reward_pct   | 67.3      |\n",
      "|    total_trades       | 6190      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 38.2      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 2.21      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.11e+05 |\n",
      "|    total_cost         | 5.97e+03 |\n",
      "|    total_reward       | 3.11e+05 |\n",
      "|    total_reward_pct   | 62.2     |\n",
      "|    total_trades       | 6204     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | -1.75    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -28.6    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.33e+05 |\n",
      "|    total_cost         | 2.88e+03 |\n",
      "|    total_reward       | 1.33e+05 |\n",
      "|    total_reward_pct   | 26.6     |\n",
      "|    total_trades       | 6173     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -0.528   |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n",
      "day: 564, episode: 160\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 670258.08\n",
      "total_reward: 170258.08\n",
      "total_cost: 2570.36\n",
      "total_trades: 6215\n",
      "Sharpe: 0.641\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.7e+05  |\n",
      "|    total_cost         | 2.57e+03 |\n",
      "|    total_reward       | 1.7e+05  |\n",
      "|    total_reward_pct   | 34.1     |\n",
      "|    total_trades       | 6215     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -25.8    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.26e+05 |\n",
      "|    total_cost         | 2.21e+03 |\n",
      "|    total_reward       | 1.26e+05 |\n",
      "|    total_reward_pct   | 25.2     |\n",
      "|    total_trades       | 6062     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0.00242  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 149      |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 24.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0.529    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.433    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.8e+05  |\n",
      "|    total_cost         | 4.33e+03 |\n",
      "|    total_reward       | 2.8e+05  |\n",
      "|    total_reward_pct   | 56       |\n",
      "|    total_trades       | 6047     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.835    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.16e+05 |\n",
      "|    total_cost         | 6.11e+03 |\n",
      "|    total_reward       | 4.16e+05 |\n",
      "|    total_reward_pct   | 83.2     |\n",
      "|    total_trades       | 6001     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 3.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8e+05    |\n",
      "|    total_cost         | 7.84e+03 |\n",
      "|    total_reward       | 3e+05    |\n",
      "|    total_reward_pct   | 59.9     |\n",
      "|    total_trades       | 5952     |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -9.29    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "day: 564, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 495727.14\n",
      "total_reward: -4272.86\n",
      "total_cost: 1526.92\n",
      "total_trades: 5891\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.96e+05  |\n",
      "|    total_cost         | 1.53e+03  |\n",
      "|    total_reward       | -4.27e+03 |\n",
      "|    total_reward_pct   | -0.855    |\n",
      "|    total_trades       | 5891      |\n",
      "| time/                 |           |\n",
      "|    fps                | 525       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | -0.473    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 3.44      |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.636     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.93e+05 |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 2.93e+05 |\n",
      "|    total_reward_pct   | 58.7     |\n",
      "|    total_trades       | 6021     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -1.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -25.4    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.97e+05 |\n",
      "|    total_cost         | 4.27e+03 |\n",
      "|    total_reward       | 2.97e+05 |\n",
      "|    total_reward_pct   | 59.3     |\n",
      "|    total_trades       | 6072     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -0.113   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.17e+05 |\n",
      "|    total_cost         | 2.9e+03  |\n",
      "|    total_reward       | 2.17e+05 |\n",
      "|    total_reward_pct   | 43.4     |\n",
      "|    total_trades       | 5983     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -0.495   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -9.24    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.23     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.28e+05  |\n",
      "|    total_cost         | 2.18e+03  |\n",
      "|    total_reward       | -7.21e+04 |\n",
      "|    total_reward_pct   | -14.4     |\n",
      "|    total_trades       | 6165      |\n",
      "| time/                 |           |\n",
      "|    fps                | 524       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 181       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 73.7      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 5.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -14.4    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "day: 564, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 814335.09\n",
      "total_reward: 314335.09\n",
      "total_cost: 7415.88\n",
      "total_trades: 6260\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.14e+05 |\n",
      "|    total_cost         | 7.42e+03 |\n",
      "|    total_reward       | 3.14e+05 |\n",
      "|    total_reward_pct   | 62.9     |\n",
      "|    total_trades       | 6260     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | -3.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 41.8     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.67e+05 |\n",
      "|    total_cost         | 8.23e+03 |\n",
      "|    total_reward       | 2.67e+05 |\n",
      "|    total_reward_pct   | 53.3     |\n",
      "|    total_trades       | 6408     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.0026   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 2.01     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.43e+05 |\n",
      "|    total_cost         | 5.28e+03 |\n",
      "|    total_reward       | 3.43e+05 |\n",
      "|    total_reward_pct   | 68.6     |\n",
      "|    total_trades       | 6342     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 9.71     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.52e+05  |\n",
      "|    total_cost         | 2.3e+03   |\n",
      "|    total_reward       | -1.48e+05 |\n",
      "|    total_reward_pct   | -29.6     |\n",
      "|    total_trades       | 6153      |\n",
      "| time/                 |           |\n",
      "|    fps                | 524       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | 0.077     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | 7.52      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.94      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.53e+05 |\n",
      "|    total_cost         | 8.7e+03  |\n",
      "|    total_reward       | 3.53e+05 |\n",
      "|    total_reward_pct   | 70.6     |\n",
      "|    total_trades       | 6299     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -35.9    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "day: 564, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 784596.93\n",
      "total_reward: 284596.93\n",
      "total_cost: 5303.40\n",
      "total_trades: 6295\n",
      "Sharpe: 0.723\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.85e+05  |\n",
      "|    total_cost         | 5.3e+03   |\n",
      "|    total_reward       | 2.85e+05  |\n",
      "|    total_reward_pct   | 56.9      |\n",
      "|    total_trades       | 6295      |\n",
      "| time/                 |           |\n",
      "|    fps                | 524       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 188       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | -7.03e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 77.6      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 6.56      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.93e+05 |\n",
      "|    total_cost         | 5.61e+03 |\n",
      "|    total_reward       | 3.93e+05 |\n",
      "|    total_reward_pct   | 78.6     |\n",
      "|    total_trades       | 6566     |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -31.5    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 3.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -0.0505  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -49.9    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 7.56     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-04-06 to  2020-07-09\n",
      "A2C Sharpe Ratio:  nan\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_1\n",
      "day: 564, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 103882.22\n",
      "total_reward: -396117.78\n",
      "total_cost: 159350.49\n",
      "total_trades: 7659\n",
      "Sharpe: -1.519\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.04e+05  |\n",
      "|    total_cost       | 1.59e+05  |\n",
      "|    total_reward     | -3.96e+05 |\n",
      "|    total_reward_pct | -79.2     |\n",
      "|    total_trades     | 7659      |\n",
      "| time/               |           |\n",
      "|    fps              | 725       |\n",
      "|    iterations       | 1         |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 2048      |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.51e+05    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | -3.49e+05   |\n",
      "|    total_reward_pct     | -69.7       |\n",
      "|    total_trades         | 7967        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016837467 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.018      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 263146.73\n",
      "total_reward: -236853.27\n",
      "total_cost: 264964.34\n",
      "total_trades: 8198\n",
      "Sharpe: -1.007\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+05    |\n",
      "|    total_cost           | 1.76e+05    |\n",
      "|    total_reward         | -3.66e+05   |\n",
      "|    total_reward_pct     | -73.2       |\n",
      "|    total_trades         | 7819        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011133815 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0651      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 238660.73\n",
      "total_reward: -261339.27\n",
      "total_cost: 263196.82\n",
      "total_trades: 8035\n",
      "Sharpe: -0.939\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.43e+05    |\n",
      "|    total_cost           | 2.14e+05    |\n",
      "|    total_reward         | -3.57e+05   |\n",
      "|    total_reward_pct     | -71.3       |\n",
      "|    total_trades         | 7946        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022517148 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0912      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 158616.61\n",
      "total_reward: -341383.39\n",
      "total_cost: 191497.72\n",
      "total_trades: 7861\n",
      "Sharpe: -1.347\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.59e+05    |\n",
      "|    total_cost           | 1.91e+05    |\n",
      "|    total_reward         | -3.41e+05   |\n",
      "|    total_reward_pct     | -68.3       |\n",
      "|    total_trades         | 7861        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009944067 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.9         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.22e+05   |\n",
      "|    total_cost           | 4.12e+05   |\n",
      "|    total_reward         | -7.79e+04  |\n",
      "|    total_reward_pct     | -15.6      |\n",
      "|    total_trades         | 8515       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 656        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01501075 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.42       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.94       |\n",
      "----------------------------------------\n",
      "day: 564, episode: 200\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 483422.43\n",
      "total_reward: -16577.57\n",
      "total_cost: 411425.32\n",
      "total_trades: 8409\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.59e+05    |\n",
      "|    total_cost           | 4.41e+05    |\n",
      "|    total_reward         | 5.87e+04    |\n",
      "|    total_reward_pct     | 11.7        |\n",
      "|    total_trades         | 8516        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018418286 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.68        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 428103.52\n",
      "total_reward: -71896.48\n",
      "total_cost: 357061.17\n",
      "total_trades: 8296\n",
      "Sharpe: -0.094\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 4.28e+05  |\n",
      "|    total_cost           | 3.57e+05  |\n",
      "|    total_reward         | -7.19e+04 |\n",
      "|    total_reward_pct     | -14.4     |\n",
      "|    total_trades         | 8296      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 654       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0122047 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.2     |\n",
      "|    explained_variance   | 0.111     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.31      |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.0168   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 2.91      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.17e+05     |\n",
      "|    total_cost           | 3.69e+05     |\n",
      "|    total_reward         | -8.28e+04    |\n",
      "|    total_reward_pct     | -16.6        |\n",
      "|    total_trades         | 8388         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 654          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152921975 |\n",
      "|    clip_fraction        | 0.175        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.681        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.36         |\n",
      "------------------------------------------\n",
      "day: 564, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 373102.42\n",
      "total_reward: -126897.58\n",
      "total_cost: 323081.75\n",
      "total_trades: 8217\n",
      "Sharpe: -0.343\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+05    |\n",
      "|    total_cost           | 2.52e+05    |\n",
      "|    total_reward         | -2.85e+05   |\n",
      "|    total_reward_pct     | -57         |\n",
      "|    total_trades         | 7848        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015060899 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.526       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 253023.71\n",
      "total_reward: -246976.29\n",
      "total_cost: 236275.97\n",
      "total_trades: 8075\n",
      "Sharpe: -0.800\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+05     |\n",
      "|    total_cost           | 2.73e+05    |\n",
      "|    total_reward         | -2.9e+05    |\n",
      "|    total_reward_pct     | -58.1       |\n",
      "|    total_trades         | 8186        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015699845 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0811      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.422       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 149056.01\n",
      "total_reward: -350943.99\n",
      "total_cost: 200032.17\n",
      "total_trades: 7931\n",
      "Sharpe: -1.284\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.49e+05    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | -3.51e+05   |\n",
      "|    total_reward_pct     | -70.2       |\n",
      "|    total_trades         | 7931        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018917587 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.393       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.1e+05     |\n",
      "|    total_cost           | 2.78e+05    |\n",
      "|    total_reward         | -1.9e+05    |\n",
      "|    total_reward_pct     | -38         |\n",
      "|    total_trades         | 8065        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 653         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016817153 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 194514.14\n",
      "total_reward: -305485.86\n",
      "total_cost: 203505.84\n",
      "total_trades: 8082\n",
      "Sharpe: -1.039\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.97e+05    |\n",
      "|    total_cost           | 2.1e+05     |\n",
      "|    total_reward         | -3.03e+05   |\n",
      "|    total_reward_pct     | -60.6       |\n",
      "|    total_trades         | 8040        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 653         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022455983 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.669       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.22        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 136671.84\n",
      "total_reward: -363328.16\n",
      "total_cost: 152423.70\n",
      "total_trades: 7946\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.74e+05    |\n",
      "|    total_cost           | 4e+05       |\n",
      "|    total_reward         | -1.26e+05   |\n",
      "|    total_reward_pct     | -25.2       |\n",
      "|    total_trades         | 8437        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 653         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010550739 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0586      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.8e+05     |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | -3.2e+05    |\n",
      "|    total_reward_pct     | -64.1       |\n",
      "|    total_trades         | 8068        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023989419 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 417491.79\n",
      "total_reward: -82508.21\n",
      "total_cost: 367005.80\n",
      "total_trades: 8585\n",
      "Sharpe: -0.159\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.56e+05    |\n",
      "|    total_cost           | 3.96e+05    |\n",
      "|    total_reward         | -4.43e+04   |\n",
      "|    total_reward_pct     | -8.85       |\n",
      "|    total_trades         | 8400        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 653         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023040086 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.51        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 216089.05\n",
      "total_reward: -283910.95\n",
      "total_cost: 206206.72\n",
      "total_trades: 7970\n",
      "Sharpe: -0.662\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.66e+05    |\n",
      "|    total_cost           | 3.26e+05    |\n",
      "|    total_reward         | -3.45e+04   |\n",
      "|    total_reward_pct     | -6.89       |\n",
      "|    total_trades         | 8466        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014086303 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 568012.86\n",
      "total_reward: 68012.86\n",
      "total_cost: 392836.91\n",
      "total_trades: 8622\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.68e+05    |\n",
      "|    total_cost           | 3.93e+05    |\n",
      "|    total_reward         | 6.8e+04     |\n",
      "|    total_reward_pct     | 13.6        |\n",
      "|    total_trades         | 8622        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017660076 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.05e+05    |\n",
      "|    total_cost           | 3.65e+05    |\n",
      "|    total_reward         | 4.93e+03    |\n",
      "|    total_reward_pct     | 0.987       |\n",
      "|    total_trades         | 8408        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028889693 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.629       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.41        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 346733.03\n",
      "total_reward: -153266.97\n",
      "total_cost: 283000.92\n",
      "total_trades: 8351\n",
      "Sharpe: -0.509\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.15e+05    |\n",
      "|    total_cost           | 3.6e+05     |\n",
      "|    total_reward         | 1.52e+04    |\n",
      "|    total_reward_pct     | 3.05        |\n",
      "|    total_trades         | 8345        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014483897 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.24        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 255\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 158659.73\n",
      "total_reward: -341340.27\n",
      "total_cost: 157734.48\n",
      "total_trades: 7766\n",
      "Sharpe: -1.041\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+05    |\n",
      "|    total_cost           | 1.68e+05    |\n",
      "|    total_reward         | -2.55e+05   |\n",
      "|    total_reward_pct     | -51         |\n",
      "|    total_trades         | 7847        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016895577 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.63        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 260\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 480209.34\n",
      "total_reward: -19790.66\n",
      "total_cost: 324120.51\n",
      "total_trades: 8354\n",
      "Sharpe: 0.035\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.8e+05     |\n",
      "|    total_cost           | 3.24e+05    |\n",
      "|    total_reward         | -1.98e+04   |\n",
      "|    total_reward_pct     | -3.96       |\n",
      "|    total_trades         | 8354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019182652 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.443       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+05    |\n",
      "|    total_cost           | 1.56e+05    |\n",
      "|    total_reward         | -3.09e+05   |\n",
      "|    total_reward_pct     | -61.8       |\n",
      "|    total_trades         | 7802        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018789904 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.52        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 265\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 412417.59\n",
      "total_reward: -87582.41\n",
      "total_cost: 247683.16\n",
      "total_trades: 8098\n",
      "Sharpe: -0.216\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.82e+05   |\n",
      "|    total_cost           | 1.78e+05   |\n",
      "|    total_reward         | -3.18e+05  |\n",
      "|    total_reward_pct     | -63.5      |\n",
      "|    total_trades         | 7921       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 652        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03125014 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.266      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.512      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00668   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 4.39       |\n",
      "----------------------------------------\n",
      "day: 564, episode: 270\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 272670.97\n",
      "total_reward: -227329.03\n",
      "total_cost: 223402.63\n",
      "total_trades: 8084\n",
      "Sharpe: -0.585\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+05    |\n",
      "|    total_cost           | 1.95e+05    |\n",
      "|    total_reward         | -2.09e+05   |\n",
      "|    total_reward_pct     | -41.8       |\n",
      "|    total_trades         | 7915        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022809837 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.19e+05    |\n",
      "|    total_cost           | 3.85e+05    |\n",
      "|    total_reward         | 4.19e+05    |\n",
      "|    total_reward_pct     | 83.8        |\n",
      "|    total_trades         | 8480        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017676923 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.696       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 275\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 634596.31\n",
      "total_reward: 134596.31\n",
      "total_cost: 338392.36\n",
      "total_trades: 8402\n",
      "Sharpe: 0.511\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.87e+05    |\n",
      "|    total_cost           | 2.41e+05    |\n",
      "|    total_reward         | 2.87e+05    |\n",
      "|    total_reward_pct     | 57.5        |\n",
      "|    total_trades         | 8132        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011121323 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.53        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 280\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 545117.20\n",
      "total_reward: 45117.20\n",
      "total_cost: 272372.48\n",
      "total_trades: 8301\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.11e+05    |\n",
      "|    total_cost           | 1.93e+05    |\n",
      "|    total_reward         | -1.89e+05   |\n",
      "|    total_reward_pct     | -37.8       |\n",
      "|    total_trades         | 7932        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022687836 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.19        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.01        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 285\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 647389.67\n",
      "total_reward: 147389.67\n",
      "total_cost: 256474.85\n",
      "total_trades: 8198\n",
      "Sharpe: 0.489\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.47e+05    |\n",
      "|    total_cost           | 2.56e+05    |\n",
      "|    total_reward         | 1.47e+05    |\n",
      "|    total_reward_pct     | 29.5        |\n",
      "|    total_trades         | 8198        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013257363 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.27e+05    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | -1.73e+05   |\n",
      "|    total_reward_pct     | -34.7       |\n",
      "|    total_trades         | 8022        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025457807 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.4         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.76        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 290\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 401063.18\n",
      "total_reward: -98936.82\n",
      "total_cost: 210373.61\n",
      "total_trades: 8054\n",
      "Sharpe: -0.197\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.01e+05   |\n",
      "|    total_cost           | 1.59e+05   |\n",
      "|    total_reward         | -2.99e+05  |\n",
      "|    total_reward_pct     | -59.8      |\n",
      "|    total_trades         | 7961       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 650        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01660224 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.416      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.76       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 8.27       |\n",
      "----------------------------------------\n",
      "day: 564, episode: 295\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 319839.80\n",
      "total_reward: -180160.20\n",
      "total_cost: 256544.29\n",
      "total_trades: 8083\n",
      "Sharpe: -0.724\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.55e+05   |\n",
      "|    total_cost           | 3.28e+05   |\n",
      "|    total_reward         | 2.55e+05   |\n",
      "|    total_reward_pct     | 51         |\n",
      "|    total_trades         | 8335       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 649        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03306386 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.526      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.996      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 4.29       |\n",
      "----------------------------------------\n",
      "day: 564, episode: 300\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 456318.27\n",
      "total_reward: -43681.73\n",
      "total_cost: 270316.49\n",
      "total_trades: 8119\n",
      "Sharpe: -0.051\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.56e+05   |\n",
      "|    total_cost           | 2.7e+05    |\n",
      "|    total_reward         | -4.37e+04  |\n",
      "|    total_reward_pct     | -8.74      |\n",
      "|    total_trades         | 8119       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 650        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03202375 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.17       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 5.6        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.48e+05    |\n",
      "|    total_cost           | 2.84e+05    |\n",
      "|    total_reward         | 1.48e+05    |\n",
      "|    total_reward_pct     | 29.5        |\n",
      "|    total_trades         | 8226        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021616373 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.69        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 305\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 440012.87\n",
      "total_reward: -59987.13\n",
      "total_cost: 229806.36\n",
      "total_trades: 8029\n",
      "Sharpe: -0.096\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 8.17e+05  |\n",
      "|    total_cost           | 3e+05     |\n",
      "|    total_reward         | 3.17e+05  |\n",
      "|    total_reward_pct     | 63.4      |\n",
      "|    total_trades         | 8075      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 650       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0309757 |\n",
      "|    clip_fraction        | 0.257     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.7     |\n",
      "|    explained_variance   | 0.465     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.71      |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.00491  |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 4.32      |\n",
      "---------------------------------------\n",
      "day: 564, episode: 310\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 311098.38\n",
      "total_reward: -188901.62\n",
      "total_cost: 151369.80\n",
      "total_trades: 7742\n",
      "Sharpe: -0.255\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.81e+05   |\n",
      "|    total_cost           | 3.22e+05   |\n",
      "|    total_reward         | 1.81e+05   |\n",
      "|    total_reward_pct     | 36.1       |\n",
      "|    total_trades         | 8290       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 649        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01717252 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.47       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.88       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 6.72       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.82e+05    |\n",
      "|    total_cost           | 1.32e+05    |\n",
      "|    total_reward         | -2.18e+05   |\n",
      "|    total_reward_pct     | -43.7       |\n",
      "|    total_trades         | 7664        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021618657 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.96        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 315\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 738654.39\n",
      "total_reward: 238654.39\n",
      "total_cost: 250505.16\n",
      "total_trades: 8062\n",
      "Sharpe: 0.658\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.36e+05    |\n",
      "|    total_cost           | 2.85e+05    |\n",
      "|    total_reward         | 1.36e+05    |\n",
      "|    total_reward_pct     | 27.2        |\n",
      "|    total_trades         | 8139        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031129345 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 5.84        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 320\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 585997.27\n",
      "total_reward: 85997.27\n",
      "total_cost: 213164.88\n",
      "total_trades: 7918\n",
      "Sharpe: 0.415\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.64e+05    |\n",
      "|    total_cost           | 1.79e+05    |\n",
      "|    total_reward         | 2.64e+05    |\n",
      "|    total_reward_pct     | 52.7        |\n",
      "|    total_trades         | 7793        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030109216 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 325\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 573853.29\n",
      "total_reward: 73853.29\n",
      "total_cost: 229358.72\n",
      "total_trades: 7948\n",
      "Sharpe: 0.370\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.74e+05    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | 7.39e+04    |\n",
      "|    total_reward_pct     | 14.8        |\n",
      "|    total_trades         | 7948        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027551264 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.85        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.84e+05    |\n",
      "|    total_cost           | 1.58e+05    |\n",
      "|    total_reward         | -1.63e+04   |\n",
      "|    total_reward_pct     | -3.26       |\n",
      "|    total_trades         | 7676        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033955403 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.87        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 330\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 428004.01\n",
      "total_reward: -71995.99\n",
      "total_cost: 135664.81\n",
      "total_trades: 7733\n",
      "Sharpe: -0.058\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.29e+05   |\n",
      "|    total_cost           | 2.67e+05   |\n",
      "|    total_reward         | 2.29e+05   |\n",
      "|    total_reward_pct     | 45.8       |\n",
      "|    total_trades         | 7997       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 650        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04833826 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.575      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.75       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00476   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 7.62       |\n",
      "----------------------------------------\n",
      "day: 564, episode: 335\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 814833.22\n",
      "total_reward: 314833.22\n",
      "total_cost: 203380.57\n",
      "total_trades: 7779\n",
      "Sharpe: 0.811\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.78e+05    |\n",
      "|    total_cost           | 1.28e+05    |\n",
      "|    total_reward         | -1.22e+05   |\n",
      "|    total_reward_pct     | -24.3       |\n",
      "|    total_trades         | 7688        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022612866 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 5.92        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 340\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 413763.50\n",
      "total_reward: -86236.50\n",
      "total_cost: 127868.51\n",
      "total_trades: 7716\n",
      "Sharpe: -0.078\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.14e+05    |\n",
      "|    total_cost           | 1.28e+05    |\n",
      "|    total_reward         | -8.62e+04   |\n",
      "|    total_reward_pct     | -17.2       |\n",
      "|    total_trades         | 7716        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025075238 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.66        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.8e+05     |\n",
      "|    total_cost           | 2.12e+05    |\n",
      "|    total_reward         | 2.8e+05     |\n",
      "|    total_reward_pct     | 55.9        |\n",
      "|    total_trades         | 7975        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018085796 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 345\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 867700.11\n",
      "total_reward: 367700.11\n",
      "total_cost: 220635.02\n",
      "total_trades: 7933\n",
      "Sharpe: 0.858\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.31e+05    |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | 2.31e+05    |\n",
      "|    total_reward_pct     | 46.3        |\n",
      "|    total_trades         | 7902        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018299941 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.32        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "day: 564, episode: 350\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 679003.49\n",
      "total_reward: 179003.49\n",
      "total_cost: 187735.10\n",
      "total_trades: 8027\n",
      "Sharpe: 0.566\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.79e+05    |\n",
      "|    total_cost           | 1.88e+05    |\n",
      "|    total_reward         | 1.79e+05    |\n",
      "|    total_reward_pct     | 35.8        |\n",
      "|    total_trades         | 8027        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023694878 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.45        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.89e+05    |\n",
      "|    total_cost           | 2.24e+05    |\n",
      "|    total_reward         | 2.89e+05    |\n",
      "|    total_reward_pct     | 57.9        |\n",
      "|    total_trades         | 8033        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022650544 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.66        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-04-06 to  2020-07-09\n",
      "PPO Sharpe Ratio:  nan\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.14e+05  |\n",
      "|    total_cost       | 3.37e+03  |\n",
      "|    total_reward     | -1.86e+05 |\n",
      "|    total_reward_pct | -37.2     |\n",
      "|    total_trades     | 6143      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 160       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total timesteps  | 2260      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 23.6      |\n",
      "|    critic_loss      | 322       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 1695      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 360\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 408434.44\n",
      "total_reward: -91565.56\n",
      "total_cost: 3698.32\n",
      "total_trades: 6121\n",
      "Sharpe: 0.017\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.92e+05  |\n",
      "|    total_cost       | 3.53e+03  |\n",
      "|    total_reward     | -1.08e+05 |\n",
      "|    total_reward_pct | -21.7     |\n",
      "|    total_trades     | 6118      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 142       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total timesteps  | 4520      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 21.6      |\n",
      "|    critic_loss      | 57.5      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 3955      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 365\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 382938.72\n",
      "total_reward: -117061.28\n",
      "total_cost: 3454.81\n",
      "total_trades: 6121\n",
      "Sharpe: -0.054\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.46e+05  |\n",
      "|    total_cost       | 3.23e+03  |\n",
      "|    total_reward     | -1.54e+05 |\n",
      "|    total_reward_pct | -30.8     |\n",
      "|    total_trades     | 6148      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 136       |\n",
      "|    time_elapsed     | 49        |\n",
      "|    total timesteps  | 6780      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 19        |\n",
      "|    critic_loss      | 29.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6215      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 370\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 426126.57\n",
      "total_reward: -73873.43\n",
      "total_cost: 3850.00\n",
      "total_trades: 6116\n",
      "Sharpe: 0.075\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.21e+05  |\n",
      "|    total_cost       | 3.76e+03  |\n",
      "|    total_reward     | -1.79e+05 |\n",
      "|    total_reward_pct | -35.7     |\n",
      "|    total_trades     | 6048      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 134       |\n",
      "|    time_elapsed     | 67        |\n",
      "|    total timesteps  | 9040      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 16.4      |\n",
      "|    critic_loss      | 18        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 8475      |\n",
      "-----------------------------------\n",
      "day: 564, episode: 375\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 355032.99\n",
      "total_reward: -144967.01\n",
      "total_cost: 4869.50\n",
      "total_trades: 6053\n",
      "Sharpe: -0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.55e+05  |\n",
      "|    total_cost       | 4.87e+03  |\n",
      "|    total_reward     | -1.45e+05 |\n",
      "|    total_reward_pct | -29       |\n",
      "|    total_trades     | 6053      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 132       |\n",
      "|    time_elapsed     | 85        |\n",
      "|    total timesteps  | 11300     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 13.8      |\n",
      "|    critic_loss      | 5.63      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 10735     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.67e+05  |\n",
      "|    total_cost       | 5.46e+03  |\n",
      "|    total_reward     | -2.33e+05 |\n",
      "|    total_reward_pct | -46.7     |\n",
      "|    total_trades     | 6009      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 102       |\n",
      "|    total timesteps  | 13560     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 11.8      |\n",
      "|    critic_loss      | 6.64      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 12995     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 380\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 431041.23\n",
      "total_reward: -68958.77\n",
      "total_cost: 4074.01\n",
      "total_trades: 5988\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.51e+05  |\n",
      "|    total_cost       | 3.46e+03  |\n",
      "|    total_reward     | -1.49e+05 |\n",
      "|    total_reward_pct | -29.7     |\n",
      "|    total_trades     | 5958      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 120       |\n",
      "|    total timesteps  | 15820     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 9.91      |\n",
      "|    critic_loss      | 43.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 15255     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 385\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 392211.44\n",
      "total_reward: -107788.56\n",
      "total_cost: 3245.30\n",
      "total_trades: 5960\n",
      "Sharpe: -0.071\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.4e+05  |\n",
      "|    total_cost       | 4.91e+03 |\n",
      "|    total_reward     | -1.6e+05 |\n",
      "|    total_reward_pct | -31.9    |\n",
      "|    total_trades     | 5971     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total timesteps  | 18080    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 8.59     |\n",
      "|    critic_loss      | 24.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17515    |\n",
      "----------------------------------\n",
      "day: 564, episode: 390\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 294683.68\n",
      "total_reward: -205316.32\n",
      "total_cost: 4081.97\n",
      "total_trades: 5953\n",
      "Sharpe: -0.279\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.5e+05  |\n",
      "|    total_cost       | 3.85e+03 |\n",
      "|    total_reward     | -2.5e+05 |\n",
      "|    total_reward_pct | -50      |\n",
      "|    total_trades     | 5947     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total timesteps  | 20340    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 7.3      |\n",
      "|    critic_loss      | 28.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19775    |\n",
      "----------------------------------\n",
      "day: 564, episode: 395\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 307432.96\n",
      "total_reward: -192567.04\n",
      "total_cost: 3966.65\n",
      "total_trades: 5940\n",
      "Sharpe: -0.345\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.07e+05  |\n",
      "|    total_cost       | 3.97e+03  |\n",
      "|    total_reward     | -1.93e+05 |\n",
      "|    total_reward_pct | -38.5     |\n",
      "|    total_trades     | 5940      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 174       |\n",
      "|    total timesteps  | 22600     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 6.31      |\n",
      "|    critic_loss      | 5.83      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 22035     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.79e+05  |\n",
      "|    total_cost       | 3.63e+03  |\n",
      "|    total_reward     | -1.21e+05 |\n",
      "|    total_reward_pct | -24.2     |\n",
      "|    total_trades     | 5949      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 191       |\n",
      "|    total timesteps  | 24860     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 5.32      |\n",
      "|    critic_loss      | 0.984     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 24295     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 400\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 397657.49\n",
      "total_reward: -102342.51\n",
      "total_cost: 3846.18\n",
      "total_trades: 5947\n",
      "Sharpe: -0.053\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.32e+05  |\n",
      "|    total_cost       | 4.76e+03  |\n",
      "|    total_reward     | -1.68e+05 |\n",
      "|    total_reward_pct | -33.6     |\n",
      "|    total_trades     | 5998      |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 209       |\n",
      "|    total timesteps  | 27120     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 4.6       |\n",
      "|    critic_loss      | 1.11      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 26555     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 405\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 351753.00\n",
      "total_reward: -148247.00\n",
      "total_cost: 4769.36\n",
      "total_trades: 6021\n",
      "Sharpe: -0.214\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.88e+05  |\n",
      "|    total_cost       | 4.16e+03  |\n",
      "|    total_reward     | -2.12e+05 |\n",
      "|    total_reward_pct | -42.4     |\n",
      "|    total_trades     | 6018      |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 227       |\n",
      "|    total timesteps  | 29380     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 3.98      |\n",
      "|    critic_loss      | 2.56      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28815     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 410\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 356615.96\n",
      "total_reward: -143384.04\n",
      "total_cost: 4275.95\n",
      "total_trades: 6021\n",
      "Sharpe: -0.150\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.93e+05  |\n",
      "|    total_cost       | 3.81e+03  |\n",
      "|    total_reward     | -2.07e+05 |\n",
      "|    total_reward_pct | -41.4     |\n",
      "|    total_trades     | 6036      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 245       |\n",
      "|    total timesteps  | 31640     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 3.48      |\n",
      "|    critic_loss      | 1.12      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 31075     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 415\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 263924.00\n",
      "total_reward: -236076.00\n",
      "total_cost: 3337.10\n",
      "total_trades: 6032\n",
      "Sharpe: -0.400\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.64e+05  |\n",
      "|    total_cost       | 3.34e+03  |\n",
      "|    total_reward     | -2.36e+05 |\n",
      "|    total_reward_pct | -47.2     |\n",
      "|    total_trades     | 6032      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 263       |\n",
      "|    total timesteps  | 33900     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.96      |\n",
      "|    critic_loss      | 1.24      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 33335     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.6e+05  |\n",
      "|    total_cost       | 3.68e+03 |\n",
      "|    total_reward     | -1.4e+05 |\n",
      "|    total_reward_pct | -28      |\n",
      "|    total_trades     | 6059     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total timesteps  | 36160    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.54     |\n",
      "|    critic_loss      | 0.844    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35595    |\n",
      "----------------------------------\n",
      "day: 564, episode: 420\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 399264.19\n",
      "total_reward: -100735.81\n",
      "total_cost: 3773.73\n",
      "total_trades: 6075\n",
      "Sharpe: -0.051\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.01e+05  |\n",
      "|    total_cost       | 3.77e+03  |\n",
      "|    total_reward     | -9.93e+04 |\n",
      "|    total_reward_pct | -19.9     |\n",
      "|    total_trades     | 6054      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 298       |\n",
      "|    total timesteps  | 38420     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 2.14      |\n",
      "|    critic_loss      | 4.1       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37855     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 425\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 409951.54\n",
      "total_reward: -90048.46\n",
      "total_cost: 3666.14\n",
      "total_trades: 6053\n",
      "Sharpe: -0.010\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.47e+05  |\n",
      "|    total_cost       | 4.41e+03  |\n",
      "|    total_reward     | -1.53e+05 |\n",
      "|    total_reward_pct | -30.7     |\n",
      "|    total_trades     | 6058      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 316       |\n",
      "|    total timesteps  | 40680     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 1.71      |\n",
      "|    critic_loss      | 2.97      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 40115     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 430\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 327894.69\n",
      "total_reward: -172105.31\n",
      "total_cost: 3257.83\n",
      "total_trades: 6040\n",
      "Sharpe: -0.127\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.69e+05  |\n",
      "|    total_cost       | 3.22e+03  |\n",
      "|    total_reward     | -2.31e+05 |\n",
      "|    total_reward_pct | -46.2     |\n",
      "|    total_trades     | 6025      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 334       |\n",
      "|    total timesteps  | 42940     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 1.34      |\n",
      "|    critic_loss      | 8.26      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 42375     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 435\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 360641.68\n",
      "total_reward: -139358.32\n",
      "total_cost: 3630.95\n",
      "total_trades: 6038\n",
      "Sharpe: -0.181\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.61e+05  |\n",
      "|    total_cost       | 3.63e+03  |\n",
      "|    total_reward     | -1.39e+05 |\n",
      "|    total_reward_pct | -27.9     |\n",
      "|    total_trades     | 6038      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 352       |\n",
      "|    total timesteps  | 45200     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 1         |\n",
      "|    critic_loss      | 0.702     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 44635     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.45e+05  |\n",
      "|    total_cost       | 2.9e+03   |\n",
      "|    total_reward     | -1.55e+05 |\n",
      "|    total_reward_pct | -31.1     |\n",
      "|    total_trades     | 5997      |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 128       |\n",
      "|    time_elapsed     | 369       |\n",
      "|    total timesteps  | 47460     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.725     |\n",
      "|    critic_loss      | 24.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 46895     |\n",
      "-----------------------------------\n",
      "day: 564, episode: 440\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 360106.70\n",
      "total_reward: -139893.30\n",
      "total_cost: 5117.48\n",
      "total_trades: 6024\n",
      "Sharpe: -0.209\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.8e+05  |\n",
      "|    total_cost       | 3.53e+03 |\n",
      "|    total_reward     | -1.2e+05 |\n",
      "|    total_reward_pct | -24.1    |\n",
      "|    total_trades     | 5986     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 387      |\n",
      "|    total timesteps  | 49720    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.471    |\n",
      "|    critic_loss      | 31.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49155    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-04-06 to  2020-07-09\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-07-09\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_441_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -937     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 6276     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 159      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total timesteps  | 2512     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -19.3    |\n",
      "|    critic_loss      | 671      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 1884     |\n",
      "----------------------------------\n",
      "day: 627, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499047.30\n",
      "total_reward: -952.70\n",
      "total_cost: 948.49\n",
      "total_trades: 6284\n",
      "Sharpe: 0.148\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -937     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 6290     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total timesteps  | 5024     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -17.7    |\n",
      "|    critic_loss      | 182      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4396     |\n",
      "----------------------------------\n",
      "day: 627, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500326.63\n",
      "total_reward: 326.63\n",
      "total_cost: 949.86\n",
      "total_trades: 6291\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 950       |\n",
      "|    total_reward     | -2.28e+03 |\n",
      "|    total_reward_pct | -0.457    |\n",
      "|    total_trades     | 6188      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 136       |\n",
      "|    time_elapsed     | 55        |\n",
      "|    total timesteps  | 7536      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -16.4     |\n",
      "|    critic_loss      | 71.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6908      |\n",
      "-----------------------------------\n",
      "day: 627, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499714.49\n",
      "total_reward: -285.51\n",
      "total_cost: 948.26\n",
      "total_trades: 6161\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.89e+05  |\n",
      "|    total_cost       | 949       |\n",
      "|    total_reward     | -1.14e+04 |\n",
      "|    total_reward_pct | -2.28     |\n",
      "|    total_trades     | 6162      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 133       |\n",
      "|    time_elapsed     | 75        |\n",
      "|    total timesteps  | 10048     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -15.2     |\n",
      "|    critic_loss      | 32.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 9420      |\n",
      "-----------------------------------\n",
      "day: 627, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499064.85\n",
      "total_reward: -935.15\n",
      "total_cost: 948.49\n",
      "total_trades: 6143\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -935     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 6143     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 132      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total timesteps  | 12560    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -14.3    |\n",
      "|    critic_loss      | 22.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11932    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.89e+05  |\n",
      "|    total_cost       | 949       |\n",
      "|    total_reward     | -1.05e+04 |\n",
      "|    total_reward_pct | -2.1      |\n",
      "|    total_trades     | 6139      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 131       |\n",
      "|    time_elapsed     | 114       |\n",
      "|    total timesteps  | 15072     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -13.1     |\n",
      "|    critic_loss      | 23.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 14444     |\n",
      "-----------------------------------\n",
      "day: 627, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499068.99\n",
      "total_reward: -931.01\n",
      "total_cost: 948.72\n",
      "total_trades: 6151\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.97e+05  |\n",
      "|    total_cost       | 949       |\n",
      "|    total_reward     | -2.89e+03 |\n",
      "|    total_reward_pct | -0.577    |\n",
      "|    total_trades     | 6141      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 130       |\n",
      "|    time_elapsed     | 134       |\n",
      "|    total timesteps  | 17584     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -12.2     |\n",
      "|    critic_loss      | 26.5      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16956     |\n",
      "-----------------------------------\n",
      "day: 627, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 496533.85\n",
      "total_reward: -3466.15\n",
      "total_cost: 948.54\n",
      "total_trades: 6160\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.1e+05  |\n",
      "|    total_cost       | 961      |\n",
      "|    total_reward     | 9.84e+03 |\n",
      "|    total_reward_pct | 1.97     |\n",
      "|    total_trades     | 6154     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total timesteps  | 20096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -11.1    |\n",
      "|    critic_loss      | 8.64     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19468    |\n",
      "----------------------------------\n",
      "day: 627, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 492034.26\n",
      "total_reward: -7965.74\n",
      "total_cost: 949.11\n",
      "total_trades: 6153\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.99e+05  |\n",
      "|    total_cost       | 951       |\n",
      "|    total_reward     | -1.24e+03 |\n",
      "|    total_reward_pct | -0.249    |\n",
      "|    total_trades     | 6159      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 129       |\n",
      "|    time_elapsed     | 174       |\n",
      "|    total timesteps  | 22608     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -10.1     |\n",
      "|    critic_loss      | 4.64      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 21980     |\n",
      "-----------------------------------\n",
      "day: 627, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499036.81\n",
      "total_reward: -963.19\n",
      "total_cost: 948.67\n",
      "total_trades: 6116\n",
      "Sharpe: 0.308\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -963     |\n",
      "|    total_reward_pct | -0.193   |\n",
      "|    total_trades     | 6116     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total timesteps  | 25120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -9.27    |\n",
      "|    critic_loss      | 11.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24492    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -935     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 6127     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total timesteps  | 27632    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.51    |\n",
      "|    critic_loss      | 7.56     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27004    |\n",
      "----------------------------------\n",
      "day: 627, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499098.61\n",
      "total_reward: -901.39\n",
      "total_cost: 948.31\n",
      "total_trades: 6124\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -285     |\n",
      "|    total_reward_pct | -0.0571  |\n",
      "|    total_trades     | 6121     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total timesteps  | 30144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -7.86    |\n",
      "|    critic_loss      | 5.04     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29516    |\n",
      "----------------------------------\n",
      "day: 627, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 491203.47\n",
      "total_reward: -8796.53\n",
      "total_cost: 948.48\n",
      "total_trades: 6408\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -936     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 6409     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total timesteps  | 32656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -7.21    |\n",
      "|    critic_loss      | 2.63     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32028    |\n",
      "----------------------------------\n",
      "day: 627, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497346.91\n",
      "total_reward: -2653.09\n",
      "total_cost: 948.57\n",
      "total_trades: 6415\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -870     |\n",
      "|    total_reward_pct | -0.174   |\n",
      "|    total_trades     | 6417     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total timesteps  | 35168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.81    |\n",
      "|    critic_loss      | 22.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34540    |\n",
      "----------------------------------\n",
      "day: 627, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499064.20\n",
      "total_reward: -935.80\n",
      "total_cost: 948.72\n",
      "total_trades: 6316\n",
      "Sharpe: 0.167\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -936     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 6316     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total timesteps  | 37680    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.38    |\n",
      "|    critic_loss      | 21.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -949     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 6307     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total timesteps  | 40192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.94    |\n",
      "|    critic_loss      | 5.59     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39564    |\n",
      "----------------------------------\n",
      "day: 627, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499008.00\n",
      "total_reward: -992.00\n",
      "total_cost: 949.02\n",
      "total_trades: 6317\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -935     |\n",
      "|    total_reward_pct | -0.187   |\n",
      "|    total_trades     | 6319     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total timesteps  | 42704    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.49    |\n",
      "|    critic_loss      | 6        |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 42076    |\n",
      "----------------------------------\n",
      "day: 627, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499677.21\n",
      "total_reward: -322.79\n",
      "total_cost: 948.35\n",
      "total_trades: 6303\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -902     |\n",
      "|    total_reward_pct | -0.18    |\n",
      "|    total_trades     | 6285     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total timesteps  | 45216    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.21    |\n",
      "|    critic_loss      | 4.02     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44588    |\n",
      "----------------------------------\n",
      "day: 627, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499050.96\n",
      "total_reward: -949.04\n",
      "total_cost: 948.30\n",
      "total_trades: 6269\n",
      "Sharpe: 0.145\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -948     |\n",
      "|    total_reward_pct | -0.19    |\n",
      "|    total_trades     | 6295     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 127      |\n",
      "|    time_elapsed     | 373      |\n",
      "|    total timesteps  | 47728    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -4.88    |\n",
      "|    critic_loss      | 12.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47100    |\n",
      "----------------------------------\n",
      "day: 627, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 484280.81\n",
      "total_reward: -15719.19\n",
      "total_cost: 948.45\n",
      "total_trades: 6307\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.84e+05  |\n",
      "|    total_cost       | 948       |\n",
      "|    total_reward     | -1.57e+04 |\n",
      "|    total_reward_pct | -3.14     |\n",
      "|    total_trades     | 6307      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 127       |\n",
      "|    time_elapsed     | 393       |\n",
      "|    total timesteps  | 50240     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -4.58     |\n",
      "|    critic_loss      | 13.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 49612     |\n",
      "-----------------------------------\n",
      "======Trading from:  2020-07-09 to  2020-10-06\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  0.0\n",
      "======Model training from:  2000-01-01 to  2020-07-09\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -0.471   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 2.98     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.179    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.15e+05 |\n",
      "|    total_cost         | 3.5e+05  |\n",
      "|    total_reward       | 1.51e+04 |\n",
      "|    total_reward_pct   | 3.02     |\n",
      "|    total_trades       | 8869     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -0.145   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -5.8     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0715   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.22e+05  |\n",
      "|    total_cost         | 1.17e+05  |\n",
      "|    total_reward       | -1.78e+05 |\n",
      "|    total_reward_pct   | -35.7     |\n",
      "|    total_trades       | 7539      |\n",
      "| time/                 |           |\n",
      "|    fps                | 520       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.151    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -8.92     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.167     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.96e+05  |\n",
      "|    total_cost         | 2.02e+04  |\n",
      "|    total_reward       | -1.04e+05 |\n",
      "|    total_reward_pct   | -20.7     |\n",
      "|    total_trades       | 6708      |\n",
      "| time/                 |           |\n",
      "|    fps                | 521       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | 0.0312    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 27.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.2       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.216   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.414    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.89e+05 |\n",
      "|    total_cost         | 1.09e+04 |\n",
      "|    total_reward       | 1.89e+05 |\n",
      "|    total_reward_pct   | 37.8     |\n",
      "|    total_trades       | 6571     |\n",
      "| time/                 |          |\n",
      "|    fps                | 522      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | 0.128    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -8.19    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.251    |\n",
      "------------------------------------\n",
      "day: 627, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 441462.51\n",
      "total_reward: -58537.49\n",
      "total_cost: 20145.53\n",
      "total_trades: 6896\n",
      "Sharpe: 0.187\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.41e+05  |\n",
      "|    total_cost         | 2.01e+04  |\n",
      "|    total_reward       | -5.85e+04 |\n",
      "|    total_reward_pct   | -11.7     |\n",
      "|    total_trades       | 6896      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | -0.171    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 5.64      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.59e+05 |\n",
      "|    total_cost         | 1.41e+04 |\n",
      "|    total_reward       | 5.87e+04 |\n",
      "|    total_reward_pct   | 11.7     |\n",
      "|    total_trades       | 6477     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 18.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.03e+05 |\n",
      "|    total_cost         | 4.94e+04 |\n",
      "|    total_reward       | 4.03e+05 |\n",
      "|    total_reward_pct   | 80.7     |\n",
      "|    total_trades       | 6524     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.146    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -10.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.336    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.65e+05  |\n",
      "|    total_cost         | 3.28e+04  |\n",
      "|    total_reward       | -3.54e+04 |\n",
      "|    total_reward_pct   | -7.08     |\n",
      "|    total_trades       | 6357      |\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 105       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 17.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.67e+05  |\n",
      "|    total_cost         | 9.02e+03  |\n",
      "|    total_reward       | -3.34e+04 |\n",
      "|    total_reward_pct   | -6.67     |\n",
      "|    total_trades       | 5979      |\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -0.0733   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 43.4      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.36      |\n",
      "-------------------------------------\n",
      "day: 627, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1044074.04\n",
      "total_reward: 544074.04\n",
      "total_cost: 10579.49\n",
      "total_trades: 6011\n",
      "Sharpe: 0.987\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 5.44e+05 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 6011     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.392   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -54.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.37e+05 |\n",
      "|    total_cost         | 5.1e+03  |\n",
      "|    total_reward       | 3.37e+05 |\n",
      "|    total_reward_pct   | 67.4     |\n",
      "|    total_trades       | 6123     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.0199  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 14.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.516    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 21.6      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.707     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.51e+05 |\n",
      "|    total_cost         | 2.74e+03 |\n",
      "|    total_reward       | 5.15e+04 |\n",
      "|    total_reward_pct   | 10.3     |\n",
      "|    total_trades       | 6255     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 22.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.884    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.21e+05 |\n",
      "|    total_cost         | 1.9e+03  |\n",
      "|    total_reward       | 2.14e+04 |\n",
      "|    total_reward_pct   | 4.27     |\n",
      "|    total_trades       | 6210     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -14.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.352    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 6.74e+03 |\n",
      "|    total_reward       | 5.34e+05 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 6532     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.452   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -65.8    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "day: 627, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 453582.32\n",
      "total_reward: -46417.68\n",
      "total_cost: 2444.73\n",
      "total_trades: 6741\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.54e+05  |\n",
      "|    total_cost         | 2.44e+03  |\n",
      "|    total_reward       | -4.64e+04 |\n",
      "|    total_reward_pct   | -9.28     |\n",
      "|    total_trades       | 6741      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -0.108    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -6.61     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.182     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.00448  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 31       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5e+05    |\n",
      "|    total_cost         | 2.82e+03 |\n",
      "|    total_reward       | -33.2    |\n",
      "|    total_reward_pct   | -0.00663 |\n",
      "|    total_trades       | 6812     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.0101  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -198     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 71.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+05 |\n",
      "|    total_cost         | 6.62e+03 |\n",
      "|    total_reward       | 4.97e+05 |\n",
      "|    total_reward_pct   | 99.3     |\n",
      "|    total_trades       | 6444     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 33.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.21e+05 |\n",
      "|    total_cost         | 5.35e+03 |\n",
      "|    total_reward       | 2.07e+04 |\n",
      "|    total_reward_pct   | 4.13     |\n",
      "|    total_trades       | 6283     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.336   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.046    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.52e+05  |\n",
      "|    total_cost         | 7.06e+03  |\n",
      "|    total_reward       | -1.48e+05 |\n",
      "|    total_reward_pct   | -29.6     |\n",
      "|    total_trades       | 6030      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 2.74e-06  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 32.2      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.83      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.0516  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -74.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.26     |\n",
      "------------------------------------\n",
      "day: 627, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1028317.27\n",
      "total_reward: 528317.27\n",
      "total_cost: 8903.72\n",
      "total_trades: 5852\n",
      "Sharpe: 0.979\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 8.9e+03  |\n",
      "|    total_reward       | 5.28e+05 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 5852     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.0245  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -12.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.543    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.42e+05 |\n",
      "|    total_cost         | 4.19e+03 |\n",
      "|    total_reward       | 4.2e+04  |\n",
      "|    total_reward_pct   | 8.39     |\n",
      "|    total_trades       | 5936     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -5.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.99e+05 |\n",
      "|    total_cost         | 4.98e+03 |\n",
      "|    total_reward       | 1.99e+05 |\n",
      "|    total_reward_pct   | 39.8     |\n",
      "|    total_trades       | 6272     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 7.58     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.55e+05  |\n",
      "|    total_cost         | 1.76e+04  |\n",
      "|    total_reward       | -4.46e+04 |\n",
      "|    total_reward_pct   | -8.92     |\n",
      "|    total_trades       | 6394      |\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 31.8      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.33      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.0454  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -71.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.3e+05  |\n",
      "|    total_cost         | 2.98e+04 |\n",
      "|    total_reward       | 2.3e+05  |\n",
      "|    total_reward_pct   | 46       |\n",
      "|    total_trades       | 6319     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.0228  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -31.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "day: 627, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1051718.79\n",
      "total_reward: 551718.79\n",
      "total_cost: 11590.18\n",
      "total_trades: 6260\n",
      "Sharpe: 1.005\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | 5.52e+05 |\n",
      "|    total_reward_pct   | 110      |\n",
      "|    total_trades       | 6260     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.39     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.77e+05  |\n",
      "|    total_cost         | 1.97e+04  |\n",
      "|    total_reward       | -2.26e+04 |\n",
      "|    total_reward_pct   | -4.51     |\n",
      "|    total_trades       | 6484      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 0.338     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 2.35      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.0335    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.03e+05 |\n",
      "|    total_cost         | 4.72e+03 |\n",
      "|    total_reward       | 1.03e+05 |\n",
      "|    total_reward_pct   | 20.6     |\n",
      "|    total_trades       | 6394     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.0834   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -60.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.0208   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 27.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.83e+05 |\n",
      "|    total_cost         | 3.89e+03 |\n",
      "|    total_reward       | 3.83e+05 |\n",
      "|    total_reward_pct   | 76.7     |\n",
      "|    total_trades       | 6008     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -7.88    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.14e+05  |\n",
      "|    total_cost         | 2.69e+03  |\n",
      "|    total_reward       | -8.57e+04 |\n",
      "|    total_reward_pct   | -17.1     |\n",
      "|    total_trades       | 5855      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -0.184    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -14.7     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.8       |\n",
      "-------------------------------------\n",
      "day: 627, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 744396.05\n",
      "total_reward: 244396.05\n",
      "total_cost: 4484.58\n",
      "total_trades: 6164\n",
      "Sharpe: 0.645\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.44e+05 |\n",
      "|    total_cost         | 4.48e+03 |\n",
      "|    total_reward       | 2.44e+05 |\n",
      "|    total_reward_pct   | 48.9     |\n",
      "|    total_trades       | 6164     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.025   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -12.3    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.284    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.04e+05  |\n",
      "|    total_cost         | 1.93e+04  |\n",
      "|    total_reward       | -1.96e+05 |\n",
      "|    total_reward_pct   | -39.2     |\n",
      "|    total_trades       | 6432      |\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -0.0382   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 9.62      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.479     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.166   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -3.64    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.37e+05  |\n",
      "|    total_cost         | 1.71e+04  |\n",
      "|    total_reward       | -1.63e+05 |\n",
      "|    total_reward_pct   | -32.6     |\n",
      "|    total_trades       | 6469      |\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -19.6     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.659     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+05  |\n",
      "|    total_cost         | 1.42e+04  |\n",
      "|    total_reward       | -1.58e+05 |\n",
      "|    total_reward_pct   | -31.7     |\n",
      "|    total_trades       | 6165      |\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 18.1      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.562     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.53e+05  |\n",
      "|    total_cost         | 2.21e+04  |\n",
      "|    total_reward       | -1.47e+05 |\n",
      "|    total_reward_pct   | -29.5     |\n",
      "|    total_trades       | 6750      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -0.0338   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -23.2     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.74      |\n",
      "-------------------------------------\n",
      "day: 627, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 515976.81\n",
      "total_reward: 15976.81\n",
      "total_cost: 36909.15\n",
      "total_trades: 6856\n",
      "Sharpe: 0.189\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.16e+05 |\n",
      "|    total_cost         | 3.69e+04 |\n",
      "|    total_reward       | 1.6e+04  |\n",
      "|    total_reward_pct   | 3.2      |\n",
      "|    total_trades       | 6856     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -1.21    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.67     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -0.000659 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -20.9     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.893     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.31e+05  |\n",
      "|    total_cost         | 2.03e+04  |\n",
      "|    total_reward       | -1.69e+05 |\n",
      "|    total_reward_pct   | -33.8     |\n",
      "|    total_trades       | 6401      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -1.32     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.0545    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.16e+05 |\n",
      "|    total_cost         | 4.72e+04 |\n",
      "|    total_reward       | 1.58e+04 |\n",
      "|    total_reward_pct   | 3.17     |\n",
      "|    total_trades       | 6086     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -4.57    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.19e+05 |\n",
      "|    total_cost         | 4.47e+04 |\n",
      "|    total_reward       | 1.19e+05 |\n",
      "|    total_reward_pct   | 23.7     |\n",
      "|    total_trades       | 5990     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.599   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -6.44    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0967   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.72e+05  |\n",
      "|    total_cost         | 2.41e+04  |\n",
      "|    total_reward       | -2.77e+04 |\n",
      "|    total_reward_pct   | -5.53     |\n",
      "|    total_trades       | 6013      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -1.24     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 13        |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 20.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.0869  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 7.32     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.172    |\n",
      "------------------------------------\n",
      "day: 627, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 793296.43\n",
      "total_reward: 293296.43\n",
      "total_cost: 64066.17\n",
      "total_trades: 5857\n",
      "Sharpe: 0.838\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.93e+05 |\n",
      "|    total_cost         | 6.41e+04 |\n",
      "|    total_reward       | 2.93e+05 |\n",
      "|    total_reward_pct   | 58.7     |\n",
      "|    total_trades       | 5857     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.315   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 17.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.886    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 6.39e+04 |\n",
      "|    total_reward       | 5.05e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 5712     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.0124  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -23.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.22e+06 |\n",
      "|    total_cost         | 6.73e+04 |\n",
      "|    total_reward       | 7.24e+05 |\n",
      "|    total_reward_pct   | 145      |\n",
      "|    total_trades       | 5988     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.803    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0963   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.736    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.59e+05 |\n",
      "|    total_cost         | 4.75e+04 |\n",
      "|    total_reward       | 5.86e+04 |\n",
      "|    total_reward_pct   | 11.7     |\n",
      "|    total_trades       | 6248     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 57.4     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 5.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.71e+05 |\n",
      "|    total_cost         | 2.96e+04 |\n",
      "|    total_reward       | 1.71e+05 |\n",
      "|    total_reward_pct   | 34.3     |\n",
      "|    total_trades       | 6052     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.452    |\n",
      "------------------------------------\n",
      "day: 627, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 883639.47\n",
      "total_reward: 383639.47\n",
      "total_cost: 30060.46\n",
      "total_trades: 5927\n",
      "Sharpe: 0.860\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.84e+05 |\n",
      "|    total_cost         | 3.01e+04 |\n",
      "|    total_reward       | 3.84e+05 |\n",
      "|    total_reward_pct   | 76.7     |\n",
      "|    total_trades       | 5927     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.0467  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -30.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.58e+05 |\n",
      "|    total_cost         | 5.02e+04 |\n",
      "|    total_reward       | 2.58e+05 |\n",
      "|    total_reward_pct   | 51.6     |\n",
      "|    total_trades       | 5928     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 0.228    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.971    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -0.109   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 27.8     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.36e+05 |\n",
      "|    total_cost         | 3.83e+04 |\n",
      "|    total_reward       | 3.36e+05 |\n",
      "|    total_reward_pct   | 67.3     |\n",
      "|    total_trades       | 5716     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -0.00453 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -15.4    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.596    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.2e+05  |\n",
      "|    total_cost         | 2.62e+04 |\n",
      "|    total_reward       | 2.2e+05  |\n",
      "|    total_reward_pct   | 43.9     |\n",
      "|    total_trades       | 5635     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 8.04     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.55e+05  |\n",
      "|    total_cost         | 1.8e+04   |\n",
      "|    total_reward       | -4.55e+04 |\n",
      "|    total_reward_pct   | -9.09     |\n",
      "|    total_trades       | 5794      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -0.383    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -2        |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.0313    |\n",
      "-------------------------------------\n",
      "day: 627, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 385373.53\n",
      "total_reward: -114626.47\n",
      "total_cost: 15515.21\n",
      "total_trades: 5912\n",
      "Sharpe: 0.014\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.85e+05  |\n",
      "|    total_cost         | 1.55e+04  |\n",
      "|    total_reward       | -1.15e+05 |\n",
      "|    total_reward_pct   | -22.9     |\n",
      "|    total_trades       | 5912      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | 0.0795    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -14.6     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.433     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 38.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.44e+05 |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | 4.37e+04 |\n",
      "|    total_reward_pct   | 8.75     |\n",
      "|    total_trades       | 5993     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.214   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.23e+05  |\n",
      "|    total_cost         | 1.49e+04  |\n",
      "|    total_reward       | -7.66e+04 |\n",
      "|    total_reward_pct   | -15.3     |\n",
      "|    total_trades       | 5966      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -28.8     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.97e+05  |\n",
      "|    total_cost         | 1.92e+04  |\n",
      "|    total_reward       | -1.03e+05 |\n",
      "|    total_reward_pct   | -20.6     |\n",
      "|    total_trades       | 6048      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 66.9      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 8.82      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.19e+06 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 6.85e+05 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 5933     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.192    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 7.99     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.465    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.0303   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 57.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.21     |\n",
      "------------------------------------\n",
      "day: 627, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 600542.19\n",
      "total_reward: 100542.19\n",
      "total_cost: 1652.49\n",
      "total_trades: 5768\n",
      "Sharpe: 0.423\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.01e+05 |\n",
      "|    total_cost         | 1.65e+03 |\n",
      "|    total_reward       | 1.01e+05 |\n",
      "|    total_reward_pct   | 20.1     |\n",
      "|    total_trades       | 5768     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0.0239   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 30.5     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.14e+05  |\n",
      "|    total_cost         | 3.65e+03  |\n",
      "|    total_reward       | -8.65e+04 |\n",
      "|    total_reward_pct   | -17.3     |\n",
      "|    total_trades       | 5843      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -5.63     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.301     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.95e+05  |\n",
      "|    total_cost         | 4.48e+03  |\n",
      "|    total_reward       | 2.95e+05  |\n",
      "|    total_reward_pct   | 59.1      |\n",
      "|    total_trades       | 5675      |\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 10        |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.62      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.39e+05 |\n",
      "|    total_cost         | 2.88e+03 |\n",
      "|    total_reward       | 3.94e+04 |\n",
      "|    total_reward_pct   | 7.89     |\n",
      "|    total_trades       | 5435     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0.033    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 23.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 6.62     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.327    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.65e+05 |\n",
      "|    total_cost         | 3.31e+03 |\n",
      "|    total_reward       | 6.5e+04  |\n",
      "|    total_reward_pct   | 13       |\n",
      "|    total_trades       | 5157     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -1.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 28.8     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "day: 627, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 973431.61\n",
      "total_reward: 473431.61\n",
      "total_cost: 11944.36\n",
      "total_trades: 5002\n",
      "Sharpe: 0.973\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.73e+05 |\n",
      "|    total_cost         | 1.19e+04 |\n",
      "|    total_reward       | 4.73e+05 |\n",
      "|    total_reward_pct   | 94.7     |\n",
      "|    total_trades       | 5002     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0.0363   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 24.8     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 4.82e+03 |\n",
      "|    total_reward       | 5.91e+05 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 4818     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -32.5    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.21e+05 |\n",
      "|    total_cost         | 5.56e+03 |\n",
      "|    total_reward       | 4.21e+05 |\n",
      "|    total_reward_pct   | 84.3     |\n",
      "|    total_trades       | 4851     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -0.49    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -11.6    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.457    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 45.9     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 5.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.49e+05 |\n",
      "|    total_cost         | 2.71e+03 |\n",
      "|    total_reward       | 4.92e+04 |\n",
      "|    total_reward_pct   | 9.83     |\n",
      "|    total_trades       | 4676     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -55.6    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 3.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 5.03e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 4567     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -29.5    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "day: 627, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1059951.06\n",
      "total_reward: 559951.06\n",
      "total_cost: 6444.34\n",
      "total_trades: 4393\n",
      "Sharpe: 1.141\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 6.44e+03 |\n",
      "|    total_reward       | 5.6e+05  |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 4393     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.071   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 52.3     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 3.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 4.85e+03 |\n",
      "|    total_reward       | 5.23e+05 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 4428     |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.219   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -10      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.292    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0.452    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -40.4    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.71e+05 |\n",
      "|    total_cost         | 3.55e+03 |\n",
      "|    total_reward       | 7.06e+04 |\n",
      "|    total_reward_pct   | 14.1     |\n",
      "|    total_trades       | 4175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.776   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 21.4     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 1.22e+04 |\n",
      "|    total_reward       | 5.87e+05 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 4243     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 38.7     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.32e+05 |\n",
      "|    total_cost         | 2.39e+03 |\n",
      "|    total_reward       | 3.16e+04 |\n",
      "|    total_reward_pct   | 6.32     |\n",
      "|    total_trades       | 4401     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.358    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 6.77     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "day: 627, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1066234.41\n",
      "total_reward: 566234.41\n",
      "total_cost: 11715.31\n",
      "total_trades: 4582\n",
      "Sharpe: 1.020\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 5.66e+05 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 4582     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.0274   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -40.5    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.3      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -9.07     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | 5.62e+05 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 4826     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 21.4     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.12e+06 |\n",
      "|    total_cost         | 8.96e+03 |\n",
      "|    total_reward       | 6.2e+05  |\n",
      "|    total_reward_pct   | 124      |\n",
      "|    total_trades       | 5022     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 13.3     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.373    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.56e+05  |\n",
      "|    total_cost         | 4.12e+03  |\n",
      "|    total_reward       | -1.44e+05 |\n",
      "|    total_reward_pct   | -28.8     |\n",
      "|    total_trades       | 4899      |\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -31.1     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 4.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 6.12e+03 |\n",
      "|    total_reward       | 5.4e+05  |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 4938     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -0.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 73.2     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 7.12     |\n",
      "------------------------------------\n",
      "day: 627, episode: 75\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1004949.41\n",
      "total_reward: 504949.41\n",
      "total_cost: 12301.87\n",
      "total_trades: 4805\n",
      "Sharpe: 0.974\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 1.23e+04 |\n",
      "|    total_reward       | 5.05e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 4805     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 41       |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.22e+05 |\n",
      "|    total_cost         | 7.08e+03 |\n",
      "|    total_reward       | 3.22e+05 |\n",
      "|    total_reward_pct   | 64.4     |\n",
      "|    total_trades       | 4771     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 12       |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.66e+05  |\n",
      "|    total_cost         | 2.23e+03  |\n",
      "|    total_reward       | -3.37e+04 |\n",
      "|    total_reward_pct   | -6.74     |\n",
      "|    total_trades       | 5012      |\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 24.2      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.859     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.38e+05 |\n",
      "|    total_cost         | 2.43e+03 |\n",
      "|    total_reward       | 3.81e+04 |\n",
      "|    total_reward_pct   | 7.61     |\n",
      "|    total_trades       | 4613     |\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 32.6     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 24.8     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.818    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.36e+05 |\n",
      "|    total_cost         | 2.44e+03 |\n",
      "|    total_reward       | 3.63e+04 |\n",
      "|    total_reward_pct   | 7.27     |\n",
      "|    total_trades       | 4710     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 6.94     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.26     |\n",
      "------------------------------------\n",
      "day: 627, episode: 80\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 511077.13\n",
      "total_reward: 11077.13\n",
      "total_cost: 2440.98\n",
      "total_trades: 4645\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.11e+05 |\n",
      "|    total_cost         | 2.44e+03 |\n",
      "|    total_reward       | 1.11e+04 |\n",
      "|    total_reward_pct   | 2.22     |\n",
      "|    total_trades       | 4645     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 42.8     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 3.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 5.71e+03 |\n",
      "|    total_reward       | 5.64e+05 |\n",
      "|    total_reward_pct   | 113      |\n",
      "|    total_trades       | 4484     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 32.1     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | 5.36e+05 |\n",
      "|    total_reward_pct   | 107      |\n",
      "|    total_trades       | 4331     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.068   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 25.8     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 1.42e+04 |\n",
      "|    total_reward       | 5.32e+05 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 4328     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.00856 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.297    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.44e+05  |\n",
      "|    total_cost         | 2.39e+03  |\n",
      "|    total_reward       | -5.63e+04 |\n",
      "|    total_reward_pct   | -11.3     |\n",
      "|    total_trades       | 4275      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | -1.61     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | 0.794     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.0921    |\n",
      "-------------------------------------\n",
      "day: 627, episode: 85\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 432511.76\n",
      "total_reward: -67488.24\n",
      "total_cost: 2315.23\n",
      "total_trades: 4473\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.33e+05  |\n",
      "|    total_cost         | 2.32e+03  |\n",
      "|    total_reward       | -6.75e+04 |\n",
      "|    total_reward_pct   | -13.5     |\n",
      "|    total_trades       | 4473      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 0.0422    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -53.1     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 3.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 18.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 8.2e+03  |\n",
      "|    total_reward       | 5.02e+05 |\n",
      "|    total_reward_pct   | 100      |\n",
      "|    total_trades       | 4436     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -3.62    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.52e+05 |\n",
      "|    total_cost         | 1.34e+04 |\n",
      "|    total_reward       | 3.52e+05 |\n",
      "|    total_reward_pct   | 70.5     |\n",
      "|    total_trades       | 4269     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 39.7     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.14e+05  |\n",
      "|    total_cost         | 3.78e+04  |\n",
      "|    total_reward       | -8.62e+04 |\n",
      "|    total_reward_pct   | -17.2     |\n",
      "|    total_trades       | 4464      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.5     |\n",
      "|    explained_variance | 0.0378    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 11.3      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.197     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.73e+05  |\n",
      "|    total_cost         | 3.88e+04  |\n",
      "|    total_reward       | -1.27e+05 |\n",
      "|    total_reward_pct   | -25.4     |\n",
      "|    total_trades       | 4543      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 2.83      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.0139    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 0.837    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 6.72     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0935   |\n",
      "------------------------------------\n",
      "day: 627, episode: 90\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 314388.14\n",
      "total_reward: -185611.86\n",
      "total_cost: 15742.18\n",
      "total_trades: 4472\n",
      "Sharpe: -0.113\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.14e+05  |\n",
      "|    total_cost         | 1.57e+04  |\n",
      "|    total_reward       | -1.86e+05 |\n",
      "|    total_reward_pct   | -37.1     |\n",
      "|    total_trades       | 4472      |\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 31.3      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 2.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.55e+05 |\n",
      "|    total_cost         | 2.92e+04 |\n",
      "|    total_reward       | 5.53e+04 |\n",
      "|    total_reward_pct   | 11.1     |\n",
      "|    total_trades       | 4795     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -15.8    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.633    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.07e+05 |\n",
      "|    total_cost         | 4.82e+04 |\n",
      "|    total_reward       | 4.07e+05 |\n",
      "|    total_reward_pct   | 81.4     |\n",
      "|    total_trades       | 4972     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 4.95     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.421    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.23e+06 |\n",
      "|    total_cost         | 2.69e+04 |\n",
      "|    total_reward       | 7.34e+05 |\n",
      "|    total_reward_pct   | 147      |\n",
      "|    total_trades       | 4976     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -18.4    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.647    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -34.4    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.2e+05   |\n",
      "|    total_cost         | 6.17e+03  |\n",
      "|    total_reward       | -8.04e+04 |\n",
      "|    total_reward_pct   | -16.1     |\n",
      "|    total_trades       | 4753      |\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | -0.01     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 34.6      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 1.56      |\n",
      "-------------------------------------\n",
      "day: 627, episode: 95\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1040052.60\n",
      "total_reward: 540052.60\n",
      "total_cost: 16349.05\n",
      "total_trades: 5030\n",
      "Sharpe: 1.049\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.04e+06  |\n",
      "|    total_cost         | 1.63e+04  |\n",
      "|    total_reward       | 5.4e+05   |\n",
      "|    total_reward_pct   | 108       |\n",
      "|    total_trades       | 5030      |\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -16.6     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.378     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 1.25e+04 |\n",
      "|    total_reward       | 5.54e+05 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 5053     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -0.0144  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 19.6     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.696    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.95e+05  |\n",
      "|    total_cost         | 2.67e+03  |\n",
      "|    total_reward       | -4.98e+03 |\n",
      "|    total_reward_pct   | -0.996    |\n",
      "|    total_trades       | 5070      |\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 22.3      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -41.1    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 8.07e+03 |\n",
      "|    total_reward       | 5.91e+05 |\n",
      "|    total_reward_pct   | 118      |\n",
      "|    total_trades       | 5245     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.131   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -15.6    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 1.25e+04 |\n",
      "|    total_reward       | 5.28e+05 |\n",
      "|    total_reward_pct   | 106      |\n",
      "|    total_trades       | 5128     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -54.2    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3.63     |\n",
      "------------------------------------\n",
      "day: 627, episode: 100\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 901153.00\n",
      "total_reward: 401153.00\n",
      "total_cost: 27755.53\n",
      "total_trades: 5356\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.01e+05 |\n",
      "|    total_cost         | 2.78e+04 |\n",
      "|    total_reward       | 4.01e+05 |\n",
      "|    total_reward_pct   | 80.2     |\n",
      "|    total_trades       | 5356     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -16.8    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.847    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.13e+05 |\n",
      "|    total_cost         | 3.1e+04  |\n",
      "|    total_reward       | 4.13e+05 |\n",
      "|    total_reward_pct   | 82.6     |\n",
      "|    total_trades       | 5427     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -0.0675  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -45.4    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.103    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 102      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.87e+05 |\n",
      "|    total_cost         | 5.86e+04 |\n",
      "|    total_reward       | 3.87e+05 |\n",
      "|    total_reward_pct   | 77.5     |\n",
      "|    total_trades       | 5764     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -0.0325  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -126     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 20.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.07e+05 |\n",
      "|    total_cost         | 4.61e+04 |\n",
      "|    total_reward       | 4.07e+05 |\n",
      "|    total_reward_pct   | 81.4     |\n",
      "|    total_trades       | 5318     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.0794   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 4.9      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.37e+05 |\n",
      "|    total_cost         | 5.28e+04 |\n",
      "|    total_reward       | 4.37e+05 |\n",
      "|    total_reward_pct   | 87.3     |\n",
      "|    total_trades       | 5286     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 3.97     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.0987   |\n",
      "------------------------------------\n",
      "day: 627, episode: 105\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1058737.85\n",
      "total_reward: 558737.85\n",
      "total_cost: 38856.29\n",
      "total_trades: 5094\n",
      "Sharpe: 1.280\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 3.89e+04 |\n",
      "|    total_reward       | 5.59e+05 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 5094     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -21.5    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 5.96     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.874    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.92e+05  |\n",
      "|    total_cost         | 1.42e+04  |\n",
      "|    total_reward       | -1.08e+05 |\n",
      "|    total_reward_pct   | -21.5     |\n",
      "|    total_trades       | 4665      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | -0.276    |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.0457    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.88e+05 |\n",
      "|    total_cost         | 2.81e+04 |\n",
      "|    total_reward       | 3.88e+05 |\n",
      "|    total_reward_pct   | 77.5     |\n",
      "|    total_trades       | 4393     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -4.79    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.177    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.17e+05 |\n",
      "|    total_cost         | 5.23e+04 |\n",
      "|    total_reward       | 3.17e+05 |\n",
      "|    total_reward_pct   | 63.3     |\n",
      "|    total_trades       | 4545     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -0.344   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -8.18    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.215    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.33e+05  |\n",
      "|    total_cost         | 9.23e+03  |\n",
      "|    total_reward       | -1.67e+05 |\n",
      "|    total_reward_pct   | -33.4     |\n",
      "|    total_trades       | 4383      |\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | -0.0146   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 21.8      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.713     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -46.2     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 3.82      |\n",
      "-------------------------------------\n",
      "day: 627, episode: 110\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 389930.59\n",
      "total_reward: -110069.41\n",
      "total_cost: 9422.80\n",
      "total_trades: 4534\n",
      "Sharpe: -0.078\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.9e+05  |\n",
      "|    total_cost         | 9.42e+03 |\n",
      "|    total_reward       | -1.1e+05 |\n",
      "|    total_reward_pct   | -22      |\n",
      "|    total_trades       | 4534     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.235    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.28e+05  |\n",
      "|    total_cost         | 9.81e+03  |\n",
      "|    total_reward       | -1.72e+05 |\n",
      "|    total_reward_pct   | -34.3     |\n",
      "|    total_trades       | 4527      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | 0.0426    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 13.9      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 1.06      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+06 |\n",
      "|    total_cost         | 2.69e+04 |\n",
      "|    total_reward       | 5.84e+05 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 4452     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 0.745    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.088    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.36e+05  |\n",
      "|    total_cost         | 1.5e+04   |\n",
      "|    total_reward       | -6.44e+04 |\n",
      "|    total_reward_pct   | -12.9     |\n",
      "|    total_trades       | 4219      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | 0.00555   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 11        |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.789     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | -0.000725 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -10       |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.209     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.12e+05  |\n",
      "|    total_cost         | 2.72e+04  |\n",
      "|    total_reward       | 1.12e+05  |\n",
      "|    total_reward_pct   | 22.4      |\n",
      "|    total_trades       | 4449      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -1.52     |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.0323    |\n",
      "-------------------------------------\n",
      "day: 627, episode: 115\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 762864.33\n",
      "total_reward: 262864.33\n",
      "total_cost: 24849.59\n",
      "total_trades: 4469\n",
      "Sharpe: 0.913\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.63e+05  |\n",
      "|    total_cost         | 2.48e+04  |\n",
      "|    total_reward       | 2.63e+05  |\n",
      "|    total_reward_pct   | 52.6      |\n",
      "|    total_trades       | 4469      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.278     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.85e+05  |\n",
      "|    total_cost         | 1.1e+04   |\n",
      "|    total_reward       | -1.15e+05 |\n",
      "|    total_reward_pct   | -23       |\n",
      "|    total_trades       | 4281      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | -5.09     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.0583    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.5e+05   |\n",
      "|    total_cost         | 1.53e+04  |\n",
      "|    total_reward       | -5.04e+04 |\n",
      "|    total_reward_pct   | -10.1     |\n",
      "|    total_trades       | 4353      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -11.2     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.208     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -4.6     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.449    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 4.47e+04 |\n",
      "|    total_reward       | 5.06e+05 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 4436     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 14.6     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.428    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.57e+05 |\n",
      "|    total_cost         | 2.52e+04 |\n",
      "|    total_reward       | 2.57e+05 |\n",
      "|    total_reward_pct   | 51.4     |\n",
      "|    total_trades       | 4312     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 27.5     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "day: 627, episode: 120\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1056971.44\n",
      "total_reward: 556971.44\n",
      "total_cost: 19788.10\n",
      "total_trades: 4065\n",
      "Sharpe: 1.194\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.06e+06  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | 5.57e+05  |\n",
      "|    total_reward_pct   | 111       |\n",
      "|    total_trades       | 4065      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | 15.3      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.276     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.67e+05 |\n",
      "|    total_cost         | 2.11e+04 |\n",
      "|    total_reward       | 3.67e+05 |\n",
      "|    total_reward_pct   | 73.4     |\n",
      "|    total_trades       | 3901     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | -0.421   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.0594   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 10.4     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.89     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.21e+05  |\n",
      "|    total_cost         | 8.95e+03  |\n",
      "|    total_reward       | 4.21e+05  |\n",
      "|    total_reward_pct   | 84.2      |\n",
      "|    total_trades       | 3659      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | 4.19      |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.0905    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.67e+05 |\n",
      "|    total_cost         | 2.55e+03 |\n",
      "|    total_reward       | 6.74e+04 |\n",
      "|    total_reward_pct   | 13.5     |\n",
      "|    total_trades       | 3540     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 30.7     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.65e+05 |\n",
      "|    total_cost         | 1.21e+04 |\n",
      "|    total_reward       | 2.65e+05 |\n",
      "|    total_reward_pct   | 53       |\n",
      "|    total_trades       | 3603     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | -2.75    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 14.3     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "day: 627, episode: 125\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 922137.77\n",
      "total_reward: 422137.77\n",
      "total_cost: 11514.72\n",
      "total_trades: 3582\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.22e+05 |\n",
      "|    total_cost         | 1.15e+04 |\n",
      "|    total_reward       | 4.22e+05 |\n",
      "|    total_reward_pct   | 84.4     |\n",
      "|    total_trades       | 3582     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 67.7     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 5.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0.734    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 26.1     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.807    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.63e+05 |\n",
      "|    total_cost         | 1.84e+04 |\n",
      "|    total_reward       | 3.63e+05 |\n",
      "|    total_reward_pct   | 72.6     |\n",
      "|    total_trades       | 3678     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -14.3    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.281    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.16e+05 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 1.16e+05 |\n",
      "|    total_reward_pct   | 23.3     |\n",
      "|    total_trades       | 3605     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -16.2    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.353    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.79e+05  |\n",
      "|    total_cost         | 9.05e+03  |\n",
      "|    total_reward       | -2.06e+04 |\n",
      "|    total_reward_pct   | -4.12     |\n",
      "|    total_trades       | 3703      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 4.24      |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.217     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.79e+05  |\n",
      "|    total_cost         | 1.18e+04  |\n",
      "|    total_reward       | -1.21e+05 |\n",
      "|    total_reward_pct   | -24.2     |\n",
      "|    total_trades       | 3815      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -0.091    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 2.04      |\n",
      "-------------------------------------\n",
      "day: 627, episode: 130\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 983496.35\n",
      "total_reward: 483496.35\n",
      "total_cost: 7079.13\n",
      "total_trades: 3769\n",
      "Sharpe: 0.963\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.83e+05 |\n",
      "|    total_cost         | 7.08e+03 |\n",
      "|    total_reward       | 4.83e+05 |\n",
      "|    total_reward_pct   | 96.7     |\n",
      "|    total_trades       | 3769     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 5.95e+03 |\n",
      "|    total_reward       | 5.53e+05 |\n",
      "|    total_reward_pct   | 111      |\n",
      "|    total_trades       | 3906     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.774    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.16e+06 |\n",
      "|    total_cost         | 1.45e+04 |\n",
      "|    total_reward       | 6.59e+05 |\n",
      "|    total_reward_pct   | 132      |\n",
      "|    total_trades       | 3756     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -21      |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -45.4    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 3.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.51e+05 |\n",
      "|    total_cost         | 2.79e+04 |\n",
      "|    total_reward       | 3.51e+05 |\n",
      "|    total_reward_pct   | 70.1     |\n",
      "|    total_trades       | 3744     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | -0.0364  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 80.9     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 7.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.74e+05  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | 3.74e+05  |\n",
      "|    total_reward_pct   | 74.7      |\n",
      "|    total_trades       | 3492      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 21.8      |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 1.01      |\n",
      "-------------------------------------\n",
      "day: 627, episode: 135\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 940744.49\n",
      "total_reward: 440744.49\n",
      "total_cost: 11171.09\n",
      "total_trades: 3433\n",
      "Sharpe: 1.099\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.41e+05 |\n",
      "|    total_cost         | 1.12e+04 |\n",
      "|    total_reward       | 4.41e+05 |\n",
      "|    total_reward_pct   | 88.1     |\n",
      "|    total_trades       | 3433     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -29.8    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.21e+05 |\n",
      "|    total_cost         | 6.71e+03 |\n",
      "|    total_reward       | 2.13e+04 |\n",
      "|    total_reward_pct   | 4.25     |\n",
      "|    total_trades       | 3431     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0.635    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 3.02     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0.00894  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -10.1    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.262    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 1.19e+04 |\n",
      "|    total_reward       | 5.11e+05 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 3595     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0.0663   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 34.6     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.01e+05 |\n",
      "|    total_cost         | 8.18e+03 |\n",
      "|    total_reward       | 3.01e+05 |\n",
      "|    total_reward_pct   | 60.2     |\n",
      "|    total_trades       | 3822     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 7.61     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0539   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.13e+06 |\n",
      "|    total_cost         | 9.89e+03 |\n",
      "|    total_reward       | 6.3e+05  |\n",
      "|    total_reward_pct   | 126      |\n",
      "|    total_trades       | 3779     |\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.173   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -54.5    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "day: 627, episode: 140\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 439709.75\n",
      "total_reward: -60290.25\n",
      "total_cost: 6789.10\n",
      "total_trades: 3819\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.4e+05   |\n",
      "|    total_cost         | 6.79e+03  |\n",
      "|    total_reward       | -6.03e+04 |\n",
      "|    total_reward_pct   | -12.1     |\n",
      "|    total_trades       | 3819      |\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.1     |\n",
      "|    explained_variance | 0.207     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 10.1      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.579     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0.0391   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 8.73     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.91e+05 |\n",
      "|    total_cost         | 7.37e+03 |\n",
      "|    total_reward       | 3.91e+05 |\n",
      "|    total_reward_pct   | 78.3     |\n",
      "|    total_trades       | 3969     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.00143 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -178     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 44.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 8.25e+03 |\n",
      "|    total_reward       | 5.38e+05 |\n",
      "|    total_reward_pct   | 108      |\n",
      "|    total_trades       | 4149     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 56.8     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 4.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.71e+05 |\n",
      "|    total_cost         | 2.43e+04 |\n",
      "|    total_reward       | 4.71e+05 |\n",
      "|    total_reward_pct   | 94.2     |\n",
      "|    total_trades       | 4350     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.705    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.96e+05 |\n",
      "|    total_cost         | 2.23e+04 |\n",
      "|    total_reward       | 4.96e+05 |\n",
      "|    total_reward_pct   | 99.1     |\n",
      "|    total_trades       | 4274     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.0974  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 16       |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.448    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0.00533  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -17.4    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 4.18     |\n",
      "------------------------------------\n",
      "day: 627, episode: 145\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 944026.24\n",
      "total_reward: 444026.24\n",
      "total_cost: 17234.58\n",
      "total_trades: 4196\n",
      "Sharpe: 1.029\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.44e+05 |\n",
      "|    total_cost         | 1.72e+04 |\n",
      "|    total_reward       | 4.44e+05 |\n",
      "|    total_reward_pct   | 88.8     |\n",
      "|    total_trades       | 4196     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0947   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.15e+06 |\n",
      "|    total_cost         | 1.72e+04 |\n",
      "|    total_reward       | 6.5e+05  |\n",
      "|    total_reward_pct   | 130      |\n",
      "|    total_trades       | 4127     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -7.49    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0826   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.86e+05 |\n",
      "|    total_cost         | 1.44e+04 |\n",
      "|    total_reward       | 4.86e+05 |\n",
      "|    total_reward_pct   | 97.1     |\n",
      "|    total_trades       | 4282     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 20.2     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.466    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.25e+05  |\n",
      "|    total_cost         | 1.5e+04   |\n",
      "|    total_reward       | 4.25e+05  |\n",
      "|    total_reward_pct   | 85        |\n",
      "|    total_trades       | 4177      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | 14.8      |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 0.358     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0.197    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -187     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.09e+05 |\n",
      "|    total_cost         | 1.47e+04 |\n",
      "|    total_reward       | 4.09e+05 |\n",
      "|    total_reward_pct   | 81.8     |\n",
      "|    total_trades       | 4080     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -21.4    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.501    |\n",
      "------------------------------------\n",
      "day: 627, episode: 150\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 490124.00\n",
      "total_reward: -9876.00\n",
      "total_cost: 7007.18\n",
      "total_trades: 3908\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.9e+05   |\n",
      "|    total_cost         | 7.01e+03  |\n",
      "|    total_reward       | -9.88e+03 |\n",
      "|    total_reward_pct   | -1.98     |\n",
      "|    total_trades       | 3908      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 21.8      |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 1.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.75e+05 |\n",
      "|    total_cost         | 4.19e+04 |\n",
      "|    total_reward       | 2.75e+05 |\n",
      "|    total_reward_pct   | 55       |\n",
      "|    total_trades       | 3965     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 14.3     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.412    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.11e+05  |\n",
      "|    total_cost         | 2e+04     |\n",
      "|    total_reward       | 3.11e+05  |\n",
      "|    total_reward_pct   | 62.1      |\n",
      "|    total_trades       | 3785      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | -40.1     |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 2.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0.0949   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -163     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 29.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.79e+05 |\n",
      "|    total_cost         | 4.57e+04 |\n",
      "|    total_reward       | 1.79e+05 |\n",
      "|    total_reward_pct   | 35.8     |\n",
      "|    total_trades       | 3788     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -0.0134  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.767    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.62e+05 |\n",
      "|    total_cost         | 1.75e+04 |\n",
      "|    total_reward       | 3.62e+05 |\n",
      "|    total_reward_pct   | 72.5     |\n",
      "|    total_trades       | 3761     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | 0.0701   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 63.8     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 3.84     |\n",
      "------------------------------------\n",
      "day: 627, episode: 155\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 788391.73\n",
      "total_reward: 288391.73\n",
      "total_cost: 21047.72\n",
      "total_trades: 3650\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.88e+05  |\n",
      "|    total_cost         | 2.1e+04   |\n",
      "|    total_reward       | 2.88e+05  |\n",
      "|    total_reward_pct   | 57.7      |\n",
      "|    total_trades       | 3650      |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 189       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 2.2       |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.517     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.81e+05 |\n",
      "|    total_cost         | 1.08e+04 |\n",
      "|    total_reward       | 1.81e+05 |\n",
      "|    total_reward_pct   | 36.1     |\n",
      "|    total_trades       | 3733     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -2.68    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.232    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -94.7    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.78e+05 |\n",
      "|    total_cost         | 3.03e+04 |\n",
      "|    total_reward       | 2.78e+05 |\n",
      "|    total_reward_pct   | 55.6     |\n",
      "|    total_trades       | 3859     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 0.000205 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 14.1     |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.791    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.79e+05 |\n",
      "|    total_cost         | 1.02e+04 |\n",
      "|    total_reward       | 2.79e+05 |\n",
      "|    total_reward_pct   | 55.8     |\n",
      "|    total_trades       | 3600     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | -0.104   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 6.56     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.371    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.38e+05 |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | 3.38e+05 |\n",
      "|    total_reward_pct   | 67.7     |\n",
      "|    total_trades       | 3536     |\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 24.3     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.808    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-07-09 to  2020-10-06\n",
      "A2C Sharpe Ratio:  nan\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.27e+05  |\n",
      "|    total_cost       | 2.02e+05  |\n",
      "|    total_reward     | -3.73e+05 |\n",
      "|    total_reward_pct | -74.5     |\n",
      "|    total_trades     | 8701      |\n",
      "| time/               |           |\n",
      "|    fps              | 709       |\n",
      "|    iterations       | 1         |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 2048      |\n",
      "-----------------------------------\n",
      "day: 627, episode: 165\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 249828.08\n",
      "total_reward: -250171.92\n",
      "total_cost: 231079.65\n",
      "total_trades: 8825\n",
      "Sharpe: -0.588\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.31e+05    |\n",
      "|    total_cost           | 1.74e+05    |\n",
      "|    total_reward         | -3.69e+05   |\n",
      "|    total_reward_pct     | -73.8       |\n",
      "|    total_trades         | 8461        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007112439 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0216      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.399       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+05    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | -3.79e+05   |\n",
      "|    total_reward_pct     | -75.8       |\n",
      "|    total_trades         | 8579        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015670821 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0615      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 170\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 160290.74\n",
      "total_reward: -339709.26\n",
      "total_cost: 217415.51\n",
      "total_trades: 8651\n",
      "Sharpe: -0.973\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.05e+05    |\n",
      "|    total_cost           | 4.29e+05    |\n",
      "|    total_reward         | -9.55e+04   |\n",
      "|    total_reward_pct     | -19.1       |\n",
      "|    total_trades         | 9254        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012842684 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.52        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 175\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 194435.10\n",
      "total_reward: -305564.90\n",
      "total_cost: 223659.53\n",
      "total_trades: 8784\n",
      "Sharpe: -0.611\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+05    |\n",
      "|    total_cost           | 2.22e+05    |\n",
      "|    total_reward         | -2.77e+05   |\n",
      "|    total_reward_pct     | -55.4       |\n",
      "|    total_trades         | 8621        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011689157 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0611      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.883       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.62e+05    |\n",
      "|    total_cost           | 3e+05       |\n",
      "|    total_reward         | -1.38e+05   |\n",
      "|    total_reward_pct     | -27.5       |\n",
      "|    total_trades         | 9004        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015521616 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 180\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 152275.55\n",
      "total_reward: -347724.45\n",
      "total_cost: 261496.97\n",
      "total_trades: 8794\n",
      "Sharpe: -1.660\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.59e+05     |\n",
      "|    total_cost           | 2.85e+05     |\n",
      "|    total_reward         | -2.41e+05    |\n",
      "|    total_reward_pct     | -48.2        |\n",
      "|    total_trades         | 8794         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 637          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126947155 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.1        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.554        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0191      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "day: 627, episode: 185\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 243494.05\n",
      "total_reward: -256505.95\n",
      "total_cost: 258529.93\n",
      "total_trades: 8751\n",
      "Sharpe: -0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+05    |\n",
      "|    total_cost           | 1.78e+05    |\n",
      "|    total_reward         | -3.83e+05   |\n",
      "|    total_reward_pct     | -76.6       |\n",
      "|    total_trades         | 8464        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024301639 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 1.9e+05     |\n",
      "|    total_reward         | -3.8e+05    |\n",
      "|    total_reward_pct     | -76.1       |\n",
      "|    total_trades         | 8734        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015373588 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.08        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 190\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 742937.92\n",
      "total_reward: 242937.92\n",
      "total_cost: 418792.52\n",
      "total_trades: 9031\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.45e+05    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | -3.55e+05   |\n",
      "|    total_reward_pct     | -71         |\n",
      "|    total_trades         | 8695        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021404395 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.67        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 195\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 194568.80\n",
      "total_reward: -305431.20\n",
      "total_cost: 199763.05\n",
      "total_trades: 8515\n",
      "Sharpe: -0.834\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+05    |\n",
      "|    total_cost           | 2e+05       |\n",
      "|    total_reward         | -3.05e+05   |\n",
      "|    total_reward_pct     | -61.1       |\n",
      "|    total_trades         | 8515        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009392971 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.87e+05     |\n",
      "|    total_cost           | 2.44e+05     |\n",
      "|    total_reward         | -3.13e+05    |\n",
      "|    total_reward_pct     | -62.7        |\n",
      "|    total_trades         | 8789         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062587606 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.376        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0209      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.89         |\n",
      "------------------------------------------\n",
      "day: 627, episode: 200\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 121809.57\n",
      "total_reward: -378190.43\n",
      "total_cost: 187977.32\n",
      "total_trades: 8629\n",
      "Sharpe: -1.265\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+05    |\n",
      "|    total_cost           | 2.56e+05    |\n",
      "|    total_reward         | -2.01e+05   |\n",
      "|    total_reward_pct     | -40.1       |\n",
      "|    total_trades         | 8729        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025584962 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.79        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 205\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 174673.91\n",
      "total_reward: -325326.09\n",
      "total_cost: 191178.70\n",
      "total_trades: 8643\n",
      "Sharpe: -0.928\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.75e+05   |\n",
      "|    total_cost           | 1.91e+05   |\n",
      "|    total_reward         | -3.25e+05  |\n",
      "|    total_reward_pct     | -65.1      |\n",
      "|    total_trades         | 8643       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 634        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03221113 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.106      |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.46       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+05    |\n",
      "|    total_cost           | 2.24e+05    |\n",
      "|    total_reward         | -2.81e+05   |\n",
      "|    total_reward_pct     | -56.3       |\n",
      "|    total_trades         | 8622        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026785592 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.18        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 210\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 477726.73\n",
      "total_reward: -22273.27\n",
      "total_cost: 374410.47\n",
      "total_trades: 8935\n",
      "Sharpe: 0.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+05    |\n",
      "|    total_cost           | 2.16e+05    |\n",
      "|    total_reward         | -2.56e+05   |\n",
      "|    total_reward_pct     | -51.3       |\n",
      "|    total_trades         | 8599        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023502067 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 215\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 191775.42\n",
      "total_reward: -308224.58\n",
      "total_cost: 217500.80\n",
      "total_trades: 8830\n",
      "Sharpe: -0.850\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+05    |\n",
      "|    total_cost           | 2.18e+05    |\n",
      "|    total_reward         | -3.08e+05   |\n",
      "|    total_reward_pct     | -61.6       |\n",
      "|    total_trades         | 8830        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016827196 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.737       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.75e+05    |\n",
      "|    total_cost           | 1.97e+05    |\n",
      "|    total_reward         | -3.25e+05   |\n",
      "|    total_reward_pct     | -65         |\n",
      "|    total_trades         | 8390        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018806167 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.439       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 220\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 242755.26\n",
      "total_reward: -257244.74\n",
      "total_cost: 301929.84\n",
      "total_trades: 8780\n",
      "Sharpe: -0.995\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.68e+05    |\n",
      "|    total_cost           | 2.04e+05    |\n",
      "|    total_reward         | -3.32e+05   |\n",
      "|    total_reward_pct     | -66.4       |\n",
      "|    total_trades         | 8541        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021646451 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.318       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 225\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 232384.61\n",
      "total_reward: -267615.39\n",
      "total_cost: 207026.96\n",
      "total_trades: 8713\n",
      "Sharpe: -0.653\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.32e+05    |\n",
      "|    total_cost           | 2.07e+05    |\n",
      "|    total_reward         | -2.68e+05   |\n",
      "|    total_reward_pct     | -53.5       |\n",
      "|    total_trades         | 8713        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020006396 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.589       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.1e+05    |\n",
      "|    total_cost           | 2.89e+05   |\n",
      "|    total_reward         | -1.9e+05   |\n",
      "|    total_reward_pct     | -38        |\n",
      "|    total_trades         | 8918       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 633        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02310003 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.398      |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 2.06       |\n",
      "----------------------------------------\n",
      "day: 627, episode: 230\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 175999.68\n",
      "total_reward: -324000.32\n",
      "total_cost: 180706.92\n",
      "total_trades: 8615\n",
      "Sharpe: -0.710\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+05    |\n",
      "|    total_cost           | 2.09e+05    |\n",
      "|    total_reward         | -2.71e+05   |\n",
      "|    total_reward_pct     | -54.3       |\n",
      "|    total_trades         | 8586        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012786402 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.51        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 235\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 250979.62\n",
      "total_reward: -249020.38\n",
      "total_cost: 238212.95\n",
      "total_trades: 8799\n",
      "Sharpe: -0.604\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.51e+05    |\n",
      "|    total_cost           | 2.38e+05    |\n",
      "|    total_reward         | -2.49e+05   |\n",
      "|    total_reward_pct     | -49.8       |\n",
      "|    total_trades         | 8799        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045799427 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5e+05       |\n",
      "|    total_cost           | 3.48e+05    |\n",
      "|    total_reward         | 66.4        |\n",
      "|    total_reward_pct     | 0.0133      |\n",
      "|    total_trades         | 8952        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022180162 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.753       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 240\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 637641.40\n",
      "total_reward: 137641.40\n",
      "total_cost: 408056.11\n",
      "total_trades: 9223\n",
      "Sharpe: 0.512\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.49e+05    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | -3.51e+05   |\n",
      "|    total_reward_pct     | -70.1       |\n",
      "|    total_trades         | 8571        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019225782 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.594       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.96e+05    |\n",
      "|    total_cost           | 3.85e+05    |\n",
      "|    total_reward         | 3.96e+05    |\n",
      "|    total_reward_pct     | 79.2        |\n",
      "|    total_trades         | 9057        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023957245 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.404       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 245\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 272853.41\n",
      "total_reward: -227146.59\n",
      "total_cost: 227375.87\n",
      "total_trades: 8720\n",
      "Sharpe: -0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+05    |\n",
      "|    total_cost           | 1.93e+05    |\n",
      "|    total_reward         | -2.81e+05   |\n",
      "|    total_reward_pct     | -56.2       |\n",
      "|    total_trades         | 8586        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039017007 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.829       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 250\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 133615.60\n",
      "total_reward: -366384.40\n",
      "total_cost: 152174.25\n",
      "total_trades: 8498\n",
      "Sharpe: -1.085\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.65e+05    |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | -1.35e+05   |\n",
      "|    total_reward_pct     | -26.9       |\n",
      "|    total_trades         | 8747        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025358753 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.7e+05     |\n",
      "|    total_cost           | 2.2e+05     |\n",
      "|    total_reward         | -2.3e+05    |\n",
      "|    total_reward_pct     | -46.1       |\n",
      "|    total_trades         | 8674        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031590793 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.97        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 255\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 171740.00\n",
      "total_reward: -328260.00\n",
      "total_cost: 163709.54\n",
      "total_trades: 8618\n",
      "Sharpe: -0.848\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.72e+05   |\n",
      "|    total_cost           | 3.41e+05   |\n",
      "|    total_reward         | -2.75e+04  |\n",
      "|    total_reward_pct     | -5.51      |\n",
      "|    total_trades         | 9007       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 631        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03708121 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.241      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.00886   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 1.52       |\n",
      "----------------------------------------\n",
      "day: 627, episode: 260\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 680291.57\n",
      "total_reward: 180291.57\n",
      "total_cost: 379419.89\n",
      "total_trades: 9192\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.21e+05    |\n",
      "|    total_cost           | 4.15e+05    |\n",
      "|    total_reward         | 2.21e+05    |\n",
      "|    total_reward_pct     | 44.1        |\n",
      "|    total_trades         | 9235        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025446735 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.797       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.56e+05    |\n",
      "|    total_cost           | 2.47e+05    |\n",
      "|    total_reward         | -1.44e+05   |\n",
      "|    total_reward_pct     | -28.7       |\n",
      "|    total_trades         | 8838        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015665296 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 5.91        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 265\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 176603.81\n",
      "total_reward: -323396.19\n",
      "total_cost: 193860.71\n",
      "total_trades: 8664\n",
      "Sharpe: -1.045\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.81e+05  |\n",
      "|    total_cost           | 2.31e+05  |\n",
      "|    total_reward         | -1.19e+05 |\n",
      "|    total_reward_pct     | -23.8     |\n",
      "|    total_trades         | 8944      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 631       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0321468 |\n",
      "|    clip_fraction        | 0.291     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.9     |\n",
      "|    explained_variance   | 0.467     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.512     |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -0.0145   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 2.22      |\n",
      "---------------------------------------\n",
      "day: 627, episode: 270\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 386518.54\n",
      "total_reward: -113481.46\n",
      "total_cost: 240435.98\n",
      "total_trades: 8672\n",
      "Sharpe: -0.177\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.87e+05   |\n",
      "|    total_cost           | 2.4e+05    |\n",
      "|    total_reward         | -1.13e+05  |\n",
      "|    total_reward_pct     | -22.7      |\n",
      "|    total_trades         | 8672       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 631        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 110        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05024988 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.38       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 1.79       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.72e+05    |\n",
      "|    total_cost           | 2.06e+05    |\n",
      "|    total_reward         | -2.28e+05   |\n",
      "|    total_reward_pct     | -45.6       |\n",
      "|    total_trades         | 8697        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048707172 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 275\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 804909.82\n",
      "total_reward: 304909.82\n",
      "total_cost: 417070.18\n",
      "total_trades: 9270\n",
      "Sharpe: 0.956\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 4.52e+05  |\n",
      "|    total_cost           | 3.43e+05  |\n",
      "|    total_reward         | -4.83e+04 |\n",
      "|    total_reward_pct     | -9.66     |\n",
      "|    total_trades         | 9211      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 630       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0339812 |\n",
      "|    clip_fraction        | 0.201     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.1     |\n",
      "|    explained_variance   | 0.52      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.493     |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.0048   |\n",
      "|    std                  | 1.06      |\n",
      "|    value_loss           | 2.4       |\n",
      "---------------------------------------\n",
      "day: 627, episode: 280\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 371633.28\n",
      "total_reward: -128366.72\n",
      "total_cost: 228708.95\n",
      "total_trades: 8850\n",
      "Sharpe: -0.186\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.72e+05    |\n",
      "|    total_cost           | 2.29e+05    |\n",
      "|    total_reward         | -1.28e+05   |\n",
      "|    total_reward_pct     | -25.7       |\n",
      "|    total_trades         | 8850        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029449683 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.64e+05    |\n",
      "|    total_cost           | 3.78e+05    |\n",
      "|    total_reward         | 1.64e+05    |\n",
      "|    total_reward_pct     | 32.7        |\n",
      "|    total_trades         | 9162        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022770029 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.58        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 285\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 366449.45\n",
      "total_reward: -133550.55\n",
      "total_cost: 231138.13\n",
      "total_trades: 8900\n",
      "Sharpe: -0.174\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 6.49e+05  |\n",
      "|    total_cost           | 3.22e+05  |\n",
      "|    total_reward         | 1.49e+05  |\n",
      "|    total_reward_pct     | 29.8      |\n",
      "|    total_trades         | 9037      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 630       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 126       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0306697 |\n",
      "|    clip_fraction        | 0.242     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.2     |\n",
      "|    explained_variance   | 0.417     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 2.94      |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -0.000358 |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 5.36      |\n",
      "---------------------------------------\n",
      "day: 627, episode: 290\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 752360.94\n",
      "total_reward: 252360.94\n",
      "total_cost: 347464.43\n",
      "total_trades: 9048\n",
      "Sharpe: 0.732\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.52e+05   |\n",
      "|    total_cost           | 3.47e+05   |\n",
      "|    total_reward         | 2.52e+05   |\n",
      "|    total_reward_pct     | 50.5       |\n",
      "|    total_trades         | 9048       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04341852 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.483      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.27       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00647   |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 2.69       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.43e+05    |\n",
      "|    total_cost           | 3.31e+05    |\n",
      "|    total_reward         | 4.26e+04    |\n",
      "|    total_reward_pct     | 8.52        |\n",
      "|    total_trades         | 9081        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032511823 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 295\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 736116.16\n",
      "total_reward: 236116.16\n",
      "total_cost: 393543.88\n",
      "total_trades: 9189\n",
      "Sharpe: 0.743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.3e+05     |\n",
      "|    total_cost           | 3.16e+05    |\n",
      "|    total_reward         | 2.99e+04    |\n",
      "|    total_reward_pct     | 5.99        |\n",
      "|    total_trades         | 8923        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013869001 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.32        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 4.52        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 300\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 489115.35\n",
      "total_reward: -10884.65\n",
      "total_cost: 196263.78\n",
      "total_trades: 8709\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.89e+05    |\n",
      "|    total_cost           | 1.96e+05    |\n",
      "|    total_reward         | -1.09e+04   |\n",
      "|    total_reward_pct     | -2.18       |\n",
      "|    total_trades         | 8709        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018801417 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 5.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.89e+05    |\n",
      "|    total_cost           | 2.36e+05    |\n",
      "|    total_reward         | -1.09e+04   |\n",
      "|    total_reward_pct     | -2.18       |\n",
      "|    total_trades         | 8842        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027068436 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 4.02        |\n",
      "-----------------------------------------\n",
      "day: 627, episode: 305\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 846653.62\n",
      "total_reward: 346653.62\n",
      "total_cost: 309249.13\n",
      "total_trades: 9019\n",
      "Sharpe: 1.003\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.64e+05   |\n",
      "|    total_cost           | 3.53e+05   |\n",
      "|    total_reward         | 4.64e+05   |\n",
      "|    total_reward_pct     | 92.9       |\n",
      "|    total_trades         | 9190       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 146        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03269604 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.496      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.04       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 3.21       |\n",
      "----------------------------------------\n",
      "day: 627, episode: 310\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 894801.38\n",
      "total_reward: 394801.38\n",
      "total_cost: 370123.08\n",
      "total_trades: 9177\n",
      "Sharpe: 1.048\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.95e+05   |\n",
      "|    total_cost           | 3.7e+05    |\n",
      "|    total_reward         | 3.95e+05   |\n",
      "|    total_reward_pct     | 79         |\n",
      "|    total_trades         | 9177       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 149        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02466098 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.5        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.7        |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.00869   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 4.63       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.32e+05   |\n",
      "|    total_cost           | 1.8e+05    |\n",
      "|    total_reward         | -2.68e+05  |\n",
      "|    total_reward_pct     | -53.6      |\n",
      "|    total_trades         | 8732       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 152        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04425233 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.551      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.88       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00789   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 5.29       |\n",
      "----------------------------------------\n",
      "day: 627, episode: 315\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 344181.78\n",
      "total_reward: -155818.22\n",
      "total_cost: 179248.11\n",
      "total_trades: 8611\n",
      "Sharpe: -0.047\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.88e+05   |\n",
      "|    total_cost           | 3.36e+05   |\n",
      "|    total_reward         | 3.88e+05   |\n",
      "|    total_reward_pct     | 77.6       |\n",
      "|    total_trades         | 9179       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03546476 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.545      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.02       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0052    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 4.67       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.04e+06   |\n",
      "|    total_cost           | 3.68e+05   |\n",
      "|    total_reward         | 5.42e+05   |\n",
      "|    total_reward_pct     | 108        |\n",
      "|    total_trades         | 9239       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03500563 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.67       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00739   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 4.54       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2020-07-09 to  2020-10-06\n",
      "PPO Sharpe Ratio:  nan\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.15e+05 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | 1.52e+04 |\n",
      "|    total_reward_pct | 3.04     |\n",
      "|    total_trades     | 6012     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 159      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total timesteps  | 2512     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -184     |\n",
      "|    critic_loss      | 1.78e+03 |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 1884     |\n",
      "----------------------------------\n",
      "day: 627, episode: 325\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 501711.70\n",
      "total_reward: 1711.70\n",
      "total_cost: 1149.17\n",
      "total_trades: 5981\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.98e+05  |\n",
      "|    total_cost       | 956       |\n",
      "|    total_reward     | -1.54e+03 |\n",
      "|    total_reward_pct | -0.307    |\n",
      "|    total_trades     | 5833      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 141       |\n",
      "|    time_elapsed     | 35        |\n",
      "|    total timesteps  | 5024      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -157      |\n",
      "|    critic_loss      | 627       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 4396      |\n",
      "-----------------------------------\n",
      "day: 627, episode: 330\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 509685.50\n",
      "total_reward: 9685.50\n",
      "total_cost: 1047.74\n",
      "total_trades: 5828\n",
      "Sharpe: 0.248\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.07e+05 |\n",
      "|    total_cost       | 1.05e+03 |\n",
      "|    total_reward     | 7.26e+03 |\n",
      "|    total_reward_pct | 1.45     |\n",
      "|    total_trades     | 5826     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 136      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total timesteps  | 7536     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -135     |\n",
      "|    critic_loss      | 211      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6908     |\n",
      "----------------------------------\n",
      "day: 627, episode: 335\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 497176.57\n",
      "total_reward: -2823.43\n",
      "total_cost: 1182.19\n",
      "total_trades: 5824\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.14e+05 |\n",
      "|    total_cost       | 1.13e+03 |\n",
      "|    total_reward     | 1.43e+04 |\n",
      "|    total_reward_pct | 2.86     |\n",
      "|    total_trades     | 5825     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 134      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total timesteps  | 10048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -117     |\n",
      "|    critic_loss      | 119      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 9420     |\n",
      "----------------------------------\n",
      "day: 627, episode: 340\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 508060.52\n",
      "total_reward: 8060.52\n",
      "total_cost: 1175.22\n",
      "total_trades: 5152\n",
      "Sharpe: 0.245\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.08e+05 |\n",
      "|    total_cost       | 1.18e+03 |\n",
      "|    total_reward     | 8.06e+03 |\n",
      "|    total_reward_pct | 1.61     |\n",
      "|    total_trades     | 5152     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 132      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total timesteps  | 12560    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -102     |\n",
      "|    critic_loss      | 88.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 11932    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.09e+05 |\n",
      "|    total_cost       | 1.19e+03 |\n",
      "|    total_reward     | 9.12e+03 |\n",
      "|    total_reward_pct | 1.82     |\n",
      "|    total_trades     | 5179     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total timesteps  | 15072    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -88.4    |\n",
      "|    critic_loss      | 52.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 14444    |\n",
      "----------------------------------\n",
      "day: 627, episode: 345\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 498921.08\n",
      "total_reward: -1078.92\n",
      "total_cost: 1167.89\n",
      "total_trades: 5174\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.16e+05 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | 1.6e+04  |\n",
      "|    total_reward_pct | 3.2      |\n",
      "|    total_trades     | 5241     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total timesteps  | 17584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -77.2    |\n",
      "|    critic_loss      | 21.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16956    |\n",
      "----------------------------------\n",
      "day: 627, episode: 350\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 516150.42\n",
      "total_reward: 16150.42\n",
      "total_cost: 1116.04\n",
      "total_trades: 5238\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.15e+05 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | 1.52e+04 |\n",
      "|    total_reward_pct | 3.03     |\n",
      "|    total_trades     | 5232     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total timesteps  | 20096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -67.3    |\n",
      "|    critic_loss      | 7.31     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 19468    |\n",
      "----------------------------------\n",
      "day: 627, episode: 355\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 515876.49\n",
      "total_reward: 15876.49\n",
      "total_cost: 1117.40\n",
      "total_trades: 5385\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.07e+05 |\n",
      "|    total_cost       | 1.15e+03 |\n",
      "|    total_reward     | 7.06e+03 |\n",
      "|    total_reward_pct | 1.41     |\n",
      "|    total_trades     | 5390     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total timesteps  | 22608    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -58.8    |\n",
      "|    critic_loss      | 12.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 21980    |\n",
      "----------------------------------\n",
      "day: 627, episode: 360\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 510882.57\n",
      "total_reward: 10882.57\n",
      "total_cost: 1159.98\n",
      "total_trades: 5375\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.11e+05 |\n",
      "|    total_cost       | 1.16e+03 |\n",
      "|    total_reward     | 1.09e+04 |\n",
      "|    total_reward_pct | 2.18     |\n",
      "|    total_trades     | 5375     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total timesteps  | 25120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -51.4    |\n",
      "|    critic_loss      | 3.67     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24492    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.06e+05 |\n",
      "|    total_cost       | 1.11e+03 |\n",
      "|    total_reward     | 6.48e+03 |\n",
      "|    total_reward_pct | 1.3      |\n",
      "|    total_trades     | 5371     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total timesteps  | 27632    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -45      |\n",
      "|    critic_loss      | 9.4      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27004    |\n",
      "----------------------------------\n",
      "day: 627, episode: 365\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 504610.12\n",
      "total_reward: 4610.12\n",
      "total_cost: 1079.27\n",
      "total_trades: 5286\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.1e+05  |\n",
      "|    total_cost       | 1.09e+03 |\n",
      "|    total_reward     | 1.04e+04 |\n",
      "|    total_reward_pct | 2.09     |\n",
      "|    total_trades     | 5278     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total timesteps  | 30144    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -39.4    |\n",
      "|    critic_loss      | 2.25     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29516    |\n",
      "----------------------------------\n",
      "day: 627, episode: 370\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 506883.80\n",
      "total_reward: 6883.80\n",
      "total_cost: 1083.22\n",
      "total_trades: 5274\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.1e+05  |\n",
      "|    total_cost       | 1.08e+03 |\n",
      "|    total_reward     | 1.02e+04 |\n",
      "|    total_reward_pct | 2.04     |\n",
      "|    total_trades     | 5290     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total timesteps  | 32656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -34.4    |\n",
      "|    critic_loss      | 15.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32028    |\n",
      "----------------------------------\n",
      "day: 627, episode: 375\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 510003.59\n",
      "total_reward: 10003.59\n",
      "total_cost: 1084.65\n",
      "total_trades: 5297\n",
      "Sharpe: 0.254\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 1.17e+03 |\n",
      "|    total_reward     | 929      |\n",
      "|    total_reward_pct | 0.186    |\n",
      "|    total_trades     | 5309     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total timesteps  | 35168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -30.1    |\n",
      "|    critic_loss      | 23.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34540    |\n",
      "----------------------------------\n",
      "day: 627, episode: 380\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500403.72\n",
      "total_reward: 403.72\n",
      "total_cost: 1093.61\n",
      "total_trades: 5307\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5e+05    |\n",
      "|    total_cost       | 1.09e+03 |\n",
      "|    total_reward     | 404      |\n",
      "|    total_reward_pct | 0.0807   |\n",
      "|    total_trades     | 5307     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total timesteps  | 37680    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -26.5    |\n",
      "|    critic_loss      | 1.49     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.1e+05  |\n",
      "|    total_cost       | 1.09e+03 |\n",
      "|    total_reward     | 9.89e+03 |\n",
      "|    total_reward_pct | 1.98     |\n",
      "|    total_trades     | 5304     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total timesteps  | 40192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -23.4    |\n",
      "|    critic_loss      | 23       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 39564    |\n",
      "----------------------------------\n",
      "day: 627, episode: 385\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 500576.32\n",
      "total_reward: 576.32\n",
      "total_cost: 1123.13\n",
      "total_trades: 5310\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 1.12e+03 |\n",
      "|    total_reward     | 1.3e+03  |\n",
      "|    total_reward_pct | 0.261    |\n",
      "|    total_trades     | 5328     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total timesteps  | 42704    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -20.8    |\n",
      "|    critic_loss      | 33.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 42076    |\n",
      "----------------------------------\n",
      "day: 627, episode: 390\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 510921.91\n",
      "total_reward: 10921.91\n",
      "total_cost: 1095.09\n",
      "total_trades: 5337\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.08e+05 |\n",
      "|    total_cost       | 1.09e+03 |\n",
      "|    total_reward     | 7.91e+03 |\n",
      "|    total_reward_pct | 1.58     |\n",
      "|    total_trades     | 5361     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total timesteps  | 45216    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -18.4    |\n",
      "|    critic_loss      | 4.46     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44588    |\n",
      "----------------------------------\n",
      "day: 627, episode: 395\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 510551.63\n",
      "total_reward: 10551.63\n",
      "total_cost: 1091.72\n",
      "total_trades: 5364\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -943     |\n",
      "|    total_reward_pct | -0.189   |\n",
      "|    total_trades     | 5366     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 372      |\n",
      "|    total timesteps  | 47728    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -16.4    |\n",
      "|    critic_loss      | 1.05     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47100    |\n",
      "----------------------------------\n",
      "day: 627, episode: 400\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 501041.02\n",
      "total_reward: 1041.02\n",
      "total_cost: 1086.72\n",
      "total_trades: 5377\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+05 |\n",
      "|    total_cost       | 1.09e+03 |\n",
      "|    total_reward     | 1.04e+03 |\n",
      "|    total_reward_pct | 0.208    |\n",
      "|    total_trades     | 5377     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 391      |\n",
      "|    total timesteps  | 50240    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -14.6    |\n",
      "|    critic_loss      | 15.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49612    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-07-09 to  2020-10-06\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-10-06\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_504_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.16e+06 |\n",
      "|    total_cost       | 4.56e+03 |\n",
      "|    total_reward     | 6.64e+05 |\n",
      "|    total_reward_pct | 133      |\n",
      "|    total_trades     | 4887     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 161      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total timesteps  | 2764     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -178     |\n",
      "|    critic_loss      | 276      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 2073     |\n",
      "----------------------------------\n",
      "day: 690, episode: 5\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 846218.61\n",
      "total_reward: 346218.61\n",
      "total_cost: 5141.56\n",
      "total_trades: 4891\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.95e+05 |\n",
      "|    total_cost       | 3.02e+03 |\n",
      "|    total_reward     | 1.95e+05 |\n",
      "|    total_reward_pct | 39       |\n",
      "|    total_trades     | 4889     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total timesteps  | 5528     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -151     |\n",
      "|    critic_loss      | 99.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 4837     |\n",
      "----------------------------------\n",
      "day: 690, episode: 10\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1734705.55\n",
      "total_reward: 1234705.55\n",
      "total_cost: 7515.54\n",
      "total_trades: 4897\n",
      "Sharpe: 1.724\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.62e+05 |\n",
      "|    total_cost       | 3.59e+03 |\n",
      "|    total_reward     | 2.62e+05 |\n",
      "|    total_reward_pct | 52.4     |\n",
      "|    total_trades     | 4882     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 136      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total timesteps  | 8292     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -130     |\n",
      "|    critic_loss      | 42.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7601     |\n",
      "----------------------------------\n",
      "day: 690, episode: 15\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499097.80\n",
      "total_reward: -902.20\n",
      "total_cost: 948.59\n",
      "total_trades: 4876\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.18e+06 |\n",
      "|    total_cost       | 4.16e+03 |\n",
      "|    total_reward     | 6.81e+05 |\n",
      "|    total_reward_pct | 136      |\n",
      "|    total_trades     | 4888     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 133      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total timesteps  | 11056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -112     |\n",
      "|    critic_loss      | 26.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 10365    |\n",
      "----------------------------------\n",
      "day: 690, episode: 20\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1146578.32\n",
      "total_reward: 646578.32\n",
      "total_cost: 3987.61\n",
      "total_trades: 4878\n",
      "Sharpe: 1.106\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.15e+06 |\n",
      "|    total_cost       | 3.99e+03 |\n",
      "|    total_reward     | 6.47e+05 |\n",
      "|    total_reward_pct | 129      |\n",
      "|    total_trades     | 4878     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 132      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total timesteps  | 13820    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -97.2    |\n",
      "|    critic_loss      | 13.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 13129    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -902     |\n",
      "|    total_reward_pct | -0.18    |\n",
      "|    total_trades     | 4875     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 131      |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total timesteps  | 16584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -84.3    |\n",
      "|    critic_loss      | 10.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15893    |\n",
      "----------------------------------\n",
      "day: 690, episode: 25\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499097.80\n",
      "total_reward: -902.20\n",
      "total_cost: 948.57\n",
      "total_trades: 4874\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.11e+05 |\n",
      "|    total_cost       | 1.35e+03 |\n",
      "|    total_reward     | 1.1e+04  |\n",
      "|    total_reward_pct | 2.19     |\n",
      "|    total_trades     | 4876     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total timesteps  | 19348    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -73      |\n",
      "|    critic_loss      | 20.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18657    |\n",
      "----------------------------------\n",
      "day: 690, episode: 30\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1038361.68\n",
      "total_reward: 538361.68\n",
      "total_cost: 3881.61\n",
      "total_trades: 4837\n",
      "Sharpe: 1.172\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.01e+06 |\n",
      "|    total_cost       | 3.86e+03 |\n",
      "|    total_reward     | 5.15e+05 |\n",
      "|    total_reward_pct | 103      |\n",
      "|    total_trades     | 4836     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 130      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total timesteps  | 22112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -63.4    |\n",
      "|    critic_loss      | 31.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 21421    |\n",
      "----------------------------------\n",
      "day: 690, episode: 35\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 977118.56\n",
      "total_reward: 477118.56\n",
      "total_cost: 3482.89\n",
      "total_trades: 4837\n",
      "Sharpe: 1.109\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 949      |\n",
      "|    total_reward     | -903     |\n",
      "|    total_reward_pct | -0.181   |\n",
      "|    total_trades     | 4831     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total timesteps  | 24876    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -55.3    |\n",
      "|    critic_loss      | 4.79     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24185    |\n",
      "----------------------------------\n",
      "day: 690, episode: 40\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 550400.84\n",
      "total_reward: 50400.84\n",
      "total_cost: 1105.32\n",
      "total_trades: 4832\n",
      "Sharpe: 0.408\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.5e+05  |\n",
      "|    total_cost       | 1.11e+03 |\n",
      "|    total_reward     | 5.04e+04 |\n",
      "|    total_reward_pct | 10.1     |\n",
      "|    total_trades     | 4832     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total timesteps  | 27640    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -48.1    |\n",
      "|    critic_loss      | 6.98     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 26949    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.58e+05 |\n",
      "|    total_cost       | 1.14e+03 |\n",
      "|    total_reward     | 5.77e+04 |\n",
      "|    total_reward_pct | 11.5     |\n",
      "|    total_trades     | 4833     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total timesteps  | 30404    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -42.2    |\n",
      "|    critic_loss      | 28.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 29713    |\n",
      "----------------------------------\n",
      "day: 690, episode: 45\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499096.76\n",
      "total_reward: -903.24\n",
      "total_cost: 948.55\n",
      "total_trades: 4831\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.4e+05  |\n",
      "|    total_cost       | 1.14e+03 |\n",
      "|    total_reward     | 3.97e+04 |\n",
      "|    total_reward_pct | 7.93     |\n",
      "|    total_trades     | 4835     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total timesteps  | 33168    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -37      |\n",
      "|    critic_loss      | 22.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 32477    |\n",
      "----------------------------------\n",
      "day: 690, episode: 50\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1092231.60\n",
      "total_reward: 592231.60\n",
      "total_cost: 3735.26\n",
      "total_trades: 4837\n",
      "Sharpe: 1.242\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.9e+05  |\n",
      "|    total_cost       | 3.85e+03 |\n",
      "|    total_reward     | 4.9e+05  |\n",
      "|    total_reward_pct | 98.1     |\n",
      "|    total_trades     | 4836     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total timesteps  | 35932    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -32.6    |\n",
      "|    critic_loss      | 14.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35241    |\n",
      "----------------------------------\n",
      "day: 690, episode: 55\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499096.73\n",
      "total_reward: -903.27\n",
      "total_cost: 948.21\n",
      "total_trades: 4831\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -903     |\n",
      "|    total_reward_pct | -0.181   |\n",
      "|    total_trades     | 4831     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total timesteps  | 38696    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -28.8    |\n",
      "|    critic_loss      | 5.5      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 38005    |\n",
      "----------------------------------\n",
      "day: 690, episode: 60\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 499096.73\n",
      "total_reward: -903.27\n",
      "total_cost: 948.21\n",
      "total_trades: 4831\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -903     |\n",
      "|    total_reward_pct | -0.181   |\n",
      "|    total_trades     | 4831     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total timesteps  | 41460    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -25.6    |\n",
      "|    critic_loss      | 18       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 40769    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+05 |\n",
      "|    total_cost       | 948      |\n",
      "|    total_reward     | -903     |\n",
      "|    total_reward_pct | -0.181   |\n",
      "|    total_trades     | 4831     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total timesteps  | 44224    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -22.7    |\n",
      "|    critic_loss      | 9.45     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43533    |\n",
      "----------------------------------\n",
      "day: 690, episode: 65\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 1092693.00\n",
      "total_reward: 592693.00\n",
      "total_cost: 3777.36\n",
      "total_trades: 4835\n",
      "Sharpe: 1.232\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.7e+05  |\n",
      "|    total_cost       | 1.17e+03 |\n",
      "|    total_reward     | 7.03e+04 |\n",
      "|    total_reward_pct | 14.1     |\n",
      "|    total_trades     | 4833     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total timesteps  | 46988    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -20.3    |\n",
      "|    critic_loss      | 3.13     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46297    |\n",
      "----------------------------------\n",
      "day: 690, episode: 70\n",
      "begin_total_asset: 500000.00\n",
      "end_total_asset: 502131.76\n",
      "total_reward: 2131.76\n",
      "total_cost: 958.90\n",
      "total_trades: 4831\n",
      "Sharpe: 0.353\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.05e+06 |\n",
      "|    total_cost       | 3.42e+03 |\n",
      "|    total_reward     | 5.46e+05 |\n",
      "|    total_reward_pct | 109      |\n",
      "|    total_trades     | 4836     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 128      |\n",
      "|    time_elapsed     | 387      |\n",
      "|    total timesteps  | 49752    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -18.3    |\n",
      "|    critic_loss      | 4.39     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49061    |\n",
      "----------------------------------\n",
      "======Trading from:  2020-10-06 to  2021-01-06\n",
      "Ensemble Strategy took:  131.28867499430973  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-0qd8acMtj1f",
    "outputId": "a7fa85f0-7825-4b9a-d313-cd99ad70ecb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126  2019-01-03  2019-04-04       DDPG        NaN        NaN         NaN\n",
       "1  189  2019-04-04  2019-07-05       DDPG        NaN        NaN         NaN\n",
       "2  252  2019-07-05  2019-10-02       DDPG        NaN        NaN         NaN\n",
       "3  315  2019-10-02  2020-01-03       DDPG        NaN        NaN         NaN\n",
       "4  378  2020-01-03  2020-04-06       DDPG        NaN        NaN         NaN\n",
       "5  441  2020-04-06  2020-07-09       DDPG        NaN        NaN         NaN\n",
       "6  504  2020-07-09  2020-10-06       DDPG        NaN        NaN         NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "q9mKF7GGtj1g",
    "outputId": "5de4e5e6-d74b-4d12-b786-7e299dabd6a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  nan\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oyosyW7_tj1g",
    "outputId": "29307dfb-1d27-4fb7-dc7a-7a34a4902d59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0       500000.0  2019-04-04           NaN  2019-04-04\n",
       "1       500000.0  2019-04-05           0.0  2019-04-05\n",
       "2       500000.0  2019-04-08           0.0  2019-04-08\n",
       "3       500000.0  2019-04-09           0.0  2019-04-09\n",
       "4       500000.0  2019-04-10           0.0  2019-04-10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wLsRdw2Ctj1h",
    "outputId": "01dd70f8-639f-49f7-8e75-60ebc88b0e4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.0\n",
      "Cumulative returns     0.0\n",
      "Annual volatility      0.0\n",
      "Sharpe ratio           NaN\n",
      "Calmar ratio           NaN\n",
      "Stability              0.0\n",
      "Max drawdown           0.0\n",
      "Omega ratio            NaN\n",
      "Sortino ratio          NaN\n",
      "Skew                   NaN\n",
      "Kurtosis               NaN\n",
      "Tail ratio             NaN\n",
      "Daily value at risk    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to IHSG===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (425, 8)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4fe69935546d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^JKSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n\u001b[0m",
      "\u001b[0;32m/home/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mbacktest_plot\u001b[0;34m(account_value, baseline_start, baseline_end, baseline_ticker, value_col_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         pyfolio.create_full_tear_sheet(\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mreturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[0;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mturnover_denom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturnover_denom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mheader_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         set_context=set_context)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     create_interesting_times_tear_sheet(returns,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[0;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbenchmark_rets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_returns_to_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     plotting.show_perf_stats(returns, benchmark_rets,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/utils.py\u001b[0m in \u001b[0;36mclip_returns_to_benchmark\u001b[0;34m(rets, benchmark_rets)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     raise KeyError(\n\u001b[0;32m-> 1316\u001b[0;31m                         \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m                         \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                         \u001b[0;34mf\"The following labels were missing: {not_found}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to IHSG===========\")\n",
    "%matplotlib inline\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^JKSE', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_perf_stats=BaselineStats('^JKSE',\n",
    "                                  baseline_start = df_account_value.loc[0,'date'],\n",
    "                                  baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
