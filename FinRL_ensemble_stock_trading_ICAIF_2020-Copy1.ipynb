{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_multiple_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "802ae0b5-d88e-46ba-8082-9eb5890f9cba"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "c437c266-2780-4c50-af8b-6868e7fdaa1f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, get_baseline, backtest_plot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-01-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLY.ME', 'YNDX.ME', 'ALRS.ME', 'AFLT.ME', 'VTBR.ME', 'GAZP.ME', 'GMKN.ME', 'IRAO.ME', 'LKOH.ME', 'MGNT.ME', 'MOEX.ME', 'NLMK.ME', 'NVTK.ME', 'ROSN.ME', 'SBER.ME', 'CHMF.ME', 'AFKS.ME', 'SNGS.ME', 'TATN.ME']\n"
     ]
    }
   ],
   "source": [
    "print(config.TOPCHIK_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (46511, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = config.START_DATE,\n",
    "                     end_date = '2021-01-19',\n",
    "                     ticker_list = config.TOPCHIK_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>54.299999</td>\n",
       "      <td>39.564133</td>\n",
       "      <td>547540.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>355.500000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>133.885422</td>\n",
       "      <td>806004.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>168.839996</td>\n",
       "      <td>171.100006</td>\n",
       "      <td>167.119995</td>\n",
       "      <td>96.636467</td>\n",
       "      <td>15012689.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>4812.000000</td>\n",
       "      <td>4675.000000</td>\n",
       "      <td>1852.150635</td>\n",
       "      <td>347308.0</td>\n",
       "      <td>GMKN.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>1616.699951</td>\n",
       "      <td>1637.060059</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>836.540039</td>\n",
       "      <td>853228.0</td>\n",
       "      <td>LKOH.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close      volume  \\\n",
       "0  2010-03-03    55.580002    55.580002    54.299999    39.564133    547540.0   \n",
       "1  2010-03-03   355.500000   365.000000   354.000000   133.885422    806004.0   \n",
       "2  2010-03-03   168.839996   171.100006   167.119995    96.636467  15012689.0   \n",
       "3  2010-03-03  4705.000000  4812.000000  4675.000000  1852.150635    347308.0   \n",
       "4  2010-03-03  1616.699951  1637.060059  1596.000000   836.540039    853228.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFLT.ME    2  \n",
       "1  CHMF.ME    2  \n",
       "2  GAZP.ME    2  \n",
       "3  GMKN.ME    2  \n",
       "4  LKOH.ME    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46506</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>275.720001</td>\n",
       "      <td>281.299988</td>\n",
       "      <td>272.950012</td>\n",
       "      <td>279.799988</td>\n",
       "      <td>7.096328e+07</td>\n",
       "      <td>SBER.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46507</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>35.865002</td>\n",
       "      <td>36.099998</td>\n",
       "      <td>4.088790e+07</td>\n",
       "      <td>SNGS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46508</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>532.400024</td>\n",
       "      <td>535.400024</td>\n",
       "      <td>523.099976</td>\n",
       "      <td>533.099976</td>\n",
       "      <td>4.929751e+06</td>\n",
       "      <td>TATN.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46509</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>0.039380</td>\n",
       "      <td>0.039440</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.039060</td>\n",
       "      <td>3.725212e+10</td>\n",
       "      <td>VTBR.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46510</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>5002.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>4990.000000</td>\n",
       "      <td>5034.000000</td>\n",
       "      <td>5.124640e+05</td>\n",
       "      <td>YNDX.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         open         high          low        close  \\\n",
       "46506  2021-01-18   275.720001   281.299988   272.950012   279.799988   \n",
       "46507  2021-01-18    36.580002    36.580002    35.865002    36.099998   \n",
       "46508  2021-01-18   532.400024   535.400024   523.099976   533.099976   \n",
       "46509  2021-01-18     0.039380     0.039440     0.038760     0.039060   \n",
       "46510  2021-01-18  5002.000000  5061.000000  4990.000000  5034.000000   \n",
       "\n",
       "             volume      tic  day  \n",
       "46506  7.096328e+07  SBER.ME    0  \n",
       "46507  4.088790e+07  SNGS.ME    0  \n",
       "46508  4.929751e+06  TATN.ME    0  \n",
       "46509  3.725212e+10  VTBR.ME    0  \n",
       "46510  5.124640e+05  YNDX.ME    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46511, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4hYkeaPiICHS",
    "outputId": "ce9d7463-a74c-4917-c96d-848a1e8ad493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>54.299999</td>\n",
       "      <td>39.564133</td>\n",
       "      <td>547540.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>355.500000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>133.885422</td>\n",
       "      <td>806004.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>168.839996</td>\n",
       "      <td>171.100006</td>\n",
       "      <td>167.119995</td>\n",
       "      <td>96.636467</td>\n",
       "      <td>15012689.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>4812.000000</td>\n",
       "      <td>4675.000000</td>\n",
       "      <td>1852.150635</td>\n",
       "      <td>347308.0</td>\n",
       "      <td>GMKN.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>1616.699951</td>\n",
       "      <td>1637.060059</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>836.540039</td>\n",
       "      <td>853228.0</td>\n",
       "      <td>LKOH.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close      volume  \\\n",
       "0  2010-03-03    55.580002    55.580002    54.299999    39.564133    547540.0   \n",
       "1  2010-03-03   355.500000   365.000000   354.000000   133.885422    806004.0   \n",
       "2  2010-03-03   168.839996   171.100006   167.119995    96.636467  15012689.0   \n",
       "3  2010-03-03  4705.000000  4812.000000  4675.000000  1852.150635    347308.0   \n",
       "4  2010-03-03  1616.699951  1637.060059  1596.000000   836.540039    853228.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFLT.ME    2  \n",
       "1  CHMF.ME    2  \n",
       "2  GAZP.ME    2  \n",
       "3  GMKN.ME    2  \n",
       "4  LKOH.ME    2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22631</th>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.800003</td>\n",
       "      <td>82.198769</td>\n",
       "      <td>34193090.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.854468</td>\n",
       "      <td>11823.012450</td>\n",
       "      <td>10893.137843</td>\n",
       "      <td>59.901695</td>\n",
       "      <td>189.210481</td>\n",
       "      <td>31.742428</td>\n",
       "      <td>11457.333887</td>\n",
       "      <td>11629.633610</td>\n",
       "      <td>18.636577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36564</th>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>SNGS.ME</td>\n",
       "      <td>31.389999</td>\n",
       "      <td>31.934999</td>\n",
       "      <td>31.180000</td>\n",
       "      <td>27.813225</td>\n",
       "      <td>12934000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.396751</td>\n",
       "      <td>178.204033</td>\n",
       "      <td>167.715623</td>\n",
       "      <td>62.415873</td>\n",
       "      <td>56.814418</td>\n",
       "      <td>31.251529</td>\n",
       "      <td>171.447953</td>\n",
       "      <td>160.129979</td>\n",
       "      <td>17.628117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73415</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>YNDX.ME</td>\n",
       "      <td>5071.000000</td>\n",
       "      <td>5131.000000</td>\n",
       "      <td>4940.200195</td>\n",
       "      <td>5077.000000</td>\n",
       "      <td>1376540.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.851581</td>\n",
       "      <td>1105.892837</td>\n",
       "      <td>913.107163</td>\n",
       "      <td>45.982931</td>\n",
       "      <td>-79.736319</td>\n",
       "      <td>36.451078</td>\n",
       "      <td>989.400000</td>\n",
       "      <td>963.066667</td>\n",
       "      <td>14.535233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59339</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>157.100006</td>\n",
       "      <td>158.889999</td>\n",
       "      <td>154.350006</td>\n",
       "      <td>143.578384</td>\n",
       "      <td>52197900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.381060</td>\n",
       "      <td>109.237920</td>\n",
       "      <td>97.331508</td>\n",
       "      <td>41.891485</td>\n",
       "      <td>-211.195211</td>\n",
       "      <td>39.047851</td>\n",
       "      <td>102.884682</td>\n",
       "      <td>105.212034</td>\n",
       "      <td>17.691455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62353</th>\n",
       "      <td>2019-02-25</td>\n",
       "      <td>TATN.ME</td>\n",
       "      <td>799.900024</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>783.000000</td>\n",
       "      <td>600.387268</td>\n",
       "      <td>948350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156823</td>\n",
       "      <td>218.568614</td>\n",
       "      <td>203.603184</td>\n",
       "      <td>49.981663</td>\n",
       "      <td>-186.123506</td>\n",
       "      <td>20.591628</td>\n",
       "      <td>211.244602</td>\n",
       "      <td>203.753558</td>\n",
       "      <td>27.386196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      tic         open         high          low  \\\n",
       "22631  2013-06-06  GAZP.ME   118.000000   118.540001   116.800003   \n",
       "36564  2015-06-09  SNGS.ME    31.389999    31.934999    31.180000   \n",
       "73415  2020-09-29  YNDX.ME  5071.000000  5131.000000  4940.200195   \n",
       "59339  2018-09-20  GAZP.ME   157.100006   158.889999   154.350006   \n",
       "62353  2019-02-25  TATN.ME   799.900024   800.000000   783.000000   \n",
       "\n",
       "             close      volume  day       macd       boll_ub       boll_lb  \\\n",
       "22631    82.198769  34193090.0  3.0  36.854468  11823.012450  10893.137843   \n",
       "36564    27.813225  12934000.0  1.0   2.396751    178.204033    167.715623   \n",
       "73415  5077.000000   1376540.0  1.0  -5.851581   1105.892837    913.107163   \n",
       "59339   143.578384  52197900.0  3.0  -1.381060    109.237920     97.331508   \n",
       "62353   600.387268    948350.0  0.0   0.156823    218.568614    203.603184   \n",
       "\n",
       "          rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "22631  59.901695  189.210481  31.742428  11457.333887  11629.633610   \n",
       "36564  62.415873   56.814418  31.251529    171.447953    160.129979   \n",
       "73415  45.982931  -79.736319  36.451078    989.400000    963.066667   \n",
       "59339  41.891485 -211.195211  39.047851    102.884682    105.212034   \n",
       "62353  49.981663 -186.123506  20.591628    211.244602    203.753558   \n",
       "\n",
       "       turbulence  \n",
       "22631   18.636577  \n",
       "36564   17.628117  \n",
       "73415   14.535233  \n",
       "59339   17.691455  \n",
       "62353   27.386196  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 19, State Space: 191\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 10, \n",
    "    \"initial_amount\": 50_000,\n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = config.START_DATE\n",
    "train_end = '2019-01-01'\n",
    "val_test_start = '2019-01-01'\n",
    "val_test_end = '2021-01-18'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,                    \n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 512\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 512\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 100_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2000-01-01 to  2019-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_3\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 3.72     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0199   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 304      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -3.45    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.024    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -1.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00477  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -71.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 9.84     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.145    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.94e+04  |\n",
      "|    total_cost         | 4.81e+04  |\n",
      "|    total_reward       | -2.06e+04 |\n",
      "|    total_reward_pct   | -41.3     |\n",
      "|    total_trades       | 26853     |\n",
      "| time/                 |           |\n",
      "|    fps                | 304       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -3.78     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -1.32     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.0034    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 304      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.349   |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.000177 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 304      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -3.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.242    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.000907 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 304       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 1.8       |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.00454   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.03e+04  |\n",
      "|    total_cost         | 5.72e+03  |\n",
      "|    total_reward       | -3.97e+04 |\n",
      "|    total_reward_pct   | -79.4     |\n",
      "|    total_trades       | 22443     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | 0.817     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 2.9       |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.00999   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.6     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.232   |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.000661 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.447    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.000279 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -3.77    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 2.61     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0118   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | 0.052    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.54     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.000686 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.11e+03  |\n",
      "|    total_cost         | 1.2e+04   |\n",
      "|    total_reward       | -4.19e+04 |\n",
      "|    total_reward_pct   | -83.8     |\n",
      "|    total_trades       | 24231     |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | -0.536    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -0.876    |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.00553   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.354   |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.000396 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -2.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 5.14     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0459   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | 0.494    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.201    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.64e+05 |\n",
      "|    total_cost         | 2.05e+04 |\n",
      "|    total_reward       | 1.14e+05 |\n",
      "|    total_reward_pct   | 229      |\n",
      "|    total_trades       | 24932    |\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | -0.931   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.483   |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00117  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | -35.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -3.46    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | -2.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -2.39    |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.0102   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | -0.122   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.851    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.00105  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | -8.82    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.321   |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.000378 |\n",
      "------------------------------------\n",
      "day: 2208, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17359.37\n",
      "total_reward: -32640.63\n",
      "total_cost: 13744.74\n",
      "total_trades: 23919\n",
      "Sharpe: -0.091\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.74e+04  |\n",
      "|    total_cost         | 1.37e+04  |\n",
      "|    total_reward       | -3.26e+04 |\n",
      "|    total_reward_pct   | -65.3     |\n",
      "|    total_trades       | 23919     |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.9     |\n",
      "|    explained_variance | -37.1     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 0.433     |\n",
      "|    std                | 1.37      |\n",
      "|    value_loss         | 0.00549   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | -0.126   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.0559  |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.000586 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | -0.629   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.779    |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.000873 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | -19.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.357    |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.00335  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.57e+03  |\n",
      "|    total_cost         | 1.12e+04  |\n",
      "|    total_reward       | -4.24e+04 |\n",
      "|    total_reward_pct   | -84.9     |\n",
      "|    total_trades       | 24394     |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.3     |\n",
      "|    explained_variance | -0.0796   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -2.03     |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 0.00369   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | -1.69    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -1.72    |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.00647  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | 0.341    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00255  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.1    |\n",
      "|    explained_variance | 0.034    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.00458  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.98e+04  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | -3.02e+04 |\n",
      "|    total_reward_pct   | -60.4     |\n",
      "|    total_trades       | 23669     |\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.3     |\n",
      "|    explained_variance | 0.179     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -3.21     |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 0.00817   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | -1.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.00205  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -1.06    |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.00161  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | -0.012   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.277    |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.00253  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | -0.0348  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -6.17    |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0448   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.99e+04  |\n",
      "|    total_cost         | 4.21e+03  |\n",
      "|    total_reward       | -2.01e+04 |\n",
      "|    total_reward_pct   | -40.1     |\n",
      "|    total_trades       | 20545     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.3     |\n",
      "|    explained_variance | -1.45     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -2.45     |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 0.00515   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | -2.71    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.0542  |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.00206  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | -1.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.25     |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 21.4     |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.402    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.9e+04  |\n",
      "|    total_cost         | 3.62e+03 |\n",
      "|    total_reward       | -981     |\n",
      "|    total_reward_pct   | -1.96    |\n",
      "|    total_trades       | 19518    |\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.492   |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.000561 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.849    |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.000702 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.294   |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.000266 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.88     |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 3.57     |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.012    |\n",
      "------------------------------------\n",
      "day: 2208, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 22010.82\n",
      "total_reward: -27989.18\n",
      "total_cost: 3348.76\n",
      "total_trades: 20309\n",
      "Sharpe: 0.175\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.2e+04  |\n",
      "|    total_cost         | 3.35e+03 |\n",
      "|    total_reward       | -2.8e+04 |\n",
      "|    total_reward_pct   | -56      |\n",
      "|    total_trades       | 20309    |\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | -0.259   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.408   |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.000163 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.718    |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.000418 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 3.13     |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.00986  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.686   |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.000707 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.33e+04 |\n",
      "|    total_cost         | 2.38e+04 |\n",
      "|    total_reward       | 3.33e+03 |\n",
      "|    total_reward_pct   | 6.65     |\n",
      "|    total_trades       | 23862    |\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | -5.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -1.76    |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 0.00278  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -2.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.13     |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 0.000131 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.0251   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.979    |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.0024   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.874   |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.000822 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.03e+04  |\n",
      "|    total_cost         | 1.91e+04  |\n",
      "|    total_reward       | -3.97e+04 |\n",
      "|    total_reward_pct   | -79.4     |\n",
      "|    total_trades       | 24003     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 1.08      |\n",
      "|    std                | 2.13      |\n",
      "|    value_loss         | 0.000686  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | -0.174   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.00174  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | -0.371   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 1.23     |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.000794 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -14.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.541   |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.00216  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.25e+04  |\n",
      "|    total_cost         | 1.39e+04  |\n",
      "|    total_reward       | -3.75e+04 |\n",
      "|    total_reward_pct   | -75       |\n",
      "|    total_trades       | 23002     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -0.682    |\n",
      "|    std                | 2.31      |\n",
      "|    value_loss         | 0.000638  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.03     |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.00112  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.229   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -2.17    |\n",
      "|    std                | 2.41     |\n",
      "|    value_loss         | 0.00295  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -3.46    |\n",
      "|    std                | 2.45     |\n",
      "|    value_loss         | 0.00801  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.6e+04  |\n",
      "|    total_cost         | 1.29e+04 |\n",
      "|    total_reward       | -2.4e+04 |\n",
      "|    total_reward_pct   | -48      |\n",
      "|    total_trades       | 23181    |\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0.675    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.909    |\n",
      "|    std                | 2.48     |\n",
      "|    value_loss         | 0.000478 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    std                | 2.53     |\n",
      "|    value_loss         | 0.00145  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -0.114   |\n",
      "|    std                | 2.58     |\n",
      "|    value_loss         | 0.000287 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 0.00131  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | -8.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -8.13    |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.0394   |\n",
      "------------------------------------\n",
      "day: 2208, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21968.99\n",
      "total_reward: -28031.01\n",
      "total_cost: 8404.26\n",
      "total_trades: 23342\n",
      "Sharpe: 0.048\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.2e+04  |\n",
      "|    total_cost         | 8.4e+03  |\n",
      "|    total_reward       | -2.8e+04 |\n",
      "|    total_reward_pct   | -56.1    |\n",
      "|    total_trades       | 23342    |\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 0.551    |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.00159  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | -0.0187  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.479    |\n",
      "|    std                | 2.77     |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | -0.0469  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 0.752    |\n",
      "|    std                | 2.81     |\n",
      "|    value_loss         | 0.000875 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | -0.00557 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -6.78    |\n",
      "|    std                | 2.84     |\n",
      "|    value_loss         | 0.0321   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.95e+04 |\n",
      "|    total_cost         | 8.2e+03  |\n",
      "|    total_reward       | -458     |\n",
      "|    total_reward_pct   | -0.916   |\n",
      "|    total_trades       | 24003    |\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0.241    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.385   |\n",
      "|    std                | 2.87     |\n",
      "|    value_loss         | 9.96e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | -1.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.0207  |\n",
      "|    std                | 2.92     |\n",
      "|    value_loss         | 1.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 0.00204  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -5.07    |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.0183   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | -0.00366 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -4.18    |\n",
      "|    std                | 3.05     |\n",
      "|    value_loss         | 0.00889  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.89e+04  |\n",
      "|    total_cost         | 8.26e+03  |\n",
      "|    total_reward       | -1.11e+04 |\n",
      "|    total_reward_pct   | -22.2     |\n",
      "|    total_trades       | 23300     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.4     |\n",
      "|    explained_variance | -0.324    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -3.34     |\n",
      "|    std                | 3.1       |\n",
      "|    value_loss         | 0.0053    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | -7.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.00162  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -0.373    |\n",
      "|    std                | 3.22      |\n",
      "|    value_loss         | 0.000178  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | -0.169   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0.151   |\n",
      "|    std                | 3.28     |\n",
      "|    value_loss         | 0.00034  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.03e+04  |\n",
      "|    total_cost         | 6.78e+03  |\n",
      "|    total_reward       | -2.97e+04 |\n",
      "|    total_reward_pct   | -59.4     |\n",
      "|    total_trades       | 23359     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -0.909    |\n",
      "|    std                | 3.34      |\n",
      "|    value_loss         | 0.000392  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 0.627    |\n",
      "|    std                | 3.42     |\n",
      "|    value_loss         | 0.000192 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 2.98     |\n",
      "|    std                | 3.5      |\n",
      "|    value_loss         | 0.00354  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -1.25    |\n",
      "|    std                | 3.56     |\n",
      "|    value_loss         | 0.000712 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.04e+04  |\n",
      "|    total_cost         | 1.8e+04   |\n",
      "|    total_reward       | -2.96e+04 |\n",
      "|    total_reward_pct   | -59.2     |\n",
      "|    total_trades       | 25404     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -1.69     |\n",
      "|    std                | 3.63      |\n",
      "|    value_loss         | 0.00169   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -2.96    |\n",
      "|    std                | 3.7      |\n",
      "|    value_loss         | 0.00435  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.756    |\n",
      "|    std                | 3.75     |\n",
      "|    value_loss         | 0.000682 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -1.11    |\n",
      "|    std                | 3.82     |\n",
      "|    value_loss         | 0.000921 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | -0.224   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 0.00292  |\n",
      "------------------------------------\n",
      "day: 2208, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21130.78\n",
      "total_reward: -28869.22\n",
      "total_cost: 11910.64\n",
      "total_trades: 24320\n",
      "Sharpe: -0.038\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.11e+04  |\n",
      "|    total_cost         | 1.19e+04  |\n",
      "|    total_reward       | -2.89e+04 |\n",
      "|    total_reward_pct   | -57.7     |\n",
      "|    total_trades       | 24320     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 0.357     |\n",
      "|    std                | 3.94      |\n",
      "|    value_loss         | 9.34e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -0.486   |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 0.000175 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.9    |\n",
      "|    explained_variance | -0.353   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -2.03    |\n",
      "|    std                | 4.13     |\n",
      "|    value_loss         | 0.00278  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.2    |\n",
      "|    explained_variance | 0.136    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.0294  |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 0.000159 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.4e+04  |\n",
      "|    total_cost         | 2.76e+04 |\n",
      "|    total_reward       | -1.6e+04 |\n",
      "|    total_reward_pct   | -32      |\n",
      "|    total_trades       | 25976    |\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | 0.0265   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.761    |\n",
      "|    std                | 4.26     |\n",
      "|    value_loss         | 0.000301 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 0.745    |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.000261 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.275    |\n",
      "|    std                | 4.43     |\n",
      "|    value_loss         | 5.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.0351   |\n",
      "|    std                | 4.55     |\n",
      "|    value_loss         | 2.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | -2.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 0.722    |\n",
      "|    std                | 4.68     |\n",
      "|    value_loss         | 0.000209 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.43e+03  |\n",
      "|    total_cost         | 1.28e+04  |\n",
      "|    total_reward       | -4.66e+04 |\n",
      "|    total_reward_pct   | -93.1     |\n",
      "|    total_trades       | 25287     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.6     |\n",
      "|    explained_variance | 0.27      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -0.829    |\n",
      "|    std                | 4.77      |\n",
      "|    value_loss         | 0.000258  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0.317   |\n",
      "|    std                | 4.85     |\n",
      "|    value_loss         | 0.000203 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 2.86     |\n",
      "|    std                | 4.94     |\n",
      "|    value_loss         | 0.00465  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -0.535    |\n",
      "|    std                | 5.02      |\n",
      "|    value_loss         | 0.000195  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.27e+03  |\n",
      "|    total_cost         | 3.58e+04  |\n",
      "|    total_reward       | -4.27e+04 |\n",
      "|    total_reward_pct   | -85.5     |\n",
      "|    total_trades       | 26549     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.9     |\n",
      "|    explained_variance | -80.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -5        |\n",
      "|    std                | 5.09      |\n",
      "|    value_loss         | 0.0278    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 2.3      |\n",
      "|    std                | 5.16     |\n",
      "|    value_loss         | 0.00229  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -4.86    |\n",
      "|    std                | 5.24     |\n",
      "|    value_loss         | 0.00819  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | -0.278   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.427    |\n",
      "|    std                | 5.34     |\n",
      "|    value_loss         | 6.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | -1.53    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -3.06    |\n",
      "|    std                | 5.44     |\n",
      "|    value_loss         | 0.00318  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.67e+03  |\n",
      "|    total_cost         | 3.8e+04   |\n",
      "|    total_reward       | -4.13e+04 |\n",
      "|    total_reward_pct   | -82.7     |\n",
      "|    total_trades       | 26819     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 5.88      |\n",
      "|    std                | 5.51      |\n",
      "|    value_loss         | 0.0124    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 2.55     |\n",
      "|    std                | 5.58     |\n",
      "|    value_loss         | 0.00347  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.8    |\n",
      "|    explained_variance | 0.121    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -1.18    |\n",
      "|    std                | 5.65     |\n",
      "|    value_loss         | 0.00131  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -3.98    |\n",
      "|    std                | 5.74     |\n",
      "|    value_loss         | 0.0046   |\n",
      "------------------------------------\n",
      "day: 2208, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17788.63\n",
      "total_reward: -32211.37\n",
      "total_cost: 70224.07\n",
      "total_trades: 28528\n",
      "Sharpe: -0.368\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.78e+04  |\n",
      "|    total_cost         | 7.02e+04  |\n",
      "|    total_reward       | -3.22e+04 |\n",
      "|    total_reward_pct   | -64.4     |\n",
      "|    total_trades       | 28528     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -0.428    |\n",
      "|    std                | 5.83      |\n",
      "|    value_loss         | 5.28e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.8    |\n",
      "|    explained_variance | 0.0658   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.025    |\n",
      "|    std                | 5.93     |\n",
      "|    value_loss         | 0.000243 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.1    |\n",
      "|    explained_variance | 0.61     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 6.05     |\n",
      "|    value_loss         | 0.000331 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | -0.042   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 6.18     |\n",
      "|    value_loss         | 0.00117  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.35e+03  |\n",
      "|    total_cost         | 2.44e+04  |\n",
      "|    total_reward       | -4.06e+04 |\n",
      "|    total_reward_pct   | -81.3     |\n",
      "|    total_trades       | 26664     |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.9     |\n",
      "|    explained_variance | -0.15     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 0.87      |\n",
      "|    std                | 6.31      |\n",
      "|    value_loss         | 0.00217   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 188       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.3     |\n",
      "|    explained_variance | -8.09e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 0.176     |\n",
      "|    std                | 6.43      |\n",
      "|    value_loss         | 0.000395  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.6    |\n",
      "|    explained_variance | 0.0712   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 43.7     |\n",
      "|    std                | 6.54     |\n",
      "|    value_loss         | 0.771    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    std                | 6.65     |\n",
      "|    value_loss         | 0.00154  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.3    |\n",
      "|    explained_variance | -9.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 4.21     |\n",
      "|    std                | 6.77     |\n",
      "|    value_loss         | 0.00576  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.73e+04  |\n",
      "|    total_cost         | 2.35e+04  |\n",
      "|    total_reward       | -3.27e+04 |\n",
      "|    total_reward_pct   | -65.5     |\n",
      "|    total_trades       | 26435     |\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -2.52     |\n",
      "|    std                | 6.89      |\n",
      "|    value_loss         | 0.00166   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | -4.88    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 0.0231   |\n",
      "|    std                | 7.04     |\n",
      "|    value_loss         | 0.000518 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.132    |\n",
      "|    std                | 7.2      |\n",
      "|    value_loss         | 5.66e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -0.247   |\n",
      "|    std                | 7.38     |\n",
      "|    value_loss         | 0.000264 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.97e+03 |\n",
      "|    total_cost         | 2.1e+04  |\n",
      "|    total_reward       | -4.6e+04 |\n",
      "|    total_reward_pct   | -92.1    |\n",
      "|    total_trades       | 25960    |\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.4    |\n",
      "|    explained_variance | 1.13e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.956    |\n",
      "|    std                | 7.59     |\n",
      "|    value_loss         | 0.000229 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 203       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66       |\n",
      "|    explained_variance | -2.72e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 0.499     |\n",
      "|    std                | 7.8       |\n",
      "|    value_loss         | 8.29e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.75    |\n",
      "|    std                | 8.02     |\n",
      "|    value_loss         | 0.000934 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.9    |\n",
      "|    explained_variance | -0.339   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 0.271    |\n",
      "|    std                | 8.18     |\n",
      "|    value_loss         | 0.000886 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.1    |\n",
      "|    explained_variance | 0.758    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 8.26     |\n",
      "|    value_loss         | 0.000643 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.18e+04  |\n",
      "|    total_cost         | 4.38e+04  |\n",
      "|    total_reward       | -1.82e+04 |\n",
      "|    total_reward_pct   | -36.5     |\n",
      "|    total_trades       | 26643     |\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.3     |\n",
      "|    explained_variance | -5.6      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -1.45     |\n",
      "|    std                | 8.39      |\n",
      "|    value_loss         | 0.00106   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -1.06    |\n",
      "|    std                | 8.56     |\n",
      "|    value_loss         | 0.000401 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.766   |\n",
      "|    std                | 8.76     |\n",
      "|    value_loss         | 0.000226 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.0927  |\n",
      "|    std                | 8.99     |\n",
      "|    value_loss         | 0.000255 |\n",
      "------------------------------------\n",
      "day: 2208, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -3893.77\n",
      "total_reward: -53893.77\n",
      "total_cost: 18060.38\n",
      "total_trades: 25424\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -3.89e+03 |\n",
      "|    total_cost         | 1.81e+04  |\n",
      "|    total_reward       | -5.39e+04 |\n",
      "|    total_reward_pct   | -108      |\n",
      "|    total_trades       | 25424     |\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 216       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69       |\n",
      "|    explained_variance | 0.334     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | -1.04     |\n",
      "|    std                | 9.18      |\n",
      "|    value_loss         | 0.000432  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 0.332    |\n",
      "|    std                | 9.37     |\n",
      "|    value_loss         | 0.000382 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 1.1       |\n",
      "|    std                | 9.56      |\n",
      "|    value_loss         | 0.000477  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.2    |\n",
      "|    explained_variance | -0.0216  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 2.13     |\n",
      "|    std                | 9.77     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.93e+03  |\n",
      "|    total_cost         | 1.95e+04  |\n",
      "|    total_reward       | -4.71e+04 |\n",
      "|    total_reward_pct   | -94.1     |\n",
      "|    total_trades       | 26096     |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 223       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | -6.23     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 1.66      |\n",
      "|    std                | 10        |\n",
      "|    value_loss         | 0.000586  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.3    |\n",
      "|    explained_variance | -0.0061  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 10.3     |\n",
      "|    value_loss         | 0.000958 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 0.603    |\n",
      "|    std                | 10.6     |\n",
      "|    value_loss         | 9.07e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 0.239    |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 0.000121 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.669   |\n",
      "|    std                | 11.2     |\n",
      "|    value_loss         | 0.000347 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.46e+03  |\n",
      "|    total_cost         | 2.57e+04  |\n",
      "|    total_reward       | -4.15e+04 |\n",
      "|    total_reward_pct   | -83.1     |\n",
      "|    total_trades       | 26058     |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 231       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 0.535     |\n",
      "|    std                | 11.5      |\n",
      "|    value_loss         | 0.00034   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.8    |\n",
      "|    explained_variance | -0.297   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0.249   |\n",
      "|    std                | 11.8     |\n",
      "|    value_loss         | 0.000144 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 235       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -1.81     |\n",
      "|    std                | 12.1      |\n",
      "|    value_loss         | 0.000781  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.0536   |\n",
      "|    std                | 12.4     |\n",
      "|    value_loss         | 0.000107 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.84e+03  |\n",
      "|    total_cost         | 1.64e+04  |\n",
      "|    total_reward       | -4.82e+04 |\n",
      "|    total_reward_pct   | -96.3     |\n",
      "|    total_trades       | 25636     |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | -0.00791  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 2.36      |\n",
      "|    std                | 12.8      |\n",
      "|    value_loss         | 0.00131   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.8    |\n",
      "|    explained_variance | -2.91    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 1.5      |\n",
      "|    std                | 13.1     |\n",
      "|    value_loss         | 0.000462 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.3    |\n",
      "|    explained_variance | -0.155   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 0.556    |\n",
      "|    std                | 13.4     |\n",
      "|    value_loss         | 8.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.288   |\n",
      "|    std                | 13.9     |\n",
      "|    value_loss         | 3.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.5    |\n",
      "|    explained_variance | -0.583   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 0.0857   |\n",
      "|    std                | 14.4     |\n",
      "|    value_loss         | 1.37e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.22e+03  |\n",
      "|    total_cost         | 1.74e+04  |\n",
      "|    total_reward       | -4.58e+04 |\n",
      "|    total_reward_pct   | -91.6     |\n",
      "|    total_trades       | 25845     |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 246       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78.1     |\n",
      "|    explained_variance | -0.00624  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -3.51     |\n",
      "|    std                | 14.8      |\n",
      "|    value_loss         | 0.00315   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.341   |\n",
      "|    std                | 15.2     |\n",
      "|    value_loss         | 9.54e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.2    |\n",
      "|    explained_variance | 0.00312  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -6.02    |\n",
      "|    std                | 15.6     |\n",
      "|    value_loss         | 0.00778  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.248    |\n",
      "|    std                | 16.1     |\n",
      "|    value_loss         | 4.6e-05  |\n",
      "------------------------------------\n",
      "day: 2208, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3036.81\n",
      "total_reward: -46963.19\n",
      "total_cost: 20456.57\n",
      "total_trades: 26007\n",
      "Sharpe: -0.412\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.04e+03 |\n",
      "|    total_cost         | 2.05e+04 |\n",
      "|    total_reward       | -4.7e+04 |\n",
      "|    total_reward_pct   | -93.9    |\n",
      "|    total_trades       | 26007    |\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 2.48     |\n",
      "|    std                | 16.6     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 0.665    |\n",
      "|    std                | 16.9     |\n",
      "|    value_loss         | 9.19e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.1    |\n",
      "|    explained_variance | 0.0733   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 17.3     |\n",
      "|    value_loss         | 0.000617 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.0405   |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 2.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82      |\n",
      "|    explained_variance | -0.329   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.104   |\n",
      "|    std                | 18.2     |\n",
      "|    value_loss         | 6.96e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.06e+03  |\n",
      "|    total_cost         | 2.94e+04  |\n",
      "|    total_reward       | -4.79e+04 |\n",
      "|    total_reward_pct   | -95.9     |\n",
      "|    total_trades       | 26729     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 261       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.4     |\n",
      "|    explained_variance | -1.86     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | -0.78     |\n",
      "|    std                | 18.5      |\n",
      "|    value_loss         | 0.000269  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.899   |\n",
      "|    std                | 18.9     |\n",
      "|    value_loss         | 0.000142 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.2    |\n",
      "|    explained_variance | -0.115   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 0.614    |\n",
      "|    std                | 19.3     |\n",
      "|    value_loss         | 0.000195 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.8    |\n",
      "|    explained_variance | -0.427   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 0.643    |\n",
      "|    std                | 20       |\n",
      "|    value_loss         | 7.12e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.14e+03  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | -4.89e+04 |\n",
      "|    total_reward_pct   | -97.7     |\n",
      "|    total_trades       | 25851     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 268       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.4     |\n",
      "|    explained_variance | 0.0946    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -0.388    |\n",
      "|    std                | 20.6      |\n",
      "|    value_loss         | 4.97e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 0.107     |\n",
      "|    std                | 21.2      |\n",
      "|    value_loss         | 1.66e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 21.8     |\n",
      "|    value_loss         | 0.00016  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.427   |\n",
      "|    std                | 22.5     |\n",
      "|    value_loss         | 4.42e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -6.12e+03 |\n",
      "|    total_cost         | 2.13e+04  |\n",
      "|    total_reward       | -5.61e+04 |\n",
      "|    total_reward_pct   | -112      |\n",
      "|    total_trades       | 26023     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 274       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86.6     |\n",
      "|    explained_variance | -0.105    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -2.01     |\n",
      "|    std                | 23.2      |\n",
      "|    value_loss         | 0.000597  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -0.233   |\n",
      "|    std                | 23.9     |\n",
      "|    value_loss         | 1.51e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.9    |\n",
      "|    explained_variance | -19.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.493   |\n",
      "|    std                | 24.7     |\n",
      "|    value_loss         | 0.000141 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.0811  |\n",
      "|    std                | 25.4     |\n",
      "|    value_loss         | 8.56e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.8    |\n",
      "|    explained_variance | -2.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.475   |\n",
      "|    std                | 26       |\n",
      "|    value_loss         | 6.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.04e+03 |\n",
      "|    total_cost         | 2.4e+04  |\n",
      "|    total_reward       | -4.5e+04 |\n",
      "|    total_reward_pct   | -89.9    |\n",
      "|    total_trades       | 26153    |\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.3    |\n",
      "|    explained_variance | -0.0649  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 26.7     |\n",
      "|    value_loss         | 0.000223 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 284       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -89.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -2.11     |\n",
      "|    std                | 27.3      |\n",
      "|    value_loss         | 0.000833  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 0.408    |\n",
      "|    std                | 28       |\n",
      "|    value_loss         | 5.25e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.782    |\n",
      "|    std                | 28.7     |\n",
      "|    value_loss         | 0.000121 |\n",
      "------------------------------------\n",
      "day: 2208, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -9077.25\n",
      "total_reward: -59077.25\n",
      "total_cost: 19452.98\n",
      "total_trades: 26229\n",
      "Sharpe: -0.233\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -9.08e+03 |\n",
      "|    total_cost         | 1.95e+04  |\n",
      "|    total_reward       | -5.91e+04 |\n",
      "|    total_reward_pct   | -118      |\n",
      "|    total_trades       | 26229     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 289       |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | -0.301    |\n",
      "|    std                | 29.5      |\n",
      "|    value_loss         | 0.000159  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.8    |\n",
      "|    explained_variance | 0.404    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -0.685   |\n",
      "|    std                | 30.4     |\n",
      "|    value_loss         | 0.000188 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.3    |\n",
      "|    explained_variance | -15.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -2.16    |\n",
      "|    std                | 31.2     |\n",
      "|    value_loss         | 0.000805 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.584    |\n",
      "|    std                | 32.2     |\n",
      "|    value_loss         | 4.02e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.4    |\n",
      "|    explained_variance | 0.0793   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 0.986    |\n",
      "|    std                | 33.1     |\n",
      "|    value_loss         | 0.000194 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4e+03    |\n",
      "|    total_cost         | 2.41e+04 |\n",
      "|    total_reward       | -4.6e+04 |\n",
      "|    total_reward_pct   | -92      |\n",
      "|    total_trades       | 26416    |\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.8    |\n",
      "|    explained_variance | -1.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -8.2     |\n",
      "|    std                | 33.7     |\n",
      "|    value_loss         | 0.00788  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.1    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    std                | 34.3     |\n",
      "|    value_loss         | 0.000451 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.5    |\n",
      "|    explained_variance | 0.0309   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 3.13     |\n",
      "|    std                | 35.1     |\n",
      "|    value_loss         | 0.0021   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.9    |\n",
      "|    explained_variance | 0.385    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 6.48     |\n",
      "|    std                | 35.9     |\n",
      "|    value_loss         | 0.0048   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.45e+03  |\n",
      "|    total_cost         | 3.16e+04  |\n",
      "|    total_reward       | -4.86e+04 |\n",
      "|    total_reward_pct   | -97.1     |\n",
      "|    total_trades       | 27206     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 304       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -95.4     |\n",
      "|    explained_variance | 0.112     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -1.1      |\n",
      "|    std                | 36.7      |\n",
      "|    value_loss         | 0.000437  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 305       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -95.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 0.435     |\n",
      "|    std                | 37.3      |\n",
      "|    value_loss         | 6.57e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.1    |\n",
      "|    explained_variance | -0.0439  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -3.74    |\n",
      "|    std                | 38.1     |\n",
      "|    value_loss         | 0.00344  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.59     |\n",
      "|    std                | 38.8     |\n",
      "|    value_loss         | 0.000297 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.92e+03  |\n",
      "|    total_cost         | 4.16e+04  |\n",
      "|    total_reward       | -4.11e+04 |\n",
      "|    total_reward_pct   | -82.2     |\n",
      "|    total_trades       | 27265     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -96.8     |\n",
      "|    explained_variance | -6.46e+03 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 34.2      |\n",
      "|    std                | 39.6      |\n",
      "|    value_loss         | 0.651     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.2    |\n",
      "|    explained_variance | -3.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 0.974    |\n",
      "|    std                | 40.3     |\n",
      "|    value_loss         | 0.000133 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 2.64     |\n",
      "|    std                | 41.3     |\n",
      "|    value_loss         | 0.00145  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 2.18     |\n",
      "|    std                | 42.2     |\n",
      "|    value_loss         | 0.000645 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.5    |\n",
      "|    explained_variance | -6.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -2.1     |\n",
      "|    std                | 43.2     |\n",
      "|    value_loss         | 0.00124  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -731      |\n",
      "|    total_cost         | 3.05e+04  |\n",
      "|    total_reward       | -5.07e+04 |\n",
      "|    total_reward_pct   | -101      |\n",
      "|    total_trades       | 26978     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 319       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99       |\n",
      "|    explained_variance | 0.00395   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -3.28     |\n",
      "|    std                | 44.4      |\n",
      "|    value_loss         | 0.00109   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.5    |\n",
      "|    explained_variance | -0.846   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    std                | 45.6     |\n",
      "|    value_loss         | 0.000383 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 0.0827   |\n",
      "|    std                | 46.9     |\n",
      "|    value_loss         | 0.000104 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 48.2     |\n",
      "|    value_loss         | 0.000293 |\n",
      "------------------------------------\n",
      "day: 2208, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4313.45\n",
      "total_reward: -45686.55\n",
      "total_cost: 24756.69\n",
      "total_trades: 26273\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.31e+03  |\n",
      "|    total_cost         | 2.48e+04  |\n",
      "|    total_reward       | -4.57e+04 |\n",
      "|    total_reward_pct   | -91.4     |\n",
      "|    total_trades       | 26273     |\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 0.852     |\n",
      "|    std                | 49.7      |\n",
      "|    value_loss         | 7.82e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | -6.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.5     |\n",
      "|    std                | 51.2     |\n",
      "|    value_loss         | 7.3e-05  |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-01-03 to  2019-04-04\n",
      "A2C Sharpe Ratio:  0.2388591775007724\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 359  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 5    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.35e+04    |\n",
      "|    total_cost           | 5.03e+04    |\n",
      "|    total_reward         | -3.65e+04   |\n",
      "|    total_reward_pct     | -73         |\n",
      "|    total_trades         | 27813       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014958667 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -2.07       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0592      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.16e+03    |\n",
      "|    total_cost           | 2.56e+04    |\n",
      "|    total_reward         | -4.28e+04   |\n",
      "|    total_reward_pct     | -85.7       |\n",
      "|    total_trades         | 26155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011612614 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.686      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0272      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.09e+04    |\n",
      "|    total_cost           | 7.63e+04    |\n",
      "|    total_reward         | -1.91e+04   |\n",
      "|    total_reward_pct     | -38.1       |\n",
      "|    total_trades         | 28763       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009871921 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.466      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0389      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 9356.64\n",
      "total_reward: -40643.36\n",
      "total_cost: 24593.99\n",
      "total_trades: 26308\n",
      "Sharpe: -0.328\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.36e+03     |\n",
      "|    total_cost           | 2.46e+04     |\n",
      "|    total_reward         | -4.06e+04    |\n",
      "|    total_reward_pct     | -81.3        |\n",
      "|    total_trades         | 26308        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064345943 |\n",
      "|    clip_fraction        | 0.0703       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | -0.573       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.296       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0221       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.97e+04     |\n",
      "|    total_cost           | 5.05e+04     |\n",
      "|    total_reward         | -3.03e+04    |\n",
      "|    total_reward_pct     | -60.6        |\n",
      "|    total_trades         | 27856        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059956936 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | -0.341       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.292       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0217      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0171       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.57e+03    |\n",
      "|    total_cost           | 1.78e+04    |\n",
      "|    total_reward         | -4.34e+04   |\n",
      "|    total_reward_pct     | -86.9       |\n",
      "|    total_trades         | 25423       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009605659 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.0806     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.01e+04    |\n",
      "|    total_cost           | 3.45e+04    |\n",
      "|    total_reward         | -2.99e+04   |\n",
      "|    total_reward_pct     | -59.7       |\n",
      "|    total_trades         | 26789       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014026828 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0142      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.7e+03     |\n",
      "|    total_cost           | 1.65e+04    |\n",
      "|    total_reward         | -4.23e+04   |\n",
      "|    total_reward_pct     | -84.6       |\n",
      "|    total_trades         | 25312       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012065936 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.00388    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17693.04\n",
      "total_reward: -32306.96\n",
      "total_cost: 30497.76\n",
      "total_trades: 26534\n",
      "Sharpe: 0.048\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+04    |\n",
      "|    total_cost           | 3.05e+04    |\n",
      "|    total_reward         | -3.23e+04   |\n",
      "|    total_reward_pct     | -64.6       |\n",
      "|    total_trades         | 26534       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013889995 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00872     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.74e+04    |\n",
      "|    total_cost           | 2.43e+04    |\n",
      "|    total_reward         | -3.26e+04   |\n",
      "|    total_reward_pct     | -65.2       |\n",
      "|    total_trades         | 26347       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011466622 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0976      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.74e+03    |\n",
      "|    total_cost           | 1.94e+04    |\n",
      "|    total_reward         | -4.23e+04   |\n",
      "|    total_reward_pct     | -84.5       |\n",
      "|    total_trades         | 25695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021658849 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 6.85e+03     |\n",
      "|    total_cost           | 1.5e+04      |\n",
      "|    total_reward         | -4.32e+04    |\n",
      "|    total_reward_pct     | -86.3        |\n",
      "|    total_trades         | 25364        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046600876 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.284       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00753      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017926574 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00717     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.02e+03    |\n",
      "|    total_cost           | 1.39e+04    |\n",
      "|    total_reward         | -4.2e+04    |\n",
      "|    total_reward_pct     | -84         |\n",
      "|    total_trades         | 24989       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017236073 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0408      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00254     |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 55919.41\n",
      "total_reward: 5919.41\n",
      "total_cost: 44199.57\n",
      "total_trades: 27944\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.59e+04    |\n",
      "|    total_cost           | 4.42e+04    |\n",
      "|    total_reward         | 5.92e+03    |\n",
      "|    total_reward_pct     | 11.8        |\n",
      "|    total_trades         | 27944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017241124 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.207      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0237      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.48e+04    |\n",
      "|    total_cost           | 4.68e+04    |\n",
      "|    total_reward         | 1.48e+04    |\n",
      "|    total_reward_pct     | 29.5        |\n",
      "|    total_trades         | 28081       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016545786 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.37e+03    |\n",
      "|    total_cost           | 1.35e+04    |\n",
      "|    total_reward         | -4.36e+04   |\n",
      "|    total_reward_pct     | -87.3       |\n",
      "|    total_trades         | 24953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012089642 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.13e+04    |\n",
      "|    total_cost           | 4.52e+04    |\n",
      "|    total_reward         | 3.13e+04    |\n",
      "|    total_reward_pct     | 62.6        |\n",
      "|    total_trades         | 27790       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008904626 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 4.9e+04     |\n",
      "|    total_reward         | 6.33e+04    |\n",
      "|    total_reward_pct     | 127         |\n",
      "|    total_trades         | 28137       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196412 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0325      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 10014.13\n",
      "total_reward: -39985.87\n",
      "total_cost: 18555.25\n",
      "total_trades: 25603\n",
      "Sharpe: -0.268\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+04       |\n",
      "|    total_cost           | 1.86e+04    |\n",
      "|    total_reward         | -4e+04      |\n",
      "|    total_reward_pct     | -80         |\n",
      "|    total_trades         | 25603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017070867 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0391      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.61e+04    |\n",
      "|    total_cost           | 2.57e+04    |\n",
      "|    total_reward         | -1.39e+04   |\n",
      "|    total_reward_pct     | -27.9       |\n",
      "|    total_trades         | 26053       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006750373 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0134      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.9e+04     |\n",
      "|    total_cost           | 4.95e+04    |\n",
      "|    total_reward         | 3.9e+04     |\n",
      "|    total_reward_pct     | 77.9        |\n",
      "|    total_trades         | 27992       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018934809 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0213      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+05    |\n",
      "|    total_cost           | 4.29e+04    |\n",
      "|    total_reward         | 6.15e+04    |\n",
      "|    total_reward_pct     | 123         |\n",
      "|    total_trades         | 27355       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014869374 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0384      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.13e+04    |\n",
      "|    total_cost           | 2.79e+04    |\n",
      "|    total_reward         | -1.87e+04   |\n",
      "|    total_reward_pct     | -37.4       |\n",
      "|    total_trades         | 26410       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014860184 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0704      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 40664.02\n",
      "total_reward: -9335.98\n",
      "total_cost: 25328.13\n",
      "total_trades: 26067\n",
      "Sharpe: 0.247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.07e+04    |\n",
      "|    total_cost           | 2.53e+04    |\n",
      "|    total_reward         | -9.34e+03   |\n",
      "|    total_reward_pct     | -18.7       |\n",
      "|    total_trades         | 26067       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012028805 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.43e+04   |\n",
      "|    total_cost           | 2.7e+04    |\n",
      "|    total_reward         | -2.57e+04  |\n",
      "|    total_reward_pct     | -51.4      |\n",
      "|    total_trades         | 26487      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 358        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01240229 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.291     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0136     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011839158 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.01e+04    |\n",
      "|    total_cost           | 1.83e+04    |\n",
      "|    total_reward         | -2.99e+04   |\n",
      "|    total_reward_pct     | -59.9       |\n",
      "|    total_trades         | 25484       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012995611 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00503     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 5.48e+03     |\n",
      "|    total_cost           | 1.21e+04     |\n",
      "|    total_reward         | -4.45e+04    |\n",
      "|    total_reward_pct     | -89          |\n",
      "|    total_trades         | 24496        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124764275 |\n",
      "|    clip_fraction        | 0.0931       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.6        |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.307       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00722      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.51e+04   |\n",
      "|    total_cost           | 1.84e+04   |\n",
      "|    total_reward         | -3.49e+04  |\n",
      "|    total_reward_pct     | -69.9      |\n",
      "|    total_trades         | 25327      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 358        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 176        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01409794 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.006      |\n",
      "----------------------------------------\n",
      "day: 2208, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 40217.13\n",
      "total_reward: -9782.87\n",
      "total_cost: 23378.48\n",
      "total_trades: 25606\n",
      "Sharpe: 0.375\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.02e+04    |\n",
      "|    total_cost           | 2.34e+04    |\n",
      "|    total_reward         | -9.78e+03   |\n",
      "|    total_reward_pct     | -19.6       |\n",
      "|    total_trades         | 25606       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019100785 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.64e+04    |\n",
      "|    total_cost           | 3.34e+04    |\n",
      "|    total_reward         | 1.64e+04    |\n",
      "|    total_reward_pct     | 32.8        |\n",
      "|    total_trades         | 26620       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014740066 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0203      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.24e+04    |\n",
      "|    total_cost           | 3.89e+04    |\n",
      "|    total_reward         | 3.24e+04    |\n",
      "|    total_reward_pct     | 64.7        |\n",
      "|    total_trades         | 26796       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017928358 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0393      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.13e+04     |\n",
      "|    total_cost           | 1.76e+04     |\n",
      "|    total_reward         | -8.69e+03    |\n",
      "|    total_reward_pct     | -17.4        |\n",
      "|    total_trades         | 24939        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153370015 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.7        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.279       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0376       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.73e+04    |\n",
      "|    total_cost           | 2.71e+04    |\n",
      "|    total_reward         | 1.73e+04    |\n",
      "|    total_reward_pct     | 34.6        |\n",
      "|    total_trades         | 26256       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018708546 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.017       |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 76948.08\n",
      "total_reward: 26948.08\n",
      "total_cost: 29999.04\n",
      "total_trades: 26524\n",
      "Sharpe: 0.329\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.69e+04   |\n",
      "|    total_cost           | 3e+04      |\n",
      "|    total_reward         | 2.69e+04   |\n",
      "|    total_reward_pct     | 53.9       |\n",
      "|    total_trades         | 26524      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 359        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01202092 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.729      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0227     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.11e+04    |\n",
      "|    total_cost           | 3.35e+04    |\n",
      "|    total_reward         | 2.11e+04    |\n",
      "|    total_reward_pct     | 42.2        |\n",
      "|    total_trades         | 26876       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019494828 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0348      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.63e+04    |\n",
      "|    total_cost           | 1.99e+04    |\n",
      "|    total_reward         | -1.37e+04   |\n",
      "|    total_reward_pct     | -27.4       |\n",
      "|    total_trades         | 25656       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012167238 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.25e+04    |\n",
      "|    total_cost           | 3.66e+04    |\n",
      "|    total_reward         | 2.25e+04    |\n",
      "|    total_reward_pct     | 45          |\n",
      "|    total_trades         | 27122       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012744516 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.58e+04    |\n",
      "|    total_cost           | 2.63e+04    |\n",
      "|    total_reward         | -1.42e+04   |\n",
      "|    total_reward_pct     | -28.4       |\n",
      "|    total_trades         | 26412       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010389548 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017332826 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 46389.16\n",
      "total_reward: -3610.84\n",
      "total_cost: 22475.95\n",
      "total_trades: 26090\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.64e+04   |\n",
      "|    total_cost           | 2.25e+04   |\n",
      "|    total_reward         | -3.61e+03  |\n",
      "|    total_reward_pct     | -7.22      |\n",
      "|    total_trades         | 26090      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 359        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 244        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01480457 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.773      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.303     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0168     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.55e+04    |\n",
      "|    total_cost           | 1.46e+04    |\n",
      "|    total_reward         | -3.45e+04   |\n",
      "|    total_reward_pct     | -69         |\n",
      "|    total_trades         | 24916       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013071933 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.48e+04    |\n",
      "|    total_cost           | 2.16e+04    |\n",
      "|    total_reward         | -5.18e+03   |\n",
      "|    total_reward_pct     | -10.4       |\n",
      "|    total_trades         | 25870       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013566698 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0192      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+04     |\n",
      "|    total_cost           | 1.52e+04    |\n",
      "|    total_reward         | -2.5e+04    |\n",
      "|    total_reward_pct     | -50         |\n",
      "|    total_trades         | 24778       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015596801 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.08e+05    |\n",
      "|    total_cost           | 3.07e+04    |\n",
      "|    total_reward         | 5.76e+04    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 26595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020418933 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 97068.84\n",
      "total_reward: 47068.84\n",
      "total_cost: 30153.57\n",
      "total_trades: 26773\n",
      "Sharpe: 0.411\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.71e+04    |\n",
      "|    total_cost           | 3.02e+04    |\n",
      "|    total_reward         | 4.71e+04    |\n",
      "|    total_reward_pct     | 94.1        |\n",
      "|    total_trades         | 26773       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016566638 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0584      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+05    |\n",
      "|    total_cost           | 3.77e+04    |\n",
      "|    total_reward         | 6.68e+04    |\n",
      "|    total_reward_pct     | 134         |\n",
      "|    total_trades         | 27280       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014008334 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0437      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-01-03 to  2019-04-04\n",
      "PPO Sharpe Ratio:  -0.05092518928466791\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
      "day: 2208, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 33884.87\n",
      "total_reward: -16115.13\n",
      "total_cost: 181.51\n",
      "total_trades: 21907\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.98e+04 |\n",
      "|    total_cost       | 486      |\n",
      "|    total_reward     | 3.98e+04 |\n",
      "|    total_reward_pct | 79.7     |\n",
      "|    total_trades     | 21663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 89       |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total timesteps  | 8836     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.42    |\n",
      "|    critic_loss      | 11       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6627     |\n",
      "----------------------------------\n",
      "day: 2208, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 72419.63\n",
      "total_reward: 22419.63\n",
      "total_cost: 214.32\n",
      "total_trades: 21182\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.24e+04 |\n",
      "|    total_cost       | 214      |\n",
      "|    total_reward     | 2.24e+04 |\n",
      "|    total_reward_pct | 44.8     |\n",
      "|    total_trades     | 21182    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total timesteps  | 17672    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.56    |\n",
      "|    critic_loss      | 3.48     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15463    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.99e+04 |\n",
      "|    total_cost       | 214      |\n",
      "|    total_reward     | 1.99e+04 |\n",
      "|    total_reward_pct | 39.8     |\n",
      "|    total_trades     | 19929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 75       |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total timesteps  | 26508    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.85    |\n",
      "|    critic_loss      | 0.997    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24299    |\n",
      "----------------------------------\n",
      "day: 2208, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49091.13\n",
      "total_reward: -908.87\n",
      "total_cost: 137.19\n",
      "total_trades: 21028\n",
      "Sharpe: 0.384\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.38e+04  |\n",
      "|    total_cost       | 152       |\n",
      "|    total_reward     | -6.23e+03 |\n",
      "|    total_reward_pct | -12.5     |\n",
      "|    total_trades     | 21211     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 73        |\n",
      "|    time_elapsed     | 479       |\n",
      "|    total timesteps  | 35344     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.89     |\n",
      "|    critic_loss      | 0.467     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 33135     |\n",
      "-----------------------------------\n",
      "day: 2208, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 51095.26\n",
      "total_reward: 1095.26\n",
      "total_cost: 140.97\n",
      "total_trades: 21277\n",
      "Sharpe: 0.412\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.3e+04  |\n",
      "|    total_cost       | 135      |\n",
      "|    total_reward     | 3.03e+03 |\n",
      "|    total_reward_pct | 6.06     |\n",
      "|    total_trades     | 21477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 607      |\n",
      "|    total timesteps  | 44180    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.79    |\n",
      "|    critic_loss      | 0.289    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41971    |\n",
      "----------------------------------\n",
      "day: 2208, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 55552.83\n",
      "total_reward: 5552.83\n",
      "total_cost: 148.25\n",
      "total_trades: 21429\n",
      "Sharpe: 0.453\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03 to  2019-04-04\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-04-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_126_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.85e+04 |\n",
      "|    total_cost       | 231      |\n",
      "|    total_reward     | 2.85e+04 |\n",
      "|    total_reward_pct | 57       |\n",
      "|    total_trades     | 23633    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 86       |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total timesteps  | 9088     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -36.9    |\n",
      "|    critic_loss      | 1.82     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6816     |\n",
      "----------------------------------\n",
      "day: 2271, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70553.19\n",
      "total_reward: 20553.19\n",
      "total_cost: 189.26\n",
      "total_trades: 23085\n",
      "Sharpe: 0.493\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.2e+04   |\n",
      "|    total_cost       | 102       |\n",
      "|    total_reward     | -8.03e+03 |\n",
      "|    total_reward_pct | -16.1     |\n",
      "|    total_trades     | 22909     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 76        |\n",
      "|    time_elapsed     | 236       |\n",
      "|    total timesteps  | 18176     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -23.2     |\n",
      "|    critic_loss      | 0.556     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 15904     |\n",
      "-----------------------------------\n",
      "day: 2271, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50066.80\n",
      "total_reward: 66.80\n",
      "total_cost: 95.14\n",
      "total_trades: 22862\n",
      "Sharpe: 0.368\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.85e+04 |\n",
      "|    total_cost       | 171      |\n",
      "|    total_reward     | 8.47e+03 |\n",
      "|    total_reward_pct | 16.9     |\n",
      "|    total_trades     | 22770    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 74       |\n",
      "|    time_elapsed     | 367      |\n",
      "|    total timesteps  | 27264    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -15      |\n",
      "|    critic_loss      | 0.256    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24992    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47121.27\n",
      "total_reward: -2878.73\n",
      "total_cost: 138.06\n",
      "total_trades: 22785\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.59e+04 |\n",
      "|    total_cost       | 170      |\n",
      "|    total_reward     | 5.94e+03 |\n",
      "|    total_reward_pct | 11.9     |\n",
      "|    total_trades     | 22771    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 73       |\n",
      "|    time_elapsed     | 497      |\n",
      "|    total timesteps  | 36352    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -10.1    |\n",
      "|    critic_loss      | 0.166    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34080    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 87333.01\n",
      "total_reward: 37333.01\n",
      "total_cost: 160.27\n",
      "total_trades: 22776\n",
      "Sharpe: 0.437\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.73e+04 |\n",
      "|    total_cost       | 160      |\n",
      "|    total_reward     | 3.73e+04 |\n",
      "|    total_reward_pct | 74.7     |\n",
      "|    total_trades     | 22776    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 629      |\n",
      "|    total timesteps  | 45440    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.96    |\n",
      "|    critic_loss      | 0.116    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43168    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-04-04 to  2019-07-05\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2000-01-01 to  2019-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 280      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.404   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.732    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0279   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.601   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.422   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00621  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.646   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.77     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00515  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -1.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -8.29    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.47e+05 |\n",
      "|    total_cost         | 3.68e+04 |\n",
      "|    total_reward       | 9.74e+04 |\n",
      "|    total_reward_pct   | 195      |\n",
      "|    total_trades       | 27671    |\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.191    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -3.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0246   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -5.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 2.01     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0066   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -17.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -2.29    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0255   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 3.07     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0156   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -9.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.48e+04  |\n",
      "|    total_cost         | 9.53e+03  |\n",
      "|    total_reward       | -2.52e+04 |\n",
      "|    total_reward_pct   | -50.4     |\n",
      "|    total_trades       | 26434     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | -4.15     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -0.0913   |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.000957  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.063    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.89e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.351   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.000453 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0.919    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.623   |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.000406 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.64e+04  |\n",
      "|    total_cost         | 4.42e+03  |\n",
      "|    total_reward       | -3.36e+04 |\n",
      "|    total_reward_pct   | -67.2     |\n",
      "|    total_trades       | 25000     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | -72.6     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 0.132     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.00298   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.166   |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 4.79e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | -1.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.368    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.000214 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | -0.186   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.00132  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.921   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -3.61    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0144   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.4e+03   |\n",
      "|    total_cost         | 5.58e+03  |\n",
      "|    total_reward       | -4.16e+04 |\n",
      "|    total_reward_pct   | -83.2     |\n",
      "|    total_trades       | 23991     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.5     |\n",
      "|    explained_variance | -133      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 1.96      |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.0574    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | -15.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.226    |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.000448 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | -0.226   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -1.16    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.00144  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0.0874   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -2.74    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.00765  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21969.44\n",
      "total_reward: -28030.56\n",
      "total_cost: 1336.14\n",
      "total_trades: 24776\n",
      "Sharpe: 0.118\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.2e+04  |\n",
      "|    total_cost         | 1.34e+03 |\n",
      "|    total_reward       | -2.8e+04 |\n",
      "|    total_reward_pct   | -56.1    |\n",
      "|    total_trades       | 24776    |\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -0.365   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.719   |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.000834 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | -0.305   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.699   |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.00651  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | -110     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.8      |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0371   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0.0044   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 2.42     |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00719  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.5     |\n",
      "|    explained_variance | -0.000535 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 1.22      |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.00182   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.27e+04  |\n",
      "|    total_cost         | 3.32e+03  |\n",
      "|    total_reward       | -7.34e+03 |\n",
      "|    total_reward_pct   | -14.7     |\n",
      "|    total_trades       | 25791     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.8     |\n",
      "|    explained_variance | 0.256     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -1.82     |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 0.00364   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.354   |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.000399 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | 0.377    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -4.19    |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.0147   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | -2.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.673    |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.00127  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.5e+04  |\n",
      "|    total_cost         | 1.65e+03 |\n",
      "|    total_reward       | -2.5e+04 |\n",
      "|    total_reward_pct   | -50.1    |\n",
      "|    total_trades       | 26514    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 0.239    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00394  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | 0.0134   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 2.07     |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.00602  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | 0.497    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.00353  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -0.321   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | -5.72    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 2.06     |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.0138   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.61e+04  |\n",
      "|    total_cost         | 2.81e+03  |\n",
      "|    total_reward       | -1.39e+04 |\n",
      "|    total_reward_pct   | -27.8     |\n",
      "|    total_trades       | 26093     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.2     |\n",
      "|    explained_variance | -674      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 2.94      |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 0.00809   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.141    |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 4.11e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 2.45     |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.00455  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | -0.168   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -4.11    |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.0216   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.01e+04  |\n",
      "|    total_cost         | 1.9e+03   |\n",
      "|    total_reward       | -9.91e+03 |\n",
      "|    total_reward_pct   | -19.8     |\n",
      "|    total_trades       | 25430     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.5     |\n",
      "|    explained_variance | 0.106     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 1.82      |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 0.00255   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | 0.746    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -1.77    |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.00226  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | -0.658   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.0294   |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.000495 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.776   |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.00116  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | 0.482    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -1.54    |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24865.08\n",
      "total_reward: -25134.92\n",
      "total_cost: 1871.42\n",
      "total_trades: 25190\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.49e+04  |\n",
      "|    total_cost         | 1.87e+03  |\n",
      "|    total_reward       | -2.51e+04 |\n",
      "|    total_reward_pct   | -50.3     |\n",
      "|    total_trades       | 25190     |\n",
      "| time/                 |           |\n",
      "|    fps                | 294       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.2     |\n",
      "|    explained_variance | 0.521     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -2.04     |\n",
      "|    std                | 1.91      |\n",
      "|    value_loss         | 0.00313   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 294      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -2.08    |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.00356  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 294      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | -0.83    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 2.59     |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.00701  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 294      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -0.0517  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -2.51    |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 0.0246   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.04e+04 |\n",
      "|    total_cost         | 1.87e+03 |\n",
      "|    total_reward       | 2.04e+04 |\n",
      "|    total_reward_pct   | 40.8     |\n",
      "|    total_trades       | 24603    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0.0636   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -34.2    |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | -60      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -3.19    |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.0183   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -1.36    |\n",
      "|    std                | 2.1      |\n",
      "|    value_loss         | 0.00115  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -3.32    |\n",
      "|    std                | 2.14     |\n",
      "|    value_loss         | 0.00742  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | -0.402   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 6.44     |\n",
      "|    std                | 2.16     |\n",
      "|    value_loss         | 0.0311   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.28e+04 |\n",
      "|    total_cost         | 1.34e+03 |\n",
      "|    total_reward       | 1.28e+04 |\n",
      "|    total_reward_pct   | 25.6     |\n",
      "|    total_trades       | 24583    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -5.63    |\n",
      "|    std                | 2.18     |\n",
      "|    value_loss         | 0.0166   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -3.46    |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.00766  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | -0.0407  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 5.47     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.0297   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | 0.0129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -1.44    |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 0.00391  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.694   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.00127  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.01e+04 |\n",
      "|    total_cost         | 4.88e+03 |\n",
      "|    total_reward       | 2.01e+04 |\n",
      "|    total_reward_pct   | 40.1     |\n",
      "|    total_trades       | 25742    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.178   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.915    |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 0.000698 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.474   |\n",
      "|    std                | 2.34     |\n",
      "|    value_loss         | 0.000414 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    std                | 2.39     |\n",
      "|    value_loss         | 0.00132  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.0886  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.706   |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.000487 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.98e+04  |\n",
      "|    total_cost         | 4.57e+03  |\n",
      "|    total_reward       | -2.02e+04 |\n",
      "|    total_reward_pct   | -40.5     |\n",
      "|    total_trades       | 25926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 1.78e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 0.0515    |\n",
      "|    std                | 2.46      |\n",
      "|    value_loss         | 1.47e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.802    |\n",
      "|    std                | 2.52     |\n",
      "|    value_loss         | 0.000314 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0.22     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 0.472    |\n",
      "|    std                | 2.58     |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0.082    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 4.76     |\n",
      "|    std                | 2.62     |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 3.9      |\n",
      "|    std                | 2.65     |\n",
      "|    value_loss         | 0.00919  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 63497.84\n",
      "total_reward: 13497.84\n",
      "total_cost: 9161.70\n",
      "total_trades: 26580\n",
      "Sharpe: 0.399\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.35e+04 |\n",
      "|    total_cost         | 9.16e+03 |\n",
      "|    total_reward       | 1.35e+04 |\n",
      "|    total_reward_pct   | 27       |\n",
      "|    total_trades       | 26580    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | -0.782   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.152   |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.000823 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -1.59    |\n",
      "|    std                | 2.75     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 7.42      |\n",
      "|    std                | 2.8       |\n",
      "|    value_loss         | 0.0251    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0.204    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.149   |\n",
      "|    std                | 2.83     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.35e+04  |\n",
      "|    total_cost         | 1.24e+04  |\n",
      "|    total_reward       | -6.54e+03 |\n",
      "|    total_reward_pct   | -13.1     |\n",
      "|    total_trades       | 26549     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -0.565    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -2.49     |\n",
      "|    std                | 2.85      |\n",
      "|    value_loss         | 0.00307   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | -1.98    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.00222  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -0.164   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -2.08    |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 0.00235  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 3.48     |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 0.00788  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -2.47    |\n",
      "|    std                | 2.99     |\n",
      "|    value_loss         | 0.00948  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.81e+04 |\n",
      "|    total_cost         | 1.82e+04 |\n",
      "|    total_reward       | 8.07e+03 |\n",
      "|    total_reward_pct   | 16.1     |\n",
      "|    total_trades       | 26768    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0.0214   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 5.86     |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -2.5     |\n",
      "|    std                | 3.07     |\n",
      "|    value_loss         | 0.00323  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0.324    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -5.24    |\n",
      "|    std                | 3.12     |\n",
      "|    value_loss         | 0.0121   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.7    |\n",
      "|    explained_variance | -0.0075  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 3.14     |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.33e+04 |\n",
      "|    total_cost         | 1.39e+04 |\n",
      "|    total_reward       | 2.33e+04 |\n",
      "|    total_reward_pct   | 46.6     |\n",
      "|    total_trades       | 26240    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 0.4      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.336    |\n",
      "|    std                | 3.17     |\n",
      "|    value_loss         | 8.99e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.217    |\n",
      "|    std                | 3.22     |\n",
      "|    value_loss         | 3.76e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.712   |\n",
      "|    std                | 3.29     |\n",
      "|    value_loss         | 0.000509 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -3.63    |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.0062   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.969   |\n",
      "|    std                | 3.38     |\n",
      "|    value_loss         | 0.00243  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.58e+04  |\n",
      "|    total_cost         | 1.54e+04  |\n",
      "|    total_reward       | -4.21e+03 |\n",
      "|    total_reward_pct   | -8.43     |\n",
      "|    total_trades       | 26116     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 0.59      |\n",
      "|    std                | 3.43      |\n",
      "|    value_loss         | 0.000176  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | -3.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.0319  |\n",
      "|    std                | 3.5      |\n",
      "|    value_loss         | 0.000275 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | -5.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.928    |\n",
      "|    std                | 3.57     |\n",
      "|    value_loss         | 0.00134  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | 0.41     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -0.745   |\n",
      "|    std                | 3.64     |\n",
      "|    value_loss         | 0.00107  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17381.56\n",
      "total_reward: -32618.44\n",
      "total_cost: 19745.73\n",
      "total_trades: 26191\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.74e+04  |\n",
      "|    total_cost         | 1.97e+04  |\n",
      "|    total_reward       | -3.26e+04 |\n",
      "|    total_reward_pct   | -65.2     |\n",
      "|    total_trades       | 26191     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.8     |\n",
      "|    explained_variance | -0.672    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -2.8      |\n",
      "|    std                | 3.69      |\n",
      "|    value_loss         | 0.00663   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.1     |\n",
      "|    explained_variance | -4.29e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 0.507     |\n",
      "|    std                | 3.76      |\n",
      "|    value_loss         | 0.000191  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.911   |\n",
      "|    std                | 3.84     |\n",
      "|    value_loss         | 0.000577 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | -0.591   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 0.861    |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.00126  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.574   |\n",
      "|    std                | 3.95     |\n",
      "|    value_loss         | 0.00364  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.38e+04  |\n",
      "|    total_cost         | 2.14e+04  |\n",
      "|    total_reward       | -1.62e+04 |\n",
      "|    total_reward_pct   | -32.3     |\n",
      "|    total_trades       | 27030     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -2.29     |\n",
      "|    std                | 3.99      |\n",
      "|    value_loss         | 0.00191   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 0.365    |\n",
      "|    std                | 4.06     |\n",
      "|    value_loss         | 0.000172 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 2.1      |\n",
      "|    std                | 4.11     |\n",
      "|    value_loss         | 0.00265  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | -0.851   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 8.56     |\n",
      "|    std                | 4.15     |\n",
      "|    value_loss         | 0.0295   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.97e+04 |\n",
      "|    total_cost         | 1.69e+04 |\n",
      "|    total_reward       | -260     |\n",
      "|    total_reward_pct   | -0.52    |\n",
      "|    total_trades       | 26357    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | -20.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 4.45     |\n",
      "|    std                | 4.19     |\n",
      "|    value_loss         | 0.00873  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -1.64     |\n",
      "|    std                | 4.25      |\n",
      "|    value_loss         | 0.00113   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.649    |\n",
      "|    std                | 4.33     |\n",
      "|    value_loss         | 0.00138  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.2    |\n",
      "|    explained_variance | -0.352   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 0.0738   |\n",
      "|    std                | 4.42     |\n",
      "|    value_loss         | 0.000263 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | -2.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -1.19    |\n",
      "|    std                | 4.49     |\n",
      "|    value_loss         | 0.000759 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.42e+04  |\n",
      "|    total_cost         | 1.96e+04  |\n",
      "|    total_reward       | -3.58e+04 |\n",
      "|    total_reward_pct   | -71.6     |\n",
      "|    total_trades       | 26583     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | -20       |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 0.451     |\n",
      "|    std                | 4.55      |\n",
      "|    value_loss         | 0.000114  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.981   |\n",
      "|    std                | 4.65     |\n",
      "|    value_loss         | 0.000342 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -0.426   |\n",
      "|    std                | 4.77     |\n",
      "|    value_loss         | 0.000281 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | -0.334   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -7.56    |\n",
      "|    std                | 4.86     |\n",
      "|    value_loss         | 0.0219   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.49     |\n",
      "|    std                | 4.92     |\n",
      "|    value_loss         | 0.000557 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.07e+04  |\n",
      "|    total_cost         | 2.22e+04  |\n",
      "|    total_reward       | -1.93e+04 |\n",
      "|    total_reward_pct   | -38.5     |\n",
      "|    total_trades       | 27479     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -0.133    |\n",
      "|    std                | 5         |\n",
      "|    value_loss         | 9.88e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -4.22    |\n",
      "|    std                | 5.08     |\n",
      "|    value_loss         | 0.00529  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.2     |\n",
      "|    explained_variance | -5.13e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | -1.73     |\n",
      "|    std                | 5.17      |\n",
      "|    value_loss         | 0.00165   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    std                | 5.23     |\n",
      "|    value_loss         | 0.0423   |\n",
      "------------------------------------\n",
      "day: 2271, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 33857.56\n",
      "total_reward: -16142.44\n",
      "total_cost: 11766.76\n",
      "total_trades: 26228\n",
      "Sharpe: 0.198\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.39e+04  |\n",
      "|    total_cost         | 1.18e+04  |\n",
      "|    total_reward       | -1.61e+04 |\n",
      "|    total_reward_pct   | -32.3     |\n",
      "|    total_trades       | 26228     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 1.7       |\n",
      "|    std                | 5.29      |\n",
      "|    value_loss         | 0.00263   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.204    |\n",
      "|    std                | 5.36     |\n",
      "|    value_loss         | 6.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | -0.0392  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    std                | 5.44     |\n",
      "|    value_loss         | 0.0469   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.3    |\n",
      "|    explained_variance | -0.0324  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 5.5      |\n",
      "|    value_loss         | 0.00557  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -4.55    |\n",
      "|    std                | 5.55     |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.41e+04  |\n",
      "|    total_cost         | 1.26e+04  |\n",
      "|    total_reward       | -1.59e+04 |\n",
      "|    total_reward_pct   | -31.9     |\n",
      "|    total_trades       | 25508     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.7     |\n",
      "|    explained_variance | 0.058     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 1.09      |\n",
      "|    std                | 5.62      |\n",
      "|    value_loss         | 0.000477  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -0.457    |\n",
      "|    std                | 5.72      |\n",
      "|    value_loss         | 0.000172  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.4    |\n",
      "|    explained_variance | -0.0133  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    std                | 5.82     |\n",
      "|    value_loss         | 0.00159  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.6    |\n",
      "|    explained_variance | -2.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    std                | 5.88     |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.67e+04  |\n",
      "|    total_cost         | 1.68e+04  |\n",
      "|    total_reward       | -1.33e+04 |\n",
      "|    total_reward_pct   | -26.5     |\n",
      "|    total_trades       | 25018     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.7     |\n",
      "|    explained_variance | -63.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -2.14     |\n",
      "|    std                | 5.93      |\n",
      "|    value_loss         | 0.00166   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61      |\n",
      "|    explained_variance | 0.368    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.108    |\n",
      "|    std                | 6.02     |\n",
      "|    value_loss         | 4.28e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | -0.356   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.419   |\n",
      "|    std                | 6.15     |\n",
      "|    value_loss         | 0.00143  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.8    |\n",
      "|    explained_variance | 0.022    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -6.66    |\n",
      "|    std                | 6.25     |\n",
      "|    value_loss         | 0.0171   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62      |\n",
      "|    explained_variance | -0.794   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -3.8     |\n",
      "|    std                | 6.32     |\n",
      "|    value_loss         | 0.00751  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.35e+04  |\n",
      "|    total_cost         | 1.77e+04  |\n",
      "|    total_reward       | -1.65e+04 |\n",
      "|    total_reward_pct   | -32.9     |\n",
      "|    total_trades       | 25893     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.2     |\n",
      "|    explained_variance | 0.715     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -1.65     |\n",
      "|    std                | 6.41      |\n",
      "|    value_loss         | 0.000787  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.6    |\n",
      "|    explained_variance | 0.138    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.0427   |\n",
      "|    std                | 6.52     |\n",
      "|    value_loss         | 5.56e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 3.35     |\n",
      "|    std                | 6.65     |\n",
      "|    value_loss         | 0.00357  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 6.73     |\n",
      "|    value_loss         | 0.00436  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.7e+04  |\n",
      "|    total_cost         | 2.15e+04 |\n",
      "|    total_reward       | -1.3e+04 |\n",
      "|    total_reward_pct   | -26      |\n",
      "|    total_trades       | 25887    |\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.3    |\n",
      "|    explained_variance | -48      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 0.516    |\n",
      "|    std                | 6.8      |\n",
      "|    value_loss         | 0.000539 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.6    |\n",
      "|    explained_variance | -19.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -0.369   |\n",
      "|    std                | 6.91     |\n",
      "|    value_loss         | 0.000133 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 1.35     |\n",
      "|    std                | 7.06     |\n",
      "|    value_loss         | 0.000476 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 0.461     |\n",
      "|    std                | 7.22      |\n",
      "|    value_loss         | 0.000124  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.43    |\n",
      "|    std                | 7.35     |\n",
      "|    value_loss         | 0.000111 |\n",
      "------------------------------------\n",
      "day: 2271, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 11219.92\n",
      "total_reward: -38780.08\n",
      "total_cost: 26553.22\n",
      "total_trades: 26457\n",
      "Sharpe: 0.259\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.12e+04  |\n",
      "|    total_cost         | 2.66e+04  |\n",
      "|    total_reward       | -3.88e+04 |\n",
      "|    total_reward_pct   | -77.6     |\n",
      "|    total_trades       | 26457     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.2     |\n",
      "|    explained_variance | -1.01     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -0.838    |\n",
      "|    std                | 7.49      |\n",
      "|    value_loss         | 0.000269  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.6    |\n",
      "|    explained_variance | -10.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 0.0535   |\n",
      "|    std                | 7.64     |\n",
      "|    value_loss         | 0.000316 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.9    |\n",
      "|    explained_variance | -0.41    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 2.89     |\n",
      "|    std                | 7.79     |\n",
      "|    value_loss         | 0.00261  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 11.2     |\n",
      "|    std                | 7.89     |\n",
      "|    value_loss         | 0.0409   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.72e+04  |\n",
      "|    total_cost         | 3.55e+04  |\n",
      "|    total_reward       | -2.28e+04 |\n",
      "|    total_reward_pct   | -45.5     |\n",
      "|    total_trades       | 27113     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 240       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 2.68      |\n",
      "|    std                | 7.98      |\n",
      "|    value_loss         | 0.00199   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.7    |\n",
      "|    explained_variance | -0.0571  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    std                | 8.12     |\n",
      "|    value_loss         | 0.00052  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.2    |\n",
      "|    explained_variance | -8.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0.393   |\n",
      "|    std                | 8.31     |\n",
      "|    value_loss         | 0.000147 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -0.22     |\n",
      "|    std                | 8.53      |\n",
      "|    value_loss         | 1.33e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.195    |\n",
      "|    std                | 8.79     |\n",
      "|    value_loss         | 1.71e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+03   |\n",
      "|    total_cost         | 1.17e+04  |\n",
      "|    total_reward       | -4.86e+04 |\n",
      "|    total_reward_pct   | -97.2     |\n",
      "|    total_trades       | 25417     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 248       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.8     |\n",
      "|    explained_variance | 0.355     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 0.481     |\n",
      "|    std                | 9.05      |\n",
      "|    value_loss         | 0.000369  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 0.748    |\n",
      "|    std                | 9.3      |\n",
      "|    value_loss         | 0.000168 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 252       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | 0.621     |\n",
      "|    std                | 9.59      |\n",
      "|    value_loss         | 0.000216  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.00813 |\n",
      "|    std                | 9.89     |\n",
      "|    value_loss         | 3.21e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.53e+03  |\n",
      "|    total_cost         | 1.58e+04  |\n",
      "|    total_reward       | -4.65e+04 |\n",
      "|    total_reward_pct   | -92.9     |\n",
      "|    total_trades       | 26590     |\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 255       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | -0.074    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 2.76      |\n",
      "|    std                | 10.2      |\n",
      "|    value_loss         | 0.00216   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.6    |\n",
      "|    explained_variance | -0.274   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 1.35     |\n",
      "|    std                | 10.5     |\n",
      "|    value_loss         | 0.000561 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 293      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 10.7     |\n",
      "|    value_loss         | 0.000438 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 3.2      |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 0.00203  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -1.57    |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 0.000767 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.32e+04  |\n",
      "|    total_cost         | 2.49e+04  |\n",
      "|    total_reward       | -3.68e+04 |\n",
      "|    total_reward_pct   | -73.6     |\n",
      "|    total_trades       | 27397     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 264       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.8     |\n",
      "|    explained_variance | 0.0731    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | 0.569     |\n",
      "|    std                | 11.2      |\n",
      "|    value_loss         | 0.000201  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 0.811     |\n",
      "|    std                | 11.5      |\n",
      "|    value_loss         | 0.000143  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -2.42    |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 0.00168  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 12.3     |\n",
      "|    std                | 12       |\n",
      "|    value_loss         | 0.0328   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -2.59    |\n",
      "|    std                | 12.1     |\n",
      "|    value_loss         | 0.00133  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 25124.67\n",
      "total_reward: -24875.33\n",
      "total_cost: 19622.12\n",
      "total_trades: 26406\n",
      "Sharpe: 0.302\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.51e+04  |\n",
      "|    total_cost         | 1.96e+04  |\n",
      "|    total_reward       | -2.49e+04 |\n",
      "|    total_reward_pct   | -49.8     |\n",
      "|    total_trades       | 26406     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 0.265     |\n",
      "|    std                | 12.3      |\n",
      "|    value_loss         | 2.14e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 0.137    |\n",
      "|    std                | 12.6     |\n",
      "|    value_loss         | 4.97e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.5    |\n",
      "|    explained_variance | 0.025    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 5.3      |\n",
      "|    std                | 12.9     |\n",
      "|    value_loss         | 0.00604  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.8    |\n",
      "|    explained_variance | -9.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -3.3     |\n",
      "|    std                | 13.1     |\n",
      "|    value_loss         | 0.00238  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.89e+04  |\n",
      "|    total_cost         | 2.91e+04  |\n",
      "|    total_reward       | -2.11e+04 |\n",
      "|    total_reward_pct   | -42.2     |\n",
      "|    total_trades       | 26891     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 0.875     |\n",
      "|    std                | 13.3      |\n",
      "|    value_loss         | 0.00129   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -0.373   |\n",
      "|    std                | 13.4     |\n",
      "|    value_loss         | 0.000313 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    std                | 13.5     |\n",
      "|    value_loss         | 0.000957 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -16.1    |\n",
      "|    std                | 13.6     |\n",
      "|    value_loss         | 0.0698   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 286       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | 3.69      |\n",
      "|    std                | 13.6      |\n",
      "|    value_loss         | 0.0036    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.65e+04 |\n",
      "|    total_cost         | 4.33e+04 |\n",
      "|    total_reward       | 2.65e+04 |\n",
      "|    total_reward_pct   | 52.9     |\n",
      "|    total_trades       | 28539    |\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.8    |\n",
      "|    explained_variance | -0.51    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 8.43     |\n",
      "|    std                | 13.8     |\n",
      "|    value_loss         | 0.0376   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77      |\n",
      "|    explained_variance | 0.00739  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.533   |\n",
      "|    std                | 14       |\n",
      "|    value_loss         | 0.000355 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.3    |\n",
      "|    explained_variance | -0.711   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -4.83    |\n",
      "|    std                | 14.1     |\n",
      "|    value_loss         | 0.00462  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 1.77     |\n",
      "|    std                | 14.4     |\n",
      "|    value_loss         | 0.000899 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.14e+03  |\n",
      "|    total_cost         | 2.99e+04  |\n",
      "|    total_reward       | -4.19e+04 |\n",
      "|    total_reward_pct   | -83.7     |\n",
      "|    total_trades       | 27684     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 295       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 0.0691    |\n",
      "|    std                | 14.7      |\n",
      "|    value_loss         | 1.86e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.4    |\n",
      "|    explained_variance | -57.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 2.17     |\n",
      "|    std                | 15       |\n",
      "|    value_loss         | 0.00174  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.428   |\n",
      "|    std                | 15.4     |\n",
      "|    value_loss         | 6.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.633    |\n",
      "|    std                | 15.9     |\n",
      "|    value_loss         | 6.42e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.2    |\n",
      "|    explained_variance | -0.321   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -0.575   |\n",
      "|    std                | 16.5     |\n",
      "|    value_loss         | 6.05e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.58e+03  |\n",
      "|    total_cost         | 1.17e+04  |\n",
      "|    total_reward       | -4.84e+04 |\n",
      "|    total_reward_pct   | -96.8     |\n",
      "|    total_trades       | 26246     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80.7     |\n",
      "|    explained_variance | -0.61     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | -5.67     |\n",
      "|    std                | 16.9      |\n",
      "|    value_loss         | 0.00507   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 2.51     |\n",
      "|    std                | 17.3     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -3.08    |\n",
      "|    std                | 17.6     |\n",
      "|    value_loss         | 0.00166  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -1.82     |\n",
      "|    std                | 17.9      |\n",
      "|    value_loss         | 0.000578  |\n",
      "-------------------------------------\n",
      "day: 2271, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6375.63\n",
      "total_reward: -43624.37\n",
      "total_cost: 24714.40\n",
      "total_trades: 27431\n",
      "Sharpe: -0.327\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.38e+03  |\n",
      "|    total_cost         | 2.47e+04  |\n",
      "|    total_reward       | -4.36e+04 |\n",
      "|    total_reward_pct   | -87.2     |\n",
      "|    total_trades       | 27431     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 0.929     |\n",
      "|    std                | 18.4      |\n",
      "|    value_loss         | 0.000177  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.236    |\n",
      "|    std                | 18.9     |\n",
      "|    value_loss         | 3.55e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.899   |\n",
      "|    std                | 19.5     |\n",
      "|    value_loss         | 0.000358 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.8    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 4.79     |\n",
      "|    std                | 19.9     |\n",
      "|    value_loss         | 0.00335  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.2    |\n",
      "|    explained_variance | -25.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 5.96     |\n",
      "|    std                | 20.3     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.27e+04  |\n",
      "|    total_cost         | 3.94e+04  |\n",
      "|    total_reward       | -2.73e+04 |\n",
      "|    total_reward_pct   | -54.7     |\n",
      "|    total_trades       | 27827     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 319       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.5     |\n",
      "|    explained_variance | -1.05     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 1.67      |\n",
      "|    std                | 20.7      |\n",
      "|    value_loss         | 0.000462  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 321       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -0.642    |\n",
      "|    std                | 21.1      |\n",
      "|    value_loss         | 7.49e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.0455   |\n",
      "|    std                | 21.6     |\n",
      "|    value_loss         | 0.000327 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.6    |\n",
      "|    explained_variance | 0.16     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -1.89    |\n",
      "|    std                | 21.9     |\n",
      "|    value_loss         | 0.000673 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.38e+03  |\n",
      "|    total_cost         | 2.85e+04  |\n",
      "|    total_reward       | -4.46e+04 |\n",
      "|    total_reward_pct   | -89.2     |\n",
      "|    total_trades       | 27419     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86       |\n",
      "|    explained_variance | -0.000406 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 2.36      |\n",
      "|    std                | 22.4      |\n",
      "|    value_loss         | 0.00123   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.4    |\n",
      "|    explained_variance | 0.0308   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -1.53    |\n",
      "|    std                | 22.8     |\n",
      "|    value_loss         | 0.000514 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.8    |\n",
      "|    explained_variance | -41.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 4.11     |\n",
      "|    std                | 23.4     |\n",
      "|    value_loss         | 0.0026   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 1.95     |\n",
      "|    std                | 23.9     |\n",
      "|    value_loss         | 0.000481 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.6    |\n",
      "|    explained_variance | -53.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -1.41    |\n",
      "|    std                | 24.4     |\n",
      "|    value_loss         | 0.000475 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.4e+03   |\n",
      "|    total_cost         | 2.4e+04   |\n",
      "|    total_reward       | -4.66e+04 |\n",
      "|    total_reward_pct   | -93.2     |\n",
      "|    total_trades       | 27050     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 334       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | -0.234    |\n",
      "|    std                | 25.1      |\n",
      "|    value_loss         | 3.11e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 0.908    |\n",
      "|    std                | 25.8     |\n",
      "|    value_loss         | 0.000127 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -0.845   |\n",
      "|    std                | 26.6     |\n",
      "|    value_loss         | 0.000148 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.8    |\n",
      "|    explained_variance | -1.13    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -1.8     |\n",
      "|    std                | 27.4     |\n",
      "|    value_loss         | 0.000448 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.55e+03  |\n",
      "|    total_cost         | 2.16e+04  |\n",
      "|    total_reward       | -4.55e+04 |\n",
      "|    total_reward_pct   | -90.9     |\n",
      "|    total_trades       | 26739     |\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -90.3     |\n",
      "|    explained_variance | -0.617    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -1.55     |\n",
      "|    std                | 28.2      |\n",
      "|    value_loss         | 0.000949  |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2019-04-04 to  2019-07-05\n",
      "A2C Sharpe Ratio:  0.44240496525330897\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 358  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 5    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.57e+04   |\n",
      "|    total_cost           | 5.73e+04   |\n",
      "|    total_reward         | -3.43e+04  |\n",
      "|    total_reward_pct     | -68.5      |\n",
      "|    total_trades         | 28672      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 354        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01128754 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0245    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0692     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.55e+04     |\n",
      "|    total_cost           | 5.59e+04     |\n",
      "|    total_reward         | -2.45e+04    |\n",
      "|    total_reward_pct     | -49          |\n",
      "|    total_trades         | 28854        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 351          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049596056 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.294       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0196      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0486       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -445        |\n",
      "|    total_cost           | 1.5e+04     |\n",
      "|    total_reward         | -5.04e+04   |\n",
      "|    total_reward_pct     | -101        |\n",
      "|    total_trades         | 25020       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012373954 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0293      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.87e+03    |\n",
      "|    total_cost           | 1.69e+04    |\n",
      "|    total_reward         | -4.51e+04   |\n",
      "|    total_reward_pct     | -90.3       |\n",
      "|    total_trades         | 25748       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 350         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015149551 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0199      |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1234.56\n",
      "total_reward: -48765.44\n",
      "total_cost: 18802.09\n",
      "total_trades: 25738\n",
      "Sharpe: -0.498\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.23e+03    |\n",
      "|    total_cost           | 1.88e+04    |\n",
      "|    total_reward         | -4.88e+04   |\n",
      "|    total_reward_pct     | -97.5       |\n",
      "|    total_trades         | 25738       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013592755 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0165      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -50.1       |\n",
      "|    total_cost           | 3.15e+04    |\n",
      "|    total_reward         | -5.01e+04   |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 27029       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007113399 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0132      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.47e+04    |\n",
      "|    total_cost           | 3.54e+04    |\n",
      "|    total_reward         | -3.53e+04   |\n",
      "|    total_reward_pct     | -70.5       |\n",
      "|    total_trades         | 27051       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012369933 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.6e+03      |\n",
      "|    total_cost           | 3.09e+04     |\n",
      "|    total_reward         | -4.24e+04    |\n",
      "|    total_reward_pct     | -84.8        |\n",
      "|    total_trades         | 27098        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114129735 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.292       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0116       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.96e+04    |\n",
      "|    total_cost           | 5.66e+04    |\n",
      "|    total_reward         | -3.04e+04   |\n",
      "|    total_reward_pct     | -60.7       |\n",
      "|    total_trades         | 28527       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010209865 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.41       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010821301 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.0357     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.023       |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 37423.73\n",
      "total_reward: -12576.27\n",
      "total_cost: 49647.78\n",
      "total_trades: 28747\n",
      "Sharpe: -0.015\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.74e+04    |\n",
      "|    total_cost           | 4.96e+04    |\n",
      "|    total_reward         | -1.26e+04   |\n",
      "|    total_reward_pct     | -25.2       |\n",
      "|    total_trades         | 28747       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014015148 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0193      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.89e+03     |\n",
      "|    total_cost           | 1.26e+04     |\n",
      "|    total_reward         | -4.71e+04    |\n",
      "|    total_reward_pct     | -94.2        |\n",
      "|    total_trades         | 25160        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105858985 |\n",
      "|    clip_fraction        | 0.0948       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.301       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0104       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.6e+03      |\n",
      "|    total_cost           | 1.7e+04      |\n",
      "|    total_reward         | -4.54e+04    |\n",
      "|    total_reward_pct     | -90.8        |\n",
      "|    total_trades         | 25735        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064866403 |\n",
      "|    clip_fraction        | 0.0929       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.31        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0073       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.71e+04    |\n",
      "|    total_cost           | 4.28e+04    |\n",
      "|    total_reward         | -3.29e+04   |\n",
      "|    total_reward_pct     | -65.8       |\n",
      "|    total_trades         | 28193       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014781286 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0146      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.77e+03    |\n",
      "|    total_cost           | 2.75e+04    |\n",
      "|    total_reward         | -4.02e+04   |\n",
      "|    total_reward_pct     | -80.5       |\n",
      "|    total_trades         | 26973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010015868 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 42978.78\n",
      "total_reward: -7021.22\n",
      "total_cost: 48113.32\n",
      "total_trades: 28432\n",
      "Sharpe: 0.141\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.3e+04     |\n",
      "|    total_cost           | 4.81e+04    |\n",
      "|    total_reward         | -7.02e+03   |\n",
      "|    total_reward_pct     | -14         |\n",
      "|    total_trades         | 28432       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009480125 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00729     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.19e+04    |\n",
      "|    total_cost           | 2.74e+04    |\n",
      "|    total_reward         | -2.81e+04   |\n",
      "|    total_reward_pct     | -56.2       |\n",
      "|    total_trades         | 26919       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013793742 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0215      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.85e+03    |\n",
      "|    total_cost           | 1.94e+04    |\n",
      "|    total_reward         | -4.21e+04   |\n",
      "|    total_reward_pct     | -84.3       |\n",
      "|    total_trades         | 26218       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021557417 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.014       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.24e+04    |\n",
      "|    total_cost           | 2.5e+04     |\n",
      "|    total_reward         | -3.76e+04   |\n",
      "|    total_reward_pct     | -75.3       |\n",
      "|    total_trades         | 26778       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007986785 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00677     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013884024 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00674     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+04    |\n",
      "|    total_cost           | 2.43e+04    |\n",
      "|    total_reward         | -2.96e+04   |\n",
      "|    total_reward_pct     | -59.1       |\n",
      "|    total_trades         | 26999       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022031106 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 34849.23\n",
      "total_reward: -15150.77\n",
      "total_cost: 41723.25\n",
      "total_trades: 28436\n",
      "Sharpe: -0.004\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.48e+04     |\n",
      "|    total_cost           | 4.17e+04     |\n",
      "|    total_reward         | -1.52e+04    |\n",
      "|    total_reward_pct     | -30.3        |\n",
      "|    total_trades         | 28436        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127565805 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.4        |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.313       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0214      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0158       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+04    |\n",
      "|    total_cost           | 2e+04       |\n",
      "|    total_reward         | -3.14e+04   |\n",
      "|    total_reward_pct     | -62.8       |\n",
      "|    total_trades         | 25960       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020220496 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0151      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+04    |\n",
      "|    total_cost           | 2.29e+04    |\n",
      "|    total_reward         | -2.39e+04   |\n",
      "|    total_reward_pct     | -47.8       |\n",
      "|    total_trades         | 26646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008405341 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00693     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.5e+03     |\n",
      "|    total_cost           | 1.99e+04    |\n",
      "|    total_reward         | -4.25e+04   |\n",
      "|    total_reward_pct     | -85         |\n",
      "|    total_trades         | 26527       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012854319 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00846     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.54e+04    |\n",
      "|    total_cost           | 2.41e+04    |\n",
      "|    total_reward         | 5.36e+03    |\n",
      "|    total_reward_pct     | 10.7        |\n",
      "|    total_trades         | 26289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018848054 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00642     |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 26829.40\n",
      "total_reward: -23170.60\n",
      "total_cost: 21340.00\n",
      "total_trades: 26348\n",
      "Sharpe: 0.345\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.68e+04    |\n",
      "|    total_cost           | 2.13e+04    |\n",
      "|    total_reward         | -2.32e+04   |\n",
      "|    total_reward_pct     | -46.3       |\n",
      "|    total_trades         | 26348       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010922254 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0231      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.77e+04    |\n",
      "|    total_cost           | 2.92e+04    |\n",
      "|    total_reward         | -1.23e+04   |\n",
      "|    total_reward_pct     | -24.6       |\n",
      "|    total_trades         | 27358       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012113653 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00802     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.2e+04    |\n",
      "|    total_cost           | 3.04e+04   |\n",
      "|    total_reward         | -1.8e+04   |\n",
      "|    total_reward_pct     | -35.9      |\n",
      "|    total_trades         | 27437      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 347        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 177        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01781125 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.307     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0113     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 346          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142775765 |\n",
      "|    clip_fraction        | 0.0949       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.5        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.297       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0198      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0141       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.64e+04    |\n",
      "|    total_cost           | 5.59e+04    |\n",
      "|    total_reward         | 2.64e+04    |\n",
      "|    total_reward_pct     | 52.8        |\n",
      "|    total_trades         | 29002       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019966455 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.269      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0662      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.23e+04    |\n",
      "|    total_cost           | 4.33e+04    |\n",
      "|    total_reward         | 2.28e+03    |\n",
      "|    total_reward_pct     | 4.55        |\n",
      "|    total_trades         | 28529       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009025982 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 18840.28\n",
      "total_reward: -31159.72\n",
      "total_cost: 23149.03\n",
      "total_trades: 27044\n",
      "Sharpe: -0.093\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+04    |\n",
      "|    total_cost           | 2.31e+04    |\n",
      "|    total_reward         | -3.12e+04   |\n",
      "|    total_reward_pct     | -62.3       |\n",
      "|    total_trades         | 27044       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018608585 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.44e+03    |\n",
      "|    total_cost           | 1.26e+04    |\n",
      "|    total_reward         | -4.26e+04   |\n",
      "|    total_reward_pct     | -85.1       |\n",
      "|    total_trades         | 25617       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017187603 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00802     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.21e+03    |\n",
      "|    total_cost           | 1.21e+04    |\n",
      "|    total_reward         | -4.28e+04   |\n",
      "|    total_reward_pct     | -85.6       |\n",
      "|    total_trades         | 25596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013571622 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00599     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+04    |\n",
      "|    total_cost           | 1.5e+04     |\n",
      "|    total_reward         | -3.74e+04   |\n",
      "|    total_reward_pct     | -74.8       |\n",
      "|    total_trades         | 26289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010928773 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00445     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+04    |\n",
      "|    total_cost           | 1.97e+04    |\n",
      "|    total_reward         | -2.82e+04   |\n",
      "|    total_reward_pct     | -56.3       |\n",
      "|    total_trades         | 26823       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016709384 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00559     |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74064.32\n",
      "total_reward: 24064.32\n",
      "total_cost: 32034.34\n",
      "total_trades: 27364\n",
      "Sharpe: 0.317\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.41e+04    |\n",
      "|    total_cost           | 3.2e+04     |\n",
      "|    total_reward         | 2.41e+04    |\n",
      "|    total_reward_pct     | 48.1        |\n",
      "|    total_trades         | 27364       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015724104 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.97e+03    |\n",
      "|    total_cost           | 1e+04       |\n",
      "|    total_reward         | -4.2e+04    |\n",
      "|    total_reward_pct     | -84.1       |\n",
      "|    total_trades         | 25075       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017275266 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017298779 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00427     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.68e+04    |\n",
      "|    total_cost           | 2.9e+04     |\n",
      "|    total_reward         | 6.79e+03    |\n",
      "|    total_reward_pct     | 13.6        |\n",
      "|    total_trades         | 27486       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013364078 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0216      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.61e+03    |\n",
      "|    total_cost           | 1.08e+04    |\n",
      "|    total_reward         | -4.44e+04   |\n",
      "|    total_reward_pct     | -88.8       |\n",
      "|    total_trades         | 25095       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016721506 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00628     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.24e+04    |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -1.76e+04   |\n",
      "|    total_reward_pct     | -35.3       |\n",
      "|    total_trades         | 25643       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013295315 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00647     |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 30627.55\n",
      "total_reward: -19372.45\n",
      "total_cost: 18491.54\n",
      "total_trades: 26099\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.06e+04    |\n",
      "|    total_cost           | 1.85e+04    |\n",
      "|    total_reward         | -1.94e+04   |\n",
      "|    total_reward_pct     | -38.7       |\n",
      "|    total_trades         | 26099       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021160424 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0101      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+04    |\n",
      "|    total_cost           | 1.28e+04    |\n",
      "|    total_reward         | -3.75e+04   |\n",
      "|    total_reward_pct     | -74.9       |\n",
      "|    total_trades         | 25285       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026576852 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0157      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 593         |\n",
      "|    total_cost           | 7.53e+03    |\n",
      "|    total_reward         | -4.94e+04   |\n",
      "|    total_reward_pct     | -98.8       |\n",
      "|    total_trades         | 24428       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015938764 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00439     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.03e+03    |\n",
      "|    total_cost           | 1.14e+04    |\n",
      "|    total_reward         | -4.1e+04    |\n",
      "|    total_reward_pct     | -81.9       |\n",
      "|    total_trades         | 25440       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025684908 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00326     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.19e+03    |\n",
      "|    total_cost           | 1.11e+04    |\n",
      "|    total_reward         | -4.18e+04   |\n",
      "|    total_reward_pct     | -83.6       |\n",
      "|    total_trades         | 25366       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012093182 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00343     |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-04-04 to  2019-07-05\n",
      "PPO Sharpe Ratio:  0.1675317418034989\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.98e+04 |\n",
      "|    total_cost       | 170      |\n",
      "|    total_reward     | 1.98e+04 |\n",
      "|    total_reward_pct | 39.6     |\n",
      "|    total_trades     | 18860    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 80       |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total timesteps  | 9088     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -21.8    |\n",
      "|    critic_loss      | 4.17     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6816     |\n",
      "----------------------------------\n",
      "day: 2271, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 64992.91\n",
      "total_reward: 14992.91\n",
      "total_cost: 211.86\n",
      "total_trades: 18160\n",
      "Sharpe: 0.421\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.88e+04 |\n",
      "|    total_cost       | 174      |\n",
      "|    total_reward     | 8.81e+03 |\n",
      "|    total_reward_pct | 17.6     |\n",
      "|    total_trades     | 18769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total timesteps  | 18176    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -14.6    |\n",
      "|    critic_loss      | 1.46     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15904    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48956.34\n",
      "total_reward: -1043.66\n",
      "total_cost: 108.41\n",
      "total_trades: 20173\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.49e+04 |\n",
      "|    total_cost       | 195      |\n",
      "|    total_reward     | 4.85e+03 |\n",
      "|    total_reward_pct | 9.71     |\n",
      "|    total_trades     | 20381    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 398      |\n",
      "|    total timesteps  | 27264    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -9.82    |\n",
      "|    critic_loss      | 0.525    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24992    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49001.77\n",
      "total_reward: -998.23\n",
      "total_cost: 102.50\n",
      "total_trades: 20059\n",
      "Sharpe: 0.377\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.63e+04 |\n",
      "|    total_cost       | 221      |\n",
      "|    total_reward     | 1.63e+04 |\n",
      "|    total_reward_pct | 32.5     |\n",
      "|    total_trades     | 19844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 541      |\n",
      "|    total timesteps  | 36352    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -6.75    |\n",
      "|    critic_loss      | 0.269    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34080    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 58830.41\n",
      "total_reward: 8830.41\n",
      "total_cost: 194.50\n",
      "total_trades: 19289\n",
      "Sharpe: 0.415\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.88e+04 |\n",
      "|    total_cost       | 195      |\n",
      "|    total_reward     | 8.83e+03 |\n",
      "|    total_reward_pct | 17.7     |\n",
      "|    total_trades     | 19289    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 684      |\n",
      "|    total timesteps  | 45440    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -4.73    |\n",
      "|    critic_loss      | 0.159    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43168    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-04-04 to  2019-07-05\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-07-05\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_189_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -1.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 5.93     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0923   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -5.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -7.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0851   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -2.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.74     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00189  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -0.0265  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -2.69    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.42e+04 |\n",
      "|    total_cost         | 3.98e+04 |\n",
      "|    total_reward       | 1.42e+04 |\n",
      "|    total_reward_pct   | 28.4     |\n",
      "|    total_trades       | 28649    |\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.38     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.000255 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -2.56    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.91     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00493  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -3.85    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -1.24    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -0.0385  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.36    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.000473 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -15.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.135    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00207  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -9.74e+03 |\n",
      "|    total_cost         | 2.11e+03  |\n",
      "|    total_reward       | -5.97e+04 |\n",
      "|    total_reward_pct   | -119      |\n",
      "|    total_trades       | 23697     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | -6.34     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 0.407     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.000398  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -76.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 2.19     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -5.77    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.0464   |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.000242 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -0.224   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.0973  |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.000135 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -789     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.969    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.00748  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.03e+03  |\n",
      "|    total_cost         | 1.27e+03  |\n",
      "|    total_reward       | -4.7e+04  |\n",
      "|    total_reward_pct   | -93.9     |\n",
      "|    total_trades       | 23440     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 0.246     |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.000505  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -0.968   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.323    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00349  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -0.509   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.685   |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.000548 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | -9.69    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.66     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.0032   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.21e+03  |\n",
      "|    total_cost         | 1.14e+03  |\n",
      "|    total_reward       | -4.18e+04 |\n",
      "|    total_reward_pct   | -83.6     |\n",
      "|    total_trades       | 23704     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 0.14      |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 2.5e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | -85.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.0034   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | -0.0258  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -1.17    |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.00236  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -0.471   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.222    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.000583 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | -2.37    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.00351  |\n",
      "------------------------------------\n",
      "day: 2334, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -9617.12\n",
      "total_reward: -59617.12\n",
      "total_cost: 770.20\n",
      "total_trades: 22361\n",
      "Sharpe: -0.260\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -9.62e+03 |\n",
      "|    total_cost         | 770       |\n",
      "|    total_reward       | -5.96e+04 |\n",
      "|    total_reward_pct   | -119      |\n",
      "|    total_trades       | 22361     |\n",
      "| time/                 |           |\n",
      "|    fps                | 291       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.1     |\n",
      "|    explained_variance | -30.4     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 0.366     |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.000339  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -0.432   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.47     |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00574  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | -0.0438  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.947    |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.000738 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -0.329   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.348    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.0006   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.233   |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 6.02e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.22e+03  |\n",
      "|    total_cost         | 1.3e+03   |\n",
      "|    total_reward       | -4.88e+04 |\n",
      "|    total_reward_pct   | -97.6     |\n",
      "|    total_trades       | 23207     |\n",
      "| time/                 |           |\n",
      "|    fps                | 291       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.2     |\n",
      "|    explained_variance | -12.1     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -1.58     |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 0.00312   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | -2.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -7.71    |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.0439   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | 0.0223   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.112   |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.000225 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | -0.0714  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 5.28     |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.019    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.36e+04  |\n",
      "|    total_cost         | 2.74e+03  |\n",
      "|    total_reward       | -3.64e+04 |\n",
      "|    total_reward_pct   | -72.8     |\n",
      "|    total_trades       | 23741     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.5     |\n",
      "|    explained_variance | 0.101     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 2.22      |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 0.00582   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | -2.69    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.733    |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.00414  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | 0.522    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.58    |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.00506  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | -0.134   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -5.41    |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.0205   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -3.66    |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.00997  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.52e+04 |\n",
      "|    total_cost         | 8.71e+03 |\n",
      "|    total_reward       | 5.19e+03 |\n",
      "|    total_reward_pct   | 10.4     |\n",
      "|    total_trades       | 24007    |\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | -1.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.00187  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0836  |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.00133  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | -0.838   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 4.56     |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -2.13    |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.00511  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 1.7      |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.00213  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.78e+04  |\n",
      "|    total_cost         | 2.85e+03  |\n",
      "|    total_reward       | -2.22e+04 |\n",
      "|    total_reward_pct   | -44.4     |\n",
      "|    total_trades       | 23607     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.7     |\n",
      "|    explained_variance | -0.247    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 3.69      |\n",
      "|    std                | 1.96      |\n",
      "|    value_loss         | 0.00993   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 1.33     |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.00134  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0.00404  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.34    |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.00255  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | -0.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.18     |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.00644  |\n",
      "------------------------------------\n",
      "day: 2334, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24661.83\n",
      "total_reward: -25338.17\n",
      "total_cost: 2940.39\n",
      "total_trades: 24022\n",
      "Sharpe: 0.020\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.47e+04  |\n",
      "|    total_cost         | 2.94e+03  |\n",
      "|    total_reward       | -2.53e+04 |\n",
      "|    total_reward_pct   | -50.7     |\n",
      "|    total_trades       | 24022     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -5.97     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -0.477    |\n",
      "|    std                | 2.08      |\n",
      "|    value_loss         | 0.000326  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | -0.668   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.197    |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 7.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    std                | 2.18     |\n",
      "|    value_loss         | 0.00141  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -2.47    |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.00466  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | -0.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.68    |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.00175  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.61e+04  |\n",
      "|    total_cost         | 2.58e+03  |\n",
      "|    total_reward       | -3.39e+04 |\n",
      "|    total_reward_pct   | -67.8     |\n",
      "|    total_trades       | 23261     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -6.17     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -0.257    |\n",
      "|    std                | 2.3       |\n",
      "|    value_loss         | 0.000228  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.751   |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.000367 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -1.19     |\n",
      "|    std                | 2.4       |\n",
      "|    value_loss         | 0.000864  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0.0826   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 2.45     |\n",
      "|    value_loss         | 0.0561   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0.738    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 2.08     |\n",
      "|    std                | 2.49     |\n",
      "|    value_loss         | 0.00264  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.97e+04  |\n",
      "|    total_cost         | 4.88e+03  |\n",
      "|    total_reward       | -3.03e+04 |\n",
      "|    total_reward_pct   | -60.5     |\n",
      "|    total_trades       | 24006     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -1.08     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -0.284    |\n",
      "|    std                | 2.54      |\n",
      "|    value_loss         | 8.44e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | -2.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.503   |\n",
      "|    std                | 2.62     |\n",
      "|    value_loss         | 0.000845 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.727    |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.00054  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.28     |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 8.26e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.08e+04  |\n",
      "|    total_cost         | 7.15e+03  |\n",
      "|    total_reward       | -3.92e+04 |\n",
      "|    total_reward_pct   | -78.4     |\n",
      "|    total_trades       | 25820     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -0.818    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 1.52      |\n",
      "|    std                | 2.8       |\n",
      "|    value_loss         | 0.001     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | -0.609   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.306   |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 5e-05    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0.000683 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -9.65    |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 0.0424   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | -0.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -1.22    |\n",
      "|    std                | 3.04     |\n",
      "|    value_loss         | 0.000786 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.606    |\n",
      "|    std                | 3.1      |\n",
      "|    value_loss         | 0.00017  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.28e+03  |\n",
      "|    total_cost         | 1.12e+04  |\n",
      "|    total_reward       | -4.27e+04 |\n",
      "|    total_reward_pct   | -85.4     |\n",
      "|    total_trades       | 25888     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.8     |\n",
      "|    explained_variance | 0.308     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 2.11      |\n",
      "|    std                | 3.15      |\n",
      "|    value_loss         | 0.00233   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -4.05    |\n",
      "|    std                | 3.18     |\n",
      "|    value_loss         | 0.0108   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 0.0569   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -3.73    |\n",
      "|    std                | 3.22     |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 11.4     |\n",
      "|    std                | 3.26     |\n",
      "|    value_loss         | 0.0567   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    std                | 3.3      |\n",
      "|    value_loss         | 0.000718 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 34352.42\n",
      "total_reward: -15647.58\n",
      "total_cost: 20276.05\n",
      "total_trades: 26616\n",
      "Sharpe: -0.005\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.44e+04  |\n",
      "|    total_cost         | 2.03e+04  |\n",
      "|    total_reward       | -1.56e+04 |\n",
      "|    total_reward_pct   | -31.3     |\n",
      "|    total_trades       | 26616     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 0.546     |\n",
      "|    std                | 3.35      |\n",
      "|    value_loss         | 0.000182  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 0.606    |\n",
      "|    std                | 3.43     |\n",
      "|    value_loss         | 0.000139 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.73     |\n",
      "|    std                | 3.51     |\n",
      "|    value_loss         | 0.000564 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.164    |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 3.41e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.72e+03  |\n",
      "|    total_cost         | 2.04e+04  |\n",
      "|    total_reward       | -4.53e+04 |\n",
      "|    total_reward_pct   | -90.6     |\n",
      "|    total_trades       | 27137     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.9     |\n",
      "|    explained_variance | -0.449    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -13.4     |\n",
      "|    std                | 3.72      |\n",
      "|    value_loss         | 0.0706    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -1.19    |\n",
      "|    std                | 3.81     |\n",
      "|    value_loss         | 0.000743 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | -43.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -2.81    |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.00731  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.32     |\n",
      "|    std                | 4        |\n",
      "|    value_loss         | 7.82e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.9    |\n",
      "|    explained_variance | 0.533    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0.459   |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 8.83e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.29e+03  |\n",
      "|    total_cost         | 3.05e+04  |\n",
      "|    total_reward       | -4.27e+04 |\n",
      "|    total_reward_pct   | -85.4     |\n",
      "|    total_trades       | 28140     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.3     |\n",
      "|    explained_variance | -0.485    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -2.27     |\n",
      "|    std                | 4.23      |\n",
      "|    value_loss         | 0.00188   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 2.05     |\n",
      "|    std                | 4.32     |\n",
      "|    value_loss         | 0.00175  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.161    |\n",
      "|    std                | 4.42     |\n",
      "|    value_loss         | 5.05e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | 0.0615   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.00211 |\n",
      "|    std                | 4.55     |\n",
      "|    value_loss         | 2.49e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | -0.382   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.162    |\n",
      "|    std                | 4.7      |\n",
      "|    value_loss         | 3.12e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.65e+03  |\n",
      "|    total_cost         | 2.71e+04  |\n",
      "|    total_reward       | -4.34e+04 |\n",
      "|    total_reward_pct   | -86.7     |\n",
      "|    total_trades       | 27741     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 1.16      |\n",
      "|    std                | 4.8       |\n",
      "|    value_loss         | 0.00109   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -1.1     |\n",
      "|    std                | 4.9      |\n",
      "|    value_loss         | 0.000643 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -0.894    |\n",
      "|    std                | 5.01      |\n",
      "|    value_loss         | 0.000992  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 0.476     |\n",
      "|    std                | 5.13      |\n",
      "|    value_loss         | 0.000124  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.37e+03  |\n",
      "|    total_cost         | 3.29e+04  |\n",
      "|    total_reward       | -4.46e+04 |\n",
      "|    total_reward_pct   | -89.3     |\n",
      "|    total_trades       | 27823     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.5     |\n",
      "|    explained_variance | -0.285    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 0.596     |\n",
      "|    std                | 5.27      |\n",
      "|    value_loss         | 0.000257  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.485    |\n",
      "|    std                | 5.43     |\n",
      "|    value_loss         | 9.66e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 0.117     |\n",
      "|    std                | 5.62      |\n",
      "|    value_loss         | 4.29e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.5    |\n",
      "|    explained_variance | -19.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.0425  |\n",
      "|    std                | 5.84     |\n",
      "|    value_loss         | 2.19e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.498   |\n",
      "|    std                | 6.08     |\n",
      "|    value_loss         | 7.41e-05 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -8878.73\n",
      "total_reward: -58878.73\n",
      "total_cost: 11617.03\n",
      "total_trades: 25331\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.88e+03 |\n",
      "|    total_cost         | 1.16e+04  |\n",
      "|    total_reward       | -5.89e+04 |\n",
      "|    total_reward_pct   | -118      |\n",
      "|    total_trades       | 25331     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.7     |\n",
      "|    explained_variance | 0.189     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -1.27     |\n",
      "|    std                | 6.24      |\n",
      "|    value_loss         | 0.000548  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 0.765     |\n",
      "|    std                | 6.4       |\n",
      "|    value_loss         | 0.000214  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.6    |\n",
      "|    explained_variance | -0.129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    std                | 6.55     |\n",
      "|    value_loss         | 0.000367 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63      |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 0.798    |\n",
      "|    std                | 6.68     |\n",
      "|    value_loss         | 0.000403 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.915   |\n",
      "|    std                | 6.81     |\n",
      "|    value_loss         | 0.000257 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.25e+03  |\n",
      "|    total_cost         | 4.32e+04  |\n",
      "|    total_reward       | -4.07e+04 |\n",
      "|    total_reward_pct   | -81.5     |\n",
      "|    total_trades       | 28162     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.7     |\n",
      "|    explained_variance | -0.318    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 0.00712   |\n",
      "|    std                | 6.94      |\n",
      "|    value_loss         | 9.49e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.331   |\n",
      "|    std                | 7.13     |\n",
      "|    value_loss         | 9.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -0.18    |\n",
      "|    std                | 7.38     |\n",
      "|    value_loss         | 2.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.6    |\n",
      "|    explained_variance | -5.6     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.269    |\n",
      "|    std                | 7.67     |\n",
      "|    value_loss         | 1.83e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -198      |\n",
      "|    total_cost         | 1.41e+04  |\n",
      "|    total_reward       | -5.02e+04 |\n",
      "|    total_reward_pct   | -100      |\n",
      "|    total_trades       | 25640     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -0.0816   |\n",
      "|    std                | 7.99      |\n",
      "|    value_loss         | 7.77e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.1    |\n",
      "|    explained_variance | -1.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 0.02     |\n",
      "|    std                | 8.3      |\n",
      "|    value_loss         | 5.91e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.8    |\n",
      "|    explained_variance | -0.078   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 2.26     |\n",
      "|    std                | 8.61     |\n",
      "|    value_loss         | 0.00185  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | -0.129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 0.959    |\n",
      "|    std                | 8.85     |\n",
      "|    value_loss         | 0.000268 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69      |\n",
      "|    explained_variance | 0.0571   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.365    |\n",
      "|    std                | 9.13     |\n",
      "|    value_loss         | 3.85e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.13e+03  |\n",
      "|    total_cost         | 2.28e+04  |\n",
      "|    total_reward       | -4.69e+04 |\n",
      "|    total_reward_pct   | -93.7     |\n",
      "|    total_trades       | 26650     |\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | 0.23      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | -0.783    |\n",
      "|    std                | 9.43      |\n",
      "|    value_loss         | 0.000485  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.829    |\n",
      "|    std                | 9.73     |\n",
      "|    value_loss         | 0.000146 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.536   |\n",
      "|    std                | 10.1     |\n",
      "|    value_loss         | 8.35e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.5    |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -0.571   |\n",
      "|    std                | 10.4     |\n",
      "|    value_loss         | 7.39e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.3    |\n",
      "|    explained_variance | 0.91     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.288    |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 1.66e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.86e+03  |\n",
      "|    total_cost         | 1.7e+04   |\n",
      "|    total_reward       | -4.81e+04 |\n",
      "|    total_reward_pct   | -96.3     |\n",
      "|    total_trades       | 26719     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -0.0298   |\n",
      "|    std                | 11.2      |\n",
      "|    value_loss         | 3.58e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 0.201    |\n",
      "|    std                | 11.6     |\n",
      "|    value_loss         | 1.34e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.1    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 11.9     |\n",
      "|    value_loss         | 0.000848 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.6    |\n",
      "|    explained_variance | -0.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.311   |\n",
      "|    std                | 12.3     |\n",
      "|    value_loss         | 4.22e-05 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -2063.75\n",
      "total_reward: -52063.75\n",
      "total_cost: 17477.88\n",
      "total_trades: 26763\n",
      "Sharpe: 0.301\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.06e+03 |\n",
      "|    total_cost         | 1.75e+04  |\n",
      "|    total_reward       | -5.21e+04 |\n",
      "|    total_reward_pct   | -104      |\n",
      "|    total_trades       | 26763     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | -0.0381   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -2.12     |\n",
      "|    std                | 12.7      |\n",
      "|    value_loss         | 0.000838  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.7    |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -1.27    |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 0.000287 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 205       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -1.99     |\n",
      "|    std                | 13.4      |\n",
      "|    value_loss         | 0.000841  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.7    |\n",
      "|    explained_variance | -0.274   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -1.62    |\n",
      "|    std                | 13.7     |\n",
      "|    value_loss         | 0.000484 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.1     |\n",
      "|    explained_variance | -2.74e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 1.01      |\n",
      "|    std                | 14        |\n",
      "|    value_loss         | 0.0002    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.59e+03  |\n",
      "|    total_cost         | 3.84e+04  |\n",
      "|    total_reward       | -4.14e+04 |\n",
      "|    total_reward_pct   | -82.8     |\n",
      "|    total_trades       | 28109     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.5     |\n",
      "|    explained_variance | -4.45     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -2.24     |\n",
      "|    std                | 14.3      |\n",
      "|    value_loss         | 0.001     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.75     |\n",
      "|    std                | 14.7     |\n",
      "|    value_loss         | 0.000191 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.7    |\n",
      "|    explained_variance | -3.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -0.171   |\n",
      "|    std                | 15.2     |\n",
      "|    value_loss         | 7.14e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.5    |\n",
      "|    explained_variance | -4.27    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.227    |\n",
      "|    std                | 15.9     |\n",
      "|    value_loss         | 1.14e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.3    |\n",
      "|    explained_variance | 0.723    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.0169  |\n",
      "|    std                | 16.6     |\n",
      "|    value_loss         | 5.33e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 245       |\n",
      "|    total_cost         | 1.09e+04  |\n",
      "|    total_reward       | -4.98e+04 |\n",
      "|    total_reward_pct   | -99.5     |\n",
      "|    total_trades       | 25720     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 0.3       |\n",
      "|    std                | 17.1      |\n",
      "|    value_loss         | 5.69e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.845    |\n",
      "|    std                | 17.6     |\n",
      "|    value_loss         | 0.000149 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.9    |\n",
      "|    explained_variance | -0.0803  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.0399  |\n",
      "|    std                | 18.1     |\n",
      "|    value_loss         | 0.000269 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.3    |\n",
      "|    explained_variance | 0.403    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -2.16    |\n",
      "|    std                | 18.5     |\n",
      "|    value_loss         | 0.000727 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.94e+03  |\n",
      "|    total_cost         | 3.69e+04  |\n",
      "|    total_reward       | -4.41e+04 |\n",
      "|    total_reward_pct   | -88.1     |\n",
      "|    total_trades       | 28066     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.8     |\n",
      "|    explained_variance | 0.144     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 1.35      |\n",
      "|    std                | 19        |\n",
      "|    value_loss         | 0.00053   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.0719  |\n",
      "|    std                | 19.4     |\n",
      "|    value_loss         | 3e-05    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.018    |\n",
      "|    std                | 19.9     |\n",
      "|    value_loss         | 2.17e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.4    |\n",
      "|    explained_variance | -0.246   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.8     |\n",
      "|    std                | 20.5     |\n",
      "|    value_loss         | 0.000234 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85       |\n",
      "|    explained_variance | -0.000119 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 0.301     |\n",
      "|    std                | 21.3      |\n",
      "|    value_loss         | 1.35e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.82e+03  |\n",
      "|    total_cost         | 2.24e+04  |\n",
      "|    total_reward       | -4.82e+04 |\n",
      "|    total_reward_pct   | -96.4     |\n",
      "|    total_trades       | 27353     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.8     |\n",
      "|    explained_variance | 0.0257    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 0.138     |\n",
      "|    std                | 22.2      |\n",
      "|    value_loss         | 1.45e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.164   |\n",
      "|    std                | 23       |\n",
      "|    value_loss         | 4.63e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -87.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 0.764     |\n",
      "|    std                | 23.8      |\n",
      "|    value_loss         | 0.000163  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 24.4     |\n",
      "|    value_loss         | 0.000265 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.2    |\n",
      "|    explained_variance | -4.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 25.2     |\n",
      "|    value_loss         | 0.000172 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3396.32\n",
      "total_reward: -46603.68\n",
      "total_cost: 26509.68\n",
      "total_trades: 27133\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.4e+03   |\n",
      "|    total_cost         | 2.65e+04  |\n",
      "|    total_reward       | -4.66e+04 |\n",
      "|    total_reward_pct   | -93.2     |\n",
      "|    total_trades       | 27133     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -0.726    |\n",
      "|    std                | 25.9      |\n",
      "|    value_loss         | 0.00023   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    std                | 26.8     |\n",
      "|    value_loss         | 8.22e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.9    |\n",
      "|    explained_variance | 0.0864   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.338    |\n",
      "|    std                | 27.5     |\n",
      "|    value_loss         | 0.000419 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 0.177    |\n",
      "|    std                | 28.2     |\n",
      "|    value_loss         | 3.42e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.35e+03  |\n",
      "|    total_cost         | 2.74e+04  |\n",
      "|    total_reward       | -4.67e+04 |\n",
      "|    total_reward_pct   | -93.3     |\n",
      "|    total_trades       | 27587     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91       |\n",
      "|    explained_variance | 0.0928    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -2        |\n",
      "|    std                | 29.1      |\n",
      "|    value_loss         | 0.000502  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.5    |\n",
      "|    explained_variance | -0.188   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.515   |\n",
      "|    std                | 29.9     |\n",
      "|    value_loss         | 3.64e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 30.8     |\n",
      "|    value_loss         | 0.000466 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 256       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -92.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -1.15     |\n",
      "|    std                | 31.7      |\n",
      "|    value_loss         | 0.000165  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.1    |\n",
      "|    explained_variance | -0.134   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.82    |\n",
      "|    std                | 32.6     |\n",
      "|    value_loss         | 0.000233 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.48e+03  |\n",
      "|    total_cost         | 2.91e+04  |\n",
      "|    total_reward       | -4.65e+04 |\n",
      "|    total_reward_pct   | -93       |\n",
      "|    total_trades       | 27618     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93.7     |\n",
      "|    explained_variance | -0.516    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -1.01     |\n",
      "|    std                | 33.6      |\n",
      "|    value_loss         | 0.000143  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 34.8     |\n",
      "|    value_loss         | 0.000173 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.73     |\n",
      "|    std                | 36       |\n",
      "|    value_loss         | 0.000177 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.5    |\n",
      "|    explained_variance | -0.152   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -2.84    |\n",
      "|    std                | 36.9     |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 38       |\n",
      "|    value_loss         | 0.000277 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.83e+03  |\n",
      "|    total_cost         | 2.82e+04  |\n",
      "|    total_reward       | -4.42e+04 |\n",
      "|    total_reward_pct   | -88.3     |\n",
      "|    total_trades       | 27399     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 268       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -96.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -1.37     |\n",
      "|    std                | 39.2      |\n",
      "|    value_loss         | 0.000243  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.764   |\n",
      "|    std                | 40.6     |\n",
      "|    value_loss         | 0.000116 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 2.18     |\n",
      "|    std                | 41.8     |\n",
      "|    value_loss         | 0.00084  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 274       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -98.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | -0.536    |\n",
      "|    std                | 43.1      |\n",
      "|    value_loss         | 4.5e-05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.89e+03  |\n",
      "|    total_cost         | 1.96e+04  |\n",
      "|    total_reward       | -4.81e+04 |\n",
      "|    total_reward_pct   | -96.2     |\n",
      "|    total_trades       | 26728     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 275       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99.1     |\n",
      "|    explained_variance | -1.57     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | -0.381    |\n",
      "|    std                | 44.6      |\n",
      "|    value_loss         | 3.05e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 277       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 0.663     |\n",
      "|    std                | 46.3      |\n",
      "|    value_loss         | 6.59e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -100      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 1.05      |\n",
      "|    std                | 48        |\n",
      "|    value_loss         | 0.000617  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | -0.413   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 1.23     |\n",
      "|    std                | 49.3     |\n",
      "|    value_loss         | 0.000267 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 283       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -102      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -0.646    |\n",
      "|    std                | 50.7      |\n",
      "|    value_loss         | 5.26e-05  |\n",
      "-------------------------------------\n",
      "day: 2334, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 495.87\n",
      "total_reward: -49504.13\n",
      "total_cost: 27197.23\n",
      "total_trades: 27647\n",
      "Sharpe: 0.263\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 496       |\n",
      "|    total_cost         | 2.72e+04  |\n",
      "|    total_reward       | -4.95e+04 |\n",
      "|    total_reward_pct   | -99       |\n",
      "|    total_trades       | 27647     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 284       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -102      |\n",
      "|    explained_variance | 0.453     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 0.218     |\n",
      "|    std                | 52.1      |\n",
      "|    value_loss         | 2.16e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.103    |\n",
      "|    std                | 53.7     |\n",
      "|    value_loss         | 9.87e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0.11     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -1.23    |\n",
      "|    std                | 55.6     |\n",
      "|    value_loss         | 0.000151 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 289       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -104      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -0.309    |\n",
      "|    std                | 57.6      |\n",
      "|    value_loss         | 2.65e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 291       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -1.83     |\n",
      "|    std                | 59.5      |\n",
      "|    value_loss         | 0.000941  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.07e+04 |\n",
      "|    total_cost         | 1.82e+04  |\n",
      "|    total_reward       | -6.07e+04 |\n",
      "|    total_reward_pct   | -121      |\n",
      "|    total_trades       | 26925     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 293       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 2.5       |\n",
      "|    std                | 61.3      |\n",
      "|    value_loss         | 0.000901  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 295       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -106      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -0.0214   |\n",
      "|    std                | 63.4      |\n",
      "|    value_loss         | 7.55e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | -0.146   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.799   |\n",
      "|    std                | 65.3     |\n",
      "|    value_loss         | 0.00015  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -1.83    |\n",
      "|    std                | 67.2     |\n",
      "|    value_loss         | 0.000367 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.5e+03   |\n",
      "|    total_cost         | 2.3e+04   |\n",
      "|    total_reward       | -4.55e+04 |\n",
      "|    total_reward_pct   | -91       |\n",
      "|    total_trades       | 27149     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 300       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -107      |\n",
      "|    explained_variance | -8.95     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -0.928    |\n",
      "|    std                | 69.3      |\n",
      "|    value_loss         | 0.000559  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.822    |\n",
      "|    std                | 71       |\n",
      "|    value_loss         | 0.000161 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 304       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -108      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 0.598     |\n",
      "|    std                | 73.1      |\n",
      "|    value_loss         | 0.00083   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | -0.141   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.475   |\n",
      "|    std                | 74.9     |\n",
      "|    value_loss         | 0.000232 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | -0.0916  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 76.8     |\n",
      "|    value_loss         | 0.000536 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.34e+03  |\n",
      "|    total_cost         | 3.96e+04  |\n",
      "|    total_reward       | -4.37e+04 |\n",
      "|    total_reward_pct   | -87.3     |\n",
      "|    total_trades       | 28767     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -110      |\n",
      "|    explained_variance | -1.37     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 1.03      |\n",
      "|    std                | 78.7      |\n",
      "|    value_loss         | 0.000124  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.0476   |\n",
      "|    std                | 80.8     |\n",
      "|    value_loss         | 4.62e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | 0.185    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 1.34     |\n",
      "|    std                | 83.5     |\n",
      "|    value_loss         | 0.00018  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -2       |\n",
      "|    std                | 86.6     |\n",
      "|    value_loss         | 0.000458 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 316       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -112      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | -0.23     |\n",
      "|    std                | 89.6      |\n",
      "|    value_loss         | 6.93e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.82e+03  |\n",
      "|    total_cost         | 1.97e+04  |\n",
      "|    total_reward       | -4.82e+04 |\n",
      "|    total_reward_pct   | -96.4     |\n",
      "|    total_trades       | 27182     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 318       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -113      |\n",
      "|    explained_variance | 0.036     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 21.8      |\n",
      "|    std                | 93        |\n",
      "|    value_loss         | 0.0634    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 96.2     |\n",
      "|    value_loss         | 0.000138 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | -1.2     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -2.46    |\n",
      "|    std                | 99.2     |\n",
      "|    value_loss         | 0.000878 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 323       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -115      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | 3.02      |\n",
      "|    std                | 102       |\n",
      "|    value_loss         | 0.000758  |\n",
      "-------------------------------------\n",
      "day: 2334, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3428.92\n",
      "total_reward: -46571.08\n",
      "total_cost: 31526.42\n",
      "total_trades: 27968\n",
      "Sharpe: 0.169\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.43e+03  |\n",
      "|    total_cost         | 3.15e+04  |\n",
      "|    total_reward       | -4.66e+04 |\n",
      "|    total_reward_pct   | -93.1     |\n",
      "|    total_trades       | 27968     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -115      |\n",
      "|    explained_variance | -0.906    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -1.06     |\n",
      "|    std                | 104       |\n",
      "|    value_loss         | 0.000149  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -116     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -0.618   |\n",
      "|    std                | 108      |\n",
      "|    value_loss         | 0.000131 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -116     |\n",
      "|    explained_variance | 0.0318   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -3.4     |\n",
      "|    std                | 111      |\n",
      "|    value_loss         | 0.000891 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -117     |\n",
      "|    explained_variance | 1.98e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -0.212   |\n",
      "|    std                | 114      |\n",
      "|    value_loss         | 0.000111 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -117     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 0.0223   |\n",
      "|    std                | 117      |\n",
      "|    value_loss         | 1.85e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.92e+03  |\n",
      "|    total_cost         | 2.53e+04  |\n",
      "|    total_reward       | -4.71e+04 |\n",
      "|    total_reward_pct   | -94.2     |\n",
      "|    total_trades       | 27736     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 334       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -118      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 0.625     |\n",
      "|    std                | 122       |\n",
      "|    value_loss         | 3.64e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -119     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.373   |\n",
      "|    std                | 127      |\n",
      "|    value_loss         | 1.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -120     |\n",
      "|    explained_variance | 0.175    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    std                | 131      |\n",
      "|    value_loss         | 0.000222 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -120     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 135      |\n",
      "|    value_loss         | 0.000284 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -121     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 0.447    |\n",
      "|    std                | 138      |\n",
      "|    value_loss         | 3.83e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.22e+03  |\n",
      "|    total_cost         | 3.03e+04  |\n",
      "|    total_reward       | -4.48e+04 |\n",
      "|    total_reward_pct   | -89.6     |\n",
      "|    total_trades       | 27604     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 343       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -121      |\n",
      "|    explained_variance | -1.85     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 0.739     |\n",
      "|    std                | 141       |\n",
      "|    value_loss         | 0.000146  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -122     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.903    |\n",
      "|    std                | 145      |\n",
      "|    value_loss         | 9.74e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 346      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -122     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 2.2      |\n",
      "|    std                | 150      |\n",
      "|    value_loss         | 0.000377 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -123     |\n",
      "|    explained_variance | -0.00942 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.27    |\n",
      "|    std                | 156      |\n",
      "|    value_loss         | 9.36e-06 |\n",
      "------------------------------------\n",
      "======Trading from:  2019-07-05 to  2019-10-02\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2000-01-01 to  2019-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 284      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -2.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.00563  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.0655   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -2.54    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0087   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -3.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.833   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00506  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -220     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 14.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.395    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.51e+04  |\n",
      "|    total_cost         | 6.55e+04  |\n",
      "|    total_reward       | -1.49e+04 |\n",
      "|    total_reward_pct   | -29.8     |\n",
      "|    total_trades       | 29429     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -253      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -0.194    |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.00913   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -68.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.533   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00719  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -5.98    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -1.17    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00214  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | -155     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.258   |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.000993 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -42.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.24     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00138  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.7e+03   |\n",
      "|    total_cost         | 1.32e+04  |\n",
      "|    total_reward       | -4.43e+04 |\n",
      "|    total_reward_pct   | -88.6     |\n",
      "|    total_trades       | 25639     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | -5.4      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 0.219     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 9.86e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -2.39    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00207  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.556    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.000708 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -0.0899  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0974   |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.000221 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -0.215   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.566   |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00625  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.57e+04 |\n",
      "|    total_cost         | 8.55e+03 |\n",
      "|    total_reward       | 2.57e+04 |\n",
      "|    total_reward_pct   | 51.4     |\n",
      "|    total_trades       | 23887    |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -2.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.991    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -108     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.00567  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.137   |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 4.17e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00177  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.27e+03  |\n",
      "|    total_cost         | 1.81e+03  |\n",
      "|    total_reward       | -4.07e+04 |\n",
      "|    total_reward_pct   | -81.5     |\n",
      "|    total_trades       | 23146     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.9     |\n",
      "|    explained_variance | -99.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -0.653    |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.00145   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | -49.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 5.17     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.027    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | -29.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.585    |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.00386  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | 0.366    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.0734  |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 9.7e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0.215    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00129  |\n",
      "------------------------------------\n",
      "day: 2334, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21175.89\n",
      "total_reward: -28824.11\n",
      "total_cost: 17255.63\n",
      "total_trades: 26678\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.12e+04  |\n",
      "|    total_cost         | 1.73e+04  |\n",
      "|    total_reward       | -2.88e+04 |\n",
      "|    total_reward_pct   | -57.6     |\n",
      "|    total_trades       | 26678     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.6     |\n",
      "|    explained_variance | -0.366    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -1.44     |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 0.00282   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | -0.309   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -3.47    |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.0147   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.73    |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.000566 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -0.0104  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.00356  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | -6.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 2.58     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0156   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.22e+04 |\n",
      "|    total_cost         | 2.23e+04 |\n",
      "|    total_reward       | 2.19e+03 |\n",
      "|    total_reward_pct   | 4.39     |\n",
      "|    total_trades       | 27020    |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | -11.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -3.66    |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.00286  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | -0.0728  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 1.89     |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.00354  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.744   |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.00102  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.92e+04  |\n",
      "|    total_cost         | 2.17e+04  |\n",
      "|    total_reward       | -3.08e+04 |\n",
      "|    total_reward_pct   | -61.6     |\n",
      "|    total_trades       | 26506     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.2     |\n",
      "|    explained_variance | -28.2     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 0.575     |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 0.000692  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | -7.15    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.499    |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.000496 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -0.338   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.134   |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.000143 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.0815   |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 6.7e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | -15.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -1.45    |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.0035   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.95e+03 |\n",
      "|    total_cost         | 1.35e+04 |\n",
      "|    total_reward       | -4e+04   |\n",
      "|    total_reward_pct   | -80.1    |\n",
      "|    total_trades       | 25901    |\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | -0.408   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.85     |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.00617  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.566   |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.00226  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38.8     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 6.13      |\n",
      "|    std                | 1.87      |\n",
      "|    value_loss         | 0.023     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | -0.0363  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -2.87    |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.00762  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | -8.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 3.22     |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 0.00708  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.17e+04  |\n",
      "|    total_cost         | 1.29e+04  |\n",
      "|    total_reward       | -1.83e+04 |\n",
      "|    total_reward_pct   | -36.6     |\n",
      "|    total_trades       | 25815     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 3.17      |\n",
      "|    std                | 1.95      |\n",
      "|    value_loss         | 0.00715   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 0.388     |\n",
      "|    std                | 1.99      |\n",
      "|    value_loss         | 0.00012   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.574   |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.000488 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | -0.165   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.2     |\n",
      "|    std                | 2.08     |\n",
      "|    value_loss         | 0.000241 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -765.95\n",
      "total_reward: -50765.95\n",
      "total_cost: 7187.29\n",
      "total_trades: 23155\n",
      "Sharpe: 0.191\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -766      |\n",
      "|    total_cost         | 7.19e+03  |\n",
      "|    total_reward       | -5.08e+04 |\n",
      "|    total_reward_pct   | -102      |\n",
      "|    total_trades       | 23155     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0.308     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 1.35      |\n",
      "|    std                | 2.13      |\n",
      "|    value_loss         | 0.0013    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | -1.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.6      |\n",
      "|    std                | 2.16     |\n",
      "|    value_loss         | 0.00234  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | 0.901    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 2.17     |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 0.0026   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.868    |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 0.000541 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0117   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.564    |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.0014   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.04e+04  |\n",
      "|    total_cost         | 3.3e+04   |\n",
      "|    total_reward       | -2.96e+04 |\n",
      "|    total_reward_pct   | -59.3     |\n",
      "|    total_trades       | 26903     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -0.998    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -0.479    |\n",
      "|    std                | 2.33      |\n",
      "|    value_loss         | 0.00023   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -1.22    |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.000874 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.259   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.251    |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.000114 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0.513    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.285   |\n",
      "|    std                | 2.48     |\n",
      "|    value_loss         | 7.22e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -5.51    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.419   |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.00014  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.73e+03  |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -4.13e+04 |\n",
      "|    total_reward_pct   | -82.5     |\n",
      "|    total_trades       | 25758     |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -1.17     |\n",
      "|    std                | 2.56      |\n",
      "|    value_loss         | 0.00478   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0.26     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -4.28    |\n",
      "|    std                | 2.58     |\n",
      "|    value_loss         | 0.0157   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0.0365   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.259    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.000762 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0.0212   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    std                | 2.64     |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.56e+04 |\n",
      "|    total_cost         | 4.22e+04 |\n",
      "|    total_reward       | 5.63e+03 |\n",
      "|    total_reward_pct   | 11.3     |\n",
      "|    total_trades       | 26836    |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | -3       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.354    |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 0.000102 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | -6.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.831   |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 0.000363 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | -5.71    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.956   |\n",
      "|    std                | 2.78     |\n",
      "|    value_loss         | 0.0006   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -2.34    |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.00341  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | -5.01e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 2.25      |\n",
      "|    std                | 2.87      |\n",
      "|    value_loss         | 0.00288   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.73e+04  |\n",
      "|    total_cost         | 1.74e+04  |\n",
      "|    total_reward       | -3.27e+04 |\n",
      "|    total_reward_pct   | -65.3     |\n",
      "|    total_trades       | 24754     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | 0.0204    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 7.34      |\n",
      "|    std                | 2.9       |\n",
      "|    value_loss         | 0.0353    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -2.56    |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 0.00807  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0.00584  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -2.2     |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 0.00397  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0.0141   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -8.31    |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 0.042    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | -0.572   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 7.15     |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.0267   |\n",
      "------------------------------------\n",
      "day: 2334, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 73651.78\n",
      "total_reward: 23651.78\n",
      "total_cost: 23068.31\n",
      "total_trades: 24478\n",
      "Sharpe: 0.297\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.37e+04 |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | 2.37e+04 |\n",
      "|    total_reward_pct   | 47.3     |\n",
      "|    total_trades       | 24478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.00282  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -2.64    |\n",
      "|    std                | 3.07     |\n",
      "|    value_loss         | 0.0124   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | -0.318   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.304    |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.000945 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -2.37    |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.0024   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.84e+03  |\n",
      "|    total_cost         | 3.56e+03  |\n",
      "|    total_reward       | -4.12e+04 |\n",
      "|    total_reward_pct   | -82.3     |\n",
      "|    total_trades       | 21162     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.1     |\n",
      "|    explained_variance | -1.12     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 0.609     |\n",
      "|    std                | 3.2       |\n",
      "|    value_loss         | 0.000285  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | -0.0531  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.671   |\n",
      "|    std                | 3.26     |\n",
      "|    value_loss         | 0.000295 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | -1.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    std                | 3.33     |\n",
      "|    value_loss         | 0.153    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | 0.253    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.69    |\n",
      "|    std                | 3.4      |\n",
      "|    value_loss         | 0.00122  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 2.37     |\n",
      "|    std                | 3.45     |\n",
      "|    value_loss         | 0.00272  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.42e+04 |\n",
      "|    total_cost         | 3.93e+03  |\n",
      "|    total_reward       | -6.42e+04 |\n",
      "|    total_reward_pct   | -128      |\n",
      "|    total_trades       | 21346     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.8     |\n",
      "|    explained_variance | -7        |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 1.14      |\n",
      "|    std                | 3.51      |\n",
      "|    value_loss         | 0.00118   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    std                | 3.58     |\n",
      "|    value_loss         | 0.00135  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.339    |\n",
      "|    std                | 3.64     |\n",
      "|    value_loss         | 0.0003   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 0.976     |\n",
      "|    std                | 3.71      |\n",
      "|    value_loss         | 0.000597  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 3.69     |\n",
      "|    std                | 3.77     |\n",
      "|    value_loss         | 0.0067   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.12e+04 |\n",
      "|    total_cost         | 3.85e+03  |\n",
      "|    total_reward       | -7.12e+04 |\n",
      "|    total_reward_pct   | -142      |\n",
      "|    total_trades       | 21866     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 0.337     |\n",
      "|    std                | 3.83      |\n",
      "|    value_loss         | 0.000286  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.208    |\n",
      "|    std                | 3.92     |\n",
      "|    value_loss         | 0.000394 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -1.37    |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.00109  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.484    |\n",
      "|    std                | 4.06     |\n",
      "|    value_loss         | 0.000164 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.18e+03 |\n",
      "|    total_cost         | 4.75e+03  |\n",
      "|    total_reward       | -5.42e+04 |\n",
      "|    total_reward_pct   | -108      |\n",
      "|    total_trades       | 22207     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.9     |\n",
      "|    explained_variance | -0.0556   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 5.5       |\n",
      "|    std                | 4.14      |\n",
      "|    value_loss         | 0.013     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 4.62     |\n",
      "|    std                | 4.18     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 3.78     |\n",
      "|    std                | 4.23     |\n",
      "|    value_loss         | 0.00456  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -0.727    |\n",
      "|    std                | 4.29      |\n",
      "|    value_loss         | 0.00311   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | -0.424   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -2.46    |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.00282  |\n",
      "------------------------------------\n",
      "day: 2334, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1315.68\n",
      "total_reward: -48684.32\n",
      "total_cost: 8993.28\n",
      "total_trades: 22858\n",
      "Sharpe: 0.308\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.32e+03  |\n",
      "|    total_cost         | 8.99e+03  |\n",
      "|    total_reward       | -4.87e+04 |\n",
      "|    total_reward_pct   | -97.4     |\n",
      "|    total_trades       | 22858     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.1     |\n",
      "|    explained_variance | -1.16     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -1.65     |\n",
      "|    std                | 4.4       |\n",
      "|    value_loss         | 0.00177   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 4.48     |\n",
      "|    value_loss         | 0.000418 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | -0.203   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 3.11     |\n",
      "|    std                | 4.56     |\n",
      "|    value_loss         | 0.00374  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -8.72    |\n",
      "|    std                | 4.61     |\n",
      "|    value_loss         | 0.0301   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | -6.71    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.857   |\n",
      "|    std                | 4.68     |\n",
      "|    value_loss         | 0.000507 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.16e+04  |\n",
      "|    total_cost         | 8.4e+03   |\n",
      "|    total_reward       | -3.84e+04 |\n",
      "|    total_reward_pct   | -76.7     |\n",
      "|    total_trades       | 22204     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 0.487     |\n",
      "|    std                | 4.75      |\n",
      "|    value_loss         | 0.000386  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.696   |\n",
      "|    std                | 4.82     |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | -0.00368 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 4.88     |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 8.86     |\n",
      "|    std                | 4.92     |\n",
      "|    value_loss         | 0.0284   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.87e+04 |\n",
      "|    total_cost         | 4.13e+04 |\n",
      "|    total_reward       | 2.87e+04 |\n",
      "|    total_reward_pct   | 57.5     |\n",
      "|    total_trades       | 24759    |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.4    |\n",
      "|    explained_variance | 0.0678   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 0.447    |\n",
      "|    std                | 4.98     |\n",
      "|    value_loss         | 9.91e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.7    |\n",
      "|    explained_variance | -72      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -1.19    |\n",
      "|    std                | 5.06     |\n",
      "|    value_loss         | 0.00211  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.689    |\n",
      "|    std                | 5.17     |\n",
      "|    value_loss         | 0.000426 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 0.609    |\n",
      "|    std                | 5.26     |\n",
      "|    value_loss         | 0.00033  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | -0.0108  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -2.54    |\n",
      "|    std                | 5.36     |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.6e+04  |\n",
      "|    total_cost         | 2.1e+04  |\n",
      "|    total_reward       | -3.4e+04 |\n",
      "|    total_reward_pct   | -67.9    |\n",
      "|    total_trades       | 24107    |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | -0.429   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -2.92    |\n",
      "|    std                | 5.44     |\n",
      "|    value_loss         | 0.0288   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 5.34     |\n",
      "|    std                | 5.5      |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.5    |\n",
      "|    explained_variance | -0.216   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 2.1      |\n",
      "|    std                | 5.56     |\n",
      "|    value_loss         | 0.00225  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -58.3    |\n",
      "|    std                | 5.62     |\n",
      "|    value_loss         | 0.992    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -2.15    |\n",
      "|    std                | 5.69     |\n",
      "|    value_loss         | 0.00152  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.27e+04  |\n",
      "|    total_cost         | 3.23e+04  |\n",
      "|    total_reward       | -2.73e+04 |\n",
      "|    total_reward_pct   | -54.5     |\n",
      "|    total_trades       | 25459     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -0.441    |\n",
      "|    std                | 5.73      |\n",
      "|    value_loss         | 0.00338   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.2    |\n",
      "|    explained_variance | -3.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 3.9      |\n",
      "|    std                | 5.77     |\n",
      "|    value_loss         | 0.00419  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.3    |\n",
      "|    explained_variance | -0.194   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 2.94     |\n",
      "|    std                | 5.81     |\n",
      "|    value_loss         | 0.00776  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.4    |\n",
      "|    explained_variance | -0.338   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 4.74     |\n",
      "|    std                | 5.84     |\n",
      "|    value_loss         | 0.0296   |\n",
      "------------------------------------\n",
      "day: 2334, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 137292.59\n",
      "total_reward: 87292.59\n",
      "total_cost: 67302.52\n",
      "total_trades: 26957\n",
      "Sharpe: 0.519\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+05 |\n",
      "|    total_cost         | 6.73e+04 |\n",
      "|    total_reward       | 8.73e+04 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 26957    |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.5    |\n",
      "|    explained_variance | -0.648   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 5.86     |\n",
      "|    value_loss         | 0.00041  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.0836  |\n",
      "|    std                | 5.95     |\n",
      "|    value_loss         | 3.07e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -2.05    |\n",
      "|    std                | 6.07     |\n",
      "|    value_loss         | 0.0013   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -2.94    |\n",
      "|    std                | 6.18     |\n",
      "|    value_loss         | 0.00254  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 3.79     |\n",
      "|    std                | 6.3      |\n",
      "|    value_loss         | 0.00397  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.19e+04  |\n",
      "|    total_cost         | 3.37e+04  |\n",
      "|    total_reward       | -2.81e+04 |\n",
      "|    total_reward_pct   | -56.3     |\n",
      "|    total_trades       | 25006     |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 211       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.2     |\n",
      "|    explained_variance | -1.33     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -0.155    |\n",
      "|    std                | 6.41      |\n",
      "|    value_loss         | 0.000262  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.93     |\n",
      "|    std                | 6.54     |\n",
      "|    value_loss         | 0.000602 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63      |\n",
      "|    explained_variance | -1.26    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    std                | 6.69     |\n",
      "|    value_loss         | 0.000543 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.5    |\n",
      "|    explained_variance | 0.496    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 1.34     |\n",
      "|    std                | 6.87     |\n",
      "|    value_loss         | 0.000469 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 0.0221    |\n",
      "|    std                | 7.07      |\n",
      "|    value_loss         | 4.57e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.48e+03  |\n",
      "|    total_cost         | 2.11e+04  |\n",
      "|    total_reward       | -4.65e+04 |\n",
      "|    total_reward_pct   | -93       |\n",
      "|    total_trades       | 24927     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 220       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.5     |\n",
      "|    explained_variance | -1.76     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -0.357    |\n",
      "|    std                | 7.25      |\n",
      "|    value_loss         | 0.000169  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 2.41     |\n",
      "|    std                | 7.43     |\n",
      "|    value_loss         | 0.00166  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.5    |\n",
      "|    explained_variance | 0.0953   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    std                | 7.64     |\n",
      "|    value_loss         | 6.7e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.2    |\n",
      "|    explained_variance | -41      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -0.552   |\n",
      "|    std                | 7.91     |\n",
      "|    value_loss         | 9.55e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 307       |\n",
      "|    total_cost         | 1.08e+04  |\n",
      "|    total_reward       | -4.97e+04 |\n",
      "|    total_reward_pct   | -99.4     |\n",
      "|    total_trades       | 23652     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67       |\n",
      "|    explained_variance | -0.134    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 1.87      |\n",
      "|    std                | 8.23      |\n",
      "|    value_loss         | 0.00105   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.4    |\n",
      "|    explained_variance | -2.52    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 0.523    |\n",
      "|    std                | 8.44     |\n",
      "|    value_loss         | 0.000119 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.05     |\n",
      "|    std                | 8.68     |\n",
      "|    value_loss         | 2.14e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.6    |\n",
      "|    explained_variance | -0.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 0.225    |\n",
      "|    std                | 8.98     |\n",
      "|    value_loss         | 1.91e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 0.111    |\n",
      "|    std                | 9.34     |\n",
      "|    value_loss         | 4.48e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.2e+03   |\n",
      "|    total_cost         | 1.38e+04  |\n",
      "|    total_reward       | -4.88e+04 |\n",
      "|    total_reward_pct   | -97.6     |\n",
      "|    total_trades       | 24968     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 236       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0.0996    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 0.458     |\n",
      "|    std                | 9.65      |\n",
      "|    value_loss         | 0.000244  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 0.251     |\n",
      "|    std                | 9.91      |\n",
      "|    value_loss         | 2.12e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 0.371    |\n",
      "|    std                | 10.2     |\n",
      "|    value_loss         | 3.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.8    |\n",
      "|    explained_variance | -0.167   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 2.08     |\n",
      "|    std                | 10.6     |\n",
      "|    value_loss         | 0.00114  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.229   |\n",
      "|    std                | 11.1     |\n",
      "|    value_loss         | 5.6e-05  |\n",
      "------------------------------------\n",
      "day: 2334, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -747.79\n",
      "total_reward: -50747.79\n",
      "total_cost: 16694.22\n",
      "total_trades: 25147\n",
      "Sharpe: -0.165\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -748      |\n",
      "|    total_cost         | 1.67e+04  |\n",
      "|    total_reward       | -5.07e+04 |\n",
      "|    total_reward_pct   | -101      |\n",
      "|    total_trades       | 25147     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.2     |\n",
      "|    explained_variance | 0.209     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -1.1      |\n",
      "|    std                | 11.4      |\n",
      "|    value_loss         | 0.00033   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.8    |\n",
      "|    explained_variance | -0.447   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.0666   |\n",
      "|    std                | 11.8     |\n",
      "|    value_loss         | 8.06e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 248       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -2.16     |\n",
      "|    std                | 12.1      |\n",
      "|    value_loss         | 0.00123   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.7    |\n",
      "|    explained_variance | -0.224   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 0.542    |\n",
      "|    std                | 12.4     |\n",
      "|    value_loss         | 0.000112 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.53e+03  |\n",
      "|    total_cost         | 3.35e+04  |\n",
      "|    total_reward       | -4.55e+04 |\n",
      "|    total_reward_pct   | -90.9     |\n",
      "|    total_trades       | 26506     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 252       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.3     |\n",
      "|    explained_variance | -0.403    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 1.16      |\n",
      "|    std                | 12.7      |\n",
      "|    value_loss         | 0.000279  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.8    |\n",
      "|    explained_variance | 0.389    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.305   |\n",
      "|    std                | 13.1     |\n",
      "|    value_loss         | 1.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 0.165    |\n",
      "|    std                | 13.5     |\n",
      "|    value_loss         | 8.98e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -0.241   |\n",
      "|    std                | 14       |\n",
      "|    value_loss         | 1.09e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -0.0435   |\n",
      "|    std                | 14.6      |\n",
      "|    value_loss         | 3.53e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 468       |\n",
      "|    total_cost         | 1.06e+04  |\n",
      "|    total_reward       | -4.95e+04 |\n",
      "|    total_reward_pct   | -99.1     |\n",
      "|    total_trades       | 25043     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78.4     |\n",
      "|    explained_variance | -1.39     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -1.87     |\n",
      "|    std                | 15        |\n",
      "|    value_loss         | 0.000996  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 262       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -2.38     |\n",
      "|    std                | 15.4      |\n",
      "|    value_loss         | 0.000958  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.221   |\n",
      "|    std                | 15.8     |\n",
      "|    value_loss         | 1.98e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -0.653   |\n",
      "|    std                | 16.3     |\n",
      "|    value_loss         | 0.000101 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.6    |\n",
      "|    explained_variance | -31.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.134    |\n",
      "|    std                | 16.9     |\n",
      "|    value_loss         | 2.28e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.47e+03  |\n",
      "|    total_cost         | 2.37e+04  |\n",
      "|    total_reward       | -4.85e+04 |\n",
      "|    total_reward_pct   | -97.1     |\n",
      "|    total_trades       | 26596     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -2.98     |\n",
      "|    std                | 17.4      |\n",
      "|    value_loss         | 0.002     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.168   |\n",
      "|    std                | 17.9     |\n",
      "|    value_loss         | 3.7e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 18.5     |\n",
      "|    value_loss         | 0.000875 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83      |\n",
      "|    explained_variance | 0.157    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -1       |\n",
      "|    std                | 19.2     |\n",
      "|    value_loss         | 0.000239 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.25e+04 |\n",
      "|    total_cost         | 2.13e+04  |\n",
      "|    total_reward       | -6.25e+04 |\n",
      "|    total_reward_pct   | -125      |\n",
      "|    total_trades       | 26366     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 276       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -83.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 0.895     |\n",
      "|    std                | 19.8      |\n",
      "|    value_loss         | 0.000784  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84      |\n",
      "|    explained_variance | -0.294   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 1.9      |\n",
      "|    std                | 20.2     |\n",
      "|    value_loss         | 0.00084  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 2.26     |\n",
      "|    std                | 20.7     |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.8    |\n",
      "|    explained_variance | 0.0302   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -1.8     |\n",
      "|    std                | 21       |\n",
      "|    value_loss         | 0.000629 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.1    |\n",
      "|    explained_variance | -1.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.501   |\n",
      "|    std                | 21.4     |\n",
      "|    value_loss         | 0.000149 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8927.99\n",
      "total_reward: -41072.01\n",
      "total_cost: 55383.68\n",
      "total_trades: 28927\n",
      "Sharpe: -0.135\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.93e+03  |\n",
      "|    total_cost         | 5.54e+04  |\n",
      "|    total_reward       | -4.11e+04 |\n",
      "|    total_reward_pct   | -82.1     |\n",
      "|    total_trades       | 28927     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 285       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.6     |\n",
      "|    explained_variance | -0.0732   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -0.195    |\n",
      "|    std                | 21.9      |\n",
      "|    value_loss         | 5.89e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -0.53    |\n",
      "|    std                | 22.6     |\n",
      "|    value_loss         | 3.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.7    |\n",
      "|    explained_variance | -0.579   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -4.78    |\n",
      "|    std                | 23.3     |\n",
      "|    value_loss         | 0.00307  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.546    |\n",
      "|    std                | 23.9     |\n",
      "|    value_loss         | 5.75e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.8    |\n",
      "|    explained_variance | -22.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 0.892    |\n",
      "|    std                | 24.7     |\n",
      "|    value_loss         | 0.000151 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.97e+03 |\n",
      "|    total_cost         | 2.22e+04 |\n",
      "|    total_reward       | -4.8e+04 |\n",
      "|    total_reward_pct   | -96.1    |\n",
      "|    total_trades       | 26510    |\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.2    |\n",
      "|    explained_variance | -0.955   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 5.33     |\n",
      "|    std                | 25.2     |\n",
      "|    value_loss         | 0.00465  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    std                | 25.7     |\n",
      "|    value_loss         | 0.000287 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.1    |\n",
      "|    explained_variance | -0.0728  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 26.4     |\n",
      "|    value_loss         | 0.00103  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.7    |\n",
      "|    explained_variance | -0.0266  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.521   |\n",
      "|    std                | 27.3     |\n",
      "|    value_loss         | 4.94e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 799       |\n",
      "|    total_cost         | 2.5e+04   |\n",
      "|    total_reward       | -4.92e+04 |\n",
      "|    total_reward_pct   | -98.4     |\n",
      "|    total_trades       | 27136     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 300       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -90.4     |\n",
      "|    explained_variance | -0.0191   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 2.5       |\n",
      "|    std                | 28.3      |\n",
      "|    value_loss         | 0.00102   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.228    |\n",
      "|    std                | 29.3     |\n",
      "|    value_loss         | 1.45e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.96    |\n",
      "|    std                | 30.5     |\n",
      "|    value_loss         | 0.000294 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 306       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -92.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -1.39     |\n",
      "|    std                | 31.4      |\n",
      "|    value_loss         | 0.000365  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93      |\n",
      "|    explained_variance | 0.0971   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -0.132   |\n",
      "|    std                | 32.4     |\n",
      "|    value_loss         | 8.72e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.64e+03  |\n",
      "|    total_cost         | 2.37e+04  |\n",
      "|    total_reward       | -4.74e+04 |\n",
      "|    total_reward_pct   | -94.7     |\n",
      "|    total_trades       | 26823     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93.6     |\n",
      "|    explained_variance | -0.0146   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | -0.849    |\n",
      "|    std                | 33.4      |\n",
      "|    value_loss         | 0.000114  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.258    |\n",
      "|    std                | 34.5     |\n",
      "|    value_loss         | 2.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.8    |\n",
      "|    explained_variance | 0.096    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.476    |\n",
      "|    std                | 35.7     |\n",
      "|    value_loss         | 3.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.6    |\n",
      "|    explained_variance | -5.26    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 0.0697   |\n",
      "|    std                | 37.2     |\n",
      "|    value_loss         | 1.61e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.5    |\n",
      "|    explained_variance | -0.213   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -0.242   |\n",
      "|    std                | 39       |\n",
      "|    value_loss         | 1.1e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -110      |\n",
      "|    total_cost         | 1.06e+04  |\n",
      "|    total_reward       | -5.01e+04 |\n",
      "|    total_reward_pct   | -100      |\n",
      "|    total_trades       | 25643     |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 318       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -97.1     |\n",
      "|    explained_variance | -1.09     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | -3.32     |\n",
      "|    std                | 40.2      |\n",
      "|    value_loss         | 0.0017    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 0.27     |\n",
      "|    std                | 41.3     |\n",
      "|    value_loss         | 3.01e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.2    |\n",
      "|    explained_variance | -1.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 0.322    |\n",
      "|    std                | 42.6     |\n",
      "|    value_loss         | 0.000279 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.6    |\n",
      "|    explained_variance | -0.0805  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 2.22     |\n",
      "|    std                | 43.5     |\n",
      "|    value_loss         | 0.000588 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5699.29\n",
      "total_reward: -44300.71\n",
      "total_cost: 35772.56\n",
      "total_trades: 27909\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.7e+03   |\n",
      "|    total_cost         | 3.58e+04  |\n",
      "|    total_reward       | -4.43e+04 |\n",
      "|    total_reward_pct   | -88.6     |\n",
      "|    total_trades       | 27909     |\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99.1     |\n",
      "|    explained_variance | 0.58      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 3.32      |\n",
      "|    std                | 44.6      |\n",
      "|    value_loss         | 0.00121   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.4    |\n",
      "|    explained_variance | 0.161    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -4.43    |\n",
      "|    std                | 45.5     |\n",
      "|    value_loss         | 0.00258  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.298   |\n",
      "|    std                | 46.4     |\n",
      "|    value_loss         | 8.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | -0.921   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -0.233   |\n",
      "|    std                | 47.6     |\n",
      "|    value_loss         | 1.24e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 4.52e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 0.225    |\n",
      "|    std                | 49.2     |\n",
      "|    value_loss         | 7.86e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 55.1      |\n",
      "|    total_cost         | 2.83e+04  |\n",
      "|    total_reward       | -4.99e+04 |\n",
      "|    total_reward_pct   | -99.9     |\n",
      "|    total_trades       | 27526     |\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 334       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | 0.305     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 6.97      |\n",
      "|    std                | 50.4      |\n",
      "|    value_loss         | 0.00501   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -7.28    |\n",
      "|    std                | 51.2     |\n",
      "|    value_loss         | 0.00514  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 0.35     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -3.32    |\n",
      "|    std                | 52       |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | -0.0715  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -0.278   |\n",
      "|    std                | 52.9     |\n",
      "|    value_loss         | 2.53e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -103      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | 0.316     |\n",
      "|    std                | 54.2      |\n",
      "|    value_loss         | 1.03e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.33e+03  |\n",
      "|    total_cost         | 4.67e+04  |\n",
      "|    total_reward       | -4.77e+04 |\n",
      "|    total_reward_pct   | -95.3     |\n",
      "|    total_trades       | 28761     |\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 343       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -103      |\n",
      "|    explained_variance | -33.4     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 0.844     |\n",
      "|    std                | 55.8      |\n",
      "|    value_loss         | 0.00021   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 345       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -104      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 0.0971    |\n",
      "|    std                | 57.8      |\n",
      "|    value_loss         | 8.57e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 4.12     |\n",
      "|    std                | 59.8     |\n",
      "|    value_loss         | 0.00169  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 61.4     |\n",
      "|    value_loss         | 0.000403 |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-07-05 to  2019-10-02\n",
      "A2C Sharpe Ratio:  -0.5504311671031271\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 347  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 5    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.88e+04    |\n",
      "|    total_cost           | 5.69e+04    |\n",
      "|    total_reward         | -3.12e+04   |\n",
      "|    total_reward_pct     | -62.3       |\n",
      "|    total_trades         | 29894       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 342         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013706067 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.834      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0568      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 13263.02\n",
      "total_reward: -36736.98\n",
      "total_cost: 31587.72\n",
      "total_trades: 27941\n",
      "Sharpe: 0.013\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.33e+04     |\n",
      "|    total_cost           | 3.16e+04     |\n",
      "|    total_reward         | -3.67e+04    |\n",
      "|    total_reward_pct     | -73.5        |\n",
      "|    total_trades         | 27941        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 341          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035961028 |\n",
      "|    clip_fraction        | 0.0764       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.286       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0369       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.74e+03    |\n",
      "|    total_cost           | 2.51e+04    |\n",
      "|    total_reward         | -4.43e+04   |\n",
      "|    total_reward_pct     | -88.5       |\n",
      "|    total_trades         | 27666       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017632205 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.09e+04    |\n",
      "|    total_cost           | 2.2e+04     |\n",
      "|    total_reward         | -3.91e+04   |\n",
      "|    total_reward_pct     | -78.3       |\n",
      "|    total_trades         | 26804       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007904853 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0217      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.53e+03   |\n",
      "|    total_cost           | 1.62e+04   |\n",
      "|    total_reward         | -4.85e+04  |\n",
      "|    total_reward_pct     | -96.9      |\n",
      "|    total_trades         | 26053      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 340        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00773671 |\n",
      "|    clip_fraction        | 0.0868     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.304     |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0143     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.68e+03    |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -4.73e+04   |\n",
      "|    total_reward_pct     | -94.6       |\n",
      "|    total_trades         | 25963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009789851 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24969.46\n",
      "total_reward: -25030.54\n",
      "total_cost: 66779.90\n",
      "total_trades: 29751\n",
      "Sharpe: -0.214\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+04     |\n",
      "|    total_cost           | 6.68e+04    |\n",
      "|    total_reward         | -2.5e+04    |\n",
      "|    total_reward_pct     | -50.1       |\n",
      "|    total_trades         | 29751       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012208788 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.404      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0227      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013919831 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0201      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.02e+04     |\n",
      "|    total_cost           | 6.15e+04     |\n",
      "|    total_reward         | -1.98e+04    |\n",
      "|    total_reward_pct     | -39.6        |\n",
      "|    total_trades         | 29625        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076551456 |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.1        |\n",
      "|    explained_variance   | 0.0129       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.29        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0169       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 998         |\n",
      "|    total_cost           | 1.15e+04    |\n",
      "|    total_reward         | -4.9e+04    |\n",
      "|    total_reward_pct     | -98         |\n",
      "|    total_trades         | 25479       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008948491 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0121      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.24e+04    |\n",
      "|    total_cost           | 2.98e+04    |\n",
      "|    total_reward         | -3.76e+04   |\n",
      "|    total_reward_pct     | -75.1       |\n",
      "|    total_trades         | 27889       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018145815 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00911     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.89e+03    |\n",
      "|    total_cost           | 2.61e+04    |\n",
      "|    total_reward         | -4.31e+04   |\n",
      "|    total_reward_pct     | -86.2       |\n",
      "|    total_trades         | 27728       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015298038 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00924     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6546.29\n",
      "total_reward: -43453.71\n",
      "total_cost: 18496.20\n",
      "total_trades: 26906\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.55e+03    |\n",
      "|    total_cost           | 1.85e+04    |\n",
      "|    total_reward         | -4.35e+04   |\n",
      "|    total_reward_pct     | -86.9       |\n",
      "|    total_trades         | 26906       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008350299 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00817     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+04    |\n",
      "|    total_cost           | 2.19e+04    |\n",
      "|    total_reward         | -3.99e+04   |\n",
      "|    total_reward_pct     | -79.8       |\n",
      "|    total_trades         | 27456       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016577449 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00883     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+04    |\n",
      "|    total_cost           | 3.05e+04    |\n",
      "|    total_reward         | -2.72e+04   |\n",
      "|    total_reward_pct     | -54.5       |\n",
      "|    total_trades         | 28038       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010329354 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00725     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008566925 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.73e+03   |\n",
      "|    total_cost           | 1.95e+04   |\n",
      "|    total_reward         | -4.43e+04  |\n",
      "|    total_reward_pct     | -88.5      |\n",
      "|    total_trades         | 27233      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 340        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01916476 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | -0.0343    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.302     |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.00404    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.59e+04    |\n",
      "|    total_cost           | 2.45e+04    |\n",
      "|    total_reward         | -3.41e+04   |\n",
      "|    total_reward_pct     | -68.2       |\n",
      "|    total_trades         | 27397       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019297276 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00999     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5931.47\n",
      "total_reward: -44068.53\n",
      "total_cost: 20800.63\n",
      "total_trades: 27209\n",
      "Sharpe: -0.337\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.93e+03    |\n",
      "|    total_cost           | 2.08e+04    |\n",
      "|    total_reward         | -4.41e+04   |\n",
      "|    total_reward_pct     | -88.1       |\n",
      "|    total_trades         | 27209       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020805549 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00628     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.27e+04    |\n",
      "|    total_cost           | 5.25e+04    |\n",
      "|    total_reward         | 1.27e+04    |\n",
      "|    total_reward_pct     | 25.5        |\n",
      "|    total_trades         | 29539       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013190202 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | -0.245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.7e+04     |\n",
      "|    total_cost           | 2.5e+04     |\n",
      "|    total_reward         | -3.3e+04    |\n",
      "|    total_reward_pct     | -66         |\n",
      "|    total_trades         | 27427       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012305549 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.64e+04    |\n",
      "|    total_cost           | 2.73e+04    |\n",
      "|    total_reward         | -3.36e+04   |\n",
      "|    total_reward_pct     | -67.3       |\n",
      "|    total_trades         | 28024       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011810852 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00895     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.62e+04    |\n",
      "|    total_cost           | 2.87e+04    |\n",
      "|    total_reward         | -1.38e+04   |\n",
      "|    total_reward_pct     | -27.6       |\n",
      "|    total_trades         | 27949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019624565 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 340        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01188717 |\n",
      "|    clip_fraction        | 0.0988     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.261      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.286     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0167     |\n",
      "----------------------------------------\n",
      "day: 2334, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 28016.60\n",
      "total_reward: -21983.40\n",
      "total_cost: 20925.81\n",
      "total_trades: 27204\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+04     |\n",
      "|    total_cost           | 2.09e+04    |\n",
      "|    total_reward         | -2.2e+04    |\n",
      "|    total_reward_pct     | -44         |\n",
      "|    total_trades         | 27204       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021234173 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.35e+05    |\n",
      "|    total_cost           | 5.55e+04    |\n",
      "|    total_reward         | 8.45e+04    |\n",
      "|    total_reward_pct     | 169         |\n",
      "|    total_trades         | 29017       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011762658 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.0505      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.263      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0695      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 5.16e+04  |\n",
      "|    total_cost           | 3.67e+04  |\n",
      "|    total_reward         | 1.6e+03   |\n",
      "|    total_reward_pct     | 3.19      |\n",
      "|    total_trades         | 28504     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 339       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 168       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0177389 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.5     |\n",
      "|    explained_variance   | 0.195     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.285    |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.018    |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 0.0549    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.65e+03    |\n",
      "|    total_cost           | 1.07e+04    |\n",
      "|    total_reward         | -4.53e+04   |\n",
      "|    total_reward_pct     | -90.7       |\n",
      "|    total_trades         | 25592       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008194714 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+04    |\n",
      "|    total_cost           | 2.5e+04     |\n",
      "|    total_reward         | -2.03e+04   |\n",
      "|    total_reward_pct     | -40.6       |\n",
      "|    total_trades         | 27238       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010017744 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00816     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 33444.73\n",
      "total_reward: -16555.27\n",
      "total_cost: 23209.19\n",
      "total_trades: 27111\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.34e+04    |\n",
      "|    total_cost           | 2.32e+04    |\n",
      "|    total_reward         | -1.66e+04   |\n",
      "|    total_reward_pct     | -33.1       |\n",
      "|    total_trades         | 27111       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013864555 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.44e+04    |\n",
      "|    total_cost           | 1.7e+04     |\n",
      "|    total_reward         | -3.56e+04   |\n",
      "|    total_reward_pct     | -71.3       |\n",
      "|    total_trades         | 26535       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014769581 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017567784 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00863     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.43e+05    |\n",
      "|    total_cost           | 3.36e+04    |\n",
      "|    total_reward         | 9.35e+04    |\n",
      "|    total_reward_pct     | 187         |\n",
      "|    total_trades         | 27511       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905903 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0445      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.18e+04    |\n",
      "|    total_cost           | 1.85e+04    |\n",
      "|    total_reward         | -8.2e+03    |\n",
      "|    total_reward_pct     | -16.4       |\n",
      "|    total_trades         | 26129       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023764478 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0286      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.46e+04    |\n",
      "|    total_cost           | 2.04e+04    |\n",
      "|    total_reward         | 4.59e+03    |\n",
      "|    total_reward_pct     | 9.18        |\n",
      "|    total_trades         | 26600       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009110229 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 13825.13\n",
      "total_reward: -36174.87\n",
      "total_cost: 17029.50\n",
      "total_trades: 26239\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.38e+04    |\n",
      "|    total_cost           | 1.7e+04     |\n",
      "|    total_reward         | -3.62e+04   |\n",
      "|    total_reward_pct     | -72.3       |\n",
      "|    total_trades         | 26239       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018273072 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.39e+04   |\n",
      "|    total_cost           | 3.25e+04   |\n",
      "|    total_reward         | 2.39e+04   |\n",
      "|    total_reward_pct     | 47.7       |\n",
      "|    total_trades         | 27272      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 340        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01592381 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.298     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0207     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.6e+03     |\n",
      "|    total_cost           | 1.2e+04     |\n",
      "|    total_reward         | -4.34e+04   |\n",
      "|    total_reward_pct     | -86.8       |\n",
      "|    total_trades         | 25682       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013095597 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.1e+05     |\n",
      "|    total_cost           | 3.14e+04    |\n",
      "|    total_reward         | 6e+04       |\n",
      "|    total_reward_pct     | 120         |\n",
      "|    total_trades         | 27524       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019883242 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0099      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 340        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02128333 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.287     |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0461     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.91e+04    |\n",
      "|    total_cost           | 2.05e+04    |\n",
      "|    total_reward         | 9.11e+03    |\n",
      "|    total_reward_pct     | 18.2        |\n",
      "|    total_trades         | 26155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018187782 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0139      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 10773.31\n",
      "total_reward: -39226.69\n",
      "total_cost: 15453.68\n",
      "total_trades: 25904\n",
      "Sharpe: 0.042\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.08e+04    |\n",
      "|    total_cost           | 1.55e+04    |\n",
      "|    total_reward         | -3.92e+04   |\n",
      "|    total_reward_pct     | -78.5       |\n",
      "|    total_trades         | 25904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009356616 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00938     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+04    |\n",
      "|    total_cost           | 1.36e+04    |\n",
      "|    total_reward         | -3.93e+04   |\n",
      "|    total_reward_pct     | -78.5       |\n",
      "|    total_trades         | 25677       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015582972 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00798     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.4e+04     |\n",
      "|    total_cost           | 2.35e+04    |\n",
      "|    total_reward         | -1.6e+04    |\n",
      "|    total_reward_pct     | -32         |\n",
      "|    total_trades         | 26659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014806717 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00879     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.94e+03     |\n",
      "|    total_cost           | 1.3e+04      |\n",
      "|    total_reward         | -4.21e+04    |\n",
      "|    total_reward_pct     | -84.1        |\n",
      "|    total_trades         | 25693        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 341          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105135245 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.8        |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.286       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00824      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.24e+04    |\n",
      "|    total_cost           | 2.16e+04    |\n",
      "|    total_reward         | -3.76e+04   |\n",
      "|    total_reward_pct     | -75.3       |\n",
      "|    total_trades         | 26548       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013378785 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0059      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 11937.80\n",
      "total_reward: -38062.20\n",
      "total_cost: 13728.76\n",
      "total_trades: 25914\n",
      "Sharpe: 0.012\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+04    |\n",
      "|    total_cost           | 1.37e+04    |\n",
      "|    total_reward         | -3.81e+04   |\n",
      "|    total_reward_pct     | -76.1       |\n",
      "|    total_trades         | 25914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016431063 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00703     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016472232 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00562     |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-07-05 to  2019-10-02\n",
      "PPO Sharpe Ratio:  -0.4732578702470633\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
      "day: 2334, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 57082.18\n",
      "total_reward: 7082.18\n",
      "total_cost: 282.54\n",
      "total_trades: 22151\n",
      "Sharpe: 0.493\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.71e+04 |\n",
      "|    total_cost       | 283      |\n",
      "|    total_reward     | 7.08e+03 |\n",
      "|    total_reward_pct | 14.2     |\n",
      "|    total_trades     | 22151    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 80       |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total timesteps  | 9340     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 35.7     |\n",
      "|    critic_loss      | 3.24     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7005     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.73e+04  |\n",
      "|    total_cost       | 403       |\n",
      "|    total_reward     | -1.27e+04 |\n",
      "|    total_reward_pct | -25.5     |\n",
      "|    total_trades     | 22083     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 71        |\n",
      "|    time_elapsed     | 260       |\n",
      "|    total timesteps  | 18680     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 21.8      |\n",
      "|    critic_loss      | 0.875     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16345     |\n",
      "-----------------------------------\n",
      "day: 2334, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 42279.52\n",
      "total_reward: -7720.48\n",
      "total_cost: 459.69\n",
      "total_trades: 21106\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.13e+04 |\n",
      "|    total_cost       | 770      |\n",
      "|    total_reward     | 1.13e+04 |\n",
      "|    total_reward_pct | 22.6     |\n",
      "|    total_trades     | 18777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 394      |\n",
      "|    total timesteps  | 28020    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 11.2     |\n",
      "|    critic_loss      | 0.509    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25685    |\n",
      "----------------------------------\n",
      "day: 2334, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47783.95\n",
      "total_reward: -2216.05\n",
      "total_cost: 431.27\n",
      "total_trades: 19064\n",
      "Sharpe: 0.491\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.07e+04 |\n",
      "|    total_cost       | 469      |\n",
      "|    total_reward     | 2.07e+04 |\n",
      "|    total_reward_pct | 41.4     |\n",
      "|    total_trades     | 19654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 528      |\n",
      "|    total timesteps  | 37360    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 5.9      |\n",
      "|    critic_loss      | 0.306    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35025    |\n",
      "----------------------------------\n",
      "day: 2334, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 60195.25\n",
      "total_reward: 10195.25\n",
      "total_cost: 385.73\n",
      "total_trades: 21537\n",
      "Sharpe: 0.489\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.99e+04  |\n",
      "|    total_cost       | 208       |\n",
      "|    total_reward     | -1.01e+04 |\n",
      "|    total_reward_pct | -20.2     |\n",
      "|    total_trades     | 21203     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 70        |\n",
      "|    time_elapsed     | 662       |\n",
      "|    total timesteps  | 46700     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 3.04      |\n",
      "|    critic_loss      | 0.231     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 44365     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-07-05 to  2019-10-02\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-10-02\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_252_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.26e+05 |\n",
      "|    total_cost       | 387      |\n",
      "|    total_reward     | 7.59e+04 |\n",
      "|    total_reward_pct | 152      |\n",
      "|    total_trades     | 23110    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 87       |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total timesteps  | 9592     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 43.6     |\n",
      "|    critic_loss      | 66.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7194     |\n",
      "----------------------------------\n",
      "day: 2397, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 142043.01\n",
      "total_reward: 92043.01\n",
      "total_cost: 451.38\n",
      "total_trades: 23189\n",
      "Sharpe: 0.578\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.76e+04 |\n",
      "|    total_cost       | 203      |\n",
      "|    total_reward     | 7.63e+03 |\n",
      "|    total_reward_pct | 15.3     |\n",
      "|    total_trades     | 24965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total timesteps  | 19184    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 25.3     |\n",
      "|    critic_loss      | 9.87     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16786    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 140569.76\n",
      "total_reward: 90569.76\n",
      "total_cost: 891.01\n",
      "total_trades: 23176\n",
      "Sharpe: 0.567\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.56e+05 |\n",
      "|    total_cost       | 725      |\n",
      "|    total_reward     | 1.06e+05 |\n",
      "|    total_reward_pct | 211      |\n",
      "|    total_trades     | 23125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 74       |\n",
      "|    time_elapsed     | 385      |\n",
      "|    total timesteps  | 28776    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 14.1     |\n",
      "|    critic_loss      | 2.54     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 26378    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 35583.66\n",
      "total_reward: -14416.34\n",
      "total_cost: 293.35\n",
      "total_trades: 22325\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.84e+04 |\n",
      "|    total_cost       | 926      |\n",
      "|    total_reward     | 3.84e+04 |\n",
      "|    total_reward_pct | 76.8     |\n",
      "|    total_trades     | 22826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 530      |\n",
      "|    total timesteps  | 38368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 7.97     |\n",
      "|    critic_loss      | 1.01     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35970    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50741.64\n",
      "total_reward: 741.64\n",
      "total_cost: 527.85\n",
      "total_trades: 22982\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.07e+04 |\n",
      "|    total_cost       | 528      |\n",
      "|    total_reward     | 742      |\n",
      "|    total_reward_pct | 1.48     |\n",
      "|    total_trades     | 22982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 683      |\n",
      "|    total timesteps  | 47960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 4.49     |\n",
      "|    critic_loss      | 0.587    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45562    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-10-02 to  2020-01-03\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2000-01-01 to  2019-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -4.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 6.32     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.148    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -10.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -2.99    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -6.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00546  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0.515    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -9.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.67e+04  |\n",
      "|    total_cost         | 4.93e+04  |\n",
      "|    total_reward       | -3.32e+03 |\n",
      "|    total_reward_pct   | -6.63     |\n",
      "|    total_trades       | 29729     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -54.7     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 1.07      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.0149    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 263      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -13.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 3.3      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0224   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -7       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 2.36     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0141   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 268      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.00707  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 269      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -17.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -4.25    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0339   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.01e+04  |\n",
      "|    total_cost         | 3.91e+04  |\n",
      "|    total_reward       | -9.87e+03 |\n",
      "|    total_reward_pct   | -19.7     |\n",
      "|    total_trades       | 28695     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | -1.16     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -0.2      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.000377  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 269      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.238   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 8.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -0.792   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.69     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.588   |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.000572 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.122    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 2.74e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.05e+04  |\n",
      "|    total_cost         | 6.98e+03  |\n",
      "|    total_reward       | -3.95e+04 |\n",
      "|    total_reward_pct   | -79       |\n",
      "|    total_trades       | 24422     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -0.611    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 1.5       |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.00315   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.523   |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.000496 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.553    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.00047  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -0.175   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.979   |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.00126  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0.498    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -1.17    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.68e+04  |\n",
      "|    total_cost         | 7.52e+03  |\n",
      "|    total_reward       | -3.32e+04 |\n",
      "|    total_reward_pct   | -66.4     |\n",
      "|    total_trades       | 24229     |\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.7     |\n",
      "|    explained_variance | 0.0633    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 3.71      |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 0.0164    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | -3.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 6.93     |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.0422   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 2.99     |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.00793  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0.512    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 2.29     |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00532  |\n",
      "------------------------------------\n",
      "day: 2397, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 96297.51\n",
      "total_reward: 46297.51\n",
      "total_cost: 6487.17\n",
      "total_trades: 23434\n",
      "Sharpe: -0.345\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.63e+04 |\n",
      "|    total_cost         | 6.49e+03 |\n",
      "|    total_reward       | 4.63e+04 |\n",
      "|    total_reward_pct   | 92.6     |\n",
      "|    total_trades       | 23434    |\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | 0.136    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -16.4    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | -16.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -22.3    |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.496    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 1.76     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.00892  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0.144    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.00161 |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.00153  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | -25.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -12.9    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.9e+04  |\n",
      "|    total_cost         | 7.72e+03 |\n",
      "|    total_reward       | 8.96e+03 |\n",
      "|    total_reward_pct   | 17.9     |\n",
      "|    total_trades       | 23641    |\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -7.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00253  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | -0.555   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.938    |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.001    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.1    |\n",
      "|    explained_variance | 9.06e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 5.7      |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.0239   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0535  |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 2.88e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.124    |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 4.52e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.78e+03  |\n",
      "|    total_cost         | 1.23e+04  |\n",
      "|    total_reward       | -4.12e+04 |\n",
      "|    total_reward_pct   | -82.4     |\n",
      "|    total_trades       | 25910     |\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 0.57      |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 0.000683  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.9    |\n",
      "|    explained_variance | 0.0605   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.0102   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.00811  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 2.67      |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 0.00499   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.17e+04 |\n",
      "|    total_cost         | 1.99e+04 |\n",
      "|    total_reward       | 1.74e+03 |\n",
      "|    total_reward_pct   | 3.48     |\n",
      "|    total_trades       | 27748    |\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | 0.217    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.843    |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.000757 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.728   |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.000396 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | -0.746   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.0558   |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.00018  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | -0.394   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.543   |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | -1.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.285    |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.000221 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.4e+04  |\n",
      "|    total_cost         | 7.57e+03 |\n",
      "|    total_reward       | -2.6e+04 |\n",
      "|    total_reward_pct   | -52      |\n",
      "|    total_trades       | 25254    |\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | 0.259    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.917   |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.00163  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.725    |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.00324  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | 0.209    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 2.25     |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.00836  |\n",
      "------------------------------------\n",
      "day: 2397, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92718.44\n",
      "total_reward: 42718.44\n",
      "total_cost: 7801.00\n",
      "total_trades: 24756\n",
      "Sharpe: 0.380\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.27e+04 |\n",
      "|    total_cost         | 7.8e+03  |\n",
      "|    total_reward       | 4.27e+04 |\n",
      "|    total_reward_pct   | 85.4     |\n",
      "|    total_trades       | 24756    |\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -172     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 1.69     |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | -2.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.0425   |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.000441 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.696    |\n",
      "|    std                | 2.08     |\n",
      "|    value_loss         | 0.000485 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | -2.37    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.158    |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 7.27e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | -1.45    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.0896  |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.000122 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.4e+03  |\n",
      "|    total_cost         | 6.78e+03  |\n",
      "|    total_reward       | -5.24e+04 |\n",
      "|    total_reward_pct   | -105      |\n",
      "|    total_trades       | 25212     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 0.16      |\n",
      "|    std                | 2.23      |\n",
      "|    value_loss         | 2.46e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -11.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.405   |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.000137 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0248   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -2.16    |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.0408  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 3.41     |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.00695  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.739   |\n",
      "|    std                | 2.45     |\n",
      "|    value_loss         | 0.000494 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.32e+04  |\n",
      "|    total_cost         | 1.23e+04  |\n",
      "|    total_reward       | -2.68e+04 |\n",
      "|    total_reward_pct   | -53.7     |\n",
      "|    total_trades       | 25596     |\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -0.546    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -0.933    |\n",
      "|    std                | 2.49      |\n",
      "|    value_loss         | 0.000601  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -27.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.0239  |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.000845 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.0225   |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 0.00123  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 2.56     |\n",
      "|    std                | 2.64     |\n",
      "|    value_loss         | 0.00384  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 2.78     |\n",
      "|    std                | 2.7      |\n",
      "|    value_loss         | 0.00415  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.2e+03   |\n",
      "|    total_cost         | 6.33e+03  |\n",
      "|    total_reward       | -4.18e+04 |\n",
      "|    total_reward_pct   | -83.6     |\n",
      "|    total_trades       | 24262     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | 0.33      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -0.522    |\n",
      "|    std                | 2.75      |\n",
      "|    value_loss         | 0.000172  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0.048    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.983    |\n",
      "|    std                | 2.81     |\n",
      "|    value_loss         | 0.00153  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 3.17      |\n",
      "|    std                | 2.85      |\n",
      "|    value_loss         | 0.00545   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 1.51     |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.00208  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.594   |\n",
      "|    std                | 2.92     |\n",
      "|    value_loss         | 0.000216 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.27e+04  |\n",
      "|    total_cost         | 4.69e+03  |\n",
      "|    total_reward       | -3.73e+04 |\n",
      "|    total_reward_pct   | -74.5     |\n",
      "|    total_trades       | 23904     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.6     |\n",
      "|    explained_variance | -2.54     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -1.32     |\n",
      "|    std                | 2.97      |\n",
      "|    value_loss         | 0.0015    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0.00379  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.731   |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.000553 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.0862  |\n",
      "|    std                | 3.06     |\n",
      "|    value_loss         | 0.00163  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.82    |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.000436 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8356.31\n",
      "total_reward: -41643.69\n",
      "total_cost: 6141.15\n",
      "total_trades: 24242\n",
      "Sharpe: 0.042\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.36e+03  |\n",
      "|    total_cost         | 6.14e+03  |\n",
      "|    total_reward       | -4.16e+04 |\n",
      "|    total_reward_pct   | -83.3     |\n",
      "|    total_trades       | 24242     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.8     |\n",
      "|    explained_variance | -2.88     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -0.0194   |\n",
      "|    std                | 3.16      |\n",
      "|    value_loss         | 3.73e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | -2.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.789   |\n",
      "|    std                | 3.23     |\n",
      "|    value_loss         | 0.000304 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -2.93    |\n",
      "|    std                | 3.31     |\n",
      "|    value_loss         | 0.00422  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 4.9      |\n",
      "|    std                | 3.36     |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | -0.392   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -4.05    |\n",
      "|    std                | 3.4      |\n",
      "|    value_loss         | 0.00738  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -456      |\n",
      "|    total_cost         | 5.13e+03  |\n",
      "|    total_reward       | -5.05e+04 |\n",
      "|    total_reward_pct   | -101      |\n",
      "|    total_trades       | 24377     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.4     |\n",
      "|    explained_variance | -100      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -1.75     |\n",
      "|    std                | 3.45      |\n",
      "|    value_loss         | 0.0146    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | -2.15    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 2.31     |\n",
      "|    std                | 3.51     |\n",
      "|    value_loss         | 0.00297  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | -0.946   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.573    |\n",
      "|    std                | 3.56     |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -2.2     |\n",
      "|    std                | 3.62     |\n",
      "|    value_loss         | 0.00222  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.7    |\n",
      "|    explained_variance | -2.78    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -0.893   |\n",
      "|    std                | 3.69     |\n",
      "|    value_loss         | 0.000483 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.83e+03  |\n",
      "|    total_cost         | 1e+04     |\n",
      "|    total_reward       | -4.02e+04 |\n",
      "|    total_reward_pct   | -80.3     |\n",
      "|    total_trades       | 24864     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52       |\n",
      "|    explained_variance | -10.4     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 5.67      |\n",
      "|    std                | 3.75      |\n",
      "|    value_loss         | 0.0177    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -1.68    |\n",
      "|    std                | 3.8      |\n",
      "|    value_loss         | 0.00159  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 0.000153 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 3.84     |\n",
      "|    value_loss         | 0.0489   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -4.63    |\n",
      "|    std                | 3.89     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | -2.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.208   |\n",
      "|    std                | 3.95     |\n",
      "|    value_loss         | 0.000106 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+04  |\n",
      "|    total_cost         | 2.07e+04 |\n",
      "|    total_reward       | -3.3e+04 |\n",
      "|    total_reward_pct   | -66      |\n",
      "|    total_trades       | 25397    |\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | -0.213   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 0.000156 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.268    |\n",
      "|    std                | 4.11     |\n",
      "|    value_loss         | 9.3e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | 0.0141   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -3.32    |\n",
      "|    std                | 4.19     |\n",
      "|    value_loss         | 0.00539  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 3.52     |\n",
      "|    std                | 4.26     |\n",
      "|    value_loss         | 0.0044   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | -0.0324  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 4.34     |\n",
      "|    std                | 4.33     |\n",
      "|    value_loss         | 0.00603  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.73e+03  |\n",
      "|    total_cost         | 1.12e+04  |\n",
      "|    total_reward       | -4.53e+04 |\n",
      "|    total_reward_pct   | -90.5     |\n",
      "|    total_trades       | 25918     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.2     |\n",
      "|    explained_variance | -421      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 1.82      |\n",
      "|    std                | 4.42      |\n",
      "|    value_loss         | 0.00307   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -0.447    |\n",
      "|    std                | 4.54      |\n",
      "|    value_loss         | 7.41e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -0.0937  |\n",
      "|    std                | 4.64     |\n",
      "|    value_loss         | 8.68e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.689   |\n",
      "|    std                | 4.74     |\n",
      "|    value_loss         | 0.000229 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6585.38\n",
      "total_reward: -43414.62\n",
      "total_cost: 4780.83\n",
      "total_trades: 24682\n",
      "Sharpe: 0.199\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.59e+03  |\n",
      "|    total_cost         | 4.78e+03  |\n",
      "|    total_reward       | -4.34e+04 |\n",
      "|    total_reward_pct   | -86.8     |\n",
      "|    total_trades       | 24682     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -1.74     |\n",
      "|    std                | 4.87      |\n",
      "|    value_loss         | 0.00122   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.5    |\n",
      "|    explained_variance | 0.0107   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.511   |\n",
      "|    std                | 5        |\n",
      "|    value_loss         | 0.00011  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -1.97    |\n",
      "|    std                | 5.14     |\n",
      "|    value_loss         | 0.00138  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.5    |\n",
      "|    explained_variance | -0.683   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.822    |\n",
      "|    std                | 5.28     |\n",
      "|    value_loss         | 0.000268 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | -7.97    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 1.86     |\n",
      "|    std                | 5.44     |\n",
      "|    value_loss         | 0.00108  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.88e+03  |\n",
      "|    total_cost         | 7.45e+03  |\n",
      "|    total_reward       | -4.71e+04 |\n",
      "|    total_reward_pct   | -94.2     |\n",
      "|    total_trades       | 25034     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.7     |\n",
      "|    explained_variance | -7.11     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 0.0568    |\n",
      "|    std                | 5.61      |\n",
      "|    value_loss         | 1.25e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.3    |\n",
      "|    explained_variance | -12      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -0.381   |\n",
      "|    std                | 5.8      |\n",
      "|    value_loss         | 7.8e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.9    |\n",
      "|    explained_variance | -8.49    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 3.32     |\n",
      "|    std                | 5.99     |\n",
      "|    value_loss         | 0.00456  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 2.03     |\n",
      "|    std                | 6.16     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.9    |\n",
      "|    explained_variance | -0.371   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.951    |\n",
      "|    std                | 6.31     |\n",
      "|    value_loss         | 0.000563 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -3.97e+03 |\n",
      "|    total_cost         | 2.44e+04  |\n",
      "|    total_reward       | -5.4e+04  |\n",
      "|    total_reward_pct   | -108      |\n",
      "|    total_trades       | 27850     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.3     |\n",
      "|    explained_variance | -6.4      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -1.31     |\n",
      "|    std                | 6.43      |\n",
      "|    value_loss         | 0.00353   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.6    |\n",
      "|    explained_variance | 0.317    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -2.07    |\n",
      "|    std                | 6.53     |\n",
      "|    value_loss         | 0.00141  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.102   |\n",
      "|    std                | 6.68     |\n",
      "|    value_loss         | 4.07e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.257    |\n",
      "|    std                | 6.85     |\n",
      "|    value_loss         | 3.02e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 0.394    |\n",
      "|    std                | 7.06     |\n",
      "|    value_loss         | 0.000222 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.55e+03 |\n",
      "|    total_cost         | 2.73e+04  |\n",
      "|    total_reward       | -5.15e+04 |\n",
      "|    total_reward_pct   | -103      |\n",
      "|    total_trades       | 28633     |\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.6     |\n",
      "|    explained_variance | -0.951    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -0.261    |\n",
      "|    std                | 7.27      |\n",
      "|    value_loss         | 4.04e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.2    |\n",
      "|    explained_variance | -0.00539 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.351    |\n",
      "|    std                | 7.49     |\n",
      "|    value_loss         | 9.96e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.7    |\n",
      "|    explained_variance | 0.0351   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -2.19    |\n",
      "|    std                | 7.68     |\n",
      "|    value_loss         | 0.00125  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.628   |\n",
      "|    std                | 7.85     |\n",
      "|    value_loss         | 0.000247 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.139   |\n",
      "|    std                | 8.05     |\n",
      "|    value_loss         | 1.45e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.18e+03  |\n",
      "|    total_cost         | 2.66e+04  |\n",
      "|    total_reward       | -4.78e+04 |\n",
      "|    total_reward_pct   | -95.6     |\n",
      "|    total_trades       | 28500     |\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -3.39     |\n",
      "|    std                | 8.25      |\n",
      "|    value_loss         | 0.00305   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 1.3      |\n",
      "|    std                | 8.49     |\n",
      "|    value_loss         | 0.000493 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.1    |\n",
      "|    explained_variance | -0.25    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.731   |\n",
      "|    std                | 8.75     |\n",
      "|    value_loss         | 0.000129 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -0.279   |\n",
      "|    std                | 9.06     |\n",
      "|    value_loss         | 2.12e-05 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1339.14\n",
      "total_reward: -48660.86\n",
      "total_cost: 12303.03\n",
      "total_trades: 27391\n",
      "Sharpe: -0.620\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.34e+03  |\n",
      "|    total_cost         | 1.23e+04  |\n",
      "|    total_reward       | -4.87e+04 |\n",
      "|    total_reward_pct   | -97.3     |\n",
      "|    total_trades       | 27391     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.5     |\n",
      "|    explained_variance | -0.432    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -2.48     |\n",
      "|    std                | 9.43      |\n",
      "|    value_loss         | 0.00128   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.2    |\n",
      "|    explained_variance | -0.261   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.442   |\n",
      "|    std                | 9.77     |\n",
      "|    value_loss         | 8.73e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.9    |\n",
      "|    explained_variance | -0.718   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.66     |\n",
      "|    std                | 10.1     |\n",
      "|    value_loss         | 0.000126 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 0.151     |\n",
      "|    std                | 10.5      |\n",
      "|    value_loss         | 1.95e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.116    |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 3.88e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -259      |\n",
      "|    total_cost         | 7.46e+03  |\n",
      "|    total_reward       | -5.03e+04 |\n",
      "|    total_reward_pct   | -101      |\n",
      "|    total_trades       | 26054     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.1     |\n",
      "|    explained_variance | -0.554    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 2.25      |\n",
      "|    std                | 11.4      |\n",
      "|    value_loss         | 0.00102   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.5    |\n",
      "|    explained_variance | -0.0129  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.169    |\n",
      "|    std                | 11.6     |\n",
      "|    value_loss         | 6.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -1.51    |\n",
      "|    std                | 11.9     |\n",
      "|    value_loss         | 0.000546 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -2.25    |\n",
      "|    std                | 12.1     |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.217    |\n",
      "|    std                | 12.4     |\n",
      "|    value_loss         | 1.9e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.46e+03  |\n",
      "|    total_cost         | 2.49e+04  |\n",
      "|    total_reward       | -4.65e+04 |\n",
      "|    total_reward_pct   | -93.1     |\n",
      "|    total_trades       | 28265     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 235       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | 0.173     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -0.00653  |\n",
      "|    std                | 12.7      |\n",
      "|    value_loss         | 3.02e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 2.28     |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 0.00131  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -8.04    |\n",
      "|    std                | 13.3     |\n",
      "|    value_loss         | 0.0165   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.4    |\n",
      "|    explained_variance | -1.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -0.966   |\n",
      "|    std                | 13.5     |\n",
      "|    value_loss         | 0.00223  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 2.39     |\n",
      "|    std                | 13.8     |\n",
      "|    value_loss         | 0.00108  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.33e+04  |\n",
      "|    total_cost         | 4.53e+04  |\n",
      "|    total_reward       | -3.67e+04 |\n",
      "|    total_reward_pct   | -73.3     |\n",
      "|    total_trades       | 29232     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 244       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.1     |\n",
      "|    explained_variance | -1.61     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -1.15     |\n",
      "|    std                | 14.1      |\n",
      "|    value_loss         | 0.000248  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.7    |\n",
      "|    explained_variance | -4.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.326    |\n",
      "|    std                | 14.5     |\n",
      "|    value_loss         | 0.000149 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.3    |\n",
      "|    explained_variance | -0.503   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 0.515    |\n",
      "|    std                | 15       |\n",
      "|    value_loss         | 5.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.0433  |\n",
      "|    std                | 15.6     |\n",
      "|    value_loss         | 1.04e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 251       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -0.00726  |\n",
      "|    std                | 16.3      |\n",
      "|    value_loss         | 7.29e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 395       |\n",
      "|    total_cost         | 6.62e+03  |\n",
      "|    total_reward       | -4.96e+04 |\n",
      "|    total_reward_pct   | -99.2     |\n",
      "|    total_trades       | 25999     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 253       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 0.279     |\n",
      "|    std                | 16.9      |\n",
      "|    value_loss         | 2.99e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.3    |\n",
      "|    explained_variance | -0.108   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 0.242    |\n",
      "|    std                | 17.5     |\n",
      "|    value_loss         | 2.02e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -0.163   |\n",
      "|    std                | 18       |\n",
      "|    value_loss         | 2.33e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 258       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -1.28     |\n",
      "|    std                | 18.5      |\n",
      "|    value_loss         | 0.000255  |\n",
      "-------------------------------------\n",
      "day: 2397, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4795.06\n",
      "total_reward: -45204.94\n",
      "total_cost: 23894.18\n",
      "total_trades: 28169\n",
      "Sharpe: 0.119\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.8e+03   |\n",
      "|    total_cost         | 2.39e+04  |\n",
      "|    total_reward       | -4.52e+04 |\n",
      "|    total_reward_pct   | -90.4     |\n",
      "|    total_trades       | 28169     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.9     |\n",
      "|    explained_variance | -0.452    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -3.19     |\n",
      "|    std                | 19.1      |\n",
      "|    value_loss         | 0.00272   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.4    |\n",
      "|    explained_variance | -0.138   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 2.73     |\n",
      "|    std                | 19.6     |\n",
      "|    value_loss         | 0.00123  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.433    |\n",
      "|    std                | 20.1     |\n",
      "|    value_loss         | 5.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -0.349   |\n",
      "|    std                | 20.5     |\n",
      "|    value_loss         | 6.4e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    std                | 21       |\n",
      "|    value_loss         | 0.000363 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.65e+03  |\n",
      "|    total_cost         | 3.67e+04  |\n",
      "|    total_reward       | -4.43e+04 |\n",
      "|    total_reward_pct   | -88.7     |\n",
      "|    total_trades       | 29110     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.3     |\n",
      "|    explained_variance | -0.0189   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | 0.892     |\n",
      "|    std                | 21.6      |\n",
      "|    value_loss         | 0.000195  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 0.176    |\n",
      "|    std                | 22.2     |\n",
      "|    value_loss         | 2.26e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.3    |\n",
      "|    explained_variance | -21.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    std                | 22.8     |\n",
      "|    value_loss         | 0.00131  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 23.4     |\n",
      "|    value_loss         | 0.000208 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -0.77    |\n",
      "|    std                | 24.2     |\n",
      "|    value_loss         | 0.000231 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -7.23e+03 |\n",
      "|    total_cost         | 2.82e+04  |\n",
      "|    total_reward       | -5.72e+04 |\n",
      "|    total_reward_pct   | -114      |\n",
      "|    total_trades       | 28762     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 278       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88       |\n",
      "|    explained_variance | -0.0892   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -0.922    |\n",
      "|    std                | 24.9      |\n",
      "|    value_loss         | 0.000403  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -0.0973   |\n",
      "|    std                | 25.6      |\n",
      "|    value_loss         | 6.77e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.1    |\n",
      "|    explained_variance | -0.297   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 26.4     |\n",
      "|    value_loss         | 0.000155 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.494   |\n",
      "|    std                | 27.1     |\n",
      "|    value_loss         | 6.19e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.2    |\n",
      "|    explained_variance | -0.217   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.257    |\n",
      "|    std                | 28       |\n",
      "|    value_loss         | 9.78e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 395       |\n",
      "|    total_cost         | 2.52e+04  |\n",
      "|    total_reward       | -4.96e+04 |\n",
      "|    total_reward_pct   | -99.2     |\n",
      "|    total_trades       | 28431     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 287       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -90.9     |\n",
      "|    explained_variance | -0.0566   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 2.75      |\n",
      "|    std                | 28.9      |\n",
      "|    value_loss         | 0.00113   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.5    |\n",
      "|    explained_variance | 0.000273 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.494   |\n",
      "|    std                | 29.9     |\n",
      "|    value_loss         | 5.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.2    |\n",
      "|    explained_variance | -7.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 31       |\n",
      "|    value_loss         | 0.000148 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 292       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93       |\n",
      "|    explained_variance | -3.64e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -0.294    |\n",
      "|    std                | 32.3      |\n",
      "|    value_loss         | 1.49e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 0.0443   |\n",
      "|    std                | 33.9     |\n",
      "|    value_loss         | 2.32e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 490       |\n",
      "|    total_cost         | 1.21e+04  |\n",
      "|    total_reward       | -4.95e+04 |\n",
      "|    total_reward_pct   | -99       |\n",
      "|    total_trades       | 26992     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 295       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -94.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 0.0567    |\n",
      "|    std                | 35.3      |\n",
      "|    value_loss         | 3.43e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -0.0469  |\n",
      "|    std                | 36.8     |\n",
      "|    value_loss         | 6.46e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -7.15    |\n",
      "|    std                | 38       |\n",
      "|    value_loss         | 0.00588  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 301       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -96.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | 0.865     |\n",
      "|    std                | 38.9      |\n",
      "|    value_loss         | 0.000419  |\n",
      "-------------------------------------\n",
      "day: 2397, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6772.34\n",
      "total_reward: -43227.66\n",
      "total_cost: 32400.95\n",
      "total_trades: 28642\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.77e+03  |\n",
      "|    total_cost         | 3.24e+04  |\n",
      "|    total_reward       | -4.32e+04 |\n",
      "|    total_reward_pct   | -86.5     |\n",
      "|    total_trades       | 28642     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -97       |\n",
      "|    explained_variance | 0.197     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -2.12     |\n",
      "|    std                | 39.9      |\n",
      "|    value_loss         | 0.000699  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.4    |\n",
      "|    explained_variance | -0.442   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.61     |\n",
      "|    std                | 40.9     |\n",
      "|    value_loss         | 0.000387 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98      |\n",
      "|    explained_variance | 0.803    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 2.63     |\n",
      "|    std                | 42.2     |\n",
      "|    value_loss         | 0.000762 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.5    |\n",
      "|    explained_variance | -0.198   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 0.898    |\n",
      "|    std                | 43.3     |\n",
      "|    value_loss         | 9.37e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.242   |\n",
      "|    std                | 44.5     |\n",
      "|    value_loss         | 8.45e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.81e+03  |\n",
      "|    total_cost         | 2.66e+04  |\n",
      "|    total_reward       | -4.62e+04 |\n",
      "|    total_reward_pct   | -92.4     |\n",
      "|    total_trades       | 28362     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 312       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99.6     |\n",
      "|    explained_variance | -0.581    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -2.73     |\n",
      "|    std                | 45.9      |\n",
      "|    value_loss         | 0.00133   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | -2.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.0423   |\n",
      "|    std                | 47       |\n",
      "|    value_loss         | 5.07e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 0.053    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -1.37    |\n",
      "|    std                | 48.4     |\n",
      "|    value_loss         | 0.000382 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -3.77    |\n",
      "|    std                | 49.5     |\n",
      "|    value_loss         | 0.00179  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 2.6      |\n",
      "|    std                | 50.7     |\n",
      "|    value_loss         | 0.000717 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.92e+03  |\n",
      "|    total_cost         | 3.81e+04  |\n",
      "|    total_reward       | -4.41e+04 |\n",
      "|    total_reward_pct   | -88.2     |\n",
      "|    total_trades       | 29123     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 321       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -102      |\n",
      "|    explained_variance | -0.418    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 0.349     |\n",
      "|    std                | 52.2      |\n",
      "|    value_loss         | 1.37e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.156    |\n",
      "|    std                | 53.9     |\n",
      "|    value_loss         | 4.43e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -0.479   |\n",
      "|    std                | 55.7     |\n",
      "|    value_loss         | 0.000216 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 326      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -0.16    |\n",
      "|    std                | 57.2     |\n",
      "|    value_loss         | 2.8e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -0.706   |\n",
      "|    std                | 58.9     |\n",
      "|    value_loss         | 5.44e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.71e+03  |\n",
      "|    total_cost         | 3.01e+04  |\n",
      "|    total_reward       | -4.43e+04 |\n",
      "|    total_reward_pct   | -88.6     |\n",
      "|    total_trades       | 28104     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 329       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | 0.076     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 2.9       |\n",
      "|    std                | 60.7      |\n",
      "|    value_loss         | 0.000831  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.0513  |\n",
      "|    std                | 62.9     |\n",
      "|    value_loss         | 7.18e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.661   |\n",
      "|    std                | 65       |\n",
      "|    value_loss         | 0.00021  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -0.519   |\n",
      "|    std                | 66.9     |\n",
      "|    value_loss         | 2.78e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 0.0535   |\n",
      "|    std                | 69.3     |\n",
      "|    value_loss         | 9.52e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.97e+03 |\n",
      "|    total_cost         | 2.12e+04 |\n",
      "|    total_reward       | -4.7e+04 |\n",
      "|    total_reward_pct   | -94.1    |\n",
      "|    total_trades       | 27627    |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 0.0888   |\n",
      "|    std                | 71.9     |\n",
      "|    value_loss         | 6.73e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -2.02    |\n",
      "|    std                | 74.8     |\n",
      "|    value_loss         | 0.000344 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 342      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 0.503    |\n",
      "|    std                | 77.1     |\n",
      "|    value_loss         | 0.000112 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.155   |\n",
      "|    std                | 79.3     |\n",
      "|    value_loss         | 5.62e-06 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -6202.78\n",
      "total_reward: -56202.78\n",
      "total_cost: 27768.06\n",
      "total_trades: 28052\n",
      "Sharpe: -0.309\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -6.2e+03  |\n",
      "|    total_cost         | 2.78e+04  |\n",
      "|    total_reward       | -5.62e+04 |\n",
      "|    total_reward_pct   | -112      |\n",
      "|    total_trades       | 28052     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 346       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -111      |\n",
      "|    explained_variance | 0.104     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 0.32      |\n",
      "|    std                | 81.5      |\n",
      "|    value_loss         | 2.69e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 347       |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -111      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | -0.769    |\n",
      "|    std                | 84.2      |\n",
      "|    value_loss         | 0.000117  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | -0.162   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -1.73    |\n",
      "|    std                | 87.1     |\n",
      "|    value_loss         | 0.00086  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 89.6     |\n",
      "|    value_loss         | 0.000256 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 353      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -113     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    std                | 92.3     |\n",
      "|    value_loss         | 0.000113 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.87e+03  |\n",
      "|    total_cost         | 2.3e+04   |\n",
      "|    total_reward       | -4.81e+04 |\n",
      "|    total_reward_pct   | -96.3     |\n",
      "|    total_trades       | 27742     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 354       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -113      |\n",
      "|    explained_variance | -0.378    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 0.0427    |\n",
      "|    std                | 95.2      |\n",
      "|    value_loss         | 4.28e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.344    |\n",
      "|    std                | 98.5     |\n",
      "|    value_loss         | 1e-05    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -115     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 102      |\n",
      "|    value_loss         | 0.000124 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -115     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 5.23     |\n",
      "|    std                | 105      |\n",
      "|    value_loss         | 0.00283  |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-10-02 to  2020-01-03\n",
      "A2C Sharpe Ratio:  0.07527193030755201\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 337  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+04    |\n",
      "|    total_cost           | 4.44e+04    |\n",
      "|    total_reward         | -2.91e+04   |\n",
      "|    total_reward_pct     | -58.1       |\n",
      "|    total_trades         | 29393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 337         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008680311 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0572      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+04    |\n",
      "|    total_cost           | 2.89e+04    |\n",
      "|    total_reward         | -3.99e+04   |\n",
      "|    total_reward_pct     | -79.9       |\n",
      "|    total_trades         | 28434       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011454248 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0401      |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 16302.57\n",
      "total_reward: -33697.43\n",
      "total_cost: 65431.29\n",
      "total_trades: 30751\n",
      "Sharpe: -0.461\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.63e+04    |\n",
      "|    total_cost           | 6.54e+04    |\n",
      "|    total_reward         | -3.37e+04   |\n",
      "|    total_reward_pct     | -67.4       |\n",
      "|    total_trades         | 30751       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006744232 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0346      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.28e+04    |\n",
      "|    total_cost           | 4.78e+04    |\n",
      "|    total_reward         | -3.72e+04   |\n",
      "|    total_reward_pct     | -74.4       |\n",
      "|    total_trades         | 29813       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009444874 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0228      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.43e+03    |\n",
      "|    total_cost           | 4.27e+04    |\n",
      "|    total_reward         | -4.16e+04   |\n",
      "|    total_reward_pct     | -83.1       |\n",
      "|    total_trades         | 29204       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012497634 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0176      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 332        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00905372 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.292     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0182     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+04       |\n",
      "|    total_cost           | 2.45e+04    |\n",
      "|    total_reward         | -4e+04      |\n",
      "|    total_reward_pct     | -79.9       |\n",
      "|    total_trades         | 27747       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021692265 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.01e+04     |\n",
      "|    total_cost           | 4.19e+04     |\n",
      "|    total_reward         | -3.99e+04    |\n",
      "|    total_reward_pct     | -79.7        |\n",
      "|    total_trades         | 29590        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050106524 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.1        |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.299       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0148       |\n",
      "------------------------------------------\n",
      "day: 2397, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 11585.98\n",
      "total_reward: -38414.02\n",
      "total_cost: 49151.63\n",
      "total_trades: 29655\n",
      "Sharpe: -0.596\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+04    |\n",
      "|    total_cost           | 4.92e+04    |\n",
      "|    total_reward         | -3.84e+04   |\n",
      "|    total_reward_pct     | -76.8       |\n",
      "|    total_trades         | 29655       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009265716 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0144      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+03    |\n",
      "|    total_cost           | 1.29e+04    |\n",
      "|    total_reward         | -4.66e+04   |\n",
      "|    total_reward_pct     | -93.3       |\n",
      "|    total_trades         | 26495       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011005833 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.79e+04     |\n",
      "|    total_cost           | 3.88e+04     |\n",
      "|    total_reward         | -3.21e+04    |\n",
      "|    total_reward_pct     | -64.2        |\n",
      "|    total_trades         | 29308        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065917904 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.309       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.013        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.82e+04     |\n",
      "|    total_cost           | 4.58e+04     |\n",
      "|    total_reward         | -3.18e+04    |\n",
      "|    total_reward_pct     | -63.6        |\n",
      "|    total_trades         | 29691        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069859102 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.0137       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.294       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0199      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0147       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005068548 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.99e+03     |\n",
      "|    total_cost           | 2.63e+04     |\n",
      "|    total_reward         | -4.1e+04     |\n",
      "|    total_reward_pct     | -82          |\n",
      "|    total_trades         | 28544        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051678754 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.213        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.287       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00422      |\n",
      "------------------------------------------\n",
      "day: 2397, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 9247.59\n",
      "total_reward: -40752.41\n",
      "total_cost: 18002.75\n",
      "total_trades: 27513\n",
      "Sharpe: -0.119\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.25e+03    |\n",
      "|    total_cost           | 1.8e+04     |\n",
      "|    total_reward         | -4.08e+04   |\n",
      "|    total_reward_pct     | -81.5       |\n",
      "|    total_trades         | 27513       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007962731 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00996     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.45e+04   |\n",
      "|    total_cost           | 6.13e+04   |\n",
      "|    total_reward         | -2.55e+04  |\n",
      "|    total_reward_pct     | -50.9      |\n",
      "|    total_trades         | 30037      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 332        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01417369 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | -0.0338    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.306     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0277     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.73e+04    |\n",
      "|    total_cost           | 4.62e+04    |\n",
      "|    total_reward         | -3.27e+04   |\n",
      "|    total_reward_pct     | -65.4       |\n",
      "|    total_trades         | 29337       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017530251 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.65e+03     |\n",
      "|    total_cost           | 1.7e+04      |\n",
      "|    total_reward         | -4.13e+04    |\n",
      "|    total_reward_pct     | -82.7        |\n",
      "|    total_trades         | 26553        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065924264 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.4        |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.297       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0137       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.39e+04   |\n",
      "|    total_cost           | 2.94e+04   |\n",
      "|    total_reward         | -3.61e+04  |\n",
      "|    total_reward_pct     | -72.3      |\n",
      "|    total_trades         | 28063      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 333        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 122        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01025244 |\n",
      "|    clip_fraction        | 0.0836     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.28      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0105     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013442405 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0134      |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 16969.61\n",
      "total_reward: -33030.39\n",
      "total_cost: 24832.53\n",
      "total_trades: 27687\n",
      "Sharpe: -0.075\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.7e+04     |\n",
      "|    total_cost           | 2.48e+04    |\n",
      "|    total_reward         | -3.3e+04    |\n",
      "|    total_reward_pct     | -66.1       |\n",
      "|    total_trades         | 27687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009221255 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00448     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.7e+04     |\n",
      "|    total_cost           | 5.3e+04     |\n",
      "|    total_reward         | -2.3e+04    |\n",
      "|    total_reward_pct     | -45.9       |\n",
      "|    total_trades         | 29911       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015717115 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0175      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.45e+04   |\n",
      "|    total_cost           | 2.76e+04   |\n",
      "|    total_reward         | -3.55e+04  |\n",
      "|    total_reward_pct     | -70.9      |\n",
      "|    total_trades         | 28360      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 333        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01627214 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.288     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0109     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.57e+04    |\n",
      "|    total_cost           | 3.67e+04    |\n",
      "|    total_reward         | -3.43e+04   |\n",
      "|    total_reward_pct     | -68.7       |\n",
      "|    total_trades         | 28945       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010407222 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00809     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.96e+03    |\n",
      "|    total_cost           | 9.39e+03    |\n",
      "|    total_reward         | -4.8e+04    |\n",
      "|    total_reward_pct     | -96.1       |\n",
      "|    total_trades         | 26101       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006059128 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 25154.32\n",
      "total_reward: -24845.68\n",
      "total_cost: 38403.64\n",
      "total_trades: 29045\n",
      "Sharpe: 0.086\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+04    |\n",
      "|    total_cost           | 3.84e+04    |\n",
      "|    total_reward         | -2.48e+04   |\n",
      "|    total_reward_pct     | -49.7       |\n",
      "|    total_trades         | 29045       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030155431 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00675     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018643998 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.84e+04    |\n",
      "|    total_cost           | 2.36e+04    |\n",
      "|    total_reward         | -2.16e+04   |\n",
      "|    total_reward_pct     | -43.2       |\n",
      "|    total_trades         | 27643       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014126721 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.72e+03   |\n",
      "|    total_cost           | 1.58e+04    |\n",
      "|    total_reward         | -5.17e+04   |\n",
      "|    total_reward_pct     | -103        |\n",
      "|    total_trades         | 26753       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010973502 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00703     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+04    |\n",
      "|    total_cost           | 2.13e+04    |\n",
      "|    total_reward         | -3.71e+04   |\n",
      "|    total_reward_pct     | -74.2       |\n",
      "|    total_trades         | 27494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017719187 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00674     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.32e+04    |\n",
      "|    total_cost           | 3.06e+04    |\n",
      "|    total_reward         | -6.76e+03   |\n",
      "|    total_reward_pct     | -13.5       |\n",
      "|    total_trades         | 28090       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022095395 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00827     |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 15740.17\n",
      "total_reward: -34259.83\n",
      "total_cost: 19890.64\n",
      "total_trades: 27394\n",
      "Sharpe: 0.163\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.57e+04   |\n",
      "|    total_cost           | 1.99e+04   |\n",
      "|    total_reward         | -3.43e+04  |\n",
      "|    total_reward_pct     | -68.5      |\n",
      "|    total_trades         | 27394      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 332        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01570843 |\n",
      "|    clip_fraction        | 0.0903     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.365      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.294     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0182     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+04    |\n",
      "|    total_cost           | 2.43e+04    |\n",
      "|    total_reward         | -2.98e+04   |\n",
      "|    total_reward_pct     | -59.5       |\n",
      "|    total_trades         | 27727       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015603078 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00742     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 333        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02057925 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.491      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.294     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0104     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.08e+04    |\n",
      "|    total_cost           | 1.97e+04    |\n",
      "|    total_reward         | -3.92e+04   |\n",
      "|    total_reward_pct     | -78.3       |\n",
      "|    total_trades         | 27618       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014181099 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00337     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.33e+04    |\n",
      "|    total_cost           | 2.46e+04    |\n",
      "|    total_reward         | -1.67e+04   |\n",
      "|    total_reward_pct     | -33.4       |\n",
      "|    total_trades         | 28348       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007912131 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+04    |\n",
      "|    total_cost           | 1.96e+04    |\n",
      "|    total_reward         | -1.99e+04   |\n",
      "|    total_reward_pct     | -39.8       |\n",
      "|    total_trades         | 27447       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016515821 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0151      |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6242.09\n",
      "total_reward: -43757.91\n",
      "total_cost: 14817.48\n",
      "total_trades: 27363\n",
      "Sharpe: -0.248\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.24e+03    |\n",
      "|    total_cost           | 1.48e+04    |\n",
      "|    total_reward         | -4.38e+04   |\n",
      "|    total_reward_pct     | -87.5       |\n",
      "|    total_trades         | 27363       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012434871 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00921     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 5.69e+04     |\n",
      "|    total_cost           | 3.33e+04     |\n",
      "|    total_reward         | 6.87e+03     |\n",
      "|    total_reward_pct     | 13.7         |\n",
      "|    total_trades         | 29126        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152753135 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.9        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.311       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0183      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00865      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+04    |\n",
      "|    total_cost           | 1.42e+04    |\n",
      "|    total_reward         | -3.66e+04   |\n",
      "|    total_reward_pct     | -73.2       |\n",
      "|    total_trades         | 26941       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013614113 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0189      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019678913 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00557     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+04    |\n",
      "|    total_cost           | 1.99e+04    |\n",
      "|    total_reward         | -1.83e+04   |\n",
      "|    total_reward_pct     | -36.5       |\n",
      "|    total_trades         | 27703       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008962928 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.51e+03    |\n",
      "|    total_cost           | 9.69e+03    |\n",
      "|    total_reward         | -4.65e+04   |\n",
      "|    total_reward_pct     | -93         |\n",
      "|    total_trades         | 26343       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018606517 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0045      |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5182.09\n",
      "total_reward: -44817.91\n",
      "total_cost: 8728.90\n",
      "total_trades: 26340\n",
      "Sharpe: -0.254\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.18e+03    |\n",
      "|    total_cost           | 8.73e+03    |\n",
      "|    total_reward         | -4.48e+04   |\n",
      "|    total_reward_pct     | -89.6       |\n",
      "|    total_trades         | 26340       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020690389 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00363     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.19e+04    |\n",
      "|    total_cost           | 3.17e+04    |\n",
      "|    total_reward         | -8.06e+03   |\n",
      "|    total_reward_pct     | -16.1       |\n",
      "|    total_trades         | 29092       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021485105 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | -0.398      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+04    |\n",
      "|    total_cost           | 1.92e+04    |\n",
      "|    total_reward         | -2.84e+04   |\n",
      "|    total_reward_pct     | -56.7       |\n",
      "|    total_trades         | 27780       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005781484 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023151841 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0134      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+04    |\n",
      "|    total_cost           | 1.75e+04    |\n",
      "|    total_reward         | -2.37e+04   |\n",
      "|    total_reward_pct     | -47.4       |\n",
      "|    total_trades         | 27571       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012689051 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00582     |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-10-02 to  2020-01-03\n",
      "PPO Sharpe Ratio:  0.3728550910774421\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
      "day: 2397, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 26350.60\n",
      "total_reward: -23649.40\n",
      "total_cost: 1500.87\n",
      "total_trades: 25271\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.51e+04 |\n",
      "|    total_cost       | 116      |\n",
      "|    total_reward     | -4.9e+03 |\n",
      "|    total_reward_pct | -9.8     |\n",
      "|    total_trades     | 19923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total timesteps  | 9592     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -31.4    |\n",
      "|    critic_loss      | 2.81     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7194     |\n",
      "----------------------------------\n",
      "day: 2397, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 55438.97\n",
      "total_reward: 5438.97\n",
      "total_cost: 117.84\n",
      "total_trades: 20759\n",
      "Sharpe: 0.504\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+04 |\n",
      "|    total_cost       | 338      |\n",
      "|    total_reward     | -85.2    |\n",
      "|    total_reward_pct | -0.17    |\n",
      "|    total_trades     | 24509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total timesteps  | 19184    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -19.5    |\n",
      "|    critic_loss      | 0.803    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16786    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 31262.06\n",
      "total_reward: -18737.94\n",
      "total_cost: 130.54\n",
      "total_trades: 24781\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.74e+04  |\n",
      "|    total_cost       | 106       |\n",
      "|    total_reward     | -2.57e+03 |\n",
      "|    total_reward_pct | -5.13     |\n",
      "|    total_trades     | 24244     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 66        |\n",
      "|    time_elapsed     | 430       |\n",
      "|    total timesteps  | 28776     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -12.6     |\n",
      "|    critic_loss      | 0.434     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 26378     |\n",
      "-----------------------------------\n",
      "day: 2397, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 57787.60\n",
      "total_reward: 7787.60\n",
      "total_cost: 376.93\n",
      "total_trades: 24166\n",
      "Sharpe: 0.470\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.78e+04 |\n",
      "|    total_cost       | 377      |\n",
      "|    total_reward     | 7.79e+03 |\n",
      "|    total_reward_pct | 15.6     |\n",
      "|    total_trades     | 24166    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 583      |\n",
      "|    total timesteps  | 38368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.35    |\n",
      "|    critic_loss      | 0.282    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35970    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.93e+04 |\n",
      "|    total_cost       | 341      |\n",
      "|    total_reward     | 9.28e+03 |\n",
      "|    total_reward_pct | 18.6     |\n",
      "|    total_trades     | 24316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 729      |\n",
      "|    total timesteps  | 47960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.69    |\n",
      "|    critic_loss      | 0.222    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45562    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74889.40\n",
      "total_reward: 24889.40\n",
      "total_cost: 281.33\n",
      "total_trades: 22935\n",
      "Sharpe: 0.547\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-02 to  2020-01-03\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-01-03\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_315_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 330  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.89e+04    |\n",
      "|    total_cost           | 8.82e+04    |\n",
      "|    total_reward         | -2.11e+04   |\n",
      "|    total_reward_pct     | -42.2       |\n",
      "|    total_trades         | 32434       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008324903 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0644      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -815       |\n",
      "|    total_cost           | 1.22e+04   |\n",
      "|    total_reward         | -5.08e+04  |\n",
      "|    total_reward_pct     | -102       |\n",
      "|    total_trades         | 26957      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 327        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01000481 |\n",
      "|    clip_fraction        | 0.098      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.284     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0363     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+04    |\n",
      "|    total_cost           | 2.8e+04     |\n",
      "|    total_reward         | -3.79e+04   |\n",
      "|    total_reward_pct     | -75.9       |\n",
      "|    total_trades         | 28578       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016491517 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0312      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.13e+04   |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -6.13e+04   |\n",
      "|    total_reward_pct     | -123        |\n",
      "|    total_trades         | 27288       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009458554 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007741781 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5389.70\n",
      "total_reward: -44610.30\n",
      "total_cost: 16916.87\n",
      "total_trades: 27518\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.39e+03    |\n",
      "|    total_cost           | 1.69e+04    |\n",
      "|    total_reward         | -4.46e+04   |\n",
      "|    total_reward_pct     | -89.2       |\n",
      "|    total_trades         | 27518       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006751759 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00593     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.39e+04    |\n",
      "|    total_cost           | 4.14e+04    |\n",
      "|    total_reward         | -3.61e+04   |\n",
      "|    total_reward_pct     | -72.2       |\n",
      "|    total_trades         | 30263       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016009577 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.337      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+04    |\n",
      "|    total_cost           | 4.33e+04    |\n",
      "|    total_reward         | -3.93e+04   |\n",
      "|    total_reward_pct     | -78.5       |\n",
      "|    total_trades         | 30386       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009787427 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.0987      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.43e+04    |\n",
      "|    total_cost           | 2.7e+04     |\n",
      "|    total_reward         | -3.57e+04   |\n",
      "|    total_reward_pct     | -71.3       |\n",
      "|    total_trades         | 28828       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012171607 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0205      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+03    |\n",
      "|    total_cost           | 1.27e+04    |\n",
      "|    total_reward         | -4.77e+04   |\n",
      "|    total_reward_pct     | -95.5       |\n",
      "|    total_trades         | 27401       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007518024 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01646073 |\n",
      "|    clip_fraction        | 0.0974     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.312      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.307     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0087     |\n",
      "----------------------------------------\n",
      "day: 2460, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -13282.05\n",
      "total_reward: -63282.05\n",
      "total_cost: 16061.48\n",
      "total_trades: 27747\n",
      "Sharpe: 0.301\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.33e+04   |\n",
      "|    total_cost           | 1.61e+04    |\n",
      "|    total_reward         | -6.33e+04   |\n",
      "|    total_reward_pct     | -127        |\n",
      "|    total_trades         | 27747       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014660173 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.124      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00347     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.39e+04     |\n",
      "|    total_cost           | 2.19e+04     |\n",
      "|    total_reward         | -3.61e+04    |\n",
      "|    total_reward_pct     | -72.2        |\n",
      "|    total_trades         | 28972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155323455 |\n",
      "|    clip_fraction        | 0.0838       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.283       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0122       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+04       |\n",
      "|    total_cost           | 2.41e+04    |\n",
      "|    total_reward         | -4e+04      |\n",
      "|    total_reward_pct     | -79.9       |\n",
      "|    total_trades         | 28745       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014463925 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.69e+04    |\n",
      "|    total_cost           | 1.86e+04    |\n",
      "|    total_reward         | -3.31e+04   |\n",
      "|    total_reward_pct     | -66.2       |\n",
      "|    total_trades         | 28464       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010719412 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00953     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.67e+04    |\n",
      "|    total_cost           | 3.21e+04    |\n",
      "|    total_reward         | -3.33e+04   |\n",
      "|    total_reward_pct     | -66.7       |\n",
      "|    total_trades         | 29862       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025893372 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | -1.53       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0154      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018313728 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00814     |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 22150.32\n",
      "total_reward: -27849.68\n",
      "total_cost: 29156.51\n",
      "total_trades: 29660\n",
      "Sharpe: -0.015\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+04    |\n",
      "|    total_cost           | 2.92e+04    |\n",
      "|    total_reward         | -2.78e+04   |\n",
      "|    total_reward_pct     | -55.7       |\n",
      "|    total_trades         | 29660       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016121719 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00529     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+04    |\n",
      "|    total_cost           | 1.74e+04    |\n",
      "|    total_reward         | -3.74e+04   |\n",
      "|    total_reward_pct     | -74.8       |\n",
      "|    total_trades         | 28457       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014635295 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00698     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.25e+04    |\n",
      "|    total_cost           | 7.32e+04    |\n",
      "|    total_reward         | 2.53e+03    |\n",
      "|    total_reward_pct     | 5.06        |\n",
      "|    total_trades         | 31723       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018187046 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | -0.0539     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0289      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.17e+04    |\n",
      "|    total_cost           | 2.84e+04    |\n",
      "|    total_reward         | -2.83e+04   |\n",
      "|    total_reward_pct     | -56.5       |\n",
      "|    total_trades         | 29667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009300923 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0178      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+04    |\n",
      "|    total_cost           | 1.78e+04    |\n",
      "|    total_reward         | -3.66e+04   |\n",
      "|    total_reward_pct     | -73.3       |\n",
      "|    total_trades         | 28421       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010437099 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00815     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014873709 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00557     |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 32116.70\n",
      "total_reward: -17883.30\n",
      "total_cost: 30981.10\n",
      "total_trades: 29835\n",
      "Sharpe: 0.090\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.21e+04    |\n",
      "|    total_cost           | 3.1e+04     |\n",
      "|    total_reward         | -1.79e+04   |\n",
      "|    total_reward_pct     | -35.8       |\n",
      "|    total_trades         | 29835       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012401805 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00781     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.38e+04    |\n",
      "|    total_cost           | 6.39e+04    |\n",
      "|    total_reward         | 3.83e+03    |\n",
      "|    total_reward_pct     | 7.66        |\n",
      "|    total_trades         | 31431       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015997566 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0256      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.98e+03    |\n",
      "|    total_cost           | 1.2e+04     |\n",
      "|    total_reward         | -4.2e+04    |\n",
      "|    total_reward_pct     | -84         |\n",
      "|    total_trades         | 27543       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012926673 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.05e+04    |\n",
      "|    total_cost           | 4.14e+04    |\n",
      "|    total_reward         | -1.95e+04   |\n",
      "|    total_reward_pct     | -39         |\n",
      "|    total_trades         | 30277       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016040333 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00804     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.55e+04    |\n",
      "|    total_cost           | 3.39e+04    |\n",
      "|    total_reward         | -1.45e+04   |\n",
      "|    total_reward_pct     | -29         |\n",
      "|    total_trades         | 29723       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014093061 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022731584 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0138      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 37961.41\n",
      "total_reward: -12038.59\n",
      "total_cost: 22011.69\n",
      "total_trades: 28540\n",
      "Sharpe: 0.361\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.8e+04     |\n",
      "|    total_cost           | 2.2e+04     |\n",
      "|    total_reward         | -1.2e+04    |\n",
      "|    total_reward_pct     | -24.1       |\n",
      "|    total_trades         | 28540       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013990224 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.09e+03    |\n",
      "|    total_cost           | 1.08e+04    |\n",
      "|    total_reward         | -4.19e+04   |\n",
      "|    total_reward_pct     | -83.8       |\n",
      "|    total_trades         | 26970       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017899888 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00555     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.03e+04    |\n",
      "|    total_cost           | 2.82e+04    |\n",
      "|    total_reward         | -2.97e+04   |\n",
      "|    total_reward_pct     | -59.4       |\n",
      "|    total_trades         | 29181       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013072214 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00884     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.53e+04    |\n",
      "|    total_cost           | 2.16e+04    |\n",
      "|    total_reward         | -3.47e+04   |\n",
      "|    total_reward_pct     | -69.4       |\n",
      "|    total_trades         | 28836       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014068006 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00991     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.71e+04     |\n",
      "|    total_cost           | 2e+04        |\n",
      "|    total_reward         | -3.29e+04    |\n",
      "|    total_reward_pct     | -65.8        |\n",
      "|    total_trades         | 28133        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113228755 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.6        |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.306       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00643      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02302225 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.585      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.287     |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0102     |\n",
      "----------------------------------------\n",
      "day: 2460, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 9804.67\n",
      "total_reward: -40195.33\n",
      "total_cost: 13511.43\n",
      "total_trades: 27780\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.8e+03     |\n",
      "|    total_cost           | 1.35e+04    |\n",
      "|    total_reward         | -4.02e+04   |\n",
      "|    total_reward_pct     | -80.4       |\n",
      "|    total_trades         | 27780       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014779503 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00311     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+04    |\n",
      "|    total_cost           | 2.46e+04    |\n",
      "|    total_reward         | -2.42e+04   |\n",
      "|    total_reward_pct     | -48.4       |\n",
      "|    total_trades         | 29358       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018792987 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.47e+04    |\n",
      "|    total_cost           | 2.59e+04    |\n",
      "|    total_reward         | -5.28e+03   |\n",
      "|    total_reward_pct     | -10.6       |\n",
      "|    total_trades         | 28960       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014445545 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00811     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+04    |\n",
      "|    total_cost           | 2.75e+04    |\n",
      "|    total_reward         | -2.14e+04   |\n",
      "|    total_reward_pct     | -42.7       |\n",
      "|    total_trades         | 29391       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015964124 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.35e+04    |\n",
      "|    total_cost           | 4.4e+04     |\n",
      "|    total_reward         | 1.35e+04    |\n",
      "|    total_reward_pct     | 27          |\n",
      "|    total_trades         | 30288       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019103803 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0176      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009929085 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0268      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 15340.90\n",
      "total_reward: -34659.10\n",
      "total_cost: 19834.46\n",
      "total_trades: 28602\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.53e+04    |\n",
      "|    total_cost           | 1.98e+04    |\n",
      "|    total_reward         | -3.47e+04   |\n",
      "|    total_reward_pct     | -69.3       |\n",
      "|    total_trades         | 28602       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018861387 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0076      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.54e+04    |\n",
      "|    total_cost           | 1.74e+04    |\n",
      "|    total_reward         | -3.46e+04   |\n",
      "|    total_reward_pct     | -69.2       |\n",
      "|    total_trades         | 28220       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010935019 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00584     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.99e+04    |\n",
      "|    total_cost           | 2.39e+04    |\n",
      "|    total_reward         | -1.01e+04   |\n",
      "|    total_reward_pct     | -20.3       |\n",
      "|    total_trades         | 29068       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015619521 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00559     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.16e+05   |\n",
      "|    total_cost           | 5.23e+04   |\n",
      "|    total_reward         | 6.64e+04   |\n",
      "|    total_reward_pct     | 133        |\n",
      "|    total_trades         | 30828      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 288        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02208289 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.365      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.303     |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0208     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.05e+03   |\n",
      "|    total_cost           | 1.06e+04   |\n",
      "|    total_reward         | -4.09e+04  |\n",
      "|    total_reward_pct     | -81.9      |\n",
      "|    total_trades         | 27617      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01434207 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.541      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.281     |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0356     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016789932 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00755     |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8372.55\n",
      "total_reward: -41627.45\n",
      "total_cost: 14214.88\n",
      "total_trades: 28159\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.37e+03   |\n",
      "|    total_cost           | 1.42e+04   |\n",
      "|    total_reward         | -4.16e+04  |\n",
      "|    total_reward_pct     | -83.3      |\n",
      "|    total_trades         | 28159      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 307        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01300244 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.744      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.294     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.00528    |\n",
      "----------------------------------------\n",
      "======Trading from:  2020-01-03 to  2020-04-06\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2000-01-01 to  2020-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 283      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.286   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.00105  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 268      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -2.58    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 3.32     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0168   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -0.0559  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.836    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00231  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0228   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.12e+04 |\n",
      "|    total_cost         | 3.93e+04 |\n",
      "|    total_reward       | 3.12e+04 |\n",
      "|    total_reward_pct   | 62.4     |\n",
      "|    total_trades       | 29774    |\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -31.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.366   |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00791  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -277     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.791   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.998   |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -3.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 3.96     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0276   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 5.62     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0526   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.25e+04 |\n",
      "|    total_cost         | 5.38e+03 |\n",
      "|    total_reward       | 2.25e+04 |\n",
      "|    total_reward_pct   | 45       |\n",
      "|    total_trades       | 27116    |\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -1.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.933   |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.00156  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -5.84e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -1.15     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.00169   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -33.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.958    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00851  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.537   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -3.46    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0176   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 1.94     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.00828  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.56e+04  |\n",
      "|    total_cost         | 3.49e+03  |\n",
      "|    total_reward       | -1.44e+04 |\n",
      "|    total_reward_pct   | -28.8     |\n",
      "|    total_trades       | 27264     |\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30       |\n",
      "|    explained_variance | -3.79     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -2.58     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.0109    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -9.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.0717  |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.000658 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | -0.253   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.9      |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00455  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -2.3     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -2.75    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0.0955   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -4.4     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0454   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.11e+05 |\n",
      "|    total_cost         | 4.82e+03 |\n",
      "|    total_reward       | 6.09e+04 |\n",
      "|    total_reward_pct   | 122      |\n",
      "|    total_trades       | 25989    |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -9.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.188    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | -2.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0731  |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.000487 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | -38.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -3.07    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.0152   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | 0.0427   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -4.37    |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.0186   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -5.05    |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.0508   |\n",
      "------------------------------------\n",
      "day: 2460, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48859.45\n",
      "total_reward: -1140.55\n",
      "total_cost: 4951.80\n",
      "total_trades: 24285\n",
      "Sharpe: 0.271\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.89e+04  |\n",
      "|    total_cost         | 4.95e+03  |\n",
      "|    total_reward       | -1.14e+03 |\n",
      "|    total_reward_pct   | -2.28     |\n",
      "|    total_trades       | 24285     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.3     |\n",
      "|    explained_variance | -91.3     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -0.539    |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.000828  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -0.568   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.575    |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.000902 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.562    |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 3.5      |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0122   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | -0.578   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 4.63     |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.0278   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.9e+04  |\n",
      "|    total_cost         | 3.01e+03 |\n",
      "|    total_reward       | -1.1e+04 |\n",
      "|    total_reward_pct   | -22.1    |\n",
      "|    total_trades       | 24555    |\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | -1.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 2.36     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.00546  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.698   |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.000751 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | 0.00265  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 3.02     |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00897  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | 0.00509  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -2.14    |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00434  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | -0.082   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 2.01     |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00365  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.94e+04  |\n",
      "|    total_cost         | 2.26e+03  |\n",
      "|    total_reward       | -3.06e+04 |\n",
      "|    total_reward_pct   | -61.3     |\n",
      "|    total_trades       | 22953     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.5     |\n",
      "|    explained_variance | -2.02     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 1.2       |\n",
      "|    std                | 1.57      |\n",
      "|    value_loss         | 0.00141   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.00111  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | -0.268   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 2.13     |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.00516  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | 0.000328 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.397   |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.000176 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.1    |\n",
      "|    explained_variance | -0.415   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.00521  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.04e+03 |\n",
      "|    total_cost         | 1.66e+03 |\n",
      "|    total_reward       | -4.2e+04 |\n",
      "|    total_reward_pct   | -83.9    |\n",
      "|    total_trades       | 22803    |\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 1.04     |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.00094  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | -0.507   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -1.64    |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.00258  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | -0.0158  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.00587  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 4.06     |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.0179   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | 0.338    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.59     |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.000497 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4e+04    |\n",
      "|    total_cost         | 1.01e+04 |\n",
      "|    total_reward       | -1e+04   |\n",
      "|    total_reward_pct   | -20.1    |\n",
      "|    total_trades       | 24815    |\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39      |\n",
      "|    explained_variance | -1.33    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.194    |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 9.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | -0.0186  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.791    |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.000556 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.671    |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.000437 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | -3.6     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.504    |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 0.00272  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | 2.19e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -1.65    |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 0.00467  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -21743.58\n",
      "total_reward: -71743.58\n",
      "total_cost: 6654.30\n",
      "total_trades: 24258\n",
      "Sharpe: 0.023\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.17e+04 |\n",
      "|    total_cost         | 6.65e+03  |\n",
      "|    total_reward       | -7.17e+04 |\n",
      "|    total_reward_pct   | -143      |\n",
      "|    total_trades       | 24258     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | -0.806    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 0.00812   |\n",
      "|    std                | 2.03      |\n",
      "|    value_loss         | 0.000186  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    std                | 2.08     |\n",
      "|    value_loss         | 0.001    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | -0.208   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -2.84    |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.00583  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 1.92     |\n",
      "|    std                | 2.16     |\n",
      "|    value_loss         | 0.00245  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | -0.171   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 1.84     |\n",
      "|    std                | 2.19     |\n",
      "|    value_loss         | 0.00227  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.73e+04  |\n",
      "|    total_cost         | 1.93e+04  |\n",
      "|    total_reward       | -2.27e+04 |\n",
      "|    total_reward_pct   | -45.4     |\n",
      "|    total_trades       | 26625     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -0.292    |\n",
      "|    std                | 2.23      |\n",
      "|    value_loss         | 0.0015    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.155    |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.000355 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -5.3     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 5.78     |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.0202   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0166  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.683   |\n",
      "|    std                | 2.32     |\n",
      "|    value_loss         | 0.00191  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -0.0175  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    std                | 2.35     |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4e+04    |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | -1e+04   |\n",
      "|    total_reward_pct   | -20      |\n",
      "|    total_trades       | 27012    |\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 11.1     |\n",
      "|    std                | 2.37     |\n",
      "|    value_loss         | 0.079    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -2.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.392    |\n",
      "|    std                | 2.4      |\n",
      "|    value_loss         | 0.00133  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.0103  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -15.5    |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -0.156   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 12.8     |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 0.086    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.5e+04  |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 3.5e+04  |\n",
      "|    total_reward_pct   | 70       |\n",
      "|    total_trades       | 25812    |\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0.277    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    std                | 2.46     |\n",
      "|    value_loss         | 2.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | -0.247   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.727    |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.00229  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -1.57    |\n",
      "|    std                | 2.54     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | -0.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    std                | 2.58     |\n",
      "|    value_loss         | 0.00219  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | -0.225   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 3.05     |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.0056   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.39e+04 |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 1.39e+04 |\n",
      "|    total_reward_pct   | 27.8     |\n",
      "|    total_trades       | 24383    |\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.388   |\n",
      "|    std                | 2.65     |\n",
      "|    value_loss         | 9.69e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | -1.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.000833 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0.573    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.318   |\n",
      "|    std                | 2.76     |\n",
      "|    value_loss         | 5.13e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | -0.0179  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.00128  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.484   |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.000285 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 26807.17\n",
      "total_reward: -23192.83\n",
      "total_cost: 5527.59\n",
      "total_trades: 23153\n",
      "Sharpe: 0.297\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.68e+04  |\n",
      "|    total_cost         | 5.53e+03  |\n",
      "|    total_reward       | -2.32e+04 |\n",
      "|    total_reward_pct   | -46.4     |\n",
      "|    total_trades       | 23153     |\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -17.2     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -1.7      |\n",
      "|    std                | 2.93      |\n",
      "|    value_loss         | 0.0121    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 4.64     |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.425    |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.000833 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -3.01    |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.00389  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0.0234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.111   |\n",
      "|    std                | 3.12     |\n",
      "|    value_loss         | 5.85e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.21e+04  |\n",
      "|    total_cost         | 9.97e+03  |\n",
      "|    total_reward       | -1.79e+04 |\n",
      "|    total_reward_pct   | -35.9     |\n",
      "|    total_trades       | 23635     |\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.9     |\n",
      "|    explained_variance | 0.293     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -0.286    |\n",
      "|    std                | 3.17      |\n",
      "|    value_loss         | 6.54e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0.00588  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.432   |\n",
      "|    std                | 3.24     |\n",
      "|    value_loss         | 0.000104 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -1.34    |\n",
      "|    std                | 3.32     |\n",
      "|    value_loss         | 0.000693 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 1.69      |\n",
      "|    std                | 3.39      |\n",
      "|    value_loss         | 0.0018    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.0357  |\n",
      "|    std                | 3.45     |\n",
      "|    value_loss         | 1.96e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.03e+04 |\n",
      "|    total_cost         | 5.36e+03  |\n",
      "|    total_reward       | -6.03e+04 |\n",
      "|    total_reward_pct   | -121      |\n",
      "|    total_trades       | 23553     |\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.8     |\n",
      "|    explained_variance | 0.0253    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 3.3       |\n",
      "|    std                | 3.52      |\n",
      "|    value_loss         | 0.00452   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | -1.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.827   |\n",
      "|    std                | 3.56     |\n",
      "|    value_loss         | 0.000728 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | -0.0583  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -5.39    |\n",
      "|    std                | 3.62     |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -3.81    |\n",
      "|    std                | 3.66     |\n",
      "|    value_loss         | 0.00756  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | -0.369   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.943    |\n",
      "|    std                | 3.71     |\n",
      "|    value_loss         | 0.000861 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.83e+04  |\n",
      "|    total_cost         | 7.99e+03  |\n",
      "|    total_reward       | -2.17e+04 |\n",
      "|    total_reward_pct   | -43.5     |\n",
      "|    total_trades       | 23630     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -0.0193   |\n",
      "|    std                | 3.75      |\n",
      "|    value_loss         | 6.52e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -0.668    |\n",
      "|    std                | 3.83      |\n",
      "|    value_loss         | 0.000222  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | -0.0969  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.24     |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.000788 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -4.59    |\n",
      "|    std                | 4.06     |\n",
      "|    value_loss         | 0.00918  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.16e+04  |\n",
      "|    total_cost         | 1.15e+04  |\n",
      "|    total_reward       | -2.84e+04 |\n",
      "|    total_reward_pct   | -56.7     |\n",
      "|    total_trades       | 24812     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.8     |\n",
      "|    explained_variance | -6.62e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -0.307    |\n",
      "|    std                | 4.12      |\n",
      "|    value_loss         | 6.8e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 0.00334  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.06    |\n",
      "|    std                | 4.22     |\n",
      "|    value_loss         | 1.54e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -1.36    |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.00108  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.2    |\n",
      "|    explained_variance | -0.206   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -1.51    |\n",
      "|    std                | 4.44     |\n",
      "|    value_loss         | 0.000901 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.0727  |\n",
      "|    std                | 4.51     |\n",
      "|    value_loss         | 0.000236 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21144.16\n",
      "total_reward: -28855.84\n",
      "total_cost: 7271.71\n",
      "total_trades: 24574\n",
      "Sharpe: 0.271\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.11e+04  |\n",
      "|    total_cost         | 7.27e+03  |\n",
      "|    total_reward       | -2.89e+04 |\n",
      "|    total_reward_pct   | -57.7     |\n",
      "|    total_trades       | 24574     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.9     |\n",
      "|    explained_variance | 0.0694    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -4.53     |\n",
      "|    std                | 4.59      |\n",
      "|    value_loss         | 0.00721   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -4.97    |\n",
      "|    std                | 4.67     |\n",
      "|    value_loss         | 0.0095   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 6.91     |\n",
      "|    std                | 4.75     |\n",
      "|    value_loss         | 0.0157   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | -0.095   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -3.11    |\n",
      "|    std                | 4.85     |\n",
      "|    value_loss         | 0.00583  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 5.19     |\n",
      "|    std                | 4.94     |\n",
      "|    value_loss         | 0.00948  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.75e+04  |\n",
      "|    total_cost         | 5.67e+03  |\n",
      "|    total_reward       | -2.25e+04 |\n",
      "|    total_reward_pct   | -45.1     |\n",
      "|    total_trades       | 23530     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.6     |\n",
      "|    explained_variance | 0.0594    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 1.53      |\n",
      "|    std                | 5.01      |\n",
      "|    value_loss         | 0.000967  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.791    |\n",
      "|    std                | 5.09     |\n",
      "|    value_loss         | 0.00112  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | 0.551    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 2.93     |\n",
      "|    std                | 5.17     |\n",
      "|    value_loss         | 0.0026   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.4    |\n",
      "|    explained_variance | 0.0116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 5.25     |\n",
      "|    value_loss         | 0.00205  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 2.73     |\n",
      "|    std                | 5.33     |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.76e+04  |\n",
      "|    total_cost         | 7.81e+03  |\n",
      "|    total_reward       | -2.24e+04 |\n",
      "|    total_reward_pct   | -44.7     |\n",
      "|    total_trades       | 24448     |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59       |\n",
      "|    explained_variance | -0.02     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -5.34     |\n",
      "|    std                | 5.41      |\n",
      "|    value_loss         | 0.00924   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.2    |\n",
      "|    explained_variance | 2.93e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -3.68    |\n",
      "|    std                | 5.48     |\n",
      "|    value_loss         | 0.00427  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -0.604    |\n",
      "|    std                | 5.55      |\n",
      "|    value_loss         | 0.0022    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 7.53     |\n",
      "|    std                | 5.6      |\n",
      "|    value_loss         | 0.028    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 2.17     |\n",
      "|    std                | 5.67     |\n",
      "|    value_loss         | 0.00292  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.91e+04 |\n",
      "|    total_cost         | 8.25e+03 |\n",
      "|    total_reward       | 1.91e+04 |\n",
      "|    total_reward_pct   | 38.1     |\n",
      "|    total_trades       | 24493    |\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.2    |\n",
      "|    explained_variance | -0.317   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 0.465    |\n",
      "|    std                | 5.75     |\n",
      "|    value_loss         | 0.000101 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.688    |\n",
      "|    std                | 5.87     |\n",
      "|    value_loss         | 0.000173 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61      |\n",
      "|    explained_variance | 0.0282   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 0.556    |\n",
      "|    std                | 6.01     |\n",
      "|    value_loss         | 0.000357 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.4    |\n",
      "|    explained_variance | -0.156   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 1.95     |\n",
      "|    std                | 6.13     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.7    |\n",
      "|    explained_variance | -0.0665  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -5.62    |\n",
      "|    std                | 6.22     |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -5.71e+03 |\n",
      "|    total_cost         | 1.31e+04  |\n",
      "|    total_reward       | -5.57e+04 |\n",
      "|    total_reward_pct   | -111      |\n",
      "|    total_trades       | 25656     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.8     |\n",
      "|    explained_variance | -0.109    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -8.83     |\n",
      "|    std                | 6.28      |\n",
      "|    value_loss         | 0.0308    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62      |\n",
      "|    explained_variance | -1.26    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -0.38    |\n",
      "|    std                | 6.34     |\n",
      "|    value_loss         | 0.000875 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.2    |\n",
      "|    explained_variance | -0.0133  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 1        |\n",
      "|    std                | 6.4      |\n",
      "|    value_loss         | 0.00402  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.3    |\n",
      "|    explained_variance | -0.0234  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 8.93     |\n",
      "|    std                | 6.45     |\n",
      "|    value_loss         | 0.0348   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.4    |\n",
      "|    explained_variance | 0.0413   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -3.91    |\n",
      "|    std                | 6.48     |\n",
      "|    value_loss         | 0.00972  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 113639.26\n",
      "total_reward: 63639.26\n",
      "total_cost: 43311.37\n",
      "total_trades: 28237\n",
      "Sharpe: 0.493\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.14e+05 |\n",
      "|    total_cost         | 4.33e+04 |\n",
      "|    total_reward       | 6.36e+04 |\n",
      "|    total_reward_pct   | 127      |\n",
      "|    total_trades       | 28237    |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -0.061   |\n",
      "|    std                | 6.57     |\n",
      "|    value_loss         | 1.77e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.1    |\n",
      "|    explained_variance | -9.58    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.758    |\n",
      "|    std                | 6.71     |\n",
      "|    value_loss         | 0.000197 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.5    |\n",
      "|    explained_variance | -0.588   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.482   |\n",
      "|    std                | 6.86     |\n",
      "|    value_loss         | 0.000144 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 1.88     |\n",
      "|    std                | 7.04     |\n",
      "|    value_loss         | 0.000912 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.83e+04  |\n",
      "|    total_cost         | 1.62e+04  |\n",
      "|    total_reward       | -3.17e+04 |\n",
      "|    total_reward_pct   | -63.5     |\n",
      "|    total_trades       | 26399     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.4     |\n",
      "|    explained_variance | -4.66     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -0.201    |\n",
      "|    std                | 7.2       |\n",
      "|    value_loss         | 3.38e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.9    |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.621   |\n",
      "|    std                | 7.4      |\n",
      "|    value_loss         | 0.000805 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | 0.85      |\n",
      "|    std                | 7.64      |\n",
      "|    value_loss         | 0.000497  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.1    |\n",
      "|    explained_variance | -0.0136  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.293   |\n",
      "|    std                | 7.85     |\n",
      "|    value_loss         | 0.000147 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.5    |\n",
      "|    explained_variance | 0.0843   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 0.939    |\n",
      "|    std                | 8.02     |\n",
      "|    value_loss         | 0.000779 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.12e+04  |\n",
      "|    total_cost         | 1.65e+04  |\n",
      "|    total_reward       | -2.88e+04 |\n",
      "|    total_reward_pct   | -57.5     |\n",
      "|    total_trades       | 26735     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.9     |\n",
      "|    explained_variance | -0.00768  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | 0.0537    |\n",
      "|    std                | 8.19      |\n",
      "|    value_loss         | 3.38e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.3    |\n",
      "|    explained_variance | 0.487    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.965   |\n",
      "|    std                | 8.39     |\n",
      "|    value_loss         | 0.000246 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 0.276     |\n",
      "|    std                | 8.65      |\n",
      "|    value_loss         | 1.75e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | -0.592   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.318    |\n",
      "|    std                | 8.88     |\n",
      "|    value_loss         | 0.000552 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.8    |\n",
      "|    explained_variance | -0.584   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 9.08     |\n",
      "|    value_loss         | 0.000517 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.73e+04  |\n",
      "|    total_cost         | 2.03e+04  |\n",
      "|    total_reward       | -3.27e+04 |\n",
      "|    total_reward_pct   | -65.4     |\n",
      "|    total_trades       | 27295     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 248       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.2     |\n",
      "|    explained_variance | -0.414    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 1.25      |\n",
      "|    std                | 9.25      |\n",
      "|    value_loss         | 0.00176   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.5    |\n",
      "|    explained_variance | -0.0706  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 9.41     |\n",
      "|    value_loss         | 0.00181  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.992   |\n",
      "|    std                | 9.56     |\n",
      "|    value_loss         | 0.000447 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 2.72     |\n",
      "|    std                | 9.72     |\n",
      "|    value_loss         | 0.00223  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 2.12     |\n",
      "|    std                | 9.92     |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.4e+04  |\n",
      "|    total_cost         | 2.41e+04 |\n",
      "|    total_reward       | -3.6e+04 |\n",
      "|    total_reward_pct   | -72.1    |\n",
      "|    total_trades       | 28918    |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.9    |\n",
      "|    explained_variance | -0.0412  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 2.89     |\n",
      "|    std                | 10.1     |\n",
      "|    value_loss         | 0.00193  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.3    |\n",
      "|    explained_variance | -0.134   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 0.55     |\n",
      "|    std                | 10.4     |\n",
      "|    value_loss         | 7.44e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.846    |\n",
      "|    std                | 10.6     |\n",
      "|    value_loss         | 0.000538 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 0.000395 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -0.591   |\n",
      "|    std                | 11.2     |\n",
      "|    value_loss         | 0.000119 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8017.70\n",
      "total_reward: -41982.30\n",
      "total_cost: 27912.05\n",
      "total_trades: 29352\n",
      "Sharpe: 0.060\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.02e+03 |\n",
      "|    total_cost         | 2.79e+04 |\n",
      "|    total_reward       | -4.2e+04 |\n",
      "|    total_reward_pct   | -84      |\n",
      "|    total_trades       | 29352    |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.2    |\n",
      "|    explained_variance | 0.476    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -0.64    |\n",
      "|    std                | 11.4     |\n",
      "|    value_loss         | 9.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.5    |\n",
      "|    explained_variance | -0.226   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.411   |\n",
      "|    std                | 11.6     |\n",
      "|    value_loss         | 0.000268 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.9    |\n",
      "|    explained_variance | -0.316   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 4.2      |\n",
      "|    std                | 11.9     |\n",
      "|    value_loss         | 0.00505  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 0.26     |\n",
      "|    std                | 12.1     |\n",
      "|    value_loss         | 9.18e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.6    |\n",
      "|    explained_variance | 0.00568  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 1.47     |\n",
      "|    std                | 12.3     |\n",
      "|    value_loss         | 0.000592 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+04  |\n",
      "|    total_cost         | 3.19e+04 |\n",
      "|    total_reward       | -3.8e+04 |\n",
      "|    total_reward_pct   | -75.9    |\n",
      "|    total_trades       | 29637    |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75      |\n",
      "|    explained_variance | -0.323   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 0.257    |\n",
      "|    std                | 12.6     |\n",
      "|    value_loss         | 1.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.681    |\n",
      "|    std                | 12.9     |\n",
      "|    value_loss         | 8.58e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 0.0564   |\n",
      "|    std                | 13.3     |\n",
      "|    value_loss         | 3.55e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 0.0535   |\n",
      "|    std                | 13.7     |\n",
      "|    value_loss         | 5.92e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.0081  |\n",
      "|    std                | 14.1     |\n",
      "|    value_loss         | 4.42e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.16e+03  |\n",
      "|    total_cost         | 1.99e+04  |\n",
      "|    total_reward       | -4.68e+04 |\n",
      "|    total_reward_pct   | -93.7     |\n",
      "|    total_trades       | 29103     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 284       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.8     |\n",
      "|    explained_variance | -0.00149  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | 0.712     |\n",
      "|    std                | 14.6      |\n",
      "|    value_loss         | 0.000145  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.28    |\n",
      "|    std                | 15.1     |\n",
      "|    value_loss         | 1.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.0494  |\n",
      "|    std                | 15.7     |\n",
      "|    value_loss         | 1.33e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80      |\n",
      "|    explained_variance | -0.701   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -1.34    |\n",
      "|    std                | 16.3     |\n",
      "|    value_loss         | 0.000306 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -0.0955  |\n",
      "|    std                | 17       |\n",
      "|    value_loss         | 1.18e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.12e+03  |\n",
      "|    total_cost         | 1.29e+04  |\n",
      "|    total_reward       | -4.79e+04 |\n",
      "|    total_reward_pct   | -95.8     |\n",
      "|    total_trades       | 28019     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 293       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.5     |\n",
      "|    explained_variance | -0.0186   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | 0.0884    |\n",
      "|    std                | 17.7      |\n",
      "|    value_loss         | 9.64e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 0.27     |\n",
      "|    std                | 18.4     |\n",
      "|    value_loss         | 1.59e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.0881   |\n",
      "|    std                | 19.1     |\n",
      "|    value_loss         | 0.000219 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.6    |\n",
      "|    explained_variance | 0.554    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.623    |\n",
      "|    std                | 19.7     |\n",
      "|    value_loss         | 6.74e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    std                | 20.4     |\n",
      "|    value_loss         | 4.23e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.39e+04 |\n",
      "|    total_cost         | 2.38e+04  |\n",
      "|    total_reward       | -6.39e+04 |\n",
      "|    total_reward_pct   | -128      |\n",
      "|    total_trades       | 28974     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.6     |\n",
      "|    explained_variance | -0.13     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | 0.00851   |\n",
      "|    std                | 20.8      |\n",
      "|    value_loss         | 1.37e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.2    |\n",
      "|    explained_variance | -0.748   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 4.93     |\n",
      "|    std                | 21.4     |\n",
      "|    value_loss         | 0.00438  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.273    |\n",
      "|    std                | 22.2     |\n",
      "|    value_loss         | 2.52e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.649   |\n",
      "|    std                | 22.9     |\n",
      "|    value_loss         | 9.27e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -2.6     |\n",
      "|    std                | 23.6     |\n",
      "|    value_loss         | 0.00155  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -18368.78\n",
      "total_reward: -68368.78\n",
      "total_cost: 15797.47\n",
      "total_trades: 28591\n",
      "Sharpe: 0.008\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.84e+04 |\n",
      "|    total_cost         | 1.58e+04  |\n",
      "|    total_reward       | -6.84e+04 |\n",
      "|    total_reward_pct   | -137      |\n",
      "|    total_trades       | 28591     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 311       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -87.4     |\n",
      "|    explained_variance | -0.0558   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 2.67      |\n",
      "|    std                | 24.1      |\n",
      "|    value_loss         | 0.00247   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -4.29    |\n",
      "|    std                | 24.6     |\n",
      "|    value_loss         | 0.00316  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.261   |\n",
      "|    std                | 25.1     |\n",
      "|    value_loss         | 3.47e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.7    |\n",
      "|    explained_variance | -0.0837  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.493   |\n",
      "|    std                | 25.9     |\n",
      "|    value_loss         | 5.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.448    |\n",
      "|    std                | 26.8     |\n",
      "|    value_loss         | 3.07e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.44e+03  |\n",
      "|    total_cost         | 2.87e+04  |\n",
      "|    total_reward       | -4.76e+04 |\n",
      "|    total_reward_pct   | -95.1     |\n",
      "|    total_trades       | 29839     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 320       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -90.1     |\n",
      "|    explained_variance | -111      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 0.706     |\n",
      "|    std                | 27.9      |\n",
      "|    value_loss         | 0.000213  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.487    |\n",
      "|    std                | 29       |\n",
      "|    value_loss         | 3.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.985    |\n",
      "|    std                | 29.9     |\n",
      "|    value_loss         | 0.000177 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -92       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -0.341    |\n",
      "|    std                | 30.7      |\n",
      "|    value_loss         | 2.01e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.6    |\n",
      "|    explained_variance | -3.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -0.796   |\n",
      "|    std                | 31.7     |\n",
      "|    value_loss         | 8.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.98e+03 |\n",
      "|    total_cost         | 2.33e+04 |\n",
      "|    total_reward       | -4.7e+04 |\n",
      "|    total_reward_pct   | -94      |\n",
      "|    total_trades       | 29013    |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.1    |\n",
      "|    explained_variance | -0.502   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -0.668   |\n",
      "|    std                | 32.5     |\n",
      "|    value_loss         | 5.82e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.0743  |\n",
      "|    std                | 33.4     |\n",
      "|    value_loss         | 1.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.1    |\n",
      "|    explained_variance | -0.244   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -2.13    |\n",
      "|    std                | 34.4     |\n",
      "|    value_loss         | 0.000509 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.7    |\n",
      "|    explained_variance | -0.159   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -1.7     |\n",
      "|    std                | 35.4     |\n",
      "|    value_loss         | 0.000429 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -0.0803  |\n",
      "|    std                | 36.4     |\n",
      "|    value_loss         | 6.23e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.61e+03  |\n",
      "|    total_cost         | 2.92e+04  |\n",
      "|    total_reward       | -4.54e+04 |\n",
      "|    total_reward_pct   | -90.8     |\n",
      "|    total_trades       | 29489     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 338       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -95.7     |\n",
      "|    explained_variance | 0.0202    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | 0.254     |\n",
      "|    std                | 37.4      |\n",
      "|    value_loss         | 9.28e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.3    |\n",
      "|    explained_variance | 0.168    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -1.4     |\n",
      "|    std                | 38.6     |\n",
      "|    value_loss         | 0.000237 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 342      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.8    |\n",
      "|    explained_variance | 0.175    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 5.26     |\n",
      "|    std                | 39.6     |\n",
      "|    value_loss         | 0.00307  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.3    |\n",
      "|    explained_variance | -0.0535  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.741   |\n",
      "|    std                | 40.6     |\n",
      "|    value_loss         | 7.08e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.94e+03  |\n",
      "|    total_cost         | 3.41e+04  |\n",
      "|    total_reward       | -4.81e+04 |\n",
      "|    total_reward_pct   | -96.1     |\n",
      "|    total_trades       | 29750     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 345       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -97.8     |\n",
      "|    explained_variance | -6.12     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | -0.189    |\n",
      "|    std                | 41.7      |\n",
      "|    value_loss         | 6.14e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.3    |\n",
      "|    explained_variance | -3.98    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -1.53    |\n",
      "|    std                | 42.9     |\n",
      "|    value_loss         | 0.000303 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -1.57    |\n",
      "|    std                | 44.1     |\n",
      "|    value_loss         | 0.000283 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 0.96     |\n",
      "|    std                | 45.3     |\n",
      "|    value_loss         | 0.000256 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 353      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.9    |\n",
      "|    explained_variance | -2.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.464   |\n",
      "|    std                | 46.6     |\n",
      "|    value_loss         | 0.000107 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -487.49\n",
      "total_reward: -50487.49\n",
      "total_cost: 22378.76\n",
      "total_trades: 29163\n",
      "Sharpe: -0.158\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -487      |\n",
      "|    total_cost         | 2.24e+04  |\n",
      "|    total_reward       | -5.05e+04 |\n",
      "|    total_reward_pct   | -101      |\n",
      "|    total_trades       | 29163     |\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 354       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -100      |\n",
      "|    explained_variance | 0.000714  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -2.8      |\n",
      "|    std                | 47.8      |\n",
      "|    value_loss         | 0.00146   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 356       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 1.81      |\n",
      "|    std                | 49.1      |\n",
      "|    value_loss         | 0.000378  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | -3.5     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 0.593    |\n",
      "|    std                | 50.7     |\n",
      "|    value_loss         | 3.74e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 0.291    |\n",
      "|    std                | 52.7     |\n",
      "|    value_loss         | 9e-06    |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-01-03 to  2020-04-06\n",
      "A2C Sharpe Ratio:  -0.091739401431527\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 333  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+03    |\n",
      "|    total_cost           | 2.22e+04    |\n",
      "|    total_reward         | -4.74e+04   |\n",
      "|    total_reward_pct     | -94.8       |\n",
      "|    total_trades         | 28407       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011501845 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0401      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.16e+04     |\n",
      "|    total_cost           | 3.8e+04      |\n",
      "|    total_reward         | -3.84e+04    |\n",
      "|    total_reward_pct     | -76.8        |\n",
      "|    total_trades         | 29942        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 329          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059617367 |\n",
      "|    clip_fraction        | 0.0893       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.273       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0317       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -3.6e+03   |\n",
      "|    total_cost           | 1.8e+04    |\n",
      "|    total_reward         | -5.36e+04  |\n",
      "|    total_reward_pct     | -107       |\n",
      "|    total_trades         | 27325      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 329        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00492989 |\n",
      "|    clip_fraction        | 0.0801     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.294     |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0215     |\n",
      "----------------------------------------\n",
      "day: 2460, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2799.42\n",
      "total_reward: -47200.58\n",
      "total_cost: 12382.02\n",
      "total_trades: 26924\n",
      "Sharpe: -0.293\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+03     |\n",
      "|    total_cost           | 1.24e+04    |\n",
      "|    total_reward         | -4.72e+04   |\n",
      "|    total_reward_pct     | -94.4       |\n",
      "|    total_trades         | 26924       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 328         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005870928 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010719594 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.31e+04    |\n",
      "|    total_cost           | 4.54e+04    |\n",
      "|    total_reward         | -3.69e+04   |\n",
      "|    total_reward_pct     | -73.8       |\n",
      "|    total_trades         | 30422       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017415954 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00829     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.3e+03     |\n",
      "|    total_cost           | 1.85e+04    |\n",
      "|    total_reward         | -4.37e+04   |\n",
      "|    total_reward_pct     | -87.4       |\n",
      "|    total_trades         | 28298       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018224303 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0168      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.64e+03    |\n",
      "|    total_cost           | 1.05e+04    |\n",
      "|    total_reward         | -4.84e+04   |\n",
      "|    total_reward_pct     | -96.7       |\n",
      "|    total_trades         | 27143       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013791206 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00822     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.78e+04    |\n",
      "|    total_cost           | 3.37e+04    |\n",
      "|    total_reward         | -3.22e+04   |\n",
      "|    total_reward_pct     | -64.5       |\n",
      "|    total_trades         | 30075       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009193344 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.104      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 30110.78\n",
      "total_reward: -19889.22\n",
      "total_cost: 65293.48\n",
      "total_trades: 31714\n",
      "Sharpe: -0.105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+04    |\n",
      "|    total_cost           | 6.53e+04    |\n",
      "|    total_reward         | -1.99e+04   |\n",
      "|    total_reward_pct     | -39.8       |\n",
      "|    total_trades         | 31714       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008199962 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010012651 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.016       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.42e+04    |\n",
      "|    total_cost           | 3.54e+04    |\n",
      "|    total_reward         | -3.58e+04   |\n",
      "|    total_reward_pct     | -71.6       |\n",
      "|    total_trades         | 30037       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017795708 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00587     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.95e+03     |\n",
      "|    total_cost           | 2.54e+04     |\n",
      "|    total_reward         | -4.01e+04    |\n",
      "|    total_reward_pct     | -80.1        |\n",
      "|    total_trades         | 29431        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055840192 |\n",
      "|    clip_fraction        | 0.0964       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.298       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0103       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.88e+03    |\n",
      "|    total_cost           | 2.82e+04    |\n",
      "|    total_reward         | -4.21e+04   |\n",
      "|    total_reward_pct     | -84.2       |\n",
      "|    total_trades         | 29722       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009318182 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00781     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.29e+04    |\n",
      "|    total_cost           | 2.15e+04    |\n",
      "|    total_reward         | -2.71e+04   |\n",
      "|    total_reward_pct     | -54.1       |\n",
      "|    total_trades         | 28790       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022973446 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 36188.55\n",
      "total_reward: -13811.45\n",
      "total_cost: 42907.89\n",
      "total_trades: 30601\n",
      "Sharpe: 0.143\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.62e+04    |\n",
      "|    total_cost           | 4.29e+04    |\n",
      "|    total_reward         | -1.38e+04   |\n",
      "|    total_reward_pct     | -27.6       |\n",
      "|    total_trades         | 30601       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012329614 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00935     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007290273 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0175      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.8e+04    |\n",
      "|    total_cost           | 4.87e+04   |\n",
      "|    total_reward         | -2.2e+04   |\n",
      "|    total_reward_pct     | -43.9      |\n",
      "|    total_trades         | 31071      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01222364 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.296     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0139     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+04    |\n",
      "|    total_cost           | 1.41e+04    |\n",
      "|    total_reward         | -3.66e+04   |\n",
      "|    total_reward_pct     | -73.3       |\n",
      "|    total_trades         | 27475       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010504561 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00973     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 9.68e+03  |\n",
      "|    total_cost           | 1.55e+04  |\n",
      "|    total_reward         | -4.03e+04 |\n",
      "|    total_reward_pct     | -80.6     |\n",
      "|    total_trades         | 27662     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 327       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 131       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.022551  |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.4     |\n",
      "|    explained_variance   | 0.545     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.302    |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -0.0182   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 0.0064    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.91e+03    |\n",
      "|    total_cost           | 1.46e+04    |\n",
      "|    total_reward         | -4.01e+04   |\n",
      "|    total_reward_pct     | -80.2       |\n",
      "|    total_trades         | 27555       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016797982 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00733     |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2502.06\n",
      "total_reward: -47497.94\n",
      "total_cost: 12350.11\n",
      "total_trades: 27244\n",
      "Sharpe: -0.304\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.5e+03     |\n",
      "|    total_cost           | 1.24e+04    |\n",
      "|    total_reward         | -4.75e+04   |\n",
      "|    total_reward_pct     | -95         |\n",
      "|    total_trades         | 27244       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010004938 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0045      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018446933 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | -0.228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00827     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.97e+04     |\n",
      "|    total_cost           | 3.03e+04     |\n",
      "|    total_reward         | -3.03e+04    |\n",
      "|    total_reward_pct     | -60.5        |\n",
      "|    total_trades         | 29447        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137533825 |\n",
      "|    clip_fraction        | 0.0876       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.5        |\n",
      "|    explained_variance   | 0.0922       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.302       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00686      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -18.8       |\n",
      "|    total_cost           | 1.63e+04    |\n",
      "|    total_reward         | -5e+04      |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 27929       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011789595 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00627     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.9e+04    |\n",
      "|    total_cost           | 5.03e+04   |\n",
      "|    total_reward         | -1.05e+03  |\n",
      "|    total_reward_pct     | -2.1       |\n",
      "|    total_trades         | 30828      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 169        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01285479 |\n",
      "|    clip_fraction        | 0.0938     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | -0.265     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.296     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0199     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.89e+03    |\n",
      "|    total_cost           | 1.81e+04    |\n",
      "|    total_reward         | -4.31e+04   |\n",
      "|    total_reward_pct     | -86.2       |\n",
      "|    total_trades         | 28365       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013900475 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 56263.57\n",
      "total_reward: 6263.57\n",
      "total_cost: 56834.34\n",
      "total_trades: 31281\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.63e+04    |\n",
      "|    total_cost           | 5.68e+04    |\n",
      "|    total_reward         | 6.26e+03    |\n",
      "|    total_reward_pct     | 12.5        |\n",
      "|    total_trades         | 31281       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014367659 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | -0.0533     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0205      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013275807 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0246      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.48e+04    |\n",
      "|    total_cost           | 2.59e+04    |\n",
      "|    total_reward         | -3.52e+04   |\n",
      "|    total_reward_pct     | -70.4       |\n",
      "|    total_trades         | 29374       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017637737 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.083       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00574     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.05e+04    |\n",
      "|    total_cost           | 1.23e+04    |\n",
      "|    total_reward         | -3.95e+04   |\n",
      "|    total_reward_pct     | -79.1       |\n",
      "|    total_trades         | 27215       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008583636 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00571     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.1e+04     |\n",
      "|    total_cost           | 3.83e+04    |\n",
      "|    total_reward         | -8.99e+03   |\n",
      "|    total_reward_pct     | -18         |\n",
      "|    total_trades         | 30238       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011784744 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -7.81e+03   |\n",
      "|    total_cost           | 1.54e+04    |\n",
      "|    total_reward         | -5.78e+04   |\n",
      "|    total_reward_pct     | -116        |\n",
      "|    total_trades         | 27902       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018716548 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00848     |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48870.38\n",
      "total_reward: -1129.62\n",
      "total_cost: 43438.09\n",
      "total_trades: 30827\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.89e+04    |\n",
      "|    total_cost           | 4.34e+04    |\n",
      "|    total_reward         | -1.13e+03   |\n",
      "|    total_reward_pct     | -2.26       |\n",
      "|    total_trades         | 30827       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013691559 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00643     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 225        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01825963 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | -0.0304    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0264     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.25e+05  |\n",
      "|    total_cost           | 6.06e+04  |\n",
      "|    total_reward         | 7.54e+04  |\n",
      "|    total_reward_pct     | 151       |\n",
      "|    total_trades         | 31611     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 326       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 231       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0142325 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.7     |\n",
      "|    explained_variance   | 0.0874    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.231    |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -0.0119   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 0.139     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.63e+04   |\n",
      "|    total_cost           | 3.07e+04   |\n",
      "|    total_reward         | -1.37e+04  |\n",
      "|    total_reward_pct     | -27.5      |\n",
      "|    total_trades         | 29472      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01415397 |\n",
      "|    clip_fraction        | 0.0807     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.558      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.288     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0211     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 4.45e+04    |\n",
      "|    total_reward         | 5.18e+04    |\n",
      "|    total_reward_pct     | 104         |\n",
      "|    total_trades         | 30339       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013877214 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0347      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -7.51e+03   |\n",
      "|    total_cost           | 1.15e+04    |\n",
      "|    total_reward         | -5.75e+04   |\n",
      "|    total_reward_pct     | -115        |\n",
      "|    total_trades         | 27469       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013755897 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0609      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85091.12\n",
      "total_reward: 35091.12\n",
      "total_cost: 41826.88\n",
      "total_trades: 29943\n",
      "Sharpe: 0.347\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.51e+04    |\n",
      "|    total_cost           | 4.18e+04    |\n",
      "|    total_reward         | 3.51e+04    |\n",
      "|    total_reward_pct     | 70.2        |\n",
      "|    total_trades         | 29943       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018268727 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0162      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017002221 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0417      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.44e+04    |\n",
      "|    total_cost           | 2.93e+04    |\n",
      "|    total_reward         | -5.63e+03   |\n",
      "|    total_reward_pct     | -11.3       |\n",
      "|    total_trades         | 29957       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014486587 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.85e+04    |\n",
      "|    total_cost           | 3.26e+04    |\n",
      "|    total_reward         | 4.85e+04    |\n",
      "|    total_reward_pct     | 97          |\n",
      "|    total_trades         | 29940       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013870341 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0384      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.28e+04    |\n",
      "|    total_cost           | 2.57e+04    |\n",
      "|    total_reward         | 2.79e+03    |\n",
      "|    total_reward_pct     | 5.57        |\n",
      "|    total_trades         | 29262       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018488824 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0206      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.16e+04     |\n",
      "|    total_cost           | 1.14e+04     |\n",
      "|    total_reward         | -3.84e+04    |\n",
      "|    total_reward_pct     | -76.8        |\n",
      "|    total_trades         | 27509        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 288          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148829315 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.9        |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.292       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0172       |\n",
      "------------------------------------------\n",
      "day: 2460, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1207.24\n",
      "total_reward: -48792.76\n",
      "total_cost: 8627.51\n",
      "total_trades: 26911\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+03    |\n",
      "|    total_cost           | 8.63e+03    |\n",
      "|    total_reward         | -4.88e+04   |\n",
      "|    total_reward_pct     | -97.6       |\n",
      "|    total_trades         | 26911       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009721726 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00838     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016344335 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00751     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.48e+04    |\n",
      "|    total_cost           | 2.46e+04    |\n",
      "|    total_reward         | 2.48e+04    |\n",
      "|    total_reward_pct     | 49.7        |\n",
      "|    total_trades         | 28014       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016006136 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0209      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-01-03 to  2020-04-06\n",
      "PPO Sharpe Ratio:  0.15681682692711651\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
      "day: 2460, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 20964.86\n",
      "total_reward: -29035.14\n",
      "total_cost: 151.42\n",
      "total_trades: 27292\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+04 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | -96.4    |\n",
      "|    total_reward_pct | -0.193   |\n",
      "|    total_trades     | 28941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 79       |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total timesteps  | 9844     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -70      |\n",
      "|    critic_loss      | 31.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7383     |\n",
      "----------------------------------\n",
      "day: 2460, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 51710.36\n",
      "total_reward: 1710.36\n",
      "total_cost: 94.82\n",
      "total_trades: 28268\n",
      "Sharpe: 0.394\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.17e+04 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | 1.71e+03 |\n",
      "|    total_reward_pct | 3.42     |\n",
      "|    total_trades     | 28268    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total timesteps  | 19688    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -45.6    |\n",
      "|    critic_loss      | 6.1      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17227    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+04 |\n",
      "|    total_cost       | 94.8     |\n",
      "|    total_reward     | -96.4    |\n",
      "|    total_reward_pct | -0.193   |\n",
      "|    total_trades     | 29070    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 436      |\n",
      "|    total timesteps  | 29532    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -28.3    |\n",
      "|    critic_loss      | 1.99     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27071    |\n",
      "----------------------------------\n",
      "day: 2460, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 85846.65\n",
      "total_reward: 35846.65\n",
      "total_cost: 149.53\n",
      "total_trades: 29295\n",
      "Sharpe: 0.518\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.28e+05 |\n",
      "|    total_cost       | 521      |\n",
      "|    total_reward     | 7.81e+04 |\n",
      "|    total_reward_pct | 156      |\n",
      "|    total_trades     | 29132    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 592      |\n",
      "|    total timesteps  | 39376    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -17.8    |\n",
      "|    critic_loss      | 0.861    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 36915    |\n",
      "----------------------------------\n",
      "day: 2460, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 203894.46\n",
      "total_reward: 153894.46\n",
      "total_cost: 480.34\n",
      "total_trades: 29192\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.45e+05 |\n",
      "|    total_cost       | 316      |\n",
      "|    total_reward     | 9.52e+04 |\n",
      "|    total_reward_pct | 190      |\n",
      "|    total_trades     | 29480    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 747      |\n",
      "|    total timesteps  | 49220    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -11.5    |\n",
      "|    critic_loss      | 0.475    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46759    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-01-03 to  2020-04-06\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-04-06\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_378_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 322  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.09e+04   |\n",
      "|    total_cost           | 7.91e+04   |\n",
      "|    total_reward         | -2.91e+04  |\n",
      "|    total_reward_pct     | -58.1      |\n",
      "|    total_trades         | 33087      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01000694 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.274     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0253    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0843     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.48e+03    |\n",
      "|    total_cost           | 2.13e+04    |\n",
      "|    total_reward         | -4.75e+04   |\n",
      "|    total_reward_pct     | -95         |\n",
      "|    total_trades         | 28982       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014676659 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0467      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 750         |\n",
      "|    total_cost           | 8.86e+03    |\n",
      "|    total_reward         | -4.92e+04   |\n",
      "|    total_reward_pct     | -98.5       |\n",
      "|    total_trades         | 26928       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014191274 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0291      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.86e+03    |\n",
      "|    total_cost           | 4.82e+04    |\n",
      "|    total_reward         | -4.71e+04   |\n",
      "|    total_reward_pct     | -94.3       |\n",
      "|    total_trades         | 31202       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009052589 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.016       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012633585 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1726.99\n",
      "total_reward: -48273.01\n",
      "total_cost: 12370.57\n",
      "total_trades: 27850\n",
      "Sharpe: -0.356\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.73e+03    |\n",
      "|    total_cost           | 1.24e+04    |\n",
      "|    total_reward         | -4.83e+04   |\n",
      "|    total_reward_pct     | -96.5       |\n",
      "|    total_trades         | 27850       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010307109 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00713     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.07e+03    |\n",
      "|    total_cost           | 2.38e+04    |\n",
      "|    total_reward         | -4.39e+04   |\n",
      "|    total_reward_pct     | -87.9       |\n",
      "|    total_trades         | 29313       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014291029 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0191      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.44e+04     |\n",
      "|    total_cost           | 7.74e+04     |\n",
      "|    total_reward         | -5.58e+03    |\n",
      "|    total_reward_pct     | -11.2        |\n",
      "|    total_trades         | 32869        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 318          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149475485 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.1        |\n",
      "|    explained_variance   | -0.0559      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.284       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0215      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0248       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.65e+03    |\n",
      "|    total_cost           | 3.37e+04    |\n",
      "|    total_reward         | -4.04e+04   |\n",
      "|    total_reward_pct     | -80.7       |\n",
      "|    total_trades         | 30653       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009649381 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0342      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009503618 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+04     |\n",
      "|    total_cost           | 5.13e+04    |\n",
      "|    total_reward         | -1.7e+04    |\n",
      "|    total_reward_pct     | -33.9       |\n",
      "|    total_trades         | 31813       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019214336 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -9139.01\n",
      "total_reward: -59139.01\n",
      "total_cost: 20344.57\n",
      "total_trades: 29453\n",
      "Sharpe: -0.197\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -9.14e+03  |\n",
      "|    total_cost           | 2.03e+04   |\n",
      "|    total_reward         | -5.91e+04  |\n",
      "|    total_reward_pct     | -118       |\n",
      "|    total_trades         | 29453      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01878621 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.5        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.291     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0129     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.9e+04     |\n",
      "|    total_cost           | 4.29e+04    |\n",
      "|    total_reward         | -1.1e+04    |\n",
      "|    total_reward_pct     | -22         |\n",
      "|    total_trades         | 31237       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010706926 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0107      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -6.85e+03   |\n",
      "|    total_cost           | 1.46e+04    |\n",
      "|    total_reward         | -5.69e+04   |\n",
      "|    total_reward_pct     | -114        |\n",
      "|    total_trades         | 27950       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012560485 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009116596 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00963     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | -4.67e+03    |\n",
      "|    total_cost           | 2.25e+04     |\n",
      "|    total_reward         | -5.47e+04    |\n",
      "|    total_reward_pct     | -109         |\n",
      "|    total_trades         | 29658        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 319          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077453535 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.314       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00409      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.02e+04    |\n",
      "|    total_cost           | 4.07e+04    |\n",
      "|    total_reward         | 168         |\n",
      "|    total_reward_pct     | 0.335       |\n",
      "|    total_trades         | 31035       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009182558 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8959.99\n",
      "total_reward: -41040.01\n",
      "total_cost: 15364.50\n",
      "total_trades: 28794\n",
      "Sharpe: -0.188\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.96e+03    |\n",
      "|    total_cost           | 1.54e+04    |\n",
      "|    total_reward         | -4.1e+04    |\n",
      "|    total_reward_pct     | -82.1       |\n",
      "|    total_trades         | 28794       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014687316 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0189      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.05e+04    |\n",
      "|    total_cost           | 5.4e+04     |\n",
      "|    total_reward         | 524         |\n",
      "|    total_reward_pct     | 1.05        |\n",
      "|    total_trades         | 31805       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016576525 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+04    |\n",
      "|    total_cost           | 2.69e+04    |\n",
      "|    total_reward         | -2.96e+04   |\n",
      "|    total_reward_pct     | -59.2       |\n",
      "|    total_trades         | 29877       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011154865 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0347      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008061194 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.39e+04    |\n",
      "|    total_cost           | 1.98e+04    |\n",
      "|    total_reward         | -3.61e+04   |\n",
      "|    total_reward_pct     | -72.2       |\n",
      "|    total_trades         | 28869       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011140289 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00372     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+04    |\n",
      "|    total_cost           | 2.84e+04    |\n",
      "|    total_reward         | -2.22e+04   |\n",
      "|    total_reward_pct     | -44.4       |\n",
      "|    total_trades         | 29589       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010339746 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0121      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 51255.43\n",
      "total_reward: 1255.43\n",
      "total_cost: 56128.80\n",
      "total_trades: 31559\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.13e+04    |\n",
      "|    total_cost           | 5.61e+04    |\n",
      "|    total_reward         | 1.26e+03    |\n",
      "|    total_reward_pct     | 2.51        |\n",
      "|    total_trades         | 31559       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018291634 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.0745      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0245      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.86e+04    |\n",
      "|    total_cost           | 7.09e+04    |\n",
      "|    total_reward         | 1.86e+04    |\n",
      "|    total_reward_pct     | 37.2        |\n",
      "|    total_trades         | 32161       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011319933 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0597      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00687507 |\n",
      "|    clip_fraction        | 0.0847     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.272     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.076      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.9e+04    |\n",
      "|    total_cost           | 3.72e+04   |\n",
      "|    total_reward         | -1.1e+04   |\n",
      "|    total_reward_pct     | -22        |\n",
      "|    total_trades         | 30244      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01592699 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.289     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0174     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -3.61e+03   |\n",
      "|    total_cost           | 1.73e+04    |\n",
      "|    total_reward         | -5.36e+04   |\n",
      "|    total_reward_pct     | -107        |\n",
      "|    total_trades         | 28677       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013010741 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.81e+04     |\n",
      "|    total_cost           | 5.38e+04     |\n",
      "|    total_reward         | 3.81e+04     |\n",
      "|    total_reward_pct     | 76.2         |\n",
      "|    total_trades         | 31461        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 319          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149441315 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.5        |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.3         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0209      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0186       |\n",
      "------------------------------------------\n",
      "day: 2523, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 45009.81\n",
      "total_reward: -4990.19\n",
      "total_cost: 34879.78\n",
      "total_trades: 29997\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.5e+04     |\n",
      "|    total_cost           | 3.49e+04    |\n",
      "|    total_reward         | -4.99e+03   |\n",
      "|    total_reward_pct     | -9.98       |\n",
      "|    total_trades         | 29997       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011455962 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.25       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020071328 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0484      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 5.17e+04    |\n",
      "|    total_reward         | 5.26e+04    |\n",
      "|    total_reward_pct     | 105         |\n",
      "|    total_trades         | 31630       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004492525 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.223      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.38e+04    |\n",
      "|    total_cost           | 2.4e+04     |\n",
      "|    total_reward         | -1.62e+04   |\n",
      "|    total_reward_pct     | -32.5       |\n",
      "|    total_trades         | 28985       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007988246 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0682      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.37e+05    |\n",
      "|    total_cost           | 7.38e+04    |\n",
      "|    total_reward         | 8.74e+04    |\n",
      "|    total_reward_pct     | 175         |\n",
      "|    total_trades         | 32348       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011860797 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0585      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.26e+05    |\n",
      "|    total_cost           | 5.58e+04    |\n",
      "|    total_reward         | 7.58e+04    |\n",
      "|    total_reward_pct     | 152         |\n",
      "|    total_trades         | 30935       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017341673 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.182      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.282       |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 27938.84\n",
      "total_reward: -22061.16\n",
      "total_cost: 18051.66\n",
      "total_trades: 28669\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.79e+04    |\n",
      "|    total_cost           | 1.81e+04    |\n",
      "|    total_reward         | -2.21e+04   |\n",
      "|    total_reward_pct     | -44.1       |\n",
      "|    total_trades         | 28669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011406414 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.229      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013711909 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.025       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.32e+05    |\n",
      "|    total_cost           | 6.03e+04    |\n",
      "|    total_reward         | 8.24e+04    |\n",
      "|    total_reward_pct     | 165         |\n",
      "|    total_trades         | 31801       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010569025 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.226      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+04    |\n",
      "|    total_cost           | 1.83e+04    |\n",
      "|    total_reward         | -2.05e+04   |\n",
      "|    total_reward_pct     | -41.1       |\n",
      "|    total_trades         | 28936       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011973887 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0974      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.89e+04    |\n",
      "|    total_cost           | 2.68e+04    |\n",
      "|    total_reward         | -1.11e+04   |\n",
      "|    total_reward_pct     | -22.2       |\n",
      "|    total_trades         | 29715       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013032407 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0369      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.24e+04     |\n",
      "|    total_cost           | 2.4e+04      |\n",
      "|    total_reward         | -1.76e+04    |\n",
      "|    total_reward_pct     | -35.1        |\n",
      "|    total_trades         | 29606        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 320          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132250525 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.7        |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.29        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0351       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 320          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 275          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147805605 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.7        |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.29        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0276       |\n",
      "------------------------------------------\n",
      "day: 2523, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 54820.86\n",
      "total_reward: 4820.86\n",
      "total_cost: 30799.82\n",
      "total_trades: 29668\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.48e+04    |\n",
      "|    total_cost           | 3.08e+04    |\n",
      "|    total_reward         | 4.82e+03    |\n",
      "|    total_reward_pct     | 9.64        |\n",
      "|    total_trades         | 29668       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018881027 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0333      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.2e+04    |\n",
      "|    total_cost           | 1.65e+04   |\n",
      "|    total_reward         | -1.8e+04   |\n",
      "|    total_reward_pct     | -36.1      |\n",
      "|    total_trades         | 28563      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 320        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 287        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01824353 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.291     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0245     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1e+04      |\n",
      "|    total_cost           | 8.21e+03   |\n",
      "|    total_reward         | -4e+04     |\n",
      "|    total_reward_pct     | -79.9      |\n",
      "|    total_trades         | 27592      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 320        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02263588 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.293     |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0176     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.74e+04    |\n",
      "|    total_cost           | 3.01e+04    |\n",
      "|    total_reward         | -2.55e+03   |\n",
      "|    total_reward_pct     | -5.1        |\n",
      "|    total_trades         | 29319       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013032166 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019652145 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0534      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+05    |\n",
      "|    total_cost           | 4.21e+04    |\n",
      "|    total_reward         | 5.44e+04    |\n",
      "|    total_reward_pct     | 109         |\n",
      "|    total_trades         | 30871       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019748345 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.232      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "======Trading from:  2020-04-06 to  2020-07-09\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2000-01-01 to  2020-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -8.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.303    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -2.55    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 2.93     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0238   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 2.84     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -0.938    |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.00347   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6e+04    |\n",
      "|    total_cost         | 5.74e+04 |\n",
      "|    total_reward       | 1e+04    |\n",
      "|    total_reward_pct   | 20       |\n",
      "|    total_trades       | 30520    |\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -5.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00426  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 4.03     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0237   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.606    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.000699 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 274      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -0.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 3.02     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.896    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.08e+04  |\n",
      "|    total_cost         | 1.6e+04   |\n",
      "|    total_reward       | -2.92e+04 |\n",
      "|    total_reward_pct   | -58.3     |\n",
      "|    total_trades       | 26110     |\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | -48.4     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 1.35      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.0147    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -18.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 3.39     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0141   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0.414    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.00284  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -1.27    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -3.45    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.018    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.151    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.82    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00571  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.43e+04 |\n",
      "|    total_cost         | 8.93e+03  |\n",
      "|    total_reward       | -6.43e+04 |\n",
      "|    total_reward_pct   | -129      |\n",
      "|    total_trades       | 26052     |\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | -7.35     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 4.2       |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.031     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -1.76    |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00388  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.678    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0016   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -7.6     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.745   |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00885  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 1.3      |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00517  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.51e+04  |\n",
      "|    total_cost         | 1.84e+04  |\n",
      "|    total_reward       | -2.49e+04 |\n",
      "|    total_reward_pct   | -49.8     |\n",
      "|    total_trades       | 26695     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.8     |\n",
      "|    explained_variance | -115      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -0.33     |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 0.000661  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.11    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 2.73e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -2.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.463   |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.000521 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.404   |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.000497 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | 8.94e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 1.77     |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.00378  |\n",
      "------------------------------------\n",
      "day: 2523, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 15585.29\n",
      "total_reward: -34414.71\n",
      "total_cost: 5951.68\n",
      "total_trades: 25905\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.56e+04  |\n",
      "|    total_cost         | 5.95e+03  |\n",
      "|    total_reward       | -3.44e+04 |\n",
      "|    total_reward_pct   | -68.8     |\n",
      "|    total_trades       | 25905     |\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.5     |\n",
      "|    explained_variance | 0.0561    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -0.378    |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.000178  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | -635     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.607   |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.000646 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -60.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.811    |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.00101  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.137    |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 1.67e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | -0.189   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.203   |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.000227 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.03e+03 |\n",
      "|    total_cost         | 6.29e+03  |\n",
      "|    total_reward       | -5.2e+04  |\n",
      "|    total_reward_pct   | -104      |\n",
      "|    total_trades       | 25363     |\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36       |\n",
      "|    explained_variance | -0.178    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -1.68     |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 0.00229   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.56    |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.00058  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | -0.542   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 1.36     |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.00405  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 2.73     |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.00583  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | 0.0658   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.00124  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.49e+04  |\n",
      "|    total_cost         | 8.46e+03  |\n",
      "|    total_reward       | -2.51e+04 |\n",
      "|    total_reward_pct   | -50.2     |\n",
      "|    total_trades       | 24428     |\n",
      "| time/                 |           |\n",
      "|    fps                | 274       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.4     |\n",
      "|    explained_variance | -0.332    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 1.57      |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 0.00311   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | 0.0373   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.00556  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | 0.76     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0476  |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.000184 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | -0.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 2.64     |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.0063   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | 0.25     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.374    |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.000427 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.26e+04  |\n",
      "|    total_cost         | 2.69e+04  |\n",
      "|    total_reward       | -1.74e+04 |\n",
      "|    total_reward_pct   | -34.9     |\n",
      "|    total_trades       | 27497     |\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38.8     |\n",
      "|    explained_variance | -5.64     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -0.201    |\n",
      "|    std                | 1.87      |\n",
      "|    value_loss         | 7.52e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.0496   |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 2.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | -0.504   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.796    |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.000712 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | -0.587   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.681    |\n",
      "|    std                | 1.99     |\n",
      "|    value_loss         | 0.000417 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | -23.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.27    |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.000508 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.31e+03  |\n",
      "|    total_cost         | 2.3e+04   |\n",
      "|    total_reward       | -4.37e+04 |\n",
      "|    total_reward_pct   | -87.4     |\n",
      "|    total_trades       | 28113     |\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.91e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 0.872     |\n",
      "|    std                | 2.08      |\n",
      "|    value_loss         | 0.00139   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.445    |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.000299 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 0.000815 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.639    |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.000561 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.00315  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0.0107   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.503   |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.000368 |\n",
      "------------------------------------\n",
      "day: 2523, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 46411.23\n",
      "total_reward: -3588.77\n",
      "total_cost: 60800.52\n",
      "total_trades: 29624\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.64e+04  |\n",
      "|    total_cost         | 6.08e+04  |\n",
      "|    total_reward       | -3.59e+03 |\n",
      "|    total_reward_pct   | -7.18     |\n",
      "|    total_trades       | 29624     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 0.0873    |\n",
      "|    std                | 2.25      |\n",
      "|    value_loss         | 1.83e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.279   |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 4.8e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -8.8     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.314    |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.000301 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -12.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.442   |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.000241 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.107   |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 7.58e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.34e+03  |\n",
      "|    total_cost         | 1.29e+04  |\n",
      "|    total_reward       | -4.67e+04 |\n",
      "|    total_reward_pct   | -93.3     |\n",
      "|    total_trades       | 26972     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -0.242    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -1.36     |\n",
      "|    std                | 2.58      |\n",
      "|    value_loss         | 0.00123   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.0589   |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 3.98e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | -0.00568 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.000918 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | -8.84    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.0746   |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 0.000462 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 0.463     |\n",
      "|    std                | 2.8       |\n",
      "|    value_loss         | 0.000103  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.09e+03  |\n",
      "|    total_cost         | 2.89e+04  |\n",
      "|    total_reward       | -4.59e+04 |\n",
      "|    total_reward_pct   | -91.8     |\n",
      "|    total_trades       | 29774     |\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -0.528    |\n",
      "|    std                | 2.86      |\n",
      "|    value_loss         | 0.000139  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -137     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.697    |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 0.000375 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | -0.823   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.811    |\n",
      "|    std                | 2.99     |\n",
      "|    value_loss         | 0.00245  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 10.6     |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.0613   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | 0.0318   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -2.97    |\n",
      "|    std                | 3.06     |\n",
      "|    value_loss         | 0.00479  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.6e+04  |\n",
      "|    total_cost         | 3.67e+04 |\n",
      "|    total_reward       | -2.4e+04 |\n",
      "|    total_reward_pct   | -47.9    |\n",
      "|    total_trades       | 29675    |\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.4    |\n",
      "|    explained_variance | -3.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -0.3     |\n",
      "|    std                | 3.1      |\n",
      "|    value_loss         | 7.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | -9.72    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.518   |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.000175 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | -0.0986  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.911    |\n",
      "|    std                | 3.23     |\n",
      "|    value_loss         | 0.000624 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0.344    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -2.05    |\n",
      "|    std                | 3.29     |\n",
      "|    value_loss         | 0.00183  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.135   |\n",
      "|    std                | 3.37     |\n",
      "|    value_loss         | 7.9e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.35e+03  |\n",
      "|    total_cost         | 2.43e+04  |\n",
      "|    total_reward       | -4.07e+04 |\n",
      "|    total_reward_pct   | -81.3     |\n",
      "|    total_trades       | 29131     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 0.0836    |\n",
      "|    std                | 3.45      |\n",
      "|    value_loss         | 7.47e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | -5.52    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    std                | 3.54     |\n",
      "|    value_loss         | 8.23e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | -14      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.201    |\n",
      "|    std                | 3.64     |\n",
      "|    value_loss         | 5.04e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0.153   |\n",
      "|    std                | 3.76     |\n",
      "|    value_loss         | 3.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 1.44e-05 |\n",
      "------------------------------------\n",
      "day: 2523, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1660.14\n",
      "total_reward: -48339.86\n",
      "total_cost: 12998.87\n",
      "total_trades: 27476\n",
      "Sharpe: -0.588\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.66e+03  |\n",
      "|    total_cost         | 1.3e+04   |\n",
      "|    total_reward       | -4.83e+04 |\n",
      "|    total_reward_pct   | -96.7     |\n",
      "|    total_trades       | 27476     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.6     |\n",
      "|    explained_variance | -6.42     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 0.633     |\n",
      "|    std                | 4.06      |\n",
      "|    value_loss         | 0.000301  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 0.587    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -0.0283  |\n",
      "|    std                | 4.21     |\n",
      "|    value_loss         | 9.44e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.9    |\n",
      "|    explained_variance | -9.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.458   |\n",
      "|    std                | 4.36     |\n",
      "|    value_loss         | 0.000206 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | -0.607   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 4.51     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | -3.49    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 0.0431   |\n",
      "|    std                | 4.65     |\n",
      "|    value_loss         | 1.07e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.43e+03  |\n",
      "|    total_cost         | 1.61e+04  |\n",
      "|    total_reward       | -4.86e+04 |\n",
      "|    total_reward_pct   | -97.1     |\n",
      "|    total_trades       | 27665     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.9     |\n",
      "|    explained_variance | -4.41e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -0.947    |\n",
      "|    std                | 4.83      |\n",
      "|    value_loss         | 0.000282  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.6    |\n",
      "|    explained_variance | -4.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -0.499   |\n",
      "|    std                | 5.02     |\n",
      "|    value_loss         | 0.000143 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.815    |\n",
      "|    std                | 5.2      |\n",
      "|    value_loss         | 0.000221 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | 0.00405  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.223    |\n",
      "|    std                | 5.34     |\n",
      "|    value_loss         | 0.000102 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.2    |\n",
      "|    explained_variance | -0.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.145    |\n",
      "|    std                | 5.47     |\n",
      "|    value_loss         | 4.35e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -6.99e+03 |\n",
      "|    total_cost         | 2.7e+04   |\n",
      "|    total_reward       | -5.7e+04  |\n",
      "|    total_reward_pct   | -114      |\n",
      "|    total_trades       | 28411     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.6     |\n",
      "|    explained_variance | 0.337     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 0.0286    |\n",
      "|    std                | 5.59      |\n",
      "|    value_loss         | 0.000243  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60      |\n",
      "|    explained_variance | -0.404   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 0.478    |\n",
      "|    std                | 5.7      |\n",
      "|    value_loss         | 0.000215 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 2.6      |\n",
      "|    std                | 5.84     |\n",
      "|    value_loss         | 0.00222  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.9    |\n",
      "|    explained_variance | -0.343   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    std                | 5.98     |\n",
      "|    value_loss         | 0.00014  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.085    |\n",
      "|    std                | 6.15     |\n",
      "|    value_loss         | 1.89e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.16e+03  |\n",
      "|    total_cost         | 2.77e+04  |\n",
      "|    total_reward       | -4.78e+04 |\n",
      "|    total_reward_pct   | -95.7     |\n",
      "|    total_trades       | 28584     |\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.1     |\n",
      "|    explained_variance | -0.678    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 1.65      |\n",
      "|    std                | 6.35      |\n",
      "|    value_loss         | 0.000948  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.5    |\n",
      "|    explained_variance | -3.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 0.328    |\n",
      "|    std                | 6.51     |\n",
      "|    value_loss         | 6.69e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.1    |\n",
      "|    explained_variance | 0.0241   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 6.7      |\n",
      "|    value_loss         | 0.288    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.5    |\n",
      "|    explained_variance | -0.0672  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -1.89    |\n",
      "|    std                | 6.85     |\n",
      "|    value_loss         | 0.00147  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.86     |\n",
      "|    std                | 7.02     |\n",
      "|    value_loss         | 0.000267 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.58e+03  |\n",
      "|    total_cost         | 3.42e+04  |\n",
      "|    total_reward       | -4.64e+04 |\n",
      "|    total_reward_pct   | -92.8     |\n",
      "|    total_trades       | 28683     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.5     |\n",
      "|    explained_variance | -0.779    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -0.962    |\n",
      "|    std                | 7.23      |\n",
      "|    value_loss         | 0.000427  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.1    |\n",
      "|    explained_variance | -0.0176  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -1.48    |\n",
      "|    std                | 7.45     |\n",
      "|    value_loss         | 0.000646 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 0.111    |\n",
      "|    std                | 7.69     |\n",
      "|    value_loss         | 6.01e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0.317   |\n",
      "|    std                | 7.97     |\n",
      "|    value_loss         | 3.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.1    |\n",
      "|    explained_variance | -0.813   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.28     |\n",
      "|    std                | 8.3      |\n",
      "|    value_loss         | 4.03e-05 |\n",
      "------------------------------------\n",
      "day: 2523, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -3153.13\n",
      "total_reward: -53153.13\n",
      "total_cost: 13576.89\n",
      "total_trades: 26972\n",
      "Sharpe: -0.319\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -3.15e+03 |\n",
      "|    total_cost         | 1.36e+04  |\n",
      "|    total_reward       | -5.32e+04 |\n",
      "|    total_reward_pct   | -106      |\n",
      "|    total_trades       | 26972     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.9     |\n",
      "|    explained_variance | -1.08e+03 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -3.17     |\n",
      "|    std                | 8.64      |\n",
      "|    value_loss         | 0.0259    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | 0.505    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -0.106   |\n",
      "|    std                | 8.87     |\n",
      "|    value_loss         | 8.8e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 189       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 0.546     |\n",
      "|    std                | 9.08      |\n",
      "|    value_loss         | 0.000128  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.3    |\n",
      "|    explained_variance | 0.185    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -0.191   |\n",
      "|    std                | 9.3      |\n",
      "|    value_loss         | 5.22e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.613   |\n",
      "|    std                | 9.53     |\n",
      "|    value_loss         | 0.000137 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 2.1      |\n",
      "|    std                | 9.84     |\n",
      "|    value_loss         | 0.000951 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.31e+03  |\n",
      "|    total_cost         | 3.49e+04  |\n",
      "|    total_reward       | -4.67e+04 |\n",
      "|    total_reward_pct   | -93.4     |\n",
      "|    total_trades       | 29630     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -0.178    |\n",
      "|    std                | 10.2      |\n",
      "|    value_loss         | 1.6e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.7    |\n",
      "|    explained_variance | -0.536   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.119   |\n",
      "|    std                | 10.5     |\n",
      "|    value_loss         | 1.43e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.5    |\n",
      "|    explained_variance | -0.0381  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -0.0281  |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 1.09e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 0.00244  |\n",
      "|    std                | 11.5     |\n",
      "|    value_loss         | 9.52e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 205       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 0.0274    |\n",
      "|    std                | 12.1      |\n",
      "|    value_loss         | 2.5e-07   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 250       |\n",
      "|    total_cost         | 7.36e+03  |\n",
      "|    total_reward       | -4.98e+04 |\n",
      "|    total_reward_pct   | -99.5     |\n",
      "|    total_trades       | 26553     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 0.742     |\n",
      "|    std                | 12.4      |\n",
      "|    value_loss         | 0.000121  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 2.69      |\n",
      "|    std                | 12.8      |\n",
      "|    value_loss         | 0.00163   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -2.79    |\n",
      "|    std                | 13.1     |\n",
      "|    value_loss         | 0.00184  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.178    |\n",
      "|    std                | 13.5     |\n",
      "|    value_loss         | 1.29e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 0.399    |\n",
      "|    std                | 14       |\n",
      "|    value_loss         | 3.22e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 748       |\n",
      "|    total_cost         | 2.54e+04  |\n",
      "|    total_reward       | -4.93e+04 |\n",
      "|    total_reward_pct   | -98.5     |\n",
      "|    total_trades       | 29299     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 216       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.5     |\n",
      "|    explained_variance | -0.232    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -4.64     |\n",
      "|    std                | 14.3      |\n",
      "|    value_loss         | 0.0047    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.9    |\n",
      "|    explained_variance | 2.44e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 0.247    |\n",
      "|    std                | 14.6     |\n",
      "|    value_loss         | 6.33e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -4.99     |\n",
      "|    std                | 15        |\n",
      "|    value_loss         | 0.00418   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.8    |\n",
      "|    explained_variance | 0.0773   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 0.314    |\n",
      "|    std                | 15.3     |\n",
      "|    value_loss         | 0.000361 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.238   |\n",
      "|    std                | 15.7     |\n",
      "|    value_loss         | 1.94e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.17e+03  |\n",
      "|    total_cost         | 4.19e+04  |\n",
      "|    total_reward       | -4.68e+04 |\n",
      "|    total_reward_pct   | -93.7     |\n",
      "|    total_trades       | 30196     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -79.9     |\n",
      "|    explained_variance | 0.135     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -0.0578   |\n",
      "|    std                | 16.2      |\n",
      "|    value_loss         | 1.81e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -0.0904   |\n",
      "|    std                | 16.8      |\n",
      "|    value_loss         | 3.42e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    std                | 17.4     |\n",
      "|    value_loss         | 0.000671 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.8    |\n",
      "|    explained_variance | -1.49    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.119    |\n",
      "|    std                | 17.9     |\n",
      "|    value_loss         | 1.94e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.4    |\n",
      "|    explained_variance | -0.359   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.264    |\n",
      "|    std                | 18.6     |\n",
      "|    value_loss         | 1.83e-05 |\n",
      "------------------------------------\n",
      "day: 2523, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1961.61\n",
      "total_reward: -48038.39\n",
      "total_cost: 21939.23\n",
      "total_trades: 28652\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.96e+03  |\n",
      "|    total_cost         | 2.19e+04  |\n",
      "|    total_reward       | -4.8e+04  |\n",
      "|    total_reward_pct   | -96.1     |\n",
      "|    total_trades       | 28652     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -5.53     |\n",
      "|    std                | 19.1      |\n",
      "|    value_loss         | 0.00503   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -1.11    |\n",
      "|    std                | 19.5     |\n",
      "|    value_loss         | 0.000233 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -83.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 2.44      |\n",
      "|    std                | 20        |\n",
      "|    value_loss         | 0.000954  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -0.629   |\n",
      "|    std                | 20.5     |\n",
      "|    value_loss         | 6.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.9    |\n",
      "|    explained_variance | -1.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 0.0669   |\n",
      "|    std                | 21.1     |\n",
      "|    value_loss         | 3.07e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.48e+03  |\n",
      "|    total_cost         | 3.74e+04  |\n",
      "|    total_reward       | -4.65e+04 |\n",
      "|    total_reward_pct   | -93       |\n",
      "|    total_trades       | 30518     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.4     |\n",
      "|    explained_variance | 0.0214    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | 2.78      |\n",
      "|    std                | 21.7      |\n",
      "|    value_loss         | 0.00126   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -0.361   |\n",
      "|    std                | 22.4     |\n",
      "|    value_loss         | 1.64e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.528   |\n",
      "|    std                | 23.2     |\n",
      "|    value_loss         | 4.57e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 0.149    |\n",
      "|    std                | 24.2     |\n",
      "|    value_loss         | 3.16e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.833   |\n",
      "|    std                | 25.3     |\n",
      "|    value_loss         | 0.000481 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | -1.2e+04 |\n",
      "|    total_cost         | 1.81e+04 |\n",
      "|    total_reward       | -6.2e+04 |\n",
      "|    total_reward_pct   | -124     |\n",
      "|    total_trades       | 28810    |\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.7    |\n",
      "|    explained_variance | 0.000216 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.277   |\n",
      "|    std                | 25.9     |\n",
      "|    value_loss         | 1.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.472   |\n",
      "|    std                | 26.7     |\n",
      "|    value_loss         | 4.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 2.83     |\n",
      "|    std                | 27.5     |\n",
      "|    value_loss         | 0.00125  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 28.3     |\n",
      "|    value_loss         | 0.000196 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.1    |\n",
      "|    explained_variance | -0.999   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.0233  |\n",
      "|    std                | 29.3     |\n",
      "|    value_loss         | 1.57e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.54e+03  |\n",
      "|    total_cost         | 2.38e+04  |\n",
      "|    total_reward       | -4.85e+04 |\n",
      "|    total_reward_pct   | -96.9     |\n",
      "|    total_trades       | 29236     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 261       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 0.499     |\n",
      "|    std                | 30.5      |\n",
      "|    value_loss         | 3.25e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 263       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -92.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | 0.0663    |\n",
      "|    std                | 31.7      |\n",
      "|    value_loss         | 3.2e-06   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -3.04    |\n",
      "|    std                | 32.8     |\n",
      "|    value_loss         | 0.00132  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 3.07     |\n",
      "|    std                | 33.7     |\n",
      "|    value_loss         | 0.00115  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.3    |\n",
      "|    explained_variance | -5.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.0277  |\n",
      "|    std                | 34.7     |\n",
      "|    value_loss         | 1.49e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.6e+03   |\n",
      "|    total_cost         | 2.59e+04  |\n",
      "|    total_reward       | -4.74e+04 |\n",
      "|    total_reward_pct   | -94.8     |\n",
      "|    total_trades       | 29499     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -95       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -0.0386   |\n",
      "|    std                | 35.9      |\n",
      "|    value_loss         | 7.75e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    std                | 37.3     |\n",
      "|    value_loss         | 4.9e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 1.88     |\n",
      "|    std                | 38.5     |\n",
      "|    value_loss         | 0.000479 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    std                | 39.5     |\n",
      "|    value_loss         | 0.000171 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.4    |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 1.74     |\n",
      "|    std                | 40.8     |\n",
      "|    value_loss         | 0.000365 |\n",
      "------------------------------------\n",
      "day: 2523, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2266.19\n",
      "total_reward: -47733.81\n",
      "total_cost: 25536.68\n",
      "total_trades: 29256\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.27e+03  |\n",
      "|    total_cost         | 2.55e+04  |\n",
      "|    total_reward       | -4.77e+04 |\n",
      "|    total_reward_pct   | -95.5     |\n",
      "|    total_trades       | 29256     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 280       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -98       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -1.89     |\n",
      "|    std                | 42.1      |\n",
      "|    value_loss         | 0.000471  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -2.06    |\n",
      "|    std                | 43.4     |\n",
      "|    value_loss         | 0.000455 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 4.15     |\n",
      "|    std                | 44.7     |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.967   |\n",
      "|    std                | 45.9     |\n",
      "|    value_loss         | 0.000209 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.0431  |\n",
      "|    std                | 47.1     |\n",
      "|    value_loss         | 2.9e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.44e+03 |\n",
      "|    total_cost         | 2.66e+04  |\n",
      "|    total_reward       | -5.14e+04 |\n",
      "|    total_reward_pct   | -103      |\n",
      "|    total_trades       | 30218     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 289       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -0.223    |\n",
      "|    std                | 48.7      |\n",
      "|    value_loss         | 6.93e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.12     |\n",
      "|    std                | 50.6     |\n",
      "|    value_loss         | 2.07e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -2.8     |\n",
      "|    std                | 52.5     |\n",
      "|    value_loss         | 0.00134  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.531   |\n",
      "|    std                | 54       |\n",
      "|    value_loss         | 0.000106 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.301   |\n",
      "|    std                | 55.9     |\n",
      "|    value_loss         | 8.59e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.54e+03  |\n",
      "|    total_cost         | 1.87e+04  |\n",
      "|    total_reward       | -4.85e+04 |\n",
      "|    total_reward_pct   | -96.9     |\n",
      "|    total_trades       | 28445     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 298       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -104      |\n",
      "|    explained_variance | -12.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -26.1     |\n",
      "|    std                | 57.3      |\n",
      "|    value_loss         | 0.0831    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    std                | 58.2     |\n",
      "|    value_loss         | 0.00017  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 0.281    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 1.53     |\n",
      "|    std                | 59.3     |\n",
      "|    value_loss         | 0.000272 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.127    |\n",
      "|    std                | 60.6     |\n",
      "|    value_loss         | 7.44e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.0575   |\n",
      "|    std                | 62.5     |\n",
      "|    value_loss         | 1.07e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.81e+03  |\n",
      "|    total_cost         | 4.75e+04  |\n",
      "|    total_reward       | -4.82e+04 |\n",
      "|    total_reward_pct   | -96.4     |\n",
      "|    total_trades       | 31180     |\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 307       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -106      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -0.124    |\n",
      "|    std                | 64.7      |\n",
      "|    value_loss         | 9.38e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -107      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -0.0524   |\n",
      "|    std                | 66.7      |\n",
      "|    value_loss         | 4.38e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 271      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | -0.347   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.0277   |\n",
      "|    std                | 69       |\n",
      "|    value_loss         | 1.92e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 313       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -108      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -0.601    |\n",
      "|    std                | 71.8      |\n",
      "|    value_loss         | 4.97e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.0689  |\n",
      "|    std                | 74.9     |\n",
      "|    value_loss         | 9.56e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.68e+03  |\n",
      "|    total_cost         | 1.72e+04  |\n",
      "|    total_reward       | -4.83e+04 |\n",
      "|    total_reward_pct   | -96.6     |\n",
      "|    total_trades       | 29277     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 317       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -110      |\n",
      "|    explained_variance | -2.41     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -1.16     |\n",
      "|    std                | 77.8      |\n",
      "|    value_loss         | 0.000535  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 0.943    |\n",
      "|    std                | 79.7     |\n",
      "|    value_loss         | 8.23e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | -5.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -0.18    |\n",
      "|    std                | 82       |\n",
      "|    value_loss         | 2.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 0.553    |\n",
      "|    std                | 84.7     |\n",
      "|    value_loss         | 3.4e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.171   |\n",
      "|    std                | 87.9     |\n",
      "|    value_loss         | 6.97e-06 |\n",
      "------------------------------------\n",
      "day: 2523, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1066.57\n",
      "total_reward: -48933.43\n",
      "total_cost: 21823.07\n",
      "total_trades: 29478\n",
      "Sharpe: -0.624\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.07e+03  |\n",
      "|    total_cost         | 2.18e+04  |\n",
      "|    total_reward       | -4.89e+04 |\n",
      "|    total_reward_pct   | -97.9     |\n",
      "|    total_trades       | 29478     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -113      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | -0.0152   |\n",
      "|    std                | 91        |\n",
      "|    value_loss         | 2.06e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -113     |\n",
      "|    explained_variance | -2.39    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 0.482    |\n",
      "|    std                | 92.7     |\n",
      "|    value_loss         | 0.000122 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -113     |\n",
      "|    explained_variance | -1.77    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -0.898   |\n",
      "|    std                | 94.8     |\n",
      "|    value_loss         | 0.000127 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.573    |\n",
      "|    std                | 97.3     |\n",
      "|    value_loss         | 3.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -115     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 101      |\n",
      "|    value_loss         | 0.000335 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.57e+03 |\n",
      "|    total_cost         | 3.05e+04  |\n",
      "|    total_reward       | -5.46e+04 |\n",
      "|    total_reward_pct   | -109      |\n",
      "|    total_trades       | 30128     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 336       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -115      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 0.225     |\n",
      "|    std                | 104       |\n",
      "|    value_loss         | 4.72e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 337       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -116      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 0.0935    |\n",
      "|    std                | 108       |\n",
      "|    value_loss         | 3.45e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -117     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -2.54    |\n",
      "|    std                | 112      |\n",
      "|    value_loss         | 0.000581 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -117      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -1.34     |\n",
      "|    std                | 115       |\n",
      "|    value_loss         | 0.000314  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -118     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 119      |\n",
      "|    value_loss         | 0.000151 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.44e+03  |\n",
      "|    total_cost         | 2.92e+04  |\n",
      "|    total_reward       | -4.66e+04 |\n",
      "|    total_reward_pct   | -93.1     |\n",
      "|    total_trades       | 29287     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 345       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -118      |\n",
      "|    explained_variance | -1.24     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 0.131     |\n",
      "|    std                | 122       |\n",
      "|    value_loss         | 1.63e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 347       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -119      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | 0.0863    |\n",
      "|    std                | 127       |\n",
      "|    value_loss         | 2.95e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -120     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 2.86     |\n",
      "|    std                | 132      |\n",
      "|    value_loss         | 0.000641 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -120     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    std                | 135      |\n",
      "|    value_loss         | 0.000204 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -121     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.537   |\n",
      "|    std                | 140      |\n",
      "|    value_loss         | 2.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.03e+03 |\n",
      "|    total_cost         | 2.35e+04 |\n",
      "|    total_reward       | -4.8e+04 |\n",
      "|    total_reward_pct   | -95.9    |\n",
      "|    total_trades       | 29147    |\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -121     |\n",
      "|    explained_variance | -1.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -0.999   |\n",
      "|    std                | 145      |\n",
      "|    value_loss         | 0.00109  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -122     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 0.499    |\n",
      "|    std                | 149      |\n",
      "|    value_loss         | 8.77e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -123     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -1.04    |\n",
      "|    std                | 154      |\n",
      "|    value_loss         | 7.61e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -123     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -0.283   |\n",
      "|    std                | 160      |\n",
      "|    value_loss         | 6.15e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 361      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -124     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.509   |\n",
      "|    std                | 165      |\n",
      "|    value_loss         | 3.14e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.25e+03 |\n",
      "|    total_cost         | 1.88e+04  |\n",
      "|    total_reward       | -5.13e+04 |\n",
      "|    total_reward_pct   | -103      |\n",
      "|    total_trades       | 28902     |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 363       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -125      |\n",
      "|    explained_variance | -0.707    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 9.84      |\n",
      "|    std                | 171       |\n",
      "|    value_loss         | 0.0102    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -125     |\n",
      "|    explained_variance | -0.064   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -0.962   |\n",
      "|    std                | 174      |\n",
      "|    value_loss         | 0.00124  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -125     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 2.32     |\n",
      "|    std                | 177      |\n",
      "|    value_loss         | 0.000652 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 270      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -126     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 3.04     |\n",
      "|    std                | 181      |\n",
      "|    value_loss         | 0.00063  |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-04-06 to  2020-07-09\n",
      "A2C Sharpe Ratio:  0.11430899258299058\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 322  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.03e+04    |\n",
      "|    total_cost           | 9.53e+04    |\n",
      "|    total_reward         | -1.97e+04   |\n",
      "|    total_reward_pct     | -39.5       |\n",
      "|    total_trades         | 33467       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007663507 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0825      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.83e+04     |\n",
      "|    total_cost           | 4.44e+04     |\n",
      "|    total_reward         | -3.17e+04    |\n",
      "|    total_reward_pct     | -63.3        |\n",
      "|    total_trades         | 31338        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 319          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077497326 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.29        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0194      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0421       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.24e+03    |\n",
      "|    total_cost           | 3.67e+04    |\n",
      "|    total_reward         | -4.28e+04   |\n",
      "|    total_reward_pct     | -85.5       |\n",
      "|    total_trades         | 30591       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006369616 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0228      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.57e+03    |\n",
      "|    total_cost           | 1.76e+04    |\n",
      "|    total_reward         | -4.74e+04   |\n",
      "|    total_reward_pct     | -94.9       |\n",
      "|    total_trades         | 28559       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009860389 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0751      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0193      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009938719 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0125      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 11679.37\n",
      "total_reward: -38320.63\n",
      "total_cost: 44671.19\n",
      "total_trades: 31169\n",
      "Sharpe: -0.388\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+04    |\n",
      "|    total_cost           | 4.47e+04    |\n",
      "|    total_reward         | -3.83e+04   |\n",
      "|    total_reward_pct     | -76.6       |\n",
      "|    total_trades         | 31169       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018496778 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.45e+03    |\n",
      "|    total_cost           | 3.39e+04    |\n",
      "|    total_reward         | -4.15e+04   |\n",
      "|    total_reward_pct     | -83.1       |\n",
      "|    total_trades         | 30646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009685609 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.65e+03    |\n",
      "|    total_cost           | 1.3e+04     |\n",
      "|    total_reward         | -4.83e+04   |\n",
      "|    total_reward_pct     | -96.7       |\n",
      "|    total_trades         | 27912       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017987555 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.8e+03    |\n",
      "|    total_cost           | 1.82e+04    |\n",
      "|    total_reward         | -5.18e+04   |\n",
      "|    total_reward_pct     | -104        |\n",
      "|    total_trades         | 28798       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013309918 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015002984 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00687     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.34e+04    |\n",
      "|    total_cost           | 7.31e+04    |\n",
      "|    total_reward         | -2.66e+04   |\n",
      "|    total_reward_pct     | -53.1       |\n",
      "|    total_trades         | 32431       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009427346 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0939      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0181      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 13964.30\n",
      "total_reward: -36035.70\n",
      "total_cost: 42494.95\n",
      "total_trades: 31242\n",
      "Sharpe: -0.199\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.4e+04    |\n",
      "|    total_cost           | 4.25e+04   |\n",
      "|    total_reward         | -3.6e+04   |\n",
      "|    total_reward_pct     | -72.1      |\n",
      "|    total_trades         | 31242      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01731424 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.308     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0149     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.13e+03   |\n",
      "|    total_cost           | 2.12e+04   |\n",
      "|    total_reward         | -4.59e+04  |\n",
      "|    total_reward_pct     | -91.7      |\n",
      "|    total_trades         | 29647      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01924399 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.295      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0129     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+04    |\n",
      "|    total_cost           | 4.42e+04    |\n",
      "|    total_reward         | -3.93e+04   |\n",
      "|    total_reward_pct     | -78.6       |\n",
      "|    total_trades         | 31217       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010515907 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00948     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012097047 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.01e+04   |\n",
      "|    total_cost           | 1.68e+04    |\n",
      "|    total_reward         | -6.01e+04   |\n",
      "|    total_reward_pct     | -120        |\n",
      "|    total_trades         | 28939       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009864637 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00209     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.6e+03     |\n",
      "|    total_cost           | 2.8e+04     |\n",
      "|    total_reward         | -4.24e+04   |\n",
      "|    total_reward_pct     | -84.8       |\n",
      "|    total_trades         | 30417       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013095124 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 33006.23\n",
      "total_reward: -16993.77\n",
      "total_cost: 46138.33\n",
      "total_trades: 32021\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+04     |\n",
      "|    total_cost           | 4.61e+04    |\n",
      "|    total_reward         | -1.7e+04    |\n",
      "|    total_reward_pct     | -34         |\n",
      "|    total_trades         | 32021       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014007345 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+04    |\n",
      "|    total_cost           | 3.11e+04    |\n",
      "|    total_reward         | -2.89e+04   |\n",
      "|    total_reward_pct     | -57.8       |\n",
      "|    total_trades         | 29971       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010871922 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0238      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -5.33e+03   |\n",
      "|    total_cost           | 2.02e+04    |\n",
      "|    total_reward         | -5.53e+04   |\n",
      "|    total_reward_pct     | -111        |\n",
      "|    total_trades         | 29394       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009703346 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.021       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009048572 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00849     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.27e+03    |\n",
      "|    total_cost           | 2.5e+04     |\n",
      "|    total_reward         | -4.07e+04   |\n",
      "|    total_reward_pct     | -81.5       |\n",
      "|    total_trades         | 29969       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013401855 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00456     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.88e+03   |\n",
      "|    total_cost           | 1.27e+04   |\n",
      "|    total_reward         | -4.81e+04  |\n",
      "|    total_reward_pct     | -96.2      |\n",
      "|    total_trades         | 28569      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01670424 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.62       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.291     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.00643    |\n",
      "----------------------------------------\n",
      "day: 2523, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 42711.62\n",
      "total_reward: -7288.38\n",
      "total_cost: 63812.24\n",
      "total_trades: 32304\n",
      "Sharpe: 0.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.27e+04    |\n",
      "|    total_cost           | 6.38e+04    |\n",
      "|    total_reward         | -7.29e+03   |\n",
      "|    total_reward_pct     | -14.6       |\n",
      "|    total_trades         | 32304       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021343026 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | -0.375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.019       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.59e+04    |\n",
      "|    total_cost           | 3.37e+04    |\n",
      "|    total_reward         | -3.41e+04   |\n",
      "|    total_reward_pct     | -68.2       |\n",
      "|    total_trades         | 30534       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014849155 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0355      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016310234 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.67e+03    |\n",
      "|    total_cost           | 2e+04       |\n",
      "|    total_reward         | -4.33e+04   |\n",
      "|    total_reward_pct     | -86.7       |\n",
      "|    total_trades         | 29843       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008218426 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00506     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.32e+04    |\n",
      "|    total_cost           | 6.54e+04    |\n",
      "|    total_reward         | -6.82e+03   |\n",
      "|    total_reward_pct     | -13.6       |\n",
      "|    total_trades         | 32670       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014667906 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.65e+04    |\n",
      "|    total_cost           | 6.03e+04    |\n",
      "|    total_reward         | -3.48e+03   |\n",
      "|    total_reward_pct     | -6.97       |\n",
      "|    total_trades         | 32210       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014068328 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0486      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 19794.95\n",
      "total_reward: -30205.05\n",
      "total_cost: 32364.23\n",
      "total_trades: 30544\n",
      "Sharpe: 0.075\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.98e+04    |\n",
      "|    total_cost           | 3.24e+04    |\n",
      "|    total_reward         | -3.02e+04   |\n",
      "|    total_reward_pct     | -60.4       |\n",
      "|    total_trades         | 30544       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014458634 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.27       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0743      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017102722 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0192      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+04    |\n",
      "|    total_cost           | 2.94e+04    |\n",
      "|    total_reward         | -3.75e+04   |\n",
      "|    total_reward_pct     | -74.9       |\n",
      "|    total_trades         | 30529       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008653243 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00757     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.23e+04    |\n",
      "|    total_cost           | 4.92e+04    |\n",
      "|    total_reward         | -7.71e+03   |\n",
      "|    total_reward_pct     | -15.4       |\n",
      "|    total_trades         | 31536       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014333941 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0189      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.56e+04    |\n",
      "|    total_cost           | 3.96e+04    |\n",
      "|    total_reward         | -1.44e+04   |\n",
      "|    total_reward_pct     | -28.8       |\n",
      "|    total_trades         | 31099       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015778726 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.37e+04    |\n",
      "|    total_cost           | 4.18e+04    |\n",
      "|    total_reward         | -1.63e+04   |\n",
      "|    total_reward_pct     | -32.5       |\n",
      "|    total_trades         | 31178       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017091122 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0213      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 12832.10\n",
      "total_reward: -37167.90\n",
      "total_cost: 18392.96\n",
      "total_trades: 29192\n",
      "Sharpe: 0.012\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.28e+04    |\n",
      "|    total_cost           | 1.84e+04    |\n",
      "|    total_reward         | -3.72e+04   |\n",
      "|    total_reward_pct     | -74.3       |\n",
      "|    total_trades         | 29192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019089825 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0226      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017577339 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00773     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.26e+04    |\n",
      "|    total_cost           | 3.94e+04    |\n",
      "|    total_reward         | -7.42e+03   |\n",
      "|    total_reward_pct     | -14.8       |\n",
      "|    total_trades         | 30761       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020474007 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0148      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.38e+04     |\n",
      "|    total_cost           | 2.37e+04     |\n",
      "|    total_reward         | -3.62e+04    |\n",
      "|    total_reward_pct     | -72.5        |\n",
      "|    total_trades         | 29908        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 318          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133035835 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.8        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.298       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0185       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.66e+04    |\n",
      "|    total_cost           | 3.29e+04    |\n",
      "|    total_reward         | -3.34e+04   |\n",
      "|    total_reward_pct     | -66.7       |\n",
      "|    total_trades         | 30680       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010324641 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00849     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.26e+04    |\n",
      "|    total_cost           | 7.14e+04    |\n",
      "|    total_reward         | 3.26e+04    |\n",
      "|    total_reward_pct     | 65.3        |\n",
      "|    total_trades         | 32270       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015915856 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011340875 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0493      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8148.99\n",
      "total_reward: -41851.01\n",
      "total_cost: 16287.80\n",
      "total_trades: 29315\n",
      "Sharpe: -0.059\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.15e+03    |\n",
      "|    total_cost           | 1.63e+04    |\n",
      "|    total_reward         | -4.19e+04   |\n",
      "|    total_reward_pct     | -83.7       |\n",
      "|    total_trades         | 29315       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010030605 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00408     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+04    |\n",
      "|    total_cost           | 1.91e+04    |\n",
      "|    total_reward         | -3.97e+04   |\n",
      "|    total_reward_pct     | -79.4       |\n",
      "|    total_trades         | 29144       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021108503 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0139      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+04    |\n",
      "|    total_cost           | 3.79e+04    |\n",
      "|    total_reward         | -2.33e+04   |\n",
      "|    total_reward_pct     | -46.5       |\n",
      "|    total_trades         | 30842       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024305236 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00698     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.35e+04    |\n",
      "|    total_cost           | 2.8e+04     |\n",
      "|    total_reward         | -2.65e+04   |\n",
      "|    total_reward_pct     | -53         |\n",
      "|    total_trades         | 30519       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018623509 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0123      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019702338 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.53e+04    |\n",
      "|    total_cost           | 5.32e+04    |\n",
      "|    total_reward         | 5.32e+03    |\n",
      "|    total_reward_pct     | 10.6        |\n",
      "|    total_trades         | 31832       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019818027 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-04-06 to  2020-07-09\n",
      "PPO Sharpe Ratio:  0.22943344868246107\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.92e+04 |\n",
      "|    total_cost       | 122      |\n",
      "|    total_reward     | 9.2e+03  |\n",
      "|    total_reward_pct | 18.4     |\n",
      "|    total_trades     | 25508    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 79       |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total timesteps  | 10096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 84       |\n",
      "|    critic_loss      | 23.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7572     |\n",
      "----------------------------------\n",
      "day: 2523, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 45143.18\n",
      "total_reward: -4856.82\n",
      "total_cost: 112.85\n",
      "total_trades: 25189\n",
      "Sharpe: 0.444\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.67e+04  |\n",
      "|    total_cost       | 132       |\n",
      "|    total_reward     | -2.33e+04 |\n",
      "|    total_reward_pct | -46.6     |\n",
      "|    total_trades     | 24799     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 70        |\n",
      "|    time_elapsed     | 286       |\n",
      "|    total timesteps  | 20192     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 48.9      |\n",
      "|    critic_loss      | 4.02      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17668     |\n",
      "-----------------------------------\n",
      "day: 2523, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 35070.19\n",
      "total_reward: -14929.81\n",
      "total_cost: 125.53\n",
      "total_trades: 25313\n",
      "Sharpe: 0.317\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.26e+04  |\n",
      "|    total_cost       | 138       |\n",
      "|    total_reward     | -1.74e+04 |\n",
      "|    total_reward_pct | -34.9     |\n",
      "|    total_trades     | 24705     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 68        |\n",
      "|    time_elapsed     | 444       |\n",
      "|    total timesteps  | 30288     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 28.6      |\n",
      "|    critic_loss      | 1.11      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 27764     |\n",
      "-----------------------------------\n",
      "day: 2523, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 53821.65\n",
      "total_reward: 3821.65\n",
      "total_cost: 202.26\n",
      "total_trades: 26726\n",
      "Sharpe: 0.456\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.96e+04  |\n",
      "|    total_cost       | 142       |\n",
      "|    total_reward     | -2.04e+04 |\n",
      "|    total_reward_pct | -40.9     |\n",
      "|    total_trades     | 27031     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 67        |\n",
      "|    time_elapsed     | 602       |\n",
      "|    total timesteps  | 40384     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 16.8      |\n",
      "|    critic_loss      | 0.532     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37860     |\n",
      "-----------------------------------\n",
      "day: 2523, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24727.77\n",
      "total_reward: -25272.23\n",
      "total_cost: 146.51\n",
      "total_trades: 25613\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.47e+04  |\n",
      "|    total_cost       | 147       |\n",
      "|    total_reward     | -2.53e+04 |\n",
      "|    total_reward_pct | -50.5     |\n",
      "|    total_trades     | 25613     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 66        |\n",
      "|    time_elapsed     | 759       |\n",
      "|    total timesteps  | 50480     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 9.78      |\n",
      "|    critic_loss      | 0.34      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 47956     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2020-04-06 to  2020-07-09\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-07-09\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_441_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 317  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+04    |\n",
      "|    total_cost           | 8.61e+04    |\n",
      "|    total_reward         | -3.78e+04   |\n",
      "|    total_reward_pct     | -75.6       |\n",
      "|    total_trades         | 33711       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005782881 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+04    |\n",
      "|    total_cost           | 7.79e+04    |\n",
      "|    total_reward         | -2.85e+04   |\n",
      "|    total_reward_pct     | -56.9       |\n",
      "|    total_trades         | 33889       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006289061 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0581      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.06e+04     |\n",
      "|    total_cost           | 5.13e+04     |\n",
      "|    total_reward         | -3.94e+04    |\n",
      "|    total_reward_pct     | -78.8        |\n",
      "|    total_trades         | 32706        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026919153 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27          |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.296       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0216      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0357       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107280575 |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.1        |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.297       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0241       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.53e+03    |\n",
      "|    total_cost           | 2.65e+04    |\n",
      "|    total_reward         | -4.45e+04   |\n",
      "|    total_reward_pct     | -88.9       |\n",
      "|    total_trades         | 30758       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013018059 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 23634.64\n",
      "total_reward: -26365.36\n",
      "total_cost: 71019.69\n",
      "total_trades: 33476\n",
      "Sharpe: -0.179\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.36e+04   |\n",
      "|    total_cost           | 7.1e+04    |\n",
      "|    total_reward         | -2.64e+04  |\n",
      "|    total_reward_pct     | -52.7      |\n",
      "|    total_trades         | 33476      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01869249 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.023     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0249     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.02e+03    |\n",
      "|    total_cost           | 2.63e+04    |\n",
      "|    total_reward         | -4.3e+04    |\n",
      "|    total_reward_pct     | -86         |\n",
      "|    total_trades         | 30466       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015909158 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0189      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.02e+04   |\n",
      "|    total_cost           | 2.26e+04    |\n",
      "|    total_reward         | -6.02e+04   |\n",
      "|    total_reward_pct     | -120        |\n",
      "|    total_trades         | 29773       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007865126 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012539024 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.71e+03    |\n",
      "|    total_cost           | 2.6e+04     |\n",
      "|    total_reward         | -4.33e+04   |\n",
      "|    total_reward_pct     | -86.6       |\n",
      "|    total_trades         | 30372       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007585287 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00497     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.68e+03   |\n",
      "|    total_cost           | 1.85e+04   |\n",
      "|    total_reward         | -4.73e+04  |\n",
      "|    total_reward_pct     | -94.6      |\n",
      "|    total_trades         | 29689      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01314689 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.31      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0093     |\n",
      "----------------------------------------\n",
      "day: 2586, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 31663.15\n",
      "total_reward: -18336.85\n",
      "total_cost: 58714.08\n",
      "total_trades: 32768\n",
      "Sharpe: -0.067\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.17e+04    |\n",
      "|    total_cost           | 5.87e+04    |\n",
      "|    total_reward         | -1.83e+04   |\n",
      "|    total_reward_pct     | -36.7       |\n",
      "|    total_trades         | 32768       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017053623 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | -0.252      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0271      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.23e+04     |\n",
      "|    total_cost           | 3.04e+04     |\n",
      "|    total_reward         | -3.77e+04    |\n",
      "|    total_reward_pct     | -75.4        |\n",
      "|    total_trades         | 31132        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128256185 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.3        |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.303       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0198      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.018        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014265909 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00941     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+03    |\n",
      "|    total_cost           | 1.82e+04    |\n",
      "|    total_reward         | -4.68e+04   |\n",
      "|    total_reward_pct     | -93.6       |\n",
      "|    total_trades         | 29774       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009043937 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00333     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.57e+04    |\n",
      "|    total_cost           | 5.57e+04    |\n",
      "|    total_reward         | -3.43e+04   |\n",
      "|    total_reward_pct     | -68.6       |\n",
      "|    total_trades         | 32858       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013556098 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.43e+03     |\n",
      "|    total_cost           | 1.06e+04     |\n",
      "|    total_reward         | -4.76e+04    |\n",
      "|    total_reward_pct     | -95.1        |\n",
      "|    total_trades         | 28528        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077384003 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.4        |\n",
      "|    explained_variance   | 0.358        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.279       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.012        |\n",
      "------------------------------------------\n",
      "day: 2586, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 44376.60\n",
      "total_reward: -5623.40\n",
      "total_cost: 80995.50\n",
      "total_trades: 33983\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.44e+04    |\n",
      "|    total_cost           | 8.1e+04     |\n",
      "|    total_reward         | -5.62e+03   |\n",
      "|    total_reward_pct     | -11.2       |\n",
      "|    total_trades         | 33983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014988628 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01131577 |\n",
      "|    clip_fraction        | 0.0863     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.249      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.27      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0406     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.59e+03    |\n",
      "|    total_cost           | 2.11e+04    |\n",
      "|    total_reward         | -4.34e+04   |\n",
      "|    total_reward_pct     | -86.8       |\n",
      "|    total_trades         | 30451       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019543335 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0054      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+04    |\n",
      "|    total_cost           | 5.64e+04    |\n",
      "|    total_reward         | -2.24e+04   |\n",
      "|    total_reward_pct     | -44.9       |\n",
      "|    total_trades         | 33016       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009529909 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -3.85e+03   |\n",
      "|    total_cost           | 2.02e+04    |\n",
      "|    total_reward         | -5.39e+04   |\n",
      "|    total_reward_pct     | -108        |\n",
      "|    total_trades         | 30513       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007385499 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013185833 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00812     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.4e+04     |\n",
      "|    total_cost           | 3.26e+04    |\n",
      "|    total_reward         | -3.6e+04    |\n",
      "|    total_reward_pct     | -72         |\n",
      "|    total_trades         | 31687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011198248 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.005       |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 19073.97\n",
      "total_reward: -30926.03\n",
      "total_cost: 27812.67\n",
      "total_trades: 29904\n",
      "Sharpe: 0.420\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+04    |\n",
      "|    total_cost           | 2.78e+04    |\n",
      "|    total_reward         | -3.09e+04   |\n",
      "|    total_reward_pct     | -61.9       |\n",
      "|    total_trades         | 29904       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010664217 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.48e+03    |\n",
      "|    total_cost           | 2.04e+04    |\n",
      "|    total_reward         | -4.45e+04   |\n",
      "|    total_reward_pct     | -89         |\n",
      "|    total_trades         | 30572       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015362361 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.71e+03    |\n",
      "|    total_cost           | 3.4e+04     |\n",
      "|    total_reward         | -4.43e+04   |\n",
      "|    total_reward_pct     | -88.6       |\n",
      "|    total_trades         | 31643       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013247798 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00737     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010814002 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.34e+04   |\n",
      "|    total_cost           | 6.8e+04    |\n",
      "|    total_reward         | 3.45e+03   |\n",
      "|    total_reward_pct     | 6.89       |\n",
      "|    total_trades         | 33364      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01715142 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.153      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0223     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.31e+04     |\n",
      "|    total_cost           | 3.23e+04     |\n",
      "|    total_reward         | -2.69e+04    |\n",
      "|    total_reward_pct     | -53.8        |\n",
      "|    total_trades         | 31690        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117280865 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.6        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.296       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0191       |\n",
      "------------------------------------------\n",
      "day: 2586, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3501.28\n",
      "total_reward: -46498.72\n",
      "total_cost: 21911.03\n",
      "total_trades: 29811\n",
      "Sharpe: -0.161\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.5e+03     |\n",
      "|    total_cost           | 2.19e+04    |\n",
      "|    total_reward         | -4.65e+04   |\n",
      "|    total_reward_pct     | -93         |\n",
      "|    total_trades         | 29811       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021300763 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0149      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.27e+04    |\n",
      "|    total_cost           | 2.38e+04    |\n",
      "|    total_reward         | -3.73e+04   |\n",
      "|    total_reward_pct     | -74.6       |\n",
      "|    total_trades         | 30618       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012559994 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00882     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018925019 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00723     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.3e+04     |\n",
      "|    total_cost           | 2.55e+04    |\n",
      "|    total_reward         | -3.7e+04    |\n",
      "|    total_reward_pct     | -74         |\n",
      "|    total_trades         | 30923       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015534181 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00296     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2e+04        |\n",
      "|    total_cost           | 2.03e+04     |\n",
      "|    total_reward         | -3e+04       |\n",
      "|    total_reward_pct     | -60          |\n",
      "|    total_trades         | 28845        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139253065 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.7        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.291       |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.012        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.97e+03    |\n",
      "|    total_cost           | 1.43e+04    |\n",
      "|    total_reward         | -4.4e+04    |\n",
      "|    total_reward_pct     | -88.1       |\n",
      "|    total_trades         | 29303       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019749355 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00645     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 65616.73\n",
      "total_reward: 15616.73\n",
      "total_cost: 65152.59\n",
      "total_trades: 33259\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.56e+04    |\n",
      "|    total_cost           | 6.52e+04    |\n",
      "|    total_reward         | 1.56e+04    |\n",
      "|    total_reward_pct     | 31.2        |\n",
      "|    total_trades         | 33259       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016353328 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | -0.513      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017618341 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0371      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.43e+03    |\n",
      "|    total_cost           | 1.79e+04    |\n",
      "|    total_reward         | -4.16e+04   |\n",
      "|    total_reward_pct     | -83.1       |\n",
      "|    total_trades         | 29686       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022128768 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00367     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.09e+04    |\n",
      "|    total_cost           | 5.28e+04    |\n",
      "|    total_reward         | 2.09e+04    |\n",
      "|    total_reward_pct     | 41.7        |\n",
      "|    total_trades         | 33062       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021638528 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0332      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.63e+04    |\n",
      "|    total_cost           | 2.01e+04    |\n",
      "|    total_reward         | -3.37e+04   |\n",
      "|    total_reward_pct     | -67.4       |\n",
      "|    total_trades         | 30010       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016870555 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0405      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -8.31e+03   |\n",
      "|    total_cost           | 1.8e+04     |\n",
      "|    total_reward         | -5.83e+04   |\n",
      "|    total_reward_pct     | -117        |\n",
      "|    total_trades         | 30184       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008100443 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00867     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020444162 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00591     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8400.93\n",
      "total_reward: -41599.07\n",
      "total_cost: 23966.40\n",
      "total_trades: 30595\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.4e+03     |\n",
      "|    total_cost           | 2.4e+04     |\n",
      "|    total_reward         | -4.16e+04   |\n",
      "|    total_reward_pct     | -83.2       |\n",
      "|    total_trades         | 30595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018834429 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00366     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.3e+04     |\n",
      "|    total_cost           | 4.03e+04    |\n",
      "|    total_reward         | 2.3e+04     |\n",
      "|    total_reward_pct     | 46          |\n",
      "|    total_trades         | 32115       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019182127 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0298      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+04    |\n",
      "|    total_cost           | 2.79e+04    |\n",
      "|    total_reward         | -2.55e+04   |\n",
      "|    total_reward_pct     | -51         |\n",
      "|    total_trades         | 30532       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015566146 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 311        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01005771 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.532      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.295     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0113     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.01e+03    |\n",
      "|    total_cost           | 1.61e+04    |\n",
      "|    total_reward         | -4.1e+04    |\n",
      "|    total_reward_pct     | -82         |\n",
      "|    total_trades         | 29667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017005771 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00286     |\n",
      "-----------------------------------------\n",
      "======Trading from:  2020-07-09 to  2020-10-06\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2000-01-01 to  2020-07-09\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 247      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.401   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.467   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0103   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 255      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -2.41    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.213   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0163   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 256      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -1.46    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.951    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0431   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 259      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.0564   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 3.48     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 261      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0.0209   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -5.45    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0566   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.71e+05 |\n",
      "|    total_cost         | 3.62e+04 |\n",
      "|    total_reward       | 1.21e+05 |\n",
      "|    total_reward_pct   | 241      |\n",
      "|    total_trades       | 29830    |\n",
      "| time/                 |          |\n",
      "|    fps                | 262      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -42.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -6.13    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0574   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 264      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -8.92    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.156    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00296  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 264      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -5.88    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 4.13     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0224   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -24.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.57    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.000783 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -28      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.218   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00585  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.42e+04  |\n",
      "|    total_cost         | 1.67e+04  |\n",
      "|    total_reward       | -2.58e+04 |\n",
      "|    total_reward_pct   | -51.6     |\n",
      "|    total_trades       | 28054     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.1     |\n",
      "|    explained_variance | -7.15     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -1.38     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.00236   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.17    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.000121 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -5.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -1.22    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.00228  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -2.38    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0338   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0.0215   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 8.66     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0913   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.84e+04  |\n",
      "|    total_cost         | 7.35e+03  |\n",
      "|    total_reward       | -1.16e+04 |\n",
      "|    total_reward_pct   | -23.3     |\n",
      "|    total_trades       | 27035     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.5     |\n",
      "|    explained_variance | -0.983    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -0.274    |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 9.51e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -0.2      |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 5.83e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 1.63      |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.0037    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.707    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.032    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -1.23    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0223   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.16e+04  |\n",
      "|    total_cost         | 5.18e+03  |\n",
      "|    total_reward       | -8.38e+03 |\n",
      "|    total_reward_pct   | -16.8     |\n",
      "|    total_trades       | 28391     |\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.6     |\n",
      "|    explained_variance | -0.0755   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 2.48      |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.00611   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 268      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | -32.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.00638  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | -2.65    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -3.18    |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.0118   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | -0.0211  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -1.71    |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0304   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 268      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | 0.0845   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.29     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0033   |\n",
      "------------------------------------\n",
      "day: 2586, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 10565.56\n",
      "total_reward: -39434.44\n",
      "total_cost: 5706.03\n",
      "total_trades: 27215\n",
      "Sharpe: -0.271\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.06e+04  |\n",
      "|    total_cost         | 5.71e+03  |\n",
      "|    total_reward       | -3.94e+04 |\n",
      "|    total_reward_pct   | -78.9     |\n",
      "|    total_trades       | 27215     |\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.4     |\n",
      "|    explained_variance | -3.95     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 4.37      |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.0238    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | -2.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.149    |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.00163  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | 0.037    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.588    |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.000929 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -0.00103 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 1.74     |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | -0.456   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 4.71     |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0629   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 3.57     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.0185   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.01e+03 |\n",
      "|    total_cost         | 2.52e+03 |\n",
      "|    total_reward       | -4.3e+04 |\n",
      "|    total_reward_pct   | -86      |\n",
      "|    total_trades       | 26432    |\n",
      "| time/                 |          |\n",
      "|    fps                | 268      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.222    |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 8.43e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 268      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 5.77     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0269   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -1.94    |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.00385  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -0.0596  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.258    |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00213  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 5.41     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0312   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.7e+04   |\n",
      "|    total_cost         | 3.07e+03  |\n",
      "|    total_reward       | -3.03e+03 |\n",
      "|    total_reward_pct   | -6.06     |\n",
      "|    total_trades       | 24541     |\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -0.0583   |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 2.6e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | -0.254   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.488    |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.000497 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -1.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.351    |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.000518 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | -0.00823 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -10.9    |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.0932   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.00868  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+05 |\n",
      "|    total_cost         | 1.59e+04 |\n",
      "|    total_reward       | 5.73e+04 |\n",
      "|    total_reward_pct   | 115      |\n",
      "|    total_trades       | 25222    |\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | -0.308   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.118   |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 1.38e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.00206  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.1    |\n",
      "|    explained_variance | 0.0173   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 0.022    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -2.83    |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.00954  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.7    |\n",
      "|    explained_variance | -23.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.549    |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.00254  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.51e+04  |\n",
      "|    total_cost         | 4.89e+03  |\n",
      "|    total_reward       | -3.49e+04 |\n",
      "|    total_reward_pct   | -69.9     |\n",
      "|    total_trades       | 25364     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38       |\n",
      "|    explained_variance | -0.634    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 2.15      |\n",
      "|    std                | 1.79      |\n",
      "|    value_loss         | 0.00383   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.887   |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.000876 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | -0.871   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.00141  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.716   |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.00163  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.202    |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.000132 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4015.10\n",
      "total_reward: -45984.90\n",
      "total_cost: 4571.48\n",
      "total_trades: 23211\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.02e+03  |\n",
      "|    total_cost         | 4.57e+03  |\n",
      "|    total_reward       | -4.6e+04  |\n",
      "|    total_reward_pct   | -92       |\n",
      "|    total_trades       | 23211     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.8     |\n",
      "|    explained_variance | -2.15e+03 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 0.12      |\n",
      "|    std                | 1.97      |\n",
      "|    value_loss         | 0.000281  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | -0.265   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.658    |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 0.000443 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | -5.78    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.465    |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.000959 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 8.94e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.0683   |\n",
      "|    std                | 2.1      |\n",
      "|    value_loss         | 0.000268 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | -1.95    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.682    |\n",
      "|    std                | 2.14     |\n",
      "|    value_loss         | 0.00098  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+03 |\n",
      "|    total_cost         | 1.16e+04 |\n",
      "|    total_reward       | -4e+04   |\n",
      "|    total_reward_pct   | -80      |\n",
      "|    total_trades       | 25216    |\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | -10.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.279    |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.000195 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.41    |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.000107 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -1.62    |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.11     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -3.3     |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 0.00677  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -2.53    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 2.7      |\n",
      "|    std                | 2.37     |\n",
      "|    value_loss         | 0.00535  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -4.92    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -2.36    |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.00639  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.24e+04  |\n",
      "|    total_cost         | 1.19e+04  |\n",
      "|    total_reward       | -2.76e+04 |\n",
      "|    total_reward_pct   | -55.1     |\n",
      "|    total_trades       | 25611     |\n",
      "| time/                 |           |\n",
      "|    fps                | 265       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -2.9      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -0.218    |\n",
      "|    std                | 2.46      |\n",
      "|    value_loss         | 0.000108  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0.66     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | -0.633   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0.818   |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.000418 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | -0.551   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -4.02    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.00978  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | -0.0284  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 2.64     |\n",
      "|    value_loss         | 0.00363  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.87e+04  |\n",
      "|    total_cost         | 1.65e+04  |\n",
      "|    total_reward       | -3.13e+04 |\n",
      "|    total_reward_pct   | -62.6     |\n",
      "|    total_trades       | 25345     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | 0.062     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -0.41     |\n",
      "|    std                | 2.67      |\n",
      "|    value_loss         | 0.000857  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -1.26    |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.00134  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | -4.75    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.11    |\n",
      "|    std                | 2.78     |\n",
      "|    value_loss         | 0.000982 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | -3.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -1.61    |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.00179  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | -4.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -1.63    |\n",
      "|    std                | 2.86     |\n",
      "|    value_loss         | 0.00553  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.81e+04  |\n",
      "|    total_cost         | 1.75e+04  |\n",
      "|    total_reward       | -1.19e+04 |\n",
      "|    total_reward_pct   | -23.8     |\n",
      "|    total_trades       | 24693     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -0.0348   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -1.11     |\n",
      "|    std                | 2.89      |\n",
      "|    value_loss         | 0.00101   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -2.32    |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 0.00295  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | -0.0336  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -0.912   |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 0.00091  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | -0.0932  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -3.78    |\n",
      "|    std                | 3.04     |\n",
      "|    value_loss         | 0.0122   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -0.806   |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.000696 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24941.81\n",
      "total_reward: -25058.19\n",
      "total_cost: 20511.39\n",
      "total_trades: 25120\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.49e+04  |\n",
      "|    total_cost         | 2.05e+04  |\n",
      "|    total_reward       | -2.51e+04 |\n",
      "|    total_reward_pct   | -50.1     |\n",
      "|    total_trades       | 25120     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 0.187     |\n",
      "|    std                | 3.13      |\n",
      "|    value_loss         | 1.55e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -1.27    |\n",
      "|    std                | 3.2      |\n",
      "|    value_loss         | 0.000634 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -3.52    |\n",
      "|    std                | 3.28     |\n",
      "|    value_loss         | 0.0103   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | -0.0346  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 7.91     |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.0274   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | -0.152   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 3.04     |\n",
      "|    std                | 3.38     |\n",
      "|    value_loss         | 0.0067   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.53e+03 |\n",
      "|    total_cost         | 7.93e+03  |\n",
      "|    total_reward       | -5.15e+04 |\n",
      "|    total_reward_pct   | -103      |\n",
      "|    total_trades       | 24767     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.2     |\n",
      "|    explained_variance | -76.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 1.06      |\n",
      "|    std                | 3.41      |\n",
      "|    value_loss         | 0.00461   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | -4.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 3.44     |\n",
      "|    value_loss         | 0.0016   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 0.374     |\n",
      "|    std                | 3.5       |\n",
      "|    value_loss         | 0.00227   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -3.37    |\n",
      "|    std                | 3.54     |\n",
      "|    value_loss         | 0.00493  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.2    |\n",
      "|    explained_variance | -0.234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -0.752   |\n",
      "|    std                | 3.58     |\n",
      "|    value_loss         | 0.00129  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.57e+03  |\n",
      "|    total_cost         | 1.65e+04  |\n",
      "|    total_reward       | -4.14e+04 |\n",
      "|    total_reward_pct   | -82.9     |\n",
      "|    total_trades       | 25956     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.4     |\n",
      "|    explained_variance | 0.0151    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 0.458     |\n",
      "|    std                | 3.62      |\n",
      "|    value_loss         | 9.9e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.7    |\n",
      "|    explained_variance | -23.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -0.343   |\n",
      "|    std                | 3.68     |\n",
      "|    value_loss         | 0.000279 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 0.525     |\n",
      "|    std                | 3.77      |\n",
      "|    value_loss         | 8.84e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 1.5      |\n",
      "|    std                | 3.84     |\n",
      "|    value_loss         | 0.000995 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | -0.0641  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 3.91     |\n",
      "|    value_loss         | 0.000454 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.1    |\n",
      "|    explained_variance | 0.033    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -6.2     |\n",
      "|    std                | 3.97     |\n",
      "|    value_loss         | 0.0251   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.86e+04  |\n",
      "|    total_cost         | 7.7e+03   |\n",
      "|    total_reward       | -3.14e+04 |\n",
      "|    total_reward_pct   | -62.9     |\n",
      "|    total_trades       | 25416     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.4     |\n",
      "|    explained_variance | -7.98     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -0.685    |\n",
      "|    std                | 4.03      |\n",
      "|    value_loss         | 0.000234  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.081   |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 2.81e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 0.433    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.636   |\n",
      "|    std                | 4.22     |\n",
      "|    value_loss         | 0.000266 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | -11.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 0.169    |\n",
      "|    std                | 4.3      |\n",
      "|    value_loss         | 0.000489 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | 0.606    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -2.71    |\n",
      "|    std                | 4.38     |\n",
      "|    value_loss         | 0.00341  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.2e+03   |\n",
      "|    total_cost         | 1.02e+04  |\n",
      "|    total_reward       | -4.38e+04 |\n",
      "|    total_reward_pct   | -87.6     |\n",
      "|    total_trades       | 25951     |\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -0.606    |\n",
      "|    std                | 4.43      |\n",
      "|    value_loss         | 0.000178  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.236    |\n",
      "|    std                | 4.5      |\n",
      "|    value_loss         | 0.000665 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 4.56     |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | -0.983   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 4.64     |\n",
      "|    value_loss         | 0.00183  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -6.59    |\n",
      "|    std                | 4.71     |\n",
      "|    value_loss         | 0.0138   |\n",
      "------------------------------------\n",
      "day: 2586, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -28455.33\n",
      "total_reward: -78455.33\n",
      "total_cost: 21586.96\n",
      "total_trades: 27728\n",
      "Sharpe: -0.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.85e+04 |\n",
      "|    total_cost         | 2.16e+04  |\n",
      "|    total_reward       | -7.85e+04 |\n",
      "|    total_reward_pct   | -157      |\n",
      "|    total_trades       | 27728     |\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.5     |\n",
      "|    explained_variance | 0.0648    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 0.0419    |\n",
      "|    std                | 4.75      |\n",
      "|    value_loss         | 5.17e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.705   |\n",
      "|    std                | 4.84     |\n",
      "|    value_loss         | 0.000161 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 0.423    |\n",
      "|    std                | 4.96     |\n",
      "|    value_loss         | 0.000161 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 5.65     |\n",
      "|    std                | 5.08     |\n",
      "|    value_loss         | 0.00973  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.2    |\n",
      "|    explained_variance | -0.00894 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 0.816    |\n",
      "|    std                | 5.18     |\n",
      "|    value_loss         | 0.000572 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.49e+04  |\n",
      "|    total_cost         | 1.41e+04  |\n",
      "|    total_reward       | -2.51e+04 |\n",
      "|    total_reward_pct   | -50.2     |\n",
      "|    total_trades       | 27643     |\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 203       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -0.195    |\n",
      "|    std                | 5.25      |\n",
      "|    value_loss         | 1.34e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | -606     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.0369  |\n",
      "|    std                | 5.37     |\n",
      "|    value_loss         | 1.72e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.4    |\n",
      "|    explained_variance | -0.0574  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    std                | 5.53     |\n",
      "|    value_loss         | 0.000643 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | -0.833    |\n",
      "|    std                | 5.67      |\n",
      "|    value_loss         | 0.000318  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.3    |\n",
      "|    explained_variance | -0.0571  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 4.12     |\n",
      "|    std                | 5.79     |\n",
      "|    value_loss         | 0.00721  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.24e+04  |\n",
      "|    total_cost         | 1.03e+04  |\n",
      "|    total_reward       | -2.76e+04 |\n",
      "|    total_reward_pct   | -55.1     |\n",
      "|    total_trades       | 26296     |\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 213       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.6     |\n",
      "|    explained_variance | 3.17e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -1.03     |\n",
      "|    std                | 5.89      |\n",
      "|    value_loss         | 0.000285  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.1    |\n",
      "|    explained_variance | -0.316   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.642    |\n",
      "|    std                | 6.03     |\n",
      "|    value_loss         | 0.000241 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.688   |\n",
      "|    std                | 6.2      |\n",
      "|    value_loss         | 0.00021  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 267      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.1    |\n",
      "|    explained_variance | -0.458   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -0.817   |\n",
      "|    std                | 6.37     |\n",
      "|    value_loss         | 0.000713 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.437   |\n",
      "|    std                | 6.5      |\n",
      "|    value_loss         | 0.000309 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.7    |\n",
      "|    explained_variance | 0.219    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 6.57     |\n",
      "|    value_loss         | 0.00193  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3e+04    |\n",
      "|    total_cost         | 1.8e+04  |\n",
      "|    total_reward       | -2e+04   |\n",
      "|    total_reward_pct   | -39.9    |\n",
      "|    total_trades       | 28202    |\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63      |\n",
      "|    explained_variance | -0.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 0.812    |\n",
      "|    std                | 6.67     |\n",
      "|    value_loss         | 0.00152  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.644   |\n",
      "|    std                | 6.78     |\n",
      "|    value_loss         | 0.000135 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 228       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 1.26      |\n",
      "|    std                | 6.93      |\n",
      "|    value_loss         | 0.000574  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.2    |\n",
      "|    explained_variance | -0.521   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -1.43    |\n",
      "|    std                | 7.1      |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.5    |\n",
      "|    explained_variance | -0.0274  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -0.53    |\n",
      "|    std                | 7.2      |\n",
      "|    value_loss         | 0.00179  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.38e+04  |\n",
      "|    total_cost         | 3.56e+04  |\n",
      "|    total_reward       | -2.62e+04 |\n",
      "|    total_reward_pct   | -52.4     |\n",
      "|    total_trades       | 30438     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.8     |\n",
      "|    explained_variance | -3.38     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 0.352     |\n",
      "|    std                | 7.33      |\n",
      "|    value_loss         | 0.000369  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.2    |\n",
      "|    explained_variance | 0.288    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 7.51     |\n",
      "|    value_loss         | 0.000413 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 0.607     |\n",
      "|    std                | 7.69      |\n",
      "|    value_loss         | 0.000318  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 0.837     |\n",
      "|    std                | 7.87      |\n",
      "|    value_loss         | 0.000534  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.5    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.408    |\n",
      "|    std                | 8.02     |\n",
      "|    value_loss         | 0.00107  |\n",
      "------------------------------------\n",
      "day: 2586, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6001.49\n",
      "total_reward: -43998.51\n",
      "total_cost: 10743.95\n",
      "total_trades: 28028\n",
      "Sharpe: -0.269\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6e+03    |\n",
      "|    total_cost         | 1.07e+04 |\n",
      "|    total_reward       | -4.4e+04 |\n",
      "|    total_reward_pct   | -88      |\n",
      "|    total_trades       | 28028    |\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -5.04    |\n",
      "|    std                | 8.13     |\n",
      "|    value_loss         | 0.00643  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 20.8     |\n",
      "|    std                | 8.26     |\n",
      "|    value_loss         | 0.0951   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.3    |\n",
      "|    explained_variance | -0.174   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.169   |\n",
      "|    std                | 8.39     |\n",
      "|    value_loss         | 5.42e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -3.98    |\n",
      "|    std                | 8.57     |\n",
      "|    value_loss         | 0.00859  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.1    |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 6.9      |\n",
      "|    std                | 8.72     |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.63e+04  |\n",
      "|    total_cost         | 3.36e+04  |\n",
      "|    total_reward       | -2.37e+04 |\n",
      "|    total_reward_pct   | -47.4     |\n",
      "|    total_trades       | 29852     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 252       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -1.15     |\n",
      "|    std                | 8.86      |\n",
      "|    value_loss         | 0.000297  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.0875   |\n",
      "|    std                | 9.07     |\n",
      "|    value_loss         | 5.31e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | 0.0217   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 2.86     |\n",
      "|    std                | 9.33     |\n",
      "|    value_loss         | 0.00184  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.8    |\n",
      "|    explained_variance | 0.0527   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -1.32    |\n",
      "|    std                | 9.57     |\n",
      "|    value_loss         | 0.000751 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.2    |\n",
      "|    explained_variance | -0.506   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -3.15    |\n",
      "|    std                | 9.76     |\n",
      "|    value_loss         | 0.00219  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.56e+04  |\n",
      "|    total_cost         | 1.43e+04  |\n",
      "|    total_reward       | -2.44e+04 |\n",
      "|    total_reward_pct   | -48.8     |\n",
      "|    total_trades       | 27866     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 262       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | -3.05     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 0.0212    |\n",
      "|    std                | 9.92      |\n",
      "|    value_loss         | 0.000143  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 264       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -0.308    |\n",
      "|    std                | 10.1      |\n",
      "|    value_loss         | 7.54e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.4    |\n",
      "|    explained_variance | -2.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.718    |\n",
      "|    std                | 10.4     |\n",
      "|    value_loss         | 0.000148 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    std                | 10.7     |\n",
      "|    value_loss         | 0.000302 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.4    |\n",
      "|    explained_variance | 0.138    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.354   |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 0.000373 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.87e+04  |\n",
      "|    total_cost         | 1.51e+04  |\n",
      "|    total_reward       | -3.13e+04 |\n",
      "|    total_reward_pct   | -62.7     |\n",
      "|    total_trades       | 28809     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 271       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.7     |\n",
      "|    explained_variance | -4.05     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 0.104     |\n",
      "|    std                | 11.1      |\n",
      "|    value_loss         | 1.68e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.232    |\n",
      "|    std                | 11.3     |\n",
      "|    value_loss         | 3.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 83.2     |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 5.03     |\n",
      "|    std                | 12       |\n",
      "|    value_loss         | 0.00512  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.5    |\n",
      "|    explained_variance | -0.0744  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 5.55     |\n",
      "|    std                | 12.2     |\n",
      "|    value_loss         | 0.00631  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.8    |\n",
      "|    explained_variance | -0.0883  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 2.27     |\n",
      "|    std                | 12.5     |\n",
      "|    value_loss         | 0.00485  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.41e+04  |\n",
      "|    total_cost         | 1.97e+04  |\n",
      "|    total_reward       | -2.59e+04 |\n",
      "|    total_reward_pct   | -51.8     |\n",
      "|    total_trades       | 29536     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 283       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | -0.474    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | 0.717     |\n",
      "|    std                | 12.7      |\n",
      "|    value_loss         | 0.000101  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.154    |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 2.99e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -2.87    |\n",
      "|    std                | 13.4     |\n",
      "|    value_loss         | 0.0017   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.5    |\n",
      "|    explained_variance | -0.00408 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 4.15     |\n",
      "|    std                | 13.6     |\n",
      "|    value_loss         | 0.0051   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -3.87    |\n",
      "|    std                | 13.8     |\n",
      "|    value_loss         | 0.00853  |\n",
      "------------------------------------\n",
      "day: 2586, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -4166.89\n",
      "total_reward: -54166.89\n",
      "total_cost: 19084.99\n",
      "total_trades: 29815\n",
      "Sharpe: -0.151\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.17e+03 |\n",
      "|    total_cost         | 1.91e+04  |\n",
      "|    total_reward       | -5.42e+04 |\n",
      "|    total_reward_pct   | -108      |\n",
      "|    total_trades       | 29815     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 292       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 0.173     |\n",
      "|    std                | 14.1      |\n",
      "|    value_loss         | 6.99e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.0227  |\n",
      "|    std                | 14.4     |\n",
      "|    value_loss         | 3.38e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.2    |\n",
      "|    explained_variance | -0.126   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -2.2     |\n",
      "|    std                | 14.8     |\n",
      "|    value_loss         | 0.000807 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -1.42    |\n",
      "|    std                | 15.2     |\n",
      "|    value_loss         | 0.000404 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    std                | 15.5     |\n",
      "|    value_loss         | 0.0455   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.14e+04  |\n",
      "|    total_cost         | 1.5e+04   |\n",
      "|    total_reward       | -2.86e+04 |\n",
      "|    total_reward_pct   | -57.2     |\n",
      "|    total_trades       | 29200     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 301       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -79.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -0.083    |\n",
      "|    std                | 15.8      |\n",
      "|    value_loss         | 1.88e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 0.251    |\n",
      "|    std                | 16.2     |\n",
      "|    value_loss         | 1.06e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.2     |\n",
      "|    std                | 16.7     |\n",
      "|    value_loss         | 7.38e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81      |\n",
      "|    explained_variance | 7.15e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -2.33    |\n",
      "|    std                | 17.2     |\n",
      "|    value_loss         | 0.000867 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | 0.216    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 2.78     |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.68e+03 |\n",
      "|    total_cost         | 1.59e+04  |\n",
      "|    total_reward       | -5.17e+04 |\n",
      "|    total_reward_pct   | -103      |\n",
      "|    total_trades       | 29043     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 311       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.9     |\n",
      "|    explained_variance | -0.00708  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 5.3       |\n",
      "|    std                | 18        |\n",
      "|    value_loss         | 0.00485   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.2    |\n",
      "|    explained_variance | -0.043   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 18.4     |\n",
      "|    value_loss         | 0.000259 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 314       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -0.274    |\n",
      "|    std                | 18.9      |\n",
      "|    value_loss         | 1.77e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 1.3      |\n",
      "|    std                | 19.5     |\n",
      "|    value_loss         | 0.000896 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.0694  |\n",
      "|    std                | 20.1     |\n",
      "|    value_loss         | 0.000125 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.27e+03  |\n",
      "|    total_cost         | 2.03e+04  |\n",
      "|    total_reward       | -4.07e+04 |\n",
      "|    total_reward_pct   | -81.5     |\n",
      "|    total_trades       | 30069     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 320       |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.4     |\n",
      "|    explained_variance | 0.634     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | 0.261     |\n",
      "|    std                | 20.6      |\n",
      "|    value_loss         | 1e-05     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.9    |\n",
      "|    explained_variance | -0.0194  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.0642  |\n",
      "|    std                | 21.2     |\n",
      "|    value_loss         | 6.44e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 4.22      |\n",
      "|    std                | 21.9      |\n",
      "|    value_loss         | 0.00315   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 326      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 1.87     |\n",
      "|    std                | 22.5     |\n",
      "|    value_loss         | 0.000601 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 328       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 0.745     |\n",
      "|    std                | 23.2      |\n",
      "|    value_loss         | 0.000138  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -3.57e+03 |\n",
      "|    total_cost         | 2.71e+04  |\n",
      "|    total_reward       | -5.36e+04 |\n",
      "|    total_reward_pct   | -107      |\n",
      "|    total_trades       | 30402     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 330       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -87       |\n",
      "|    explained_variance | -2.27     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 1.48      |\n",
      "|    std                | 23.7      |\n",
      "|    value_loss         | 0.000408  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -0.156   |\n",
      "|    std                | 24.2     |\n",
      "|    value_loss         | 4.92e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -0.0277  |\n",
      "|    std                | 24.9     |\n",
      "|    value_loss         | 2.35e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 2.33     |\n",
      "|    std                | 25.7     |\n",
      "|    value_loss         | 0.000765 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.175    |\n",
      "|    std                | 26.4     |\n",
      "|    value_loss         | 0.000338 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.4    |\n",
      "|    explained_variance | -0.85    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -7.31    |\n",
      "|    std                | 26.8     |\n",
      "|    value_loss         | 0.00977  |\n",
      "------------------------------------\n",
      "day: 2586, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -25231.32\n",
      "total_reward: -75231.32\n",
      "total_cost: 17560.83\n",
      "total_trades: 29967\n",
      "Sharpe: -0.327\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.52e+04 |\n",
      "|    total_cost         | 1.76e+04  |\n",
      "|    total_reward       | -7.52e+04 |\n",
      "|    total_reward_pct   | -150      |\n",
      "|    total_trades       | 29967     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -89.7     |\n",
      "|    explained_variance | -0.265    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 0.407     |\n",
      "|    std                | 27.2      |\n",
      "|    value_loss         | 0.00021   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 3.07     |\n",
      "|    std                | 27.6     |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.4    |\n",
      "|    explained_variance | -4.79    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.191   |\n",
      "|    std                | 28.2     |\n",
      "|    value_loss         | 7.35e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.9    |\n",
      "|    explained_variance | -21.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 0.0263   |\n",
      "|    std                | 29       |\n",
      "|    value_loss         | 0.000292 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    std                | 30       |\n",
      "|    value_loss         | 0.000522 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.44e+03  |\n",
      "|    total_cost         | 3.61e+04  |\n",
      "|    total_reward       | -4.16e+04 |\n",
      "|    total_reward_pct   | -83.1     |\n",
      "|    total_trades       | 31258     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 350       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -92.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 0.00548   |\n",
      "|    std                | 30.9      |\n",
      "|    value_loss         | 7.53e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -0.222   |\n",
      "|    std                | 32       |\n",
      "|    value_loss         | 1e-05    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.4    |\n",
      "|    explained_variance | 0.183    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -4.23    |\n",
      "|    std                | 33.1     |\n",
      "|    value_loss         | 0.00224  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.8    |\n",
      "|    explained_variance | -0.18    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -0.799   |\n",
      "|    std                | 33.9     |\n",
      "|    value_loss         | 0.00029  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.3    |\n",
      "|    explained_variance | -0.435   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -3.07    |\n",
      "|    std                | 34.6     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.4e+04  |\n",
      "|    total_cost         | 2.95e+04 |\n",
      "|    total_reward       | -3.6e+04 |\n",
      "|    total_reward_pct   | -72      |\n",
      "|    total_trades       | 30152    |\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.7    |\n",
      "|    explained_variance | 0.00132  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -0.875   |\n",
      "|    std                | 35.5     |\n",
      "|    value_loss         | 0.000179 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 362      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.269   |\n",
      "|    std                | 36.5     |\n",
      "|    value_loss         | 1.28e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 364      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 2.6      |\n",
      "|    std                | 37.6     |\n",
      "|    value_loss         | 0.00125  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 366       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -96.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 1.5       |\n",
      "|    std                | 38.7      |\n",
      "|    value_loss         | 0.000268  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 0.576    |\n",
      "|    std                | 39.9     |\n",
      "|    value_loss         | 4.09e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.76e+03 |\n",
      "|    total_cost         | 1.49e+04  |\n",
      "|    total_reward       | -5.18e+04 |\n",
      "|    total_reward_pct   | -104      |\n",
      "|    total_trades       | 29613     |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 369       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -97.6     |\n",
      "|    explained_variance | 0.197     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 0.192     |\n",
      "|    std                | 41.3      |\n",
      "|    value_loss         | 1.51e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 371      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.411    |\n",
      "|    std                | 42.8     |\n",
      "|    value_loss         | 2.2e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -6.94    |\n",
      "|    std                | 44.5     |\n",
      "|    value_loss         | 0.00627  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 266      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 375      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 1.03     |\n",
      "|    std                | 45.7     |\n",
      "|    value_loss         | 0.000178 |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-07-09 to  2020-10-06\n",
      "A2C Sharpe Ratio:  -0.21502134379449994\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 321  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2586, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3624.51\n",
      "total_reward: -46375.49\n",
      "total_cost: 27137.26\n",
      "total_trades: 30528\n",
      "Sharpe: -0.418\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.62e+03   |\n",
      "|    total_cost           | 2.71e+04   |\n",
      "|    total_reward         | -4.64e+04  |\n",
      "|    total_reward_pct     | -92.8      |\n",
      "|    total_trades         | 30528      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01270018 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.9      |\n",
      "|    explained_variance   | 0.0579     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.278     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.0632     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.2e+04    |\n",
      "|    total_cost           | 1.77e+04    |\n",
      "|    total_reward         | -6.2e+04    |\n",
      "|    total_reward_pct     | -124        |\n",
      "|    total_trades         | 28902       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013809728 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.0268      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.43e+04    |\n",
      "|    total_cost           | 5.06e+04    |\n",
      "|    total_reward         | -3.57e+04   |\n",
      "|    total_reward_pct     | -71.4       |\n",
      "|    total_trades         | 31958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007122999 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.023       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011534014 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0186      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.93e+03    |\n",
      "|    total_cost           | 2.34e+04    |\n",
      "|    total_reward         | -4.11e+04   |\n",
      "|    total_reward_pct     | -82.1       |\n",
      "|    total_trades         | 29785       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011381031 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00884     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.01e+03    |\n",
      "|    total_cost           | 2.23e+04    |\n",
      "|    total_reward         | -4.1e+04    |\n",
      "|    total_reward_pct     | -82         |\n",
      "|    total_trades         | 29164       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013102643 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -10523.58\n",
      "total_reward: -60523.58\n",
      "total_cost: 25012.69\n",
      "total_trades: 29888\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -1.05e+04  |\n",
      "|    total_cost           | 2.5e+04    |\n",
      "|    total_reward         | -6.05e+04  |\n",
      "|    total_reward_pct     | -121       |\n",
      "|    total_trades         | 29888      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01297112 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.305     |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00985    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+04    |\n",
      "|    total_cost           | 5.77e+04    |\n",
      "|    total_reward         | -2.41e+04   |\n",
      "|    total_reward_pct     | -48.2       |\n",
      "|    total_trades         | 32110       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013485032 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.85       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0226      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012765967 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.32e+04    |\n",
      "|    total_cost           | 2.6e+04     |\n",
      "|    total_reward         | -3.68e+04   |\n",
      "|    total_reward_pct     | -73.6       |\n",
      "|    total_trades         | 29372       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017410489 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00783     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.82e+04    |\n",
      "|    total_cost           | 5.54e+04    |\n",
      "|    total_reward         | -2.18e+04   |\n",
      "|    total_reward_pct     | -43.7       |\n",
      "|    total_trades         | 32369       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012402448 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0148      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.83e+04    |\n",
      "|    total_cost           | 1.09e+05    |\n",
      "|    total_reward         | 8.26e+03    |\n",
      "|    total_reward_pct     | 16.5        |\n",
      "|    total_trades         | 34335       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012794316 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0346      |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 29506.86\n",
      "total_reward: -20493.14\n",
      "total_cost: 36179.21\n",
      "total_trades: 31257\n",
      "Sharpe: 0.187\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+04    |\n",
      "|    total_cost           | 3.62e+04    |\n",
      "|    total_reward         | -2.05e+04   |\n",
      "|    total_reward_pct     | -41         |\n",
      "|    total_trades         | 31257       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006797489 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.098       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0469      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014667944 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0211      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -630        |\n",
      "|    total_cost           | 2.21e+04    |\n",
      "|    total_reward         | -5.06e+04   |\n",
      "|    total_reward_pct     | -101        |\n",
      "|    total_trades         | 29808       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015426168 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00437     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.74e+03    |\n",
      "|    total_cost           | 1.5e+04     |\n",
      "|    total_reward         | -4.43e+04   |\n",
      "|    total_reward_pct     | -88.5       |\n",
      "|    total_trades         | 28760       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020879999 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+04    |\n",
      "|    total_cost           | 2.52e+04    |\n",
      "|    total_reward         | -3.88e+04   |\n",
      "|    total_reward_pct     | -77.7       |\n",
      "|    total_trades         | 30154       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017927982 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.78e+04    |\n",
      "|    total_cost           | 2.75e+04    |\n",
      "|    total_reward         | -3.22e+04   |\n",
      "|    total_reward_pct     | -64.4       |\n",
      "|    total_trades         | 30322       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020640839 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0854      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0123      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017975219 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00762     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 28382.04\n",
      "total_reward: -21617.96\n",
      "total_cost: 31402.85\n",
      "total_trades: 30906\n",
      "Sharpe: 0.102\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.84e+04   |\n",
      "|    total_cost           | 3.14e+04   |\n",
      "|    total_reward         | -2.16e+04  |\n",
      "|    total_reward_pct     | -43.2      |\n",
      "|    total_trades         | 30906      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612042 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.00612    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.7e+04     |\n",
      "|    total_cost           | 5.03e+04    |\n",
      "|    total_reward         | 2.7e+04     |\n",
      "|    total_reward_pct     | 54          |\n",
      "|    total_trades         | 31775       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017606482 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0143      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+04    |\n",
      "|    total_cost           | 1.46e+04    |\n",
      "|    total_reward         | -3.78e+04   |\n",
      "|    total_reward_pct     | -75.7       |\n",
      "|    total_trades         | 28628       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011199587 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0398      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01008714 |\n",
      "|    clip_fraction        | 0.0935     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.295     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.00892    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+04    |\n",
      "|    total_cost           | 2.55e+04    |\n",
      "|    total_reward         | -2.24e+04   |\n",
      "|    total_reward_pct     | -44.8       |\n",
      "|    total_trades         | 29837       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015459485 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.43e+04    |\n",
      "|    total_cost           | 4.89e+04    |\n",
      "|    total_reward         | 1.43e+04    |\n",
      "|    total_reward_pct     | 28.6        |\n",
      "|    total_trades         | 31942       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013155139 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0186      |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 23087.84\n",
      "total_reward: -26912.16\n",
      "total_cost: 32477.58\n",
      "total_trades: 30873\n",
      "Sharpe: 0.111\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.31e+04     |\n",
      "|    total_cost           | 3.25e+04     |\n",
      "|    total_reward         | -2.69e+04    |\n",
      "|    total_reward_pct     | -53.8        |\n",
      "|    total_trades         | 30873        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 313          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147846155 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.4        |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.297       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0268       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.38e+04    |\n",
      "|    total_cost           | 5.24e+04    |\n",
      "|    total_reward         | 4.38e+04    |\n",
      "|    total_reward_pct     | 87.7        |\n",
      "|    total_trades         | 32442       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011218552 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017246827 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0558      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.55e+04    |\n",
      "|    total_cost           | 1.9e+04     |\n",
      "|    total_reward         | -3.45e+04   |\n",
      "|    total_reward_pct     | -69         |\n",
      "|    total_trades         | 29573       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008163112 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00366     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.82e+04     |\n",
      "|    total_cost           | 2.48e+04     |\n",
      "|    total_reward         | -3.18e+04    |\n",
      "|    total_reward_pct     | -63.6        |\n",
      "|    total_trades         | 30332        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 313          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031299721 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.5        |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.313       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0229      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00706      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.04e+04   |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -6.04e+04   |\n",
      "|    total_reward_pct     | -121        |\n",
      "|    total_trades         | 29276       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017539851 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00688     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47396.65\n",
      "total_reward: -2603.35\n",
      "total_cost: 42762.21\n",
      "total_trades: 31723\n",
      "Sharpe: 0.198\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.74e+04    |\n",
      "|    total_cost           | 4.28e+04    |\n",
      "|    total_reward         | -2.6e+03    |\n",
      "|    total_reward_pct     | -5.21       |\n",
      "|    total_trades         | 31723       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007410519 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00943     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013503181 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.0309      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0236      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.83e+04    |\n",
      "|    total_cost           | 7.33e+04    |\n",
      "|    total_reward         | 4.83e+04    |\n",
      "|    total_reward_pct     | 96.5        |\n",
      "|    total_trades         | 32915       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008926553 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.255      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.26e+03    |\n",
      "|    total_cost           | 2.2e+04     |\n",
      "|    total_reward         | -4.17e+04   |\n",
      "|    total_reward_pct     | -83.5       |\n",
      "|    total_trades         | 30262       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010899236 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0583      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.42e+04   |\n",
      "|    total_cost           | 2.29e+04   |\n",
      "|    total_reward         | -3.58e+04  |\n",
      "|    total_reward_pct     | -71.7      |\n",
      "|    total_trades         | 30218      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 241        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01254311 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.293     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0118     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.13e+04    |\n",
      "|    total_cost           | 2.99e+04    |\n",
      "|    total_reward         | -2.87e+04   |\n",
      "|    total_reward_pct     | -57.5       |\n",
      "|    total_trades         | 30638       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010292052 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01483391 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.286     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "day: 2586, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 10700.44\n",
      "total_reward: -39299.56\n",
      "total_cost: 17001.30\n",
      "total_trades: 29564\n",
      "Sharpe: -0.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+04    |\n",
      "|    total_cost           | 1.7e+04     |\n",
      "|    total_reward         | -3.93e+04   |\n",
      "|    total_reward_pct     | -78.6       |\n",
      "|    total_trades         | 29564       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014674695 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00261     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.25e+04   |\n",
      "|    total_cost           | 2.37e+04    |\n",
      "|    total_reward         | -6.25e+04   |\n",
      "|    total_reward_pct     | -125        |\n",
      "|    total_trades         | 29898       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369921 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00599     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | -3.63e+03    |\n",
      "|    total_cost           | 1.53e+04     |\n",
      "|    total_reward         | -5.36e+04    |\n",
      "|    total_reward_pct     | -107         |\n",
      "|    total_trades         | 29026        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047783107 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.7        |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.294       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00777      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.11e+04    |\n",
      "|    total_cost           | 3.11e+04    |\n",
      "|    total_reward         | -2.89e+04   |\n",
      "|    total_reward_pct     | -57.8       |\n",
      "|    total_trades         | 31295       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023538303 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00803     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016391963 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0185      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.37e+05    |\n",
      "|    total_cost           | 4.8e+04     |\n",
      "|    total_reward         | 8.68e+04    |\n",
      "|    total_reward_pct     | 174         |\n",
      "|    total_trades         | 31991       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017592043 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0721      |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5317.78\n",
      "total_reward: -44682.22\n",
      "total_cost: 19170.35\n",
      "total_trades: 29494\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.32e+03    |\n",
      "|    total_cost           | 1.92e+04    |\n",
      "|    total_reward         | -4.47e+04   |\n",
      "|    total_reward_pct     | -89.4       |\n",
      "|    total_trades         | 29494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010781305 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.216      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+04    |\n",
      "|    total_cost           | 1.86e+04    |\n",
      "|    total_reward         | -2.36e+04   |\n",
      "|    total_reward_pct     | -47.2       |\n",
      "|    total_trades         | 29118       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015302243 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0148      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 312          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100642815 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.8        |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.303       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00941      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.2e+04     |\n",
      "|    total_cost           | 2.86e+04    |\n",
      "|    total_reward         | 2.02e+03    |\n",
      "|    total_reward_pct     | 4.05        |\n",
      "|    total_trades         | 30725       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015398889 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.021       |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-07-09 to  2020-10-06\n",
      "PPO Sharpe Ratio:  -0.0714032631158356\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_1\n",
      "day: 2586, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 46101.42\n",
      "total_reward: -3898.58\n",
      "total_cost: 120.69\n",
      "total_trades: 19558\n",
      "Sharpe: 0.349\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+04 |\n",
      "|    total_cost       | 288      |\n",
      "|    total_reward     | -120     |\n",
      "|    total_reward_pct | -0.24    |\n",
      "|    total_trades     | 19072    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total timesteps  | 10348    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -22.4    |\n",
      "|    critic_loss      | 5.8      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7761     |\n",
      "----------------------------------\n",
      "day: 2586, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 43671.92\n",
      "total_reward: -6328.08\n",
      "total_cost: 229.75\n",
      "total_trades: 19201\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.96e+04 |\n",
      "|    total_cost       | 111      |\n",
      "|    total_reward     | 9.62e+03 |\n",
      "|    total_reward_pct | 19.2     |\n",
      "|    total_trades     | 19292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total timesteps  | 20696    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -13.6    |\n",
      "|    critic_loss      | 1.93     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18109    |\n",
      "----------------------------------\n",
      "day: 2586, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47129.68\n",
      "total_reward: -2870.32\n",
      "total_cost: 115.13\n",
      "total_trades: 18893\n",
      "Sharpe: 0.481\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.71e+04  |\n",
      "|    total_cost       | 115       |\n",
      "|    total_reward     | -2.87e+03 |\n",
      "|    total_reward_pct | -5.74     |\n",
      "|    total_trades     | 18893     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 68        |\n",
      "|    time_elapsed     | 450       |\n",
      "|    total timesteps  | 31044     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -8.53     |\n",
      "|    critic_loss      | 0.497     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28457     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.82e+04  |\n",
      "|    total_cost       | 125       |\n",
      "|    total_reward     | -1.83e+03 |\n",
      "|    total_reward_pct | -3.66     |\n",
      "|    total_trades     | 18719     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 68        |\n",
      "|    time_elapsed     | 602       |\n",
      "|    total timesteps  | 41392     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -5.63     |\n",
      "|    critic_loss      | 0.304     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 38805     |\n",
      "-----------------------------------\n",
      "day: 2586, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48174.30\n",
      "total_reward: -1825.70\n",
      "total_cost: 103.12\n",
      "total_trades: 18660\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.61e+04 |\n",
      "|    total_cost       | 260      |\n",
      "|    total_reward     | 6.12e+03 |\n",
      "|    total_reward_pct | 12.2     |\n",
      "|    total_trades     | 19050    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 754      |\n",
      "|    total timesteps  | 51740    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.83    |\n",
      "|    critic_loss      | 0.223    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49153    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-07-09 to  2020-10-06\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-10-06\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 512}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_504_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.53e+04  |\n",
      "|    total_cost       | 106       |\n",
      "|    total_reward     | -4.71e+03 |\n",
      "|    total_reward_pct | -9.41     |\n",
      "|    total_trades     | 26046     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 85        |\n",
      "|    time_elapsed     | 124       |\n",
      "|    total timesteps  | 10600     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -121      |\n",
      "|    critic_loss      | 165       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7950      |\n",
      "-----------------------------------\n",
      "day: 2649, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 43454.71\n",
      "total_reward: -6545.29\n",
      "total_cost: 103.17\n",
      "total_trades: 25560\n",
      "Sharpe: 0.288\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.19e+04  |\n",
      "|    total_cost       | 154       |\n",
      "|    total_reward     | -1.81e+04 |\n",
      "|    total_reward_pct | -36.2     |\n",
      "|    total_trades     | 25304     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 75        |\n",
      "|    time_elapsed     | 279       |\n",
      "|    total timesteps  | 21200     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -70.1     |\n",
      "|    critic_loss      | 12.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 18550     |\n",
      "-----------------------------------\n",
      "day: 2649, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 28233.75\n",
      "total_reward: -21766.25\n",
      "total_cost: 171.15\n",
      "total_trades: 25309\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.75e+04  |\n",
      "|    total_cost       | 168       |\n",
      "|    total_reward     | -2.25e+04 |\n",
      "|    total_reward_pct | -45       |\n",
      "|    total_trades     | 25131     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 73        |\n",
      "|    time_elapsed     | 435       |\n",
      "|    total timesteps  | 31800     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -42.2     |\n",
      "|    critic_loss      | 3.43      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 29150     |\n",
      "-----------------------------------\n",
      "day: 2649, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 37955.30\n",
      "total_reward: -12044.70\n",
      "total_cost: 160.49\n",
      "total_trades: 25495\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.46e+04  |\n",
      "|    total_cost       | 165       |\n",
      "|    total_reward     | -1.54e+04 |\n",
      "|    total_reward_pct | -30.8     |\n",
      "|    total_trades     | 25866     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 71        |\n",
      "|    time_elapsed     | 590       |\n",
      "|    total timesteps  | 42400     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -25.9     |\n",
      "|    critic_loss      | 1.33      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 39750     |\n",
      "-----------------------------------\n",
      "======Trading from:  2020-10-06 to  2021-01-06\n",
      "Ensemble Strategy took:  227.24443712234498  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.238859</td>\n",
       "      <td>-0.0509252</td>\n",
       "      <td>0.453521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.442405</td>\n",
       "      <td>0.167532</td>\n",
       "      <td>0.0361946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.550431</td>\n",
       "      <td>-0.473258</td>\n",
       "      <td>-0.111794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.0752719</td>\n",
       "      <td>0.372855</td>\n",
       "      <td>0.316493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.0917394</td>\n",
       "      <td>0.156817</td>\n",
       "      <td>-0.138685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.114309</td>\n",
       "      <td>0.229433</td>\n",
       "      <td>0.0665803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.215021</td>\n",
       "      <td>-0.0714033</td>\n",
       "      <td>0.485365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126  2019-01-03  2019-04-04       DDPG   0.238859 -0.0509252    0.453521\n",
       "1  189  2019-04-04  2019-07-05        A2C   0.442405   0.167532   0.0361946\n",
       "2  252  2019-07-05  2019-10-02       DDPG  -0.550431  -0.473258   -0.111794\n",
       "3  315  2019-10-02  2020-01-03        PPO  0.0752719   0.372855    0.316493\n",
       "4  378  2020-01-03  2020-04-06        PPO -0.0917394   0.156817   -0.138685\n",
       "5  441  2020-04-06  2020-07-09        PPO   0.114309   0.229433   0.0665803\n",
       "6  504  2020-07-09  2020-10-06       DDPG  -0.215021 -0.0714033    0.485365"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  -0.15648211010283852\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49468.524601</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>-0.010630</td>\n",
       "      <td>2019-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49793.101929</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>2019-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49603.455157</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>-0.003809</td>\n",
       "      <td>2019-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49509.999700</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>2019-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   50000.000000  2019-04-04           NaN  2019-04-04\n",
       "1   49468.524601  2019-04-05     -0.010630  2019-04-05\n",
       "2   49793.101929  2019-04-08      0.006561  2019-04-08\n",
       "3   49603.455157  2019-04-09     -0.003809  2019-04-09\n",
       "4   49509.999700  2019-04-10     -0.001884  2019-04-10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return         -0.067948\n",
      "Cumulative returns    -0.115862\n",
      "Annual volatility      0.249680\n",
      "Sharpe ratio          -0.156482\n",
      "Calmar ratio          -0.147327\n",
      "Stability              0.636025\n",
      "Max drawdown          -0.461209\n",
      "Omega ratio            0.969923\n",
      "Sortino ratio         -0.208536\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.975634\n",
      "Daily value at risk   -0.031612\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to IHSG===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (425, 8)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4fe69935546d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^JKSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n\u001b[0m",
      "\u001b[0;32m/home/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mbacktest_plot\u001b[0;34m(account_value, baseline_start, baseline_end, baseline_ticker, value_col_name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         pyfolio.create_full_tear_sheet(\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mreturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[0;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mturnover_denom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturnover_denom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mheader_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         set_context=set_context)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     create_interesting_times_tear_sheet(returns,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[0;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbenchmark_rets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_returns_to_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     plotting.show_perf_stats(returns, benchmark_rets,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/utils.py\u001b[0m in \u001b[0;36mclip_returns_to_benchmark\u001b[0;34m(rets, benchmark_rets)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     raise KeyError(\n\u001b[0;32m-> 1316\u001b[0;31m                         \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m                         \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                         \u001b[0;34mf\"The following labels were missing: {not_found}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to IHSG===========\")\n",
    "%matplotlib inline\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^JKSE', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_perf_stats=backtest_stats('^JKSE',\n",
    "                                  baseline_start = df_account_value.loc[0,'date'],\n",
    "                                  baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_multiple_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
