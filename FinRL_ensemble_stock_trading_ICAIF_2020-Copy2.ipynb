{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_multiple_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "802ae0b5-d88e-46ba-8082-9eb5890f9cba"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "c437c266-2780-4c50-af8b-6868e7fdaa1f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, get_baseline, backtest_plot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-01-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLY.ME', 'YNDX.ME', 'ALRS.ME', 'AFLT.ME', 'VTBR.ME', 'GAZP.ME', 'GMKN.ME', 'IRAO.ME', 'LKOH.ME', 'MGNT.ME', 'MOEX.ME', 'NLMK.ME', 'NVTK.ME', 'ROSN.ME', 'SBER.ME', 'CHMF.ME', 'AFKS.ME', 'SNGS.ME', 'TATN.ME']\n"
     ]
    }
   ],
   "source": [
    "print(config.TOPCHIK_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (46511, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = config.START_DATE,\n",
    "                     end_date = '2021-01-19',\n",
    "                     ticker_list = config.TOPCHIK_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>54.299999</td>\n",
       "      <td>39.564133</td>\n",
       "      <td>547540.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>355.500000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>133.885422</td>\n",
       "      <td>806004.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>168.839996</td>\n",
       "      <td>171.100006</td>\n",
       "      <td>167.119995</td>\n",
       "      <td>96.636467</td>\n",
       "      <td>15012689.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>4812.000000</td>\n",
       "      <td>4675.000000</td>\n",
       "      <td>1852.150635</td>\n",
       "      <td>347308.0</td>\n",
       "      <td>GMKN.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>1616.699951</td>\n",
       "      <td>1637.060059</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>836.540039</td>\n",
       "      <td>853228.0</td>\n",
       "      <td>LKOH.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close      volume  \\\n",
       "0  2010-03-03    55.580002    55.580002    54.299999    39.564133    547540.0   \n",
       "1  2010-03-03   355.500000   365.000000   354.000000   133.885422    806004.0   \n",
       "2  2010-03-03   168.839996   171.100006   167.119995    96.636467  15012689.0   \n",
       "3  2010-03-03  4705.000000  4812.000000  4675.000000  1852.150635    347308.0   \n",
       "4  2010-03-03  1616.699951  1637.060059  1596.000000   836.540039    853228.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFLT.ME    2  \n",
       "1  CHMF.ME    2  \n",
       "2  GAZP.ME    2  \n",
       "3  GMKN.ME    2  \n",
       "4  LKOH.ME    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46506</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>275.720001</td>\n",
       "      <td>281.299988</td>\n",
       "      <td>272.950012</td>\n",
       "      <td>279.799988</td>\n",
       "      <td>7.096328e+07</td>\n",
       "      <td>SBER.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46507</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>35.865002</td>\n",
       "      <td>36.099998</td>\n",
       "      <td>4.088790e+07</td>\n",
       "      <td>SNGS.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46508</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>532.400024</td>\n",
       "      <td>535.400024</td>\n",
       "      <td>523.099976</td>\n",
       "      <td>533.099976</td>\n",
       "      <td>4.929751e+06</td>\n",
       "      <td>TATN.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46509</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>0.039380</td>\n",
       "      <td>0.039440</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.039060</td>\n",
       "      <td>3.725212e+10</td>\n",
       "      <td>VTBR.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46510</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>5002.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>4990.000000</td>\n",
       "      <td>5034.000000</td>\n",
       "      <td>5.124640e+05</td>\n",
       "      <td>YNDX.ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         open         high          low        close  \\\n",
       "46506  2021-01-18   275.720001   281.299988   272.950012   279.799988   \n",
       "46507  2021-01-18    36.580002    36.580002    35.865002    36.099998   \n",
       "46508  2021-01-18   532.400024   535.400024   523.099976   533.099976   \n",
       "46509  2021-01-18     0.039380     0.039440     0.038760     0.039060   \n",
       "46510  2021-01-18  5002.000000  5061.000000  4990.000000  5034.000000   \n",
       "\n",
       "             volume      tic  day  \n",
       "46506  7.096328e+07  SBER.ME    0  \n",
       "46507  4.088790e+07  SNGS.ME    0  \n",
       "46508  4.929751e+06  TATN.ME    0  \n",
       "46509  3.725212e+10  VTBR.ME    0  \n",
       "46510  5.124640e+05  YNDX.ME    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46511, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4hYkeaPiICHS",
    "outputId": "ce9d7463-a74c-4917-c96d-848a1e8ad493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>55.580002</td>\n",
       "      <td>54.299999</td>\n",
       "      <td>39.564133</td>\n",
       "      <td>547540.0</td>\n",
       "      <td>AFLT.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>355.500000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>133.885422</td>\n",
       "      <td>806004.0</td>\n",
       "      <td>CHMF.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>168.839996</td>\n",
       "      <td>171.100006</td>\n",
       "      <td>167.119995</td>\n",
       "      <td>96.636467</td>\n",
       "      <td>15012689.0</td>\n",
       "      <td>GAZP.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>4812.000000</td>\n",
       "      <td>4675.000000</td>\n",
       "      <td>1852.150635</td>\n",
       "      <td>347308.0</td>\n",
       "      <td>GMKN.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-03</td>\n",
       "      <td>1616.699951</td>\n",
       "      <td>1637.060059</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>836.540039</td>\n",
       "      <td>853228.0</td>\n",
       "      <td>LKOH.ME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close      volume  \\\n",
       "0  2010-03-03    55.580002    55.580002    54.299999    39.564133    547540.0   \n",
       "1  2010-03-03   355.500000   365.000000   354.000000   133.885422    806004.0   \n",
       "2  2010-03-03   168.839996   171.100006   167.119995    96.636467  15012689.0   \n",
       "3  2010-03-03  4705.000000  4812.000000  4675.000000  1852.150635    347308.0   \n",
       "4  2010-03-03  1616.699951  1637.060059  1596.000000   836.540039    853228.0   \n",
       "\n",
       "       tic  day  \n",
       "0  AFLT.ME    2  \n",
       "1  CHMF.ME    2  \n",
       "2  GAZP.ME    2  \n",
       "3  GMKN.ME    2  \n",
       "4  LKOH.ME    2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19926</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>TATN.ME</td>\n",
       "      <td>217.110001</td>\n",
       "      <td>220.949997</td>\n",
       "      <td>217.110001</td>\n",
       "      <td>112.692490</td>\n",
       "      <td>935.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.914459</td>\n",
       "      <td>2201.740397</td>\n",
       "      <td>2051.222640</td>\n",
       "      <td>43.740359</td>\n",
       "      <td>-114.285745</td>\n",
       "      <td>28.407658</td>\n",
       "      <td>2122.508366</td>\n",
       "      <td>2139.696606</td>\n",
       "      <td>9.194579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38016</th>\n",
       "      <td>2015-08-24</td>\n",
       "      <td>MOEX.ME</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>71.370003</td>\n",
       "      <td>66.550003</td>\n",
       "      <td>48.633202</td>\n",
       "      <td>8789290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.722145</td>\n",
       "      <td>300.894539</td>\n",
       "      <td>269.605842</td>\n",
       "      <td>62.889452</td>\n",
       "      <td>370.055631</td>\n",
       "      <td>51.736144</td>\n",
       "      <td>286.084442</td>\n",
       "      <td>288.722674</td>\n",
       "      <td>19.961763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>2010-04-09</td>\n",
       "      <td>NLMK.ME</td>\n",
       "      <td>107.010002</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>107.010002</td>\n",
       "      <td>49.644722</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.425547</td>\n",
       "      <td>55.746447</td>\n",
       "      <td>51.311696</td>\n",
       "      <td>45.584443</td>\n",
       "      <td>-24.770892</td>\n",
       "      <td>12.861473</td>\n",
       "      <td>53.103637</td>\n",
       "      <td>54.734913</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15422</th>\n",
       "      <td>2012-05-22</td>\n",
       "      <td>SBER.ME</td>\n",
       "      <td>82.699997</td>\n",
       "      <td>83.360001</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>48.453693</td>\n",
       "      <td>18538680.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.869171</td>\n",
       "      <td>90.195036</td>\n",
       "      <td>81.072541</td>\n",
       "      <td>43.068266</td>\n",
       "      <td>-126.431893</td>\n",
       "      <td>20.034822</td>\n",
       "      <td>85.434373</td>\n",
       "      <td>86.858409</td>\n",
       "      <td>2.784742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14542</th>\n",
       "      <td>2012-04-06</td>\n",
       "      <td>ROSN.ME</td>\n",
       "      <td>211.899994</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>207.500000</td>\n",
       "      <td>143.068710</td>\n",
       "      <td>375836.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.269982</td>\n",
       "      <td>123.618274</td>\n",
       "      <td>118.702576</td>\n",
       "      <td>48.415122</td>\n",
       "      <td>-23.653982</td>\n",
       "      <td>16.601940</td>\n",
       "      <td>120.699021</td>\n",
       "      <td>120.953801</td>\n",
       "      <td>1.038983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      tic        open        high         low       close  \\\n",
       "19926  2013-01-14  TATN.ME  217.110001  220.949997  217.110001  112.692490   \n",
       "38016  2015-08-24  MOEX.ME   70.000000   71.370003   66.550003   48.633202   \n",
       "709    2010-04-09  NLMK.ME  107.010002  110.800003  107.010002   49.644722   \n",
       "15422  2012-05-22  SBER.ME   82.699997   83.360001   80.699997   48.453693   \n",
       "14542  2012-04-06  ROSN.ME  211.899994  212.000000  207.500000  143.068710   \n",
       "\n",
       "           volume  day       macd      boll_ub      boll_lb     rsi_30  \\\n",
       "19926       935.0  0.0 -17.914459  2201.740397  2051.222640  43.740359   \n",
       "38016   8789290.0  0.0   2.722145   300.894539   269.605842  62.889452   \n",
       "709        2838.0  4.0  -0.425547    55.746447    51.311696  45.584443   \n",
       "15422  18538680.0  1.0  -0.869171    90.195036    81.072541  43.068266   \n",
       "14542    375836.0  4.0  -0.269982   123.618274   118.702576  48.415122   \n",
       "\n",
       "           cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "19926 -114.285745  28.407658   2122.508366   2139.696606    9.194579  \n",
       "38016  370.055631  51.736144    286.084442    288.722674   19.961763  \n",
       "709    -24.770892  12.861473     53.103637     54.734913    0.000000  \n",
       "15422 -126.431893  20.034822     85.434373     86.858409    2.784742  \n",
       "14542  -23.653982  16.601940    120.699021    120.953801    1.038983  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 19, State Space: 191\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 10, \n",
    "    \"initial_amount\": 50_000,\n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = config.START_DATE\n",
    "train_end = '2019-01-01'\n",
    "val_test_start = '2019-01-01'\n",
    "val_test_end = '2021-01-18'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 100_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2010-01-01 to  2019-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.222   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 2.95     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0733   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.0655  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -1.45    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.00413  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 0.362    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.187    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 8.94e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -3.69    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0234   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+04 |\n",
      "|    total_cost         | 3.39e+04 |\n",
      "|    total_reward       | 4.97e+04 |\n",
      "|    total_reward_pct   | 99.5     |\n",
      "|    total_trades       | 25187    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -11.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 3.43     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0321   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.348    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.000662 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0.444    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 7.79     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0798   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.798   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 2.59     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.017    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.71e+04  |\n",
      "|    total_cost         | 1.86e+04  |\n",
      "|    total_reward       | -2.29e+04 |\n",
      "|    total_reward_pct   | -45.8     |\n",
      "|    total_trades       | 22844     |\n",
      "| time/                 |           |\n",
      "|    fps                | 244       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -2.31     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -4.5      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.0233    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -1.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.94     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00455  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -1.65    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.414    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.000264 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0.364    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 3.5      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0159   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -0.39    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0073   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.03e+04  |\n",
      "|    total_cost         | 2.48e+04  |\n",
      "|    total_reward       | -2.97e+04 |\n",
      "|    total_reward_pct   | -59.4     |\n",
      "|    total_trades       | 22809     |\n",
      "| time/                 |           |\n",
      "|    fps                | 243       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | 0.418     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -2.71     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.00793   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.735   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00369  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.00352  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -13.4    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.49e+04 |\n",
      "|    total_cost         | 1.21e+04 |\n",
      "|    total_reward       | 4.95e+03 |\n",
      "|    total_reward_pct   | 9.89     |\n",
      "|    total_trades       | 21830    |\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -3.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 2.18     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0119   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -3.46    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -1.23    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00144  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -4.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -2.81    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 244       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 5.2       |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.0433    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -2.9     |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "day: 2208, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47582.21\n",
      "total_reward: -2417.79\n",
      "total_cost: 9582.34\n",
      "total_trades: 22897\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.76e+04  |\n",
      "|    total_cost         | 9.58e+03  |\n",
      "|    total_reward       | -2.42e+03 |\n",
      "|    total_reward_pct   | -4.84     |\n",
      "|    total_trades       | 22897     |\n",
      "| time/                 |           |\n",
      "|    fps                | 244       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -1.58     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -0.179    |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 8.81e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -1.97    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00291  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | 0.73     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.637   |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.000653 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | -0.0411  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -4.02    |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.024    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.74e+04 |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 7.4e+03  |\n",
      "|    total_reward_pct   | 14.8     |\n",
      "|    total_trades       | 22891    |\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -12      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.00592  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | 0.657    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -2.96    |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.0082   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -1.8     |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -9.33    |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.28e+05 |\n",
      "|    total_cost         | 1.61e+04 |\n",
      "|    total_reward       | 7.77e+04 |\n",
      "|    total_reward_pct   | 155      |\n",
      "|    total_trades       | 25489    |\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | -5.5     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -2.56    |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.00845  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.1    |\n",
      "|    explained_variance | -40.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.00336  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.301    |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.000212 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0.0828   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.105    |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 1.63e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.223    |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 5.98e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.92e+03  |\n",
      "|    total_cost         | 4.13e+03  |\n",
      "|    total_reward       | -4.71e+04 |\n",
      "|    total_reward_pct   | -94.2     |\n",
      "|    total_trades       | 23891     |\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.7     |\n",
      "|    explained_variance | 0.035     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -0.018    |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 6.13e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | -18.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.431    |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00123  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -27.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.372   |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.000441 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | -0.276   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 1.88     |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.0032   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.98e+03 |\n",
      "|    total_cost         | 6.13e+03 |\n",
      "|    total_reward       | -4.3e+04 |\n",
      "|    total_reward_pct   | -86      |\n",
      "|    total_trades       | 24898    |\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | -5.85    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -1.24    |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.00178  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -0.216   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.00318  |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 4.24e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.295    |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 8.35e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 0.594     |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 0.000396  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | 0.372    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.368    |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.000338 |\n",
      "------------------------------------\n",
      "day: 2208, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4980.32\n",
      "total_reward: -45019.68\n",
      "total_cost: 6115.51\n",
      "total_trades: 23794\n",
      "Sharpe: -0.139\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.98e+03 |\n",
      "|    total_cost         | 6.12e+03 |\n",
      "|    total_reward       | -4.5e+04 |\n",
      "|    total_reward_pct   | -90      |\n",
      "|    total_trades       | 23794    |\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | -0.379   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.478   |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.000344 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | -11      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.87    |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.00065  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | 0.277    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.784   |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 0.0005   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | -0.0621  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.467   |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.000426 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.57e+04  |\n",
      "|    total_cost         | 5.28e+03  |\n",
      "|    total_reward       | -3.43e+04 |\n",
      "|    total_reward_pct   | -68.6     |\n",
      "|    total_trades       | 23363     |\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -2.95     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -3.25     |\n",
      "|    std                | 1.98      |\n",
      "|    value_loss         | 0.00768   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | -2.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.683    |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 0.000335 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 2.42     |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.00308  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.521   |\n",
      "|    std                | 2.1      |\n",
      "|    value_loss         | 0.00311  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -3.12    |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.0109   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.33e+04  |\n",
      "|    total_cost         | 4.1e+03   |\n",
      "|    total_reward       | -2.67e+04 |\n",
      "|    total_reward_pct   | -53.5     |\n",
      "|    total_trades       | 22450     |\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 0.381     |\n",
      "|    std                | 2.16      |\n",
      "|    value_loss         | 0.000108  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42      |\n",
      "|    explained_variance | -3.92    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.761    |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 0.000633 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.441    |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 0.000377 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.00334 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -4.2     |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.22e+04 |\n",
      "|    total_cost         | 5.23e+03 |\n",
      "|    total_reward       | 2.21e+03 |\n",
      "|    total_reward_pct   | 4.42     |\n",
      "|    total_trades       | 21466    |\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.301    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -2.5     |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.00662  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    std                | 2.32     |\n",
      "|    value_loss         | 0.0045   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -3.28     |\n",
      "|    std                | 2.34      |\n",
      "|    value_loss         | 0.00567   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -9.99    |\n",
      "|    std                | 2.37     |\n",
      "|    value_loss         | 0.0811   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6e+04    |\n",
      "|    total_cost         | 5.6e+03  |\n",
      "|    total_reward       | 9.99e+03 |\n",
      "|    total_reward_pct   | 20       |\n",
      "|    total_trades       | 20496    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | -4.62    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.375    |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.000217 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -1.27    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.675    |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.000241 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -0.242   |\n",
      "|    std                | 2.47     |\n",
      "|    value_loss         | 0.0001   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -3.68    |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 0.00957  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | -7.58    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -18      |\n",
      "|    std                | 2.52     |\n",
      "|    value_loss         | 0.158    |\n",
      "------------------------------------\n",
      "day: 2208, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 46883.67\n",
      "total_reward: -3116.33\n",
      "total_cost: 4018.87\n",
      "total_trades: 19683\n",
      "Sharpe: 0.365\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.69e+04  |\n",
      "|    total_cost         | 4.02e+03  |\n",
      "|    total_reward       | -3.12e+03 |\n",
      "|    total_reward_pct   | -6.23     |\n",
      "|    total_trades       | 19683     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -0.0186   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 0.124     |\n",
      "|    std                | 2.55      |\n",
      "|    value_loss         | 0.00345   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0.365   |\n",
      "|    std                | 2.58     |\n",
      "|    value_loss         | 0.000911 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | -0.072   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 0.105    |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 0.000101 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -8.19    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.0751   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.4e+04  |\n",
      "|    total_cost         | 4.1e+03  |\n",
      "|    total_reward       | 2.4e+04  |\n",
      "|    total_reward_pct   | 48       |\n",
      "|    total_trades       | 19260    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | -0.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 0.246    |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 0.000395 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 1.96e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 0.0115   |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 2.52e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -1.16    |\n",
      "|    std                | 2.73     |\n",
      "|    value_loss         | 0.00122  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -4.15    |\n",
      "|    std                | 2.78     |\n",
      "|    value_loss         | 0.0103   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | -0.024   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -2.99    |\n",
      "|    std                | 2.8      |\n",
      "|    value_loss         | 0.00566  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.65e+04  |\n",
      "|    total_cost         | 2.13e+03  |\n",
      "|    total_reward       | -3.35e+04 |\n",
      "|    total_reward_pct   | -67       |\n",
      "|    total_trades       | 19438     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -0.219    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -2.74     |\n",
      "|    std                | 2.84      |\n",
      "|    value_loss         | 0.0039    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 7.07     |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.0303   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.0238   |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.000998 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0.295    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -5.51    |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.5e+04  |\n",
      "|    total_cost         | 2.48e+03 |\n",
      "|    total_reward       | -1.5e+04 |\n",
      "|    total_reward_pct   | -30.1    |\n",
      "|    total_trades       | 19959    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | -0.225   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.00165  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 3.06     |\n",
      "|    value_loss         | 0.000717 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0.00327  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 2.72     |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.00358  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | -0.0249  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -7.19    |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.0264   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.14e+04  |\n",
      "|    total_cost         | 1.54e+03  |\n",
      "|    total_reward       | -1.86e+04 |\n",
      "|    total_reward_pct   | -37.2     |\n",
      "|    total_trades       | 19104     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -3.25     |\n",
      "|    std                | 3.19      |\n",
      "|    value_loss         | 0.00723   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0.252    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -3.76    |\n",
      "|    std                | 3.22     |\n",
      "|    value_loss         | 0.00691  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -3.96    |\n",
      "|    std                | 3.25     |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -5.66    |\n",
      "|    std                | 3.27     |\n",
      "|    value_loss         | 0.027    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -38.8    |\n",
      "|    std                | 3.29     |\n",
      "|    value_loss         | 0.842    |\n",
      "------------------------------------\n",
      "day: 2208, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 89004.78\n",
      "total_reward: 39004.78\n",
      "total_cost: 2633.33\n",
      "total_trades: 18920\n",
      "Sharpe: 0.365\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.9e+04  |\n",
      "|    total_cost         | 2.63e+03 |\n",
      "|    total_reward       | 3.9e+04  |\n",
      "|    total_reward_pct   | 78       |\n",
      "|    total_trades       | 18920    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | -211     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 1.3      |\n",
      "|    std                | 3.33     |\n",
      "|    value_loss         | 0.00123  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -0.27     |\n",
      "|    std                | 3.39      |\n",
      "|    value_loss         | 7.51e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -0.932   |\n",
      "|    std                | 3.46     |\n",
      "|    value_loss         | 0.000912 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.7     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 5.81      |\n",
      "|    std                | 3.5       |\n",
      "|    value_loss         | 0.0189    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.39e+04 |\n",
      "|    total_cost         | 1.98e+03 |\n",
      "|    total_reward       | -6.1e+03 |\n",
      "|    total_reward_pct   | -12.2    |\n",
      "|    total_trades       | 19359    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 1.71     |\n",
      "|    std                | 3.54     |\n",
      "|    value_loss         | 0.00154  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.2    |\n",
      "|    explained_variance | -11.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -0.417   |\n",
      "|    std                | 3.59     |\n",
      "|    value_loss         | 0.000831 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.404    |\n",
      "|    std                | 3.65     |\n",
      "|    value_loss         | 0.000367 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -1.31    |\n",
      "|    std                | 3.72     |\n",
      "|    value_loss         | 0.000869 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -4.69    |\n",
      "|    std                | 3.76     |\n",
      "|    value_loss         | 0.012    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.44e+04  |\n",
      "|    total_cost         | 3.67e+03  |\n",
      "|    total_reward       | -2.56e+04 |\n",
      "|    total_reward_pct   | -51.2     |\n",
      "|    total_trades       | 20846     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 198       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.3     |\n",
      "|    explained_variance | 0.426     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 1.05      |\n",
      "|    std                | 3.81      |\n",
      "|    value_loss         | 0.00072   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | -1.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.751    |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 0.000289 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0.0195   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 4.23     |\n",
      "|    std                | 3.94     |\n",
      "|    value_loss         | 0.00795  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -2       |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.00241  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+04  |\n",
      "|    total_cost         | 6.63e+03 |\n",
      "|    total_reward       | -1.8e+04 |\n",
      "|    total_reward_pct   | -35.9    |\n",
      "|    total_trades       | 22413    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -0.23    |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 4.43e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 0.162    |\n",
      "|    std                | 4.1      |\n",
      "|    value_loss         | 1.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -7.71    |\n",
      "|    std                | 4.19     |\n",
      "|    value_loss         | 0.0214   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 4.24     |\n",
      "|    value_loss         | 0.0553   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | -0.413   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -3.69    |\n",
      "|    std                | 4.25     |\n",
      "|    value_loss         | 0.00969  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.88e+04 |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 8.76e+03 |\n",
      "|    total_reward_pct   | 17.5     |\n",
      "|    total_trades       | 22911    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -0.0226  |\n",
      "|    std                | 4.31     |\n",
      "|    value_loss         | 1.28e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | -0.177    |\n",
      "|    std                | 4.39      |\n",
      "|    value_loss         | 0.000912  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 9.2      |\n",
      "|    std                | 4.47     |\n",
      "|    value_loss         | 0.0341   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -2.44    |\n",
      "|    std                | 4.51     |\n",
      "|    value_loss         | 0.0141   |\n",
      "------------------------------------\n",
      "day: 2208, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 44866.40\n",
      "total_reward: -5133.60\n",
      "total_cost: 7388.01\n",
      "total_trades: 23112\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.49e+04  |\n",
      "|    total_cost         | 7.39e+03  |\n",
      "|    total_reward       | -5.13e+03 |\n",
      "|    total_reward_pct   | -10.3     |\n",
      "|    total_trades       | 23112     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -0.124    |\n",
      "|    std                | 4.54      |\n",
      "|    value_loss         | 1.01e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.536    |\n",
      "|    std                | 4.62     |\n",
      "|    value_loss         | 0.000256 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -1.77    |\n",
      "|    std                | 4.7      |\n",
      "|    value_loss         | 0.00143  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 2.68     |\n",
      "|    std                | 4.76     |\n",
      "|    value_loss         | 0.00621  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.89e+04  |\n",
      "|    total_cost         | 6.5e+03   |\n",
      "|    total_reward       | -1.11e+04 |\n",
      "|    total_reward_pct   | -22.2     |\n",
      "|    total_trades       | 23101     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.7     |\n",
      "|    explained_variance | 0.0268    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 4.11      |\n",
      "|    std                | 4.79      |\n",
      "|    value_loss         | 0.00662   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | 0.12     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 1.67     |\n",
      "|    std                | 4.86     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 38.8     |\n",
      "|    std                | 4.94     |\n",
      "|    value_loss         | 0.803    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -5.89     |\n",
      "|    std                | 5         |\n",
      "|    value_loss         | 0.0219    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.6    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 2.57     |\n",
      "|    std                | 5.02     |\n",
      "|    value_loss         | 0.0601   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.33e+04 |\n",
      "|    total_cost         | 6.72e+03 |\n",
      "|    total_reward       | 1.33e+04 |\n",
      "|    total_reward_pct   | 26.6     |\n",
      "|    total_trades       | 23087    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    std                | 5.07     |\n",
      "|    value_loss         | 0.000712 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 0.758     |\n",
      "|    std                | 5.15      |\n",
      "|    value_loss         | 0.000257  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.212    |\n",
      "|    std                | 5.25     |\n",
      "|    value_loss         | 0.000114 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -0.754   |\n",
      "|    std                | 5.35     |\n",
      "|    value_loss         | 0.00312  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.23e+04  |\n",
      "|    total_cost         | 1.31e+04  |\n",
      "|    total_reward       | -2.77e+04 |\n",
      "|    total_reward_pct   | -55.4     |\n",
      "|    total_trades       | 24253     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 251       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.1     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -0.381    |\n",
      "|    std                | 5.43      |\n",
      "|    value_loss         | 0.000209  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.425    |\n",
      "|    std                | 5.54     |\n",
      "|    value_loss         | 6.86e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.9    |\n",
      "|    explained_variance | -3.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.986   |\n",
      "|    std                | 5.68     |\n",
      "|    value_loss         | 0.000454 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 2.95     |\n",
      "|    std                | 5.79     |\n",
      "|    value_loss         | 0.00288  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 2.55     |\n",
      "|    std                | 5.85     |\n",
      "|    value_loss         | 0.00249  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.78e+04  |\n",
      "|    total_cost         | 1.39e+04  |\n",
      "|    total_reward       | -1.22e+04 |\n",
      "|    total_reward_pct   | -24.5     |\n",
      "|    total_trades       | 24718     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 261       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 1.33      |\n",
      "|    std                | 5.94      |\n",
      "|    value_loss         | 0.000587  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -1.5     |\n",
      "|    std                | 6.06     |\n",
      "|    value_loss         | 0.000837 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 1.47     |\n",
      "|    std                | 6.18     |\n",
      "|    value_loss         | 0.000647 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -1.89    |\n",
      "|    std                | 6.29     |\n",
      "|    value_loss         | 0.00137  |\n",
      "------------------------------------\n",
      "day: 2208, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 12569.61\n",
      "total_reward: -37430.39\n",
      "total_cost: 13287.97\n",
      "total_trades: 24943\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.26e+04  |\n",
      "|    total_cost         | 1.33e+04  |\n",
      "|    total_reward       | -3.74e+04 |\n",
      "|    total_reward_pct   | -74.9     |\n",
      "|    total_trades       | 24943     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | -0.0562   |\n",
      "|    std                | 6.4       |\n",
      "|    value_loss         | 0.000331  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 271       |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 0.573     |\n",
      "|    std                | 6.53      |\n",
      "|    value_loss         | 0.000215  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 3.96     |\n",
      "|    std                | 6.67     |\n",
      "|    value_loss         | 0.00395  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.2    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 8.99     |\n",
      "|    std                | 6.76     |\n",
      "|    value_loss         | 0.0247   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.06e+04  |\n",
      "|    total_cost         | 1.05e+04  |\n",
      "|    total_reward       | -1.94e+04 |\n",
      "|    total_reward_pct   | -38.8     |\n",
      "|    total_trades       | 24212     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 277       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.4     |\n",
      "|    explained_variance | -27.7     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -1.34     |\n",
      "|    std                | 6.82      |\n",
      "|    value_loss         | 0.00264   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.7    |\n",
      "|    explained_variance | 0.765    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -2.52    |\n",
      "|    std                | 6.91     |\n",
      "|    value_loss         | 0.00157  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 0.873    |\n",
      "|    std                | 7.05     |\n",
      "|    value_loss         | 0.000275 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 0.816    |\n",
      "|    std                | 7.18     |\n",
      "|    value_loss         | 0.000341 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.7    |\n",
      "|    explained_variance | 0.313    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -5.26    |\n",
      "|    std                | 7.3      |\n",
      "|    value_loss         | 0.00757  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.5e+04  |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | -2.5e+04 |\n",
      "|    total_reward_pct   | -50      |\n",
      "|    total_trades       | 24347    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.657    |\n",
      "|    std                | 7.41     |\n",
      "|    value_loss         | 0.000763 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 7.54     |\n",
      "|    value_loss         | 0.00079  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -1.18    |\n",
      "|    std                | 7.69     |\n",
      "|    value_loss         | 0.000367 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.1    |\n",
      "|    explained_variance | 0.044    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -2.61    |\n",
      "|    std                | 7.86     |\n",
      "|    value_loss         | 0.00251  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.26e+04  |\n",
      "|    total_cost         | 1.05e+04  |\n",
      "|    total_reward       | -3.74e+04 |\n",
      "|    total_reward_pct   | -74.8     |\n",
      "|    total_trades       | 24396     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 296       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.4     |\n",
      "|    explained_variance | -1.76     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 1.23      |\n",
      "|    std                | 7.97      |\n",
      "|    value_loss         | 0.000695  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.7    |\n",
      "|    explained_variance | -0.00508 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 0.763    |\n",
      "|    std                | 8.1      |\n",
      "|    value_loss         | 0.00015  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -1.86    |\n",
      "|    std                | 8.23     |\n",
      "|    value_loss         | 0.00253  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.2    |\n",
      "|    explained_variance | -1.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -1.43    |\n",
      "|    std                | 8.35     |\n",
      "|    value_loss         | 0.000757 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.4    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -0.0788  |\n",
      "|    std                | 8.4      |\n",
      "|    value_loss         | 0.000955 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.48e+04  |\n",
      "|    total_cost         | 1.83e+04  |\n",
      "|    total_reward       | -1.52e+04 |\n",
      "|    total_reward_pct   | -30.5     |\n",
      "|    total_trades       | 25636     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 306       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.6     |\n",
      "|    explained_variance | -0.000782 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -3.26     |\n",
      "|    std                | 8.51      |\n",
      "|    value_loss         | 0.00294   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.615   |\n",
      "|    std                | 8.69     |\n",
      "|    value_loss         | 0.000131 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -2.66    |\n",
      "|    std                | 8.88     |\n",
      "|    value_loss         | 0.00178  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -6.76    |\n",
      "|    std                | 8.98     |\n",
      "|    value_loss         | 0.0122   |\n",
      "------------------------------------\n",
      "day: 2208, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 32021.17\n",
      "total_reward: -17978.83\n",
      "total_cost: 14972.97\n",
      "total_trades: 25263\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+04  |\n",
      "|    total_cost         | 1.5e+04  |\n",
      "|    total_reward       | -1.8e+04 |\n",
      "|    total_reward_pct   | -36      |\n",
      "|    total_trades       | 25263    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.8    |\n",
      "|    explained_variance | -0.0995  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 7.41     |\n",
      "|    std                | 9.06     |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 1.9      |\n",
      "|    std                | 9.15     |\n",
      "|    value_loss         | 0.000942 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.1    |\n",
      "|    explained_variance | 0.0709   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.405   |\n",
      "|    std                | 9.22     |\n",
      "|    value_loss         | 0.00475  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 6.09     |\n",
      "|    std                | 9.29     |\n",
      "|    value_loss         | 0.0111   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | -0.332   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 6.52     |\n",
      "|    std                | 9.34     |\n",
      "|    value_loss         | 0.0546   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.52e+04 |\n",
      "|    total_cost         | 2.17e+04 |\n",
      "|    total_reward       | 3.52e+04 |\n",
      "|    total_reward_pct   | 70.5     |\n",
      "|    total_trades       | 26060    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 0.182    |\n",
      "|    std                | 9.45     |\n",
      "|    value_loss         | 1.61e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -1.04     |\n",
      "|    std                | 9.61      |\n",
      "|    value_loss         | 0.000254  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.3    |\n",
      "|    explained_variance | 0.0123   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -0.271   |\n",
      "|    std                | 9.79     |\n",
      "|    value_loss         | 0.000336 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 330       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -2.68     |\n",
      "|    std                | 9.91      |\n",
      "|    value_loss         | 0.015     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.26e+04  |\n",
      "|    total_cost         | 1.84e+04  |\n",
      "|    total_reward       | -7.43e+03 |\n",
      "|    total_reward_pct   | -14.9     |\n",
      "|    total_trades       | 25284     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 332       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0.0393    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -0.536    |\n",
      "|    std                | 9.99      |\n",
      "|    value_loss         | 0.00011   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -3.1     |\n",
      "|    std                | 10.1     |\n",
      "|    value_loss         | 0.00282  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.848    |\n",
      "|    std                | 10.3     |\n",
      "|    value_loss         | 0.000323 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 339       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | 3.84      |\n",
      "|    std                | 10.5      |\n",
      "|    value_loss         | 0.0038    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.09e+04  |\n",
      "|    total_cost         | 1.79e+04  |\n",
      "|    total_reward       | -2.91e+04 |\n",
      "|    total_reward_pct   | -58.2     |\n",
      "|    total_trades       | 25225     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -6.79     |\n",
      "|    std                | 10.6      |\n",
      "|    value_loss         | 0.0098    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -0.787   |\n",
      "|    std                | 10.8     |\n",
      "|    value_loss         | 0.000751 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.892   |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 0.000264 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.347   |\n",
      "|    std                | 11.1     |\n",
      "|    value_loss         | 0.000568 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73      |\n",
      "|    explained_variance | -5.53    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -2.92    |\n",
      "|    std                | 11.3     |\n",
      "|    value_loss         | 0.00312  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.61e+04  |\n",
      "|    total_cost         | 2.72e+04  |\n",
      "|    total_reward       | -1.39e+04 |\n",
      "|    total_reward_pct   | -27.8     |\n",
      "|    total_trades       | 26377     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 351       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.2     |\n",
      "|    explained_variance | -5.42     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 1.28      |\n",
      "|    std                | 11.4      |\n",
      "|    value_loss         | 0.000476  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 353      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.5    |\n",
      "|    explained_variance | -2.93    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.481    |\n",
      "|    std                | 11.6     |\n",
      "|    value_loss         | 0.000146 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74      |\n",
      "|    explained_variance | 0.0457   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.436   |\n",
      "|    std                | 11.9     |\n",
      "|    value_loss         | 5.52e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 357      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.00705 |\n",
      "|    std                | 12.3     |\n",
      "|    value_loss         | 2.47e-06 |\n",
      "------------------------------------\n",
      "day: 2208, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2652.03\n",
      "total_reward: -47347.97\n",
      "total_cost: 13592.68\n",
      "total_trades: 25312\n",
      "Sharpe: -0.428\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.65e+03  |\n",
      "|    total_cost         | 1.36e+04  |\n",
      "|    total_reward       | -4.73e+04 |\n",
      "|    total_reward_pct   | -94.7     |\n",
      "|    total_trades       | 25312     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 359       |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.1     |\n",
      "|    explained_variance | -5.25e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | 0.601     |\n",
      "|    std                | 12.6      |\n",
      "|    value_loss         | 8.59e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 361      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 0.0423   |\n",
      "|    std                | 12.9     |\n",
      "|    value_loss         | 6.28e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.1    |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -0.927   |\n",
      "|    std                | 13.3     |\n",
      "|    value_loss         | 0.000219 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.8    |\n",
      "|    explained_variance | 4.41e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 1.34     |\n",
      "|    std                | 13.8     |\n",
      "|    value_loss         | 0.000361 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.4    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 0.712    |\n",
      "|    std                | 14.2     |\n",
      "|    value_loss         | 0.000115 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.12e+03  |\n",
      "|    total_cost         | 1.39e+04  |\n",
      "|    total_reward       | -4.59e+04 |\n",
      "|    total_reward_pct   | -91.8     |\n",
      "|    total_trades       | 25175     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 369       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.9     |\n",
      "|    explained_variance | 0.0495    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | -0.446    |\n",
      "|    std                | 14.7      |\n",
      "|    value_loss         | 6.69e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 371      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.63     |\n",
      "|    std                | 15.1     |\n",
      "|    value_loss         | 7.77e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 373       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -79.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | 0.641     |\n",
      "|    std                | 15.6      |\n",
      "|    value_loss         | 0.000101  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 375      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.8    |\n",
      "|    explained_variance | -1.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.453   |\n",
      "|    std                | 16.2     |\n",
      "|    value_loss         | 3.75e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.52e+03  |\n",
      "|    total_cost         | 1.28e+04  |\n",
      "|    total_reward       | -4.85e+04 |\n",
      "|    total_reward_pct   | -97       |\n",
      "|    total_trades       | 24882     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 377       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80.5     |\n",
      "|    explained_variance | -0.344    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -1.35     |\n",
      "|    std                | 16.8      |\n",
      "|    value_loss         | 0.000335  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 379      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    std                | 17.2     |\n",
      "|    value_loss         | 0.000338 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | -0.0303  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -5.69    |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 0.00597  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 383      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.0109   |\n",
      "|    std                | 18       |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -249      |\n",
      "|    total_cost         | 2.02e+04  |\n",
      "|    total_reward       | -5.02e+04 |\n",
      "|    total_reward_pct   | -100      |\n",
      "|    total_trades       | 25666     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 385       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.2     |\n",
      "|    explained_variance | -11.1     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 0.914     |\n",
      "|    std                | 18.4      |\n",
      "|    value_loss         | 0.000276  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.6    |\n",
      "|    explained_variance | -0.0599  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    std                | 18.8     |\n",
      "|    value_loss         | 0.000312 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 389       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -83.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 0.438     |\n",
      "|    std                | 19.4      |\n",
      "|    value_loss         | 0.000137  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    std                | 19.9     |\n",
      "|    value_loss         | 0.000403 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 393       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 0.0594    |\n",
      "|    std                | 20.3      |\n",
      "|    value_loss         | 8.81e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.97e+03 |\n",
      "|    total_cost         | 2.86e+04 |\n",
      "|    total_reward       | -4.4e+04 |\n",
      "|    total_reward_pct   | -88.1    |\n",
      "|    total_trades       | 26356    |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 395      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.6    |\n",
      "|    explained_variance | -1.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 0.197    |\n",
      "|    std                | 20.8     |\n",
      "|    value_loss         | 3.21e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 398       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | 1.57      |\n",
      "|    std                | 21.4      |\n",
      "|    value_loss         | 0.000426  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.6    |\n",
      "|    explained_variance | -0.183   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 0.554    |\n",
      "|    std                | 22       |\n",
      "|    value_loss         | 4.49e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.2    |\n",
      "|    explained_variance | -0.194   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.628    |\n",
      "|    std                | 22.6     |\n",
      "|    value_loss         | 0.000251 |\n",
      "------------------------------------\n",
      "day: 2208, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2478.79\n",
      "total_reward: -47521.21\n",
      "total_cost: 19950.28\n",
      "total_trades: 25686\n",
      "Sharpe: -0.039\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.48e+03  |\n",
      "|    total_cost         | 2e+04     |\n",
      "|    total_reward       | -4.75e+04 |\n",
      "|    total_reward_pct   | -95       |\n",
      "|    total_trades       | 25686     |\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 404       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86.7     |\n",
      "|    explained_variance | -1.74     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 2.74      |\n",
      "|    std                | 23.2      |\n",
      "|    value_loss         | 0.00147   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 0.881    |\n",
      "|    std                | 23.7     |\n",
      "|    value_loss         | 0.000203 |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-01-03 to  2019-04-04\n",
      "A2C Sharpe Ratio:  0.06179863715282755\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 277  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.71e+04    |\n",
      "|    total_cost           | 7.65e+04    |\n",
      "|    total_reward         | -2.29e+04   |\n",
      "|    total_reward_pct     | -45.9       |\n",
      "|    total_trades         | 28576       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017210301 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.701      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0595      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.6e+03     |\n",
      "|    total_cost           | 1.42e+04    |\n",
      "|    total_reward         | -4.74e+04   |\n",
      "|    total_reward_pct     | -94.8       |\n",
      "|    total_trades         | 24412       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014623925 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0196      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+04    |\n",
      "|    total_cost           | 2.53e+04    |\n",
      "|    total_reward         | -3.99e+04   |\n",
      "|    total_reward_pct     | -79.7       |\n",
      "|    total_trades         | 25654       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011820152 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 10068.35\n",
      "total_reward: -39931.65\n",
      "total_cost: 25132.93\n",
      "total_trades: 25440\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+04    |\n",
      "|    total_cost           | 2.51e+04    |\n",
      "|    total_reward         | -3.99e+04   |\n",
      "|    total_reward_pct     | -79.9       |\n",
      "|    total_trades         | 25440       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016717672 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0154      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.56e+03    |\n",
      "|    total_cost           | 2.61e+04    |\n",
      "|    total_reward         | -4.34e+04   |\n",
      "|    total_reward_pct     | -86.9       |\n",
      "|    total_trades         | 25781       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018203802 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.541      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.32e+04    |\n",
      "|    total_cost           | 2.67e+04    |\n",
      "|    total_reward         | -3.68e+04   |\n",
      "|    total_reward_pct     | -73.5       |\n",
      "|    total_trades         | 25592       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009297797 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0142      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.45e+03   |\n",
      "|    total_cost           | 3.48e+04   |\n",
      "|    total_reward         | -4.35e+04  |\n",
      "|    total_reward_pct     | -87.1      |\n",
      "|    total_trades         | 26493      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02292705 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | -0.206     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.014      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.41e+04   |\n",
      "|    total_cost           | 5.28e+04   |\n",
      "|    total_reward         | -1.59e+04  |\n",
      "|    total_reward_pct     | -31.7      |\n",
      "|    total_trades         | 27570      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01973981 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.0433     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.312     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0124     |\n",
      "----------------------------------------\n",
      "day: 2208, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 19775.75\n",
      "total_reward: -30224.25\n",
      "total_cost: 52829.94\n",
      "total_trades: 27361\n",
      "Sharpe: -0.347\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.98e+04    |\n",
      "|    total_cost           | 5.28e+04    |\n",
      "|    total_reward         | -3.02e+04   |\n",
      "|    total_reward_pct     | -60.4       |\n",
      "|    total_trades         | 27361       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020908322 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0159      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 531         |\n",
      "|    total_cost           | 1.86e+04    |\n",
      "|    total_reward         | -4.95e+04   |\n",
      "|    total_reward_pct     | -98.9       |\n",
      "|    total_trades         | 25121       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011443678 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.52e+03    |\n",
      "|    total_cost           | 1.77e+04    |\n",
      "|    total_reward         | -4.55e+04   |\n",
      "|    total_reward_pct     | -91         |\n",
      "|    total_trades         | 24909       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014631705 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00526     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.54e+03    |\n",
      "|    total_cost           | 2e+04       |\n",
      "|    total_reward         | -4.05e+04   |\n",
      "|    total_reward_pct     | -80.9       |\n",
      "|    total_trades         | 25067       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017527025 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00498     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017197372 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00573     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+04    |\n",
      "|    total_cost           | 2.17e+04    |\n",
      "|    total_reward         | -3.07e+04   |\n",
      "|    total_reward_pct     | -61.4       |\n",
      "|    total_trades         | 24933       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017320935 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00845     |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -8013.54\n",
      "total_reward: -58013.54\n",
      "total_cost: 14976.71\n",
      "total_trades: 24485\n",
      "Sharpe: 0.584\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -8.01e+03   |\n",
      "|    total_cost           | 1.5e+04     |\n",
      "|    total_reward         | -5.8e+04    |\n",
      "|    total_reward_pct     | -116        |\n",
      "|    total_trades         | 24485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010959764 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00386     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -6.3e+03    |\n",
      "|    total_cost           | 1.7e+04     |\n",
      "|    total_reward         | -5.63e+04   |\n",
      "|    total_reward_pct     | -113        |\n",
      "|    total_trades         | 24865       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011217405 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.326      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00352     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.63e+03    |\n",
      "|    total_cost           | 1.79e+04    |\n",
      "|    total_reward         | -4.44e+04   |\n",
      "|    total_reward_pct     | -88.7       |\n",
      "|    total_trades         | 25206       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019938193 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.325      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00655     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+03    |\n",
      "|    total_cost           | 1.45e+04    |\n",
      "|    total_reward         | -4.74e+04   |\n",
      "|    total_reward_pct     | -94.8       |\n",
      "|    total_trades         | 24794       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017494999 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0035      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.38e+03    |\n",
      "|    total_cost           | 1.03e+04    |\n",
      "|    total_reward         | -4.66e+04   |\n",
      "|    total_reward_pct     | -93.2       |\n",
      "|    total_trades         | 23802       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021123119 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00209     |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5092.94\n",
      "total_reward: -44907.06\n",
      "total_cost: 18295.71\n",
      "total_trades: 24982\n",
      "Sharpe: 0.008\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.09e+03    |\n",
      "|    total_cost           | 1.83e+04    |\n",
      "|    total_reward         | -4.49e+04   |\n",
      "|    total_reward_pct     | -89.8       |\n",
      "|    total_trades         | 24982       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026548276 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00301     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+04    |\n",
      "|    total_cost           | 2.36e+04    |\n",
      "|    total_reward         | -3.08e+04   |\n",
      "|    total_reward_pct     | -61.6       |\n",
      "|    total_trades         | 25630       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031236527 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00304     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -3.17e+03   |\n",
      "|    total_cost           | 1.57e+04    |\n",
      "|    total_reward         | -5.32e+04   |\n",
      "|    total_reward_pct     | -106        |\n",
      "|    total_trades         | 24701       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022670202 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00488     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.54e+04    |\n",
      "|    total_cost           | 1.68e+04    |\n",
      "|    total_reward         | -3.46e+04   |\n",
      "|    total_reward_pct     | -69.3       |\n",
      "|    total_trades         | 24856       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020108193 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.315      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00242     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.96e+03    |\n",
      "|    total_cost           | 2.75e+04    |\n",
      "|    total_reward         | -4.4e+04    |\n",
      "|    total_reward_pct     | -88.1       |\n",
      "|    total_trades         | 26251       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025128659 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | -0.355      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4772.88\n",
      "total_reward: -45227.12\n",
      "total_cost: 11080.52\n",
      "total_trades: 24091\n",
      "Sharpe: -0.281\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.77e+03   |\n",
      "|    total_cost           | 1.11e+04   |\n",
      "|    total_reward         | -4.52e+04  |\n",
      "|    total_reward_pct     | -90.5      |\n",
      "|    total_trades         | 24091      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01392644 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.285     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0107     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.4e+04    |\n",
      "|    total_cost           | 3e+04      |\n",
      "|    total_reward         | -5.98e+03  |\n",
      "|    total_reward_pct     | -12        |\n",
      "|    total_trades         | 25784      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02409907 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.0826     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.306     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.00423    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026992433 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0231      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.69e+03    |\n",
      "|    total_cost           | 1.14e+04    |\n",
      "|    total_reward         | -4.43e+04   |\n",
      "|    total_reward_pct     | -88.6       |\n",
      "|    total_trades         | 23837       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021180764 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0022      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.8e+03     |\n",
      "|    total_cost           | 1.11e+04    |\n",
      "|    total_reward         | -4.42e+04   |\n",
      "|    total_reward_pct     | -88.4       |\n",
      "|    total_trades         | 23635       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023988474 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.321      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00262     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | -5.06e+03    |\n",
      "|    total_cost           | 1.09e+04     |\n",
      "|    total_reward         | -5.51e+04    |\n",
      "|    total_reward_pct     | -110         |\n",
      "|    total_trades         | 23746        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 233          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152188055 |\n",
      "|    clip_fraction        | 0.242        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -28          |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.311       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0199      |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00239      |\n",
      "------------------------------------------\n",
      "day: 2208, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 34428.34\n",
      "total_reward: -15571.66\n",
      "total_cost: 33887.45\n",
      "total_trades: 26256\n",
      "Sharpe: -0.022\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.44e+04   |\n",
      "|    total_cost           | 3.39e+04   |\n",
      "|    total_reward         | -1.56e+04  |\n",
      "|    total_reward_pct     | -31.1      |\n",
      "|    total_trades         | 26256      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 240        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02689451 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | -0.0405    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.304     |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0207    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.51e+04   |\n",
      "|    total_cost           | 2.05e+04   |\n",
      "|    total_reward         | -3.49e+04  |\n",
      "|    total_reward_pct     | -69.7      |\n",
      "|    total_trades         | 24723      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 248        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02568705 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.307     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.012      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.04e+03    |\n",
      "|    total_cost           | 1.3e+04     |\n",
      "|    total_reward         | -4.1e+04    |\n",
      "|    total_reward_pct     | -81.9       |\n",
      "|    total_trades         | 24175       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023027746 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00356     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.34e+04    |\n",
      "|    total_cost           | 3.18e+04    |\n",
      "|    total_reward         | 1.34e+04    |\n",
      "|    total_reward_pct     | 26.8        |\n",
      "|    total_trades         | 26178       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030126411 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | -0.0529     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0288      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.02e+03    |\n",
      "|    total_cost           | 9.78e+03    |\n",
      "|    total_reward         | -4.7e+04    |\n",
      "|    total_reward_pct     | -94         |\n",
      "|    total_trades         | 23756       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038039967 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 27318.34\n",
      "total_reward: -22681.66\n",
      "total_cost: 20669.82\n",
      "total_trades: 25009\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.73e+04    |\n",
      "|    total_cost           | 2.07e+04    |\n",
      "|    total_reward         | -2.27e+04   |\n",
      "|    total_reward_pct     | -45.4       |\n",
      "|    total_trades         | 25009       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024482846 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00351     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.58e+03   |\n",
      "|    total_cost           | 1.19e+04   |\n",
      "|    total_reward         | -4.24e+04  |\n",
      "|    total_reward_pct     | -84.8      |\n",
      "|    total_trades         | 24110      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01912114 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.303     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.00981    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.61e+04    |\n",
      "|    total_cost           | 1.78e+04    |\n",
      "|    total_reward         | -1.39e+04   |\n",
      "|    total_reward_pct     | -27.8       |\n",
      "|    total_trades         | 24950       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021750815 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00378     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.52e+04    |\n",
      "|    total_cost           | 2.14e+04    |\n",
      "|    total_reward         | -1.48e+04   |\n",
      "|    total_reward_pct     | -29.6       |\n",
      "|    total_trades         | 25289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020881737 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00603     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.86e+03    |\n",
      "|    total_cost           | 1.1e+04     |\n",
      "|    total_reward         | -4.41e+04   |\n",
      "|    total_reward_pct     | -88.3       |\n",
      "|    total_trades         | 23755       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038832497 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00824     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024168227 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | -0.0303     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.315      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00383     |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50120.32\n",
      "total_reward: 120.32\n",
      "total_cost: 33442.28\n",
      "total_trades: 26378\n",
      "Sharpe: 0.130\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.01e+04    |\n",
      "|    total_cost           | 3.34e+04    |\n",
      "|    total_reward         | 120         |\n",
      "|    total_reward_pct     | 0.241       |\n",
      "|    total_trades         | 26378       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029593457 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+04    |\n",
      "|    total_cost           | 1.62e+04    |\n",
      "|    total_reward         | -3.82e+04   |\n",
      "|    total_reward_pct     | -76.3       |\n",
      "|    total_trades         | 24698       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021862475 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00482     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.94e+04    |\n",
      "|    total_cost           | 1.48e+04    |\n",
      "|    total_reward         | -2.06e+04   |\n",
      "|    total_reward_pct     | -41.2       |\n",
      "|    total_trades         | 24463       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039182123 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00983     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.54e+04    |\n",
      "|    total_cost           | 2.91e+04    |\n",
      "|    total_reward         | 1.54e+04    |\n",
      "|    total_reward_pct     | 30.8        |\n",
      "|    total_trades         | 26018       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043855235 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.253      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.07e+04    |\n",
      "|    total_cost           | 3.46e+04    |\n",
      "|    total_reward         | 2.07e+04    |\n",
      "|    total_reward_pct     | 41.3        |\n",
      "|    total_trades         | 26362       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042436834 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0263      |\n",
      "-----------------------------------------\n",
      "day: 2208, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 37278.23\n",
      "total_reward: -12721.77\n",
      "total_cost: 25898.04\n",
      "total_trades: 25873\n",
      "Sharpe: 0.117\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.73e+04   |\n",
      "|    total_cost           | 2.59e+04   |\n",
      "|    total_reward         | -1.27e+04  |\n",
      "|    total_reward_pct     | -25.4      |\n",
      "|    total_trades         | 25873      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 362        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03485192 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.6      |\n",
      "|    explained_variance   | 0.474      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.292     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.0289     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+03    |\n",
      "|    total_cost           | 1.32e+04    |\n",
      "|    total_reward         | -4.78e+04   |\n",
      "|    total_reward_pct     | -95.5       |\n",
      "|    total_trades         | 24284       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030258961 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00974     |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-01-03 to  2019-04-04\n",
      "PPO Sharpe Ratio:  0.23783932788781736\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
      "day: 2208, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 28126.70\n",
      "total_reward: -21873.30\n",
      "total_cost: 142.52\n",
      "total_trades: 17699\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.94e+04  |\n",
      "|    total_cost       | 187       |\n",
      "|    total_reward     | -1.06e+04 |\n",
      "|    total_reward_pct | -21.2     |\n",
      "|    total_trades     | 17457     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 123       |\n",
      "|    time_elapsed     | 71        |\n",
      "|    total timesteps  | 8836      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 28.9      |\n",
      "|    critic_loss      | 5.25      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6627      |\n",
      "-----------------------------------\n",
      "day: 2208, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 44579.90\n",
      "total_reward: -5420.10\n",
      "total_cost: 124.41\n",
      "total_trades: 18051\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.46e+04  |\n",
      "|    total_cost       | 124       |\n",
      "|    total_reward     | -5.42e+03 |\n",
      "|    total_reward_pct | -10.8     |\n",
      "|    total_trades     | 18051     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 112       |\n",
      "|    time_elapsed     | 156       |\n",
      "|    total timesteps  | 17672     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 17.9      |\n",
      "|    critic_loss      | 1.6       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 15463     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.88e+04 |\n",
      "|    total_cost       | 132      |\n",
      "|    total_reward     | 8.8e+03  |\n",
      "|    total_reward_pct | 17.6     |\n",
      "|    total_trades     | 18325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 109      |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total timesteps  | 26508    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 11       |\n",
      "|    critic_loss      | 1.03     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24299    |\n",
      "----------------------------------\n",
      "day: 2208, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 42467.48\n",
      "total_reward: -7532.52\n",
      "total_cost: 139.70\n",
      "total_trades: 18671\n",
      "Sharpe: 0.339\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.52e+04 |\n",
      "|    total_cost       | 144      |\n",
      "|    total_reward     | 1.52e+04 |\n",
      "|    total_reward_pct | 30.4     |\n",
      "|    total_trades     | 18448    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 107      |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total timesteps  | 35344    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 6.6      |\n",
      "|    critic_loss      | 0.67     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 33135    |\n",
      "----------------------------------\n",
      "day: 2208, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 34298.90\n",
      "total_reward: -15701.10\n",
      "total_cost: 149.46\n",
      "total_trades: 18504\n",
      "Sharpe: 0.246\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.54e+04 |\n",
      "|    total_cost       | 108      |\n",
      "|    total_reward     | 5.45e+03 |\n",
      "|    total_reward_pct | 10.9     |\n",
      "|    total_trades     | 18107    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 106      |\n",
      "|    time_elapsed     | 413      |\n",
      "|    total timesteps  | 44180    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.87     |\n",
      "|    critic_loss      | 0.687    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 41971    |\n",
      "----------------------------------\n",
      "day: 2208, episode: 115\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 32731.18\n",
      "total_reward: -17268.82\n",
      "total_cost: 171.68\n",
      "total_trades: 17880\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03 to  2019-04-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_126_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.11e+04 |\n",
      "|    total_cost       | 103      |\n",
      "|    total_reward     | 1.1e+03  |\n",
      "|    total_reward_pct | 2.2      |\n",
      "|    total_trades     | 26768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total timesteps  | 9088     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 142      |\n",
      "|    critic_loss      | 776      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6816     |\n",
      "----------------------------------\n",
      "day: 2271, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 63086.08\n",
      "total_reward: 13086.08\n",
      "total_cost: 136.90\n",
      "total_trades: 27164\n",
      "Sharpe: 0.310\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.08e+04 |\n",
      "|    total_cost       | 130      |\n",
      "|    total_reward     | 1.08e+04 |\n",
      "|    total_reward_pct | 21.7     |\n",
      "|    total_trades     | 26285    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 110      |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total timesteps  | 18176    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 82.5     |\n",
      "|    critic_loss      | 44.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15904    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 56318.69\n",
      "total_reward: 6318.69\n",
      "total_cost: 116.51\n",
      "total_trades: 25389\n",
      "Sharpe: 0.301\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.2e+04  |\n",
      "|    total_cost       | 111      |\n",
      "|    total_reward     | 1.97e+03 |\n",
      "|    total_reward_pct | 3.94     |\n",
      "|    total_trades     | 25471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total timesteps  | 27264    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 50.5     |\n",
      "|    critic_loss      | 12.9     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 24992    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 61847.54\n",
      "total_reward: 11847.54\n",
      "total_cost: 121.59\n",
      "total_trades: 25330\n",
      "Sharpe: 0.463\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.79e+04  |\n",
      "|    total_cost       | 144       |\n",
      "|    total_reward     | -3.21e+04 |\n",
      "|    total_reward_pct | -64.2     |\n",
      "|    total_trades     | 21836     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 106       |\n",
      "|    time_elapsed     | 341       |\n",
      "|    total timesteps  | 36352     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 31        |\n",
      "|    critic_loss      | 3.75      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 34080     |\n",
      "-----------------------------------\n",
      "day: 2271, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 45193.38\n",
      "total_reward: -4806.62\n",
      "total_cost: 139.49\n",
      "total_trades: 21523\n",
      "Sharpe: 0.389\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.52e+04  |\n",
      "|    total_cost       | 139       |\n",
      "|    total_reward     | -4.81e+03 |\n",
      "|    total_reward_pct | -9.61     |\n",
      "|    total_trades     | 21523     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 105       |\n",
      "|    time_elapsed     | 430       |\n",
      "|    total timesteps  | 45440     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 19        |\n",
      "|    critic_loss      | 1.89      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 43168     |\n",
      "-----------------------------------\n",
      "======Trading from:  2019-04-04 to  2019-07-05\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2010-01-01 to  2019-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -2.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -5.57    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0441   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.852   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -4.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0282   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -2       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 2.1      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00589  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -7.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.47e+05 |\n",
      "|    total_cost         | 3.13e+04 |\n",
      "|    total_reward       | 9.7e+04  |\n",
      "|    total_reward_pct   | 194      |\n",
      "|    total_trades       | 22453    |\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -1.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.874   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00208  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -6.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.861   |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0013   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.0119  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.51     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00609  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -1.72    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00274  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -5.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.65e+03  |\n",
      "|    total_cost         | 1.01e+04  |\n",
      "|    total_reward       | -4.64e+04 |\n",
      "|    total_reward_pct   | -92.7     |\n",
      "|    total_trades       | 19352     |\n",
      "| time/                 |           |\n",
      "|    fps                | 239       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.9     |\n",
      "|    explained_variance | -0.026    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 14.4      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.247     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -22.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -2.45    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0077   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0.0758   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 1.79     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.00555  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -0.784   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.267   |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00936  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.2e+04  |\n",
      "|    total_cost         | 2.16e+04 |\n",
      "|    total_reward       | 3.2e+04  |\n",
      "|    total_reward_pct   | 63.9     |\n",
      "|    total_trades       | 20280    |\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -12.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -5.82    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0541   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -10.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 1.03     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00382  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -33.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.959    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.00289 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 3.26     |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | -6.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.893   |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00496  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.95e+04  |\n",
      "|    total_cost         | 3.23e+04  |\n",
      "|    total_reward       | -2.05e+04 |\n",
      "|    total_reward_pct   | -41       |\n",
      "|    total_trades       | 21744     |\n",
      "| time/                 |           |\n",
      "|    fps                | 240       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31       |\n",
      "|    explained_variance | -54.2     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 0.101     |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 0.00508   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -4.86    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 1.63     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00395  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | -5.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.297   |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00059  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | -9.37    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -1.71    |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.00523  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 10083.14\n",
      "total_reward: -39916.86\n",
      "total_cost: 28584.81\n",
      "total_trades: 20526\n",
      "Sharpe: -0.270\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.01e+04  |\n",
      "|    total_cost         | 2.86e+04  |\n",
      "|    total_reward       | -3.99e+04 |\n",
      "|    total_reward_pct   | -79.8     |\n",
      "|    total_trades       | 20526     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.1     |\n",
      "|    explained_variance | -55.8     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 3.69      |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.0153    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | -11.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -2.63    |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.0071   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | -43.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -1.51    |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0283   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.1    |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0134   |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.000576 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0332  |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 4.48e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.87e+04  |\n",
      "|    total_cost         | 2.07e+04  |\n",
      "|    total_reward       | -3.13e+04 |\n",
      "|    total_reward_pct   | -62.5     |\n",
      "|    total_trades       | 19760     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.9     |\n",
      "|    explained_variance | 0.26      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -0.521    |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 0.000252  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -0.208    |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 5.77e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | -2.5e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -2.14    |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.00476  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | -0.081   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -2.93    |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.00797  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.38e+04  |\n",
      "|    total_cost         | 1.4e+04   |\n",
      "|    total_reward       | -6.16e+03 |\n",
      "|    total_reward_pct   | -12.3     |\n",
      "|    total_trades       | 21016     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.3     |\n",
      "|    explained_variance | -4.46     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 0.0175    |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 4.72e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -0.0354  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.156    |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.00013  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | -0.592   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.00283  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | -1.52    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.296    |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.00173  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | -0.871   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.0021   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.92e+04  |\n",
      "|    total_cost         | 2.22e+04  |\n",
      "|    total_reward       | -2.08e+04 |\n",
      "|    total_reward_pct   | -41.6     |\n",
      "|    total_trades       | 22841     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.1     |\n",
      "|    explained_variance | -44.5     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -0.268    |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 0.000246  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.127    |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 2.44e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.312   |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.000167 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | -0.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -1.25    |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.98e+03 |\n",
      "|    total_cost         | 2.42e+04 |\n",
      "|    total_reward       | -4.4e+04 |\n",
      "|    total_reward_pct   | -88      |\n",
      "|    total_trades       | 22980    |\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | -243     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 9.28     |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.104    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | 0.201    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.254    |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.000173 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | -13.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.445    |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 0.000202 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | -4.75    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.213   |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 9.02e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | -1.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    std                | 2.08     |\n",
      "|    value_loss         | 0.00277  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -4096.05\n",
      "total_reward: -54096.05\n",
      "total_cost: 19787.96\n",
      "total_trades: 23617\n",
      "Sharpe: -0.076\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.1e+03  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | -5.41e+04 |\n",
      "|    total_reward_pct   | -108      |\n",
      "|    total_trades       | 23617     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | -1.06     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -3.89     |\n",
      "|    std                | 2.13      |\n",
      "|    value_loss         | 0.0105    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | -1.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.828   |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 0.000508 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0.445    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.000727 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -1.5      |\n",
      "|    std                | 2.27      |\n",
      "|    value_loss         | 0.00206   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.16e+03  |\n",
      "|    total_cost         | 2.3e+04   |\n",
      "|    total_reward       | -4.48e+04 |\n",
      "|    total_reward_pct   | -89.7     |\n",
      "|    total_trades       | 25119     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0.228     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -15.4     |\n",
      "|    std                | 2.32      |\n",
      "|    value_loss         | 0.906     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | -0.657   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    std                | 2.34     |\n",
      "|    value_loss         | 0.00354  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -5.69    |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.0186   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.437   |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.00048  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -3.37    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 4.99     |\n",
      "|    std                | 2.46     |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+04  |\n",
      "|    total_cost         | 3.19e+04 |\n",
      "|    total_reward       | -2.2e+04 |\n",
      "|    total_reward_pct   | -43.9    |\n",
      "|    total_trades       | 25208    |\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -2.34    |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 0.00312  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.145    |\n",
      "|    std                | 2.53     |\n",
      "|    value_loss         | 3.07e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -1.36     |\n",
      "|    std                | 2.58      |\n",
      "|    value_loss         | 0.00144   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | -0.983   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.0934  |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 0.000235 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -0.151    |\n",
      "|    std                | 2.68      |\n",
      "|    value_loss         | 9.98e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.29e+04  |\n",
      "|    total_cost         | 2.64e+04  |\n",
      "|    total_reward       | -3.71e+04 |\n",
      "|    total_reward_pct   | -74.3     |\n",
      "|    total_trades       | 24013     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -12.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -0.269    |\n",
      "|    std                | 2.73      |\n",
      "|    value_loss         | 0.000146  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | -0.0245  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.646    |\n",
      "|    std                | 2.79     |\n",
      "|    value_loss         | 0.000417 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 2.65     |\n",
      "|    std                | 2.85     |\n",
      "|    value_loss         | 0.0041   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | -0.823   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -1.66    |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.00138  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.45e+04  |\n",
      "|    total_cost         | 1.17e+04  |\n",
      "|    total_reward       | -3.55e+04 |\n",
      "|    total_reward_pct   | -71       |\n",
      "|    total_trades       | 22132     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -2.1      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -1.15     |\n",
      "|    std                | 2.93      |\n",
      "|    value_loss         | 0.00225   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.183    |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 5.41e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | -0.195   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 4.36     |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.00926  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.2    |\n",
      "|    explained_variance | -0.0324  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 4.35     |\n",
      "|    std                | 3.06     |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0.354   |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47365.19\n",
      "total_reward: -2634.81\n",
      "total_cost: 22053.44\n",
      "total_trades: 23408\n",
      "Sharpe: 0.195\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.74e+04  |\n",
      "|    total_cost         | 2.21e+04  |\n",
      "|    total_reward       | -2.63e+03 |\n",
      "|    total_reward_pct   | -5.27     |\n",
      "|    total_trades       | 23408     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.5     |\n",
      "|    explained_variance | 0.214     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -1.84     |\n",
      "|    std                | 3.11      |\n",
      "|    value_loss         | 0.00353   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | -0.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -2.86    |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.0036   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 0.0131   |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.000478 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.4    |\n",
      "|    explained_variance | -3.83    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -3.97    |\n",
      "|    std                | 3.26     |\n",
      "|    value_loss         | 0.00897  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.35e+04  |\n",
      "|    total_cost         | 2.78e+04  |\n",
      "|    total_reward       | -2.65e+04 |\n",
      "|    total_reward_pct   | -53       |\n",
      "|    total_trades       | 24348     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.6     |\n",
      "|    explained_variance | 0.465     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 1.09      |\n",
      "|    std                | 3.3       |\n",
      "|    value_loss         | 0.000752  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | -0.731   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.205    |\n",
      "|    std                | 3.34     |\n",
      "|    value_loss         | 0.00283  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.1    |\n",
      "|    explained_variance | -0.834   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -1.64    |\n",
      "|    std                | 3.39     |\n",
      "|    value_loss         | 0.00191  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.851    |\n",
      "|    std                | 3.43     |\n",
      "|    value_loss         | 0.00167  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 2.56     |\n",
      "|    std                | 3.48     |\n",
      "|    value_loss         | 0.00251  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.5e+04  |\n",
      "|    total_cost         | 4e+04    |\n",
      "|    total_reward       | -2.5e+04 |\n",
      "|    total_reward_pct   | -49.9    |\n",
      "|    total_trades       | 24411    |\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.9    |\n",
      "|    explained_variance | 0.203    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.557    |\n",
      "|    std                | 3.54     |\n",
      "|    value_loss         | 0.000191 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    std                | 3.62     |\n",
      "|    value_loss         | 0.000678 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.16    |\n",
      "|    std                | 3.71     |\n",
      "|    value_loss         | 4.69e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -1.96    |\n",
      "|    std                | 3.82     |\n",
      "|    value_loss         | 0.00152  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.17e+04  |\n",
      "|    total_cost         | 1.56e+04  |\n",
      "|    total_reward       | -3.83e+04 |\n",
      "|    total_reward_pct   | -76.6     |\n",
      "|    total_trades       | 22360     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.8     |\n",
      "|    explained_variance | 0.211     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 0.507     |\n",
      "|    std                | 3.9       |\n",
      "|    value_loss         | 0.000206  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0.667    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.0401   |\n",
      "|    std                | 4        |\n",
      "|    value_loss         | 9.33e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.00989  |\n",
      "|    std                | 4.11     |\n",
      "|    value_loss         | 1.11e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.755   |\n",
      "|    std                | 4.24     |\n",
      "|    value_loss         | 0.000219 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 4.37     |\n",
      "|    value_loss         | 0.000448 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.05e+04  |\n",
      "|    total_cost         | 9.11e+03  |\n",
      "|    total_reward       | -3.95e+04 |\n",
      "|    total_reward_pct   | -79       |\n",
      "|    total_trades       | 21842     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.3     |\n",
      "|    explained_variance | 0.0894    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 1.8       |\n",
      "|    std                | 4.46      |\n",
      "|    value_loss         | 0.00128   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | 0.167    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 1.47     |\n",
      "|    std                | 4.54     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.00466  |\n",
      "|    std                | 4.64     |\n",
      "|    value_loss         | 3.2e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    std                | 4.75     |\n",
      "|    value_loss         | 0.000678 |\n",
      "------------------------------------\n",
      "day: 2271, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 11185.34\n",
      "total_reward: -38814.66\n",
      "total_cost: 22136.03\n",
      "total_trades: 24820\n",
      "Sharpe: -0.179\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.12e+04  |\n",
      "|    total_cost         | 2.21e+04  |\n",
      "|    total_reward       | -3.88e+04 |\n",
      "|    total_reward_pct   | -77.6     |\n",
      "|    total_trades       | 24820     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -0.141    |\n",
      "|    std                | 4.87      |\n",
      "|    value_loss         | 0.000198  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.5    |\n",
      "|    explained_variance | -0.0279  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.284   |\n",
      "|    std                | 5        |\n",
      "|    value_loss         | 3.93e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 0.196     |\n",
      "|    std                | 5.16      |\n",
      "|    value_loss         | 2.47e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.6    |\n",
      "|    explained_variance | -0.407   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 0.743    |\n",
      "|    std                | 5.28     |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | -0.182   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -2.62    |\n",
      "|    std                | 5.39     |\n",
      "|    value_loss         | 0.00321  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.2e+04  |\n",
      "|    total_cost         | 2.6e+04  |\n",
      "|    total_reward       | -2.8e+04 |\n",
      "|    total_reward_pct   | -56.1    |\n",
      "|    total_trades       | 24681    |\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.383   |\n",
      "|    std                | 5.46     |\n",
      "|    value_loss         | 0.000536 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 7.38     |\n",
      "|    std                | 5.51     |\n",
      "|    value_loss         | 0.0193   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.6     |\n",
      "|    explained_variance | -0.000272 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 3.38      |\n",
      "|    std                | 5.57      |\n",
      "|    value_loss         | 0.00424   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.8    |\n",
      "|    explained_variance | 0.00514  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 10       |\n",
      "|    std                | 5.63     |\n",
      "|    value_loss         | 0.0319   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.47e+04 |\n",
      "|    total_cost         | 2.37e+04 |\n",
      "|    total_reward       | 2.47e+04 |\n",
      "|    total_reward_pct   | 49.5     |\n",
      "|    total_trades       | 24478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.9    |\n",
      "|    explained_variance | -64.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    std                | 5.67     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.2    |\n",
      "|    explained_variance | 0.00286  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 0.144    |\n",
      "|    std                | 5.75     |\n",
      "|    value_loss         | 0.0174   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | 0.744     |\n",
      "|    std                | 5.84      |\n",
      "|    value_loss         | 0.000299  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 0.382    |\n",
      "|    std                | 5.98     |\n",
      "|    value_loss         | 4.32e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 2.77     |\n",
      "|    std                | 6.12     |\n",
      "|    value_loss         | 0.00317  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.32e+04  |\n",
      "|    total_cost         | 1.39e+04  |\n",
      "|    total_reward       | -3.68e+04 |\n",
      "|    total_reward_pct   | -73.6     |\n",
      "|    total_trades       | 23282     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 216       |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 0.863     |\n",
      "|    std                | 6.24      |\n",
      "|    value_loss         | 0.00182   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.671   |\n",
      "|    std                | 6.33     |\n",
      "|    value_loss         | 0.000499 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -0.0809  |\n",
      "|    std                | 6.43     |\n",
      "|    value_loss         | 0.000919 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.6    |\n",
      "|    explained_variance | 0.13     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 6.53     |\n",
      "|    value_loss         | 0.00262  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -4.49    |\n",
      "|    std                | 6.62     |\n",
      "|    value_loss         | 0.00839  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.57e+04  |\n",
      "|    total_cost         | 1.81e+04  |\n",
      "|    total_reward       | -1.43e+04 |\n",
      "|    total_reward_pct   | -28.5     |\n",
      "|    total_trades       | 23829     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | 9.95      |\n",
      "|    std                | 6.69      |\n",
      "|    value_loss         | 0.0258    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 2.92     |\n",
      "|    std                | 6.74     |\n",
      "|    value_loss         | 0.00264  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -2.86    |\n",
      "|    std                | 6.82     |\n",
      "|    value_loss         | 0.0158   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 0.047    |\n",
      "|    std                | 6.87     |\n",
      "|    value_loss         | 0.00104  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74726.88\n",
      "total_reward: 24726.88\n",
      "total_cost: 33473.53\n",
      "total_trades: 25077\n",
      "Sharpe: 0.306\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.47e+04 |\n",
      "|    total_cost         | 3.35e+04 |\n",
      "|    total_reward       | 2.47e+04 |\n",
      "|    total_reward_pct   | 49.5     |\n",
      "|    total_trades       | 25077    |\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.7    |\n",
      "|    explained_variance | -0.449   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 6.99     |\n",
      "|    std                | 6.92     |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.388   |\n",
      "|    std                | 7        |\n",
      "|    value_loss         | 4.83e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.37    |\n",
      "|    std                | 7.11     |\n",
      "|    value_loss         | 0.000347 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    std                | 7.22     |\n",
      "|    value_loss         | 0.000852 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -2.01    |\n",
      "|    std                | 7.33     |\n",
      "|    value_loss         | 0.00122  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.47e+04  |\n",
      "|    total_cost         | 3.72e+04  |\n",
      "|    total_reward       | -3.53e+04 |\n",
      "|    total_reward_pct   | -70.5     |\n",
      "|    total_trades       | 25534     |\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.2     |\n",
      "|    explained_variance | -1.3      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 1.29      |\n",
      "|    std                | 7.49      |\n",
      "|    value_loss         | 0.000475  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -1.45    |\n",
      "|    std                | 7.65     |\n",
      "|    value_loss         | 0.000528 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.1    |\n",
      "|    explained_variance | 0.0375   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 0.445    |\n",
      "|    std                | 7.84     |\n",
      "|    value_loss         | 0.000106 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.6    |\n",
      "|    explained_variance | -0.568   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    std                | 8.05     |\n",
      "|    value_loss         | 0.000483 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.14e+03  |\n",
      "|    total_cost         | 2.05e+04  |\n",
      "|    total_reward       | -4.49e+04 |\n",
      "|    total_reward_pct   | -89.7     |\n",
      "|    total_trades       | 24786     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 254       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67       |\n",
      "|    explained_variance | -4.24     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 0.0453    |\n",
      "|    std                | 8.25      |\n",
      "|    value_loss         | 1.34e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.6    |\n",
      "|    explained_variance | -11.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.274    |\n",
      "|    std                | 8.51     |\n",
      "|    value_loss         | 3.37e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.3    |\n",
      "|    explained_variance | -0.0281  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.0478  |\n",
      "|    std                | 8.81     |\n",
      "|    value_loss         | 0.000197 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -1.36    |\n",
      "|    std                | 9.04     |\n",
      "|    value_loss         | 0.00053  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.2    |\n",
      "|    explained_variance | 0.233    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -1.54    |\n",
      "|    std                | 9.24     |\n",
      "|    value_loss         | 0.000698 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.43e+04  |\n",
      "|    total_cost         | 2.78e+04  |\n",
      "|    total_reward       | -3.57e+04 |\n",
      "|    total_reward_pct   | -71.5     |\n",
      "|    total_trades       | 24839     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 264       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -0.357    |\n",
      "|    std                | 9.45      |\n",
      "|    value_loss         | 6.35e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.426    |\n",
      "|    std                | 9.73     |\n",
      "|    value_loss         | 4e-05    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.7    |\n",
      "|    explained_variance | -0.133   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 0.705    |\n",
      "|    std                | 10       |\n",
      "|    value_loss         | 0.000125 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 0.834    |\n",
      "|    std                | 10.3     |\n",
      "|    value_loss         | 0.000153 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.37e+03  |\n",
      "|    total_cost         | 2.06e+04  |\n",
      "|    total_reward       | -4.36e+04 |\n",
      "|    total_reward_pct   | -87.3     |\n",
      "|    total_trades       | 25103     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 272       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | -0.277    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | 0.939     |\n",
      "|    std                | 10.6      |\n",
      "|    value_loss         | 0.000385  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.2    |\n",
      "|    explained_variance | 0.052    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.468    |\n",
      "|    std                | 10.8     |\n",
      "|    value_loss         | 0.000111 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 0.553    |\n",
      "|    std                | 11.2     |\n",
      "|    value_loss         | 6.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -0.186   |\n",
      "|    std                | 11.6     |\n",
      "|    value_loss         | 8.28e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.921   |\n",
      "|    std                | 12       |\n",
      "|    value_loss         | 0.000156 |\n",
      "------------------------------------\n",
      "day: 2271, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2012.63\n",
      "total_reward: -47987.37\n",
      "total_cost: 12980.05\n",
      "total_trades: 24751\n",
      "Sharpe: -0.106\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.01e+03 |\n",
      "|    total_cost         | 1.3e+04  |\n",
      "|    total_reward       | -4.8e+04 |\n",
      "|    total_reward_pct   | -96      |\n",
      "|    total_trades       | 24751    |\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.8    |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.718   |\n",
      "|    std                | 12.4     |\n",
      "|    value_loss         | 0.000102 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.5    |\n",
      "|    explained_variance | -279     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 4.58     |\n",
      "|    std                | 12.9     |\n",
      "|    value_loss         | 0.0131   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 2.59     |\n",
      "|    std                | 13.2     |\n",
      "|    value_loss         | 0.00136  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    std                | 13.5     |\n",
      "|    value_loss         | 0.0006   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.45e+04  |\n",
      "|    total_cost         | 3.22e+04  |\n",
      "|    total_reward       | -3.55e+04 |\n",
      "|    total_reward_pct   | -71       |\n",
      "|    total_trades       | 26422     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 291       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.7     |\n",
      "|    explained_variance | 0.0671    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 1.17      |\n",
      "|    std                | 13.7      |\n",
      "|    value_loss         | 0.00026   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.2    |\n",
      "|    explained_variance | 0.0369   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 1.03     |\n",
      "|    std                | 14.1     |\n",
      "|    value_loss         | 0.000189 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 19.2     |\n",
      "|    std                | 14.6     |\n",
      "|    value_loss         | 0.274    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.3    |\n",
      "|    explained_variance | -0.0441  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -2.07    |\n",
      "|    std                | 15       |\n",
      "|    value_loss         | 0.000927 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    std                | 15.3     |\n",
      "|    value_loss         | 0.000563 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.09e+03  |\n",
      "|    total_cost         | 2.67e+04  |\n",
      "|    total_reward       | -4.19e+04 |\n",
      "|    total_reward_pct   | -83.8     |\n",
      "|    total_trades       | 26302     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 301       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -79.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 0.181     |\n",
      "|    std                | 15.7      |\n",
      "|    value_loss         | 0.00012   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -79.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 0.135     |\n",
      "|    std                | 16.3      |\n",
      "|    value_loss         | 8.47e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.6    |\n",
      "|    explained_variance | -0.363   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 16.8     |\n",
      "|    value_loss         | 0.000411 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    std                | 17.3     |\n",
      "|    value_loss         | 0.000691 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.4e+03   |\n",
      "|    total_cost         | 2.74e+04  |\n",
      "|    total_reward       | -4.26e+04 |\n",
      "|    total_reward_pct   | -85.2     |\n",
      "|    total_trades       | 26326     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.6     |\n",
      "|    explained_variance | 0.307     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 0.451     |\n",
      "|    std                | 17.7      |\n",
      "|    value_loss         | 3.37e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    std                | 18.3     |\n",
      "|    value_loss         | 8.31e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.451    |\n",
      "|    std                | 18.9     |\n",
      "|    value_loss         | 4.03e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 0.347    |\n",
      "|    std                | 19.4     |\n",
      "|    value_loss         | 3.04e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.778   |\n",
      "|    std                | 19.9     |\n",
      "|    value_loss         | 0.000161 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.85e+03  |\n",
      "|    total_cost         | 2.85e+04  |\n",
      "|    total_reward       | -4.31e+04 |\n",
      "|    total_reward_pct   | -86.3     |\n",
      "|    total_trades       | 26500     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 320       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.3     |\n",
      "|    explained_variance | -0.0427   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | 0.908     |\n",
      "|    std                | 20.4      |\n",
      "|    value_loss         | 0.000238  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 322       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 0.701     |\n",
      "|    std                | 21.1      |\n",
      "|    value_loss         | 7.31e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.4    |\n",
      "|    explained_variance | 0.0386   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -6.75    |\n",
      "|    std                | 21.7     |\n",
      "|    value_loss         | 0.00668  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 326      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.182    |\n",
      "|    std                | 22.2     |\n",
      "|    value_loss         | 0.000116 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.655   |\n",
      "|    std                | 22.9     |\n",
      "|    value_loss         | 0.000304 |\n",
      "------------------------------------\n",
      "day: 2271, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -1853.43\n",
      "total_reward: -51853.43\n",
      "total_cost: 27801.40\n",
      "total_trades: 26594\n",
      "Sharpe: 0.213\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.85e+03 |\n",
      "|    total_cost         | 2.78e+04  |\n",
      "|    total_reward       | -5.19e+04 |\n",
      "|    total_reward_pct   | -104      |\n",
      "|    total_trades       | 26594     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 330       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 0.447     |\n",
      "|    std                | 23.4      |\n",
      "|    value_loss         | 9.68e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.307   |\n",
      "|    std                | 24.1     |\n",
      "|    value_loss         | 4.41e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 335       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -87.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 0.918     |\n",
      "|    std                | 24.6      |\n",
      "|    value_loss         | 0.000672  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.2    |\n",
      "|    explained_variance | 0.068    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 0.104    |\n",
      "|    std                | 25.2     |\n",
      "|    value_loss         | 3.14e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.34e+03  |\n",
      "|    total_cost         | 3.54e+04  |\n",
      "|    total_reward       | -4.17e+04 |\n",
      "|    total_reward_pct   | -83.3     |\n",
      "|    total_trades       | 27372     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 339       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -0.746    |\n",
      "|    std                | 25.8      |\n",
      "|    value_loss         | 0.000102  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.0792   |\n",
      "|    std                | 26.5     |\n",
      "|    value_loss         | 1.36e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.8    |\n",
      "|    explained_variance | -0.355   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 27.4     |\n",
      "|    value_loss         | 0.000501 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.00585 |\n",
      "|    std                | 28       |\n",
      "|    value_loss         | 5.78e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 0.102    |\n",
      "|    std                | 28.8     |\n",
      "|    value_loss         | 3.57e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.03e+03 |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | -4.6e+04 |\n",
      "|    total_reward_pct   | -91.9    |\n",
      "|    total_trades       | 26383    |\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.3    |\n",
      "|    explained_variance | 0.261    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -1.83    |\n",
      "|    std                | 29.7     |\n",
      "|    value_loss         | 0.00041  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.228   |\n",
      "|    std                | 30.6     |\n",
      "|    value_loss         | 1.18e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 353      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.7    |\n",
      "|    explained_variance | 0.192    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.514   |\n",
      "|    std                | 31.8     |\n",
      "|    value_loss         | 3.63e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.0156  |\n",
      "|    std                | 33.1     |\n",
      "|    value_loss         | 8.37e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 420       |\n",
      "|    total_cost         | 1.14e+04  |\n",
      "|    total_reward       | -4.96e+04 |\n",
      "|    total_reward_pct   | -99.2     |\n",
      "|    total_trades       | 25444     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 358       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -94.2     |\n",
      "|    explained_variance | -0.605    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 2.25      |\n",
      "|    std                | 34.6      |\n",
      "|    value_loss         | 0.000737  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.8    |\n",
      "|    explained_variance | 1.43e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -2.16    |\n",
      "|    std                | 35.6     |\n",
      "|    value_loss         | 0.000545 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 362      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.3    |\n",
      "|    explained_variance | -0.0104  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 0.389    |\n",
      "|    std                | 36.5     |\n",
      "|    value_loss         | 3.83e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 364      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.8    |\n",
      "|    explained_variance | 0.00208  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.777    |\n",
      "|    std                | 37.5     |\n",
      "|    value_loss         | 8.17e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 366      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -0.72    |\n",
      "|    std                | 38.6     |\n",
      "|    value_loss         | 0.000111 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.25e+03  |\n",
      "|    total_cost         | 2.66e+04  |\n",
      "|    total_reward       | -4.48e+04 |\n",
      "|    total_reward_pct   | -89.5     |\n",
      "|    total_trades       | 27287     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 368       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -96.9     |\n",
      "|    explained_variance | 0.0836    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | -1.17     |\n",
      "|    std                | 39.9      |\n",
      "|    value_loss         | 0.000154  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 370      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.125    |\n",
      "|    std                | 41.4     |\n",
      "|    value_loss         | 2.35e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 372       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -98.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -6.78     |\n",
      "|    std                | 42.8      |\n",
      "|    value_loss         | 0.00549   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -1.4     |\n",
      "|    std                | 44.1     |\n",
      "|    value_loss         | 0.00024  |\n",
      "------------------------------------\n",
      "day: 2271, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -5648.02\n",
      "total_reward: -55648.02\n",
      "total_cost: 24097.48\n",
      "total_trades: 26338\n",
      "Sharpe: -0.152\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -5.65e+03 |\n",
      "|    total_cost         | 2.41e+04  |\n",
      "|    total_reward       | -5.56e+04 |\n",
      "|    total_reward_pct   | -111      |\n",
      "|    total_trades       | 26338     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 376       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99.3     |\n",
      "|    explained_variance | 0.0664    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 3.62      |\n",
      "|    std                | 45.1      |\n",
      "|    value_loss         | 0.0017    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -0.058   |\n",
      "|    std                | 46       |\n",
      "|    value_loss         | 3.65e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 381       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -100      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -0.182    |\n",
      "|    std                | 47.2      |\n",
      "|    value_loss         | 9.18e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 383      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | -0.0137  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 0.736    |\n",
      "|    std                | 48.3     |\n",
      "|    value_loss         | 7.58e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 0.569    |\n",
      "|    std                | 49.6     |\n",
      "|    value_loss         | 4.29e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.48e+03  |\n",
      "|    total_cost         | 2.95e+04  |\n",
      "|    total_reward       | -4.55e+04 |\n",
      "|    total_reward_pct   | -91       |\n",
      "|    total_trades       | 27199     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 387       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | 0.517     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 4.7       |\n",
      "|    std                | 50.5      |\n",
      "|    value_loss         | 0.0022    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 389      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -1.11    |\n",
      "|    std                | 51.4     |\n",
      "|    value_loss         | 0.000156 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 52.7     |\n",
      "|    value_loss         | 0.000216 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 0.342    |\n",
      "|    std                | 54.1     |\n",
      "|    value_loss         | 1.87e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 779       |\n",
      "|    total_cost         | 2.64e+04  |\n",
      "|    total_reward       | -4.92e+04 |\n",
      "|    total_reward_pct   | -98.4     |\n",
      "|    total_trades       | 26836     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 395       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -103      |\n",
      "|    explained_variance | -3.76     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 0.859     |\n",
      "|    std                | 56        |\n",
      "|    value_loss         | 0.000347  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 397      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 0.0686   |\n",
      "|    std                | 58       |\n",
      "|    value_loss         | 2.49e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 399       |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | 1.67      |\n",
      "|    std                | 60.1      |\n",
      "|    value_loss         | 0.000359  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 2.93     |\n",
      "|    std                | 62       |\n",
      "|    value_loss         | 0.000901 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 404      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | -1.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 64.1     |\n",
      "|    value_loss         | 0.000194 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.4e+03   |\n",
      "|    total_cost         | 2.45e+04  |\n",
      "|    total_reward       | -4.76e+04 |\n",
      "|    total_reward_pct   | -95.2     |\n",
      "|    total_trades       | 26824     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 406       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -106      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | 1.2       |\n",
      "|    std                | 65.9      |\n",
      "|    value_loss         | 0.000321  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 408      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    std                | 67.1     |\n",
      "|    value_loss         | 0.000588 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 68.6     |\n",
      "|    value_loss         | 0.000253 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 412      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -0.722   |\n",
      "|    std                | 70.4     |\n",
      "|    value_loss         | 4.93e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.21e+03  |\n",
      "|    total_cost         | 2.7e+04   |\n",
      "|    total_reward       | -4.78e+04 |\n",
      "|    total_reward_pct   | -95.6     |\n",
      "|    total_trades       | 27378     |\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 414       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -108      |\n",
      "|    explained_variance | 0.273     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -1.37     |\n",
      "|    std                | 72.9      |\n",
      "|    value_loss         | 0.000188  |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2019-04-04 to  2019-07-05\n",
      "A2C Sharpe Ratio:  -0.22537294906104974\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 274  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.6e+04    |\n",
      "|    total_cost           | 8.11e+04   |\n",
      "|    total_reward         | -2.4e+04   |\n",
      "|    total_reward_pct     | -48        |\n",
      "|    total_trades         | 29878      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01826784 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | -0.26      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.275     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.0828     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.81e+03    |\n",
      "|    total_cost           | 1.57e+04    |\n",
      "|    total_reward         | -4.52e+04   |\n",
      "|    total_reward_pct     | -90.4       |\n",
      "|    total_trades         | 25793       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023612332 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.17e+04   |\n",
      "|    total_cost           | 2.68e+04   |\n",
      "|    total_reward         | -3.83e+04  |\n",
      "|    total_reward_pct     | -76.6      |\n",
      "|    total_trades         | 26888      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01696771 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.526      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.319     |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0271    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0161     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.84e+04    |\n",
      "|    total_cost           | 6.52e+04    |\n",
      "|    total_reward         | -3.16e+04   |\n",
      "|    total_reward_pct     | -63.3       |\n",
      "|    total_trades         | 29010       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026160626 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.218      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.024       |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8618.80\n",
      "total_reward: -41381.20\n",
      "total_cost: 29306.92\n",
      "total_trades: 27226\n",
      "Sharpe: -0.324\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.62e+03    |\n",
      "|    total_cost           | 2.93e+04    |\n",
      "|    total_reward         | -4.14e+04   |\n",
      "|    total_reward_pct     | -82.8       |\n",
      "|    total_trades         | 27226       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010612112 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0144      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.95e+03    |\n",
      "|    total_cost           | 1.76e+04    |\n",
      "|    total_reward         | -4.5e+04    |\n",
      "|    total_reward_pct     | -90.1       |\n",
      "|    total_trades         | 25816       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022613961 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00938     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.92e+04    |\n",
      "|    total_cost           | 5.12e+04    |\n",
      "|    total_reward         | -2.08e+04   |\n",
      "|    total_reward_pct     | -41.7       |\n",
      "|    total_trades         | 28825       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019792408 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00892     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -3.18e+03  |\n",
      "|    total_cost           | 1.35e+04   |\n",
      "|    total_reward         | -5.32e+04  |\n",
      "|    total_reward_pct     | -106       |\n",
      "|    total_trades         | 25085      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02427576 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.293     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0208     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -6.46e+03   |\n",
      "|    total_cost           | 1.51e+04    |\n",
      "|    total_reward         | -5.65e+04   |\n",
      "|    total_reward_pct     | -113        |\n",
      "|    total_trades         | 25652       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024034813 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00621     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022329915 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00577     |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1485.72\n",
      "total_reward: -48514.28\n",
      "total_cost: 17893.45\n",
      "total_trades: 25964\n",
      "Sharpe: -0.307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.49e+03    |\n",
      "|    total_cost           | 1.79e+04    |\n",
      "|    total_reward         | -4.85e+04   |\n",
      "|    total_reward_pct     | -97         |\n",
      "|    total_trades         | 25964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024697978 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | -0.646      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00325     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -4.47e+03   |\n",
      "|    total_cost           | 1.99e+04    |\n",
      "|    total_reward         | -5.45e+04   |\n",
      "|    total_reward_pct     | -109        |\n",
      "|    total_trades         | 26400       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017790664 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00486     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.85e+03    |\n",
      "|    total_cost           | 2.17e+04    |\n",
      "|    total_reward         | -4.41e+04   |\n",
      "|    total_reward_pct     | -88.3       |\n",
      "|    total_trades         | 26840       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020835666 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.322      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00572     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -3.37       |\n",
      "|    total_cost           | 1.64e+04    |\n",
      "|    total_reward         | -5e+04      |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 25864       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028588135 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0032      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.75e+03   |\n",
      "|    total_cost           | 1.42e+04   |\n",
      "|    total_reward         | -4.62e+04  |\n",
      "|    total_reward_pct     | -92.5      |\n",
      "|    total_trades         | 25821      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02391565 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.736      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.313     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.00338    |\n",
      "----------------------------------------\n",
      "day: 2271, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 7641.79\n",
      "total_reward: -42358.21\n",
      "total_cost: 15609.59\n",
      "total_trades: 26319\n",
      "Sharpe: -0.212\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.64e+03    |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -4.24e+04   |\n",
      "|    total_reward_pct     | -84.7       |\n",
      "|    total_trades         | 26319       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025208376 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00443     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.55e+04    |\n",
      "|    total_cost           | 2.83e+04    |\n",
      "|    total_reward         | -3.45e+04   |\n",
      "|    total_reward_pct     | -69         |\n",
      "|    total_trades         | 27975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024818458 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | -0.393      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00806     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.98e+04   |\n",
      "|    total_cost           | 4.75e+04   |\n",
      "|    total_reward         | -2.02e+04  |\n",
      "|    total_reward_pct     | -40.5      |\n",
      "|    total_trades         | 28849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03335566 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | -0.00955   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.303     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0245    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0113     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.1e+04    |\n",
      "|    total_cost           | 3.08e+04   |\n",
      "|    total_reward         | -2.9e+04   |\n",
      "|    total_reward_pct     | -58        |\n",
      "|    total_trades         | 27951      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02407716 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.248      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.295     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.015      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022249393 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.316      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+03    |\n",
      "|    total_cost           | 1.71e+04    |\n",
      "|    total_reward         | -4.82e+04   |\n",
      "|    total_reward_pct     | -96.5       |\n",
      "|    total_trades         | 26246       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026526798 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00274     |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 32658.09\n",
      "total_reward: -17341.91\n",
      "total_cost: 46581.01\n",
      "total_trades: 29079\n",
      "Sharpe: -0.059\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.27e+04    |\n",
      "|    total_cost           | 4.66e+04    |\n",
      "|    total_reward         | -1.73e+04   |\n",
      "|    total_reward_pct     | -34.7       |\n",
      "|    total_trades         | 29079       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023768384 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | -0.232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.41e+04    |\n",
      "|    total_cost           | 4.99e+04    |\n",
      "|    total_reward         | -1.59e+04   |\n",
      "|    total_reward_pct     | -31.8       |\n",
      "|    total_trades         | 29510       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029058546 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0204      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.32e+04   |\n",
      "|    total_cost           | 3.84e+04   |\n",
      "|    total_reward         | 3.22e+03   |\n",
      "|    total_reward_pct     | 6.45       |\n",
      "|    total_trades         | 28504      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 194        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02238458 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.287     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0209     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.26e+03    |\n",
      "|    total_cost           | 1.13e+04    |\n",
      "|    total_reward         | -4.57e+04   |\n",
      "|    total_reward_pct     | -91.5       |\n",
      "|    total_trades         | 25770       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034507155 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0138      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.46e+04    |\n",
      "|    total_cost           | 1.72e+04    |\n",
      "|    total_reward         | -2.54e+04   |\n",
      "|    total_reward_pct     | -50.8       |\n",
      "|    total_trades         | 26879       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023390237 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00543     |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 18555.15\n",
      "total_reward: -31444.85\n",
      "total_cost: 21498.78\n",
      "total_trades: 26960\n",
      "Sharpe: -0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+04    |\n",
      "|    total_cost           | 2.15e+04    |\n",
      "|    total_reward         | -3.14e+04   |\n",
      "|    total_reward_pct     | -62.9       |\n",
      "|    total_trades         | 26960       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031731274 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.324      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.08e+03   |\n",
      "|    total_cost           | 1.24e+04    |\n",
      "|    total_reward         | -5.11e+04   |\n",
      "|    total_reward_pct     | -102        |\n",
      "|    total_trades         | 25779       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030810654 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00668     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.73e+04    |\n",
      "|    total_cost           | 3.03e+04    |\n",
      "|    total_reward         | -2.72e+03   |\n",
      "|    total_reward_pct     | -5.44       |\n",
      "|    total_trades         | 27728       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030564023 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | -0.46       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00981     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 240        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02989886 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.295     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0239     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.55e+04   |\n",
      "|    total_cost           | 1.98e+04   |\n",
      "|    total_reward         | -1.45e+04  |\n",
      "|    total_reward_pct     | -29        |\n",
      "|    total_trades         | 26650      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 248        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03300662 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.282     |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00983   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0232     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+04    |\n",
      "|    total_cost           | 2.11e+04    |\n",
      "|    total_reward         | -3.14e+04   |\n",
      "|    total_reward_pct     | -62.8       |\n",
      "|    total_trades         | 26764       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018222634 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00773     |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3232.91\n",
      "total_reward: -46767.09\n",
      "total_cost: 11273.89\n",
      "total_trades: 25541\n",
      "Sharpe: -0.457\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.23e+03    |\n",
      "|    total_cost           | 1.13e+04    |\n",
      "|    total_reward         | -4.68e+04   |\n",
      "|    total_reward_pct     | -93.5       |\n",
      "|    total_trades         | 25541       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019699417 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00344     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.07e+04  |\n",
      "|    total_cost           | 2.52e+04  |\n",
      "|    total_reward         | -2.93e+04 |\n",
      "|    total_reward_pct     | -58.7     |\n",
      "|    total_trades         | 26955     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 263       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 271       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.038229  |\n",
      "|    clip_fraction        | 0.238     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.2     |\n",
      "|    explained_variance   | 0.341     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.275    |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.0193   |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 0.00593   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.8e+03     |\n",
      "|    total_cost           | 8.61e+03    |\n",
      "|    total_reward         | -4.82e+04   |\n",
      "|    total_reward_pct     | -96.4       |\n",
      "|    total_trades         | 24779       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024960801 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.322      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00387     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.12e+04    |\n",
      "|    total_cost           | 2.88e+04    |\n",
      "|    total_reward         | -8.77e+03   |\n",
      "|    total_reward_pct     | -17.5       |\n",
      "|    total_trades         | 27618       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027986217 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00584     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.5e+04     |\n",
      "|    total_cost           | 3.61e+04    |\n",
      "|    total_reward         | -4.96e+03   |\n",
      "|    total_reward_pct     | -9.92       |\n",
      "|    total_trades         | 28247       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023940235 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0312      |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 38239.15\n",
      "total_reward: -11760.85\n",
      "total_cost: 31989.42\n",
      "total_trades: 27985\n",
      "Sharpe: 0.026\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.82e+04   |\n",
      "|    total_cost           | 3.2e+04    |\n",
      "|    total_reward         | -1.18e+04  |\n",
      "|    total_reward_pct     | -23.5      |\n",
      "|    total_trades         | 27985      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03809055 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.314     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0212    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0259     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.59e+04    |\n",
      "|    total_cost           | 3.23e+04    |\n",
      "|    total_reward         | 1.59e+04    |\n",
      "|    total_reward_pct     | 31.7        |\n",
      "|    total_trades         | 28036       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025333669 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0209      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022071406 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0383      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.41e+04    |\n",
      "|    total_cost           | 1.94e+04    |\n",
      "|    total_reward         | -5.87e+03   |\n",
      "|    total_reward_pct     | -11.7       |\n",
      "|    total_trades         | 26773       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024879329 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0196      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.68e+04    |\n",
      "|    total_cost           | 3.15e+04    |\n",
      "|    total_reward         | 6.75e+03    |\n",
      "|    total_reward_pct     | 13.5        |\n",
      "|    total_trades         | 27777       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023446828 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0236      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+04    |\n",
      "|    total_cost           | 1.81e+04    |\n",
      "|    total_reward         | -3.11e+04   |\n",
      "|    total_reward_pct     | -62.3       |\n",
      "|    total_trades         | 26802       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029246511 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.01        |\n",
      "-----------------------------------------\n",
      "day: 2271, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 68772.03\n",
      "total_reward: 18772.03\n",
      "total_cost: 28657.83\n",
      "total_trades: 27464\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.88e+04    |\n",
      "|    total_cost           | 2.87e+04    |\n",
      "|    total_reward         | 1.88e+04    |\n",
      "|    total_reward_pct     | 37.5        |\n",
      "|    total_trades         | 27464       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032701336 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.323      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0213      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.71e+04    |\n",
      "|    total_cost           | 3.14e+04    |\n",
      "|    total_reward         | 2.71e+04    |\n",
      "|    total_reward_pct     | 54.1        |\n",
      "|    total_trades         | 27612       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024207413 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0334      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+04    |\n",
      "|    total_cost           | 1.7e+04     |\n",
      "|    total_reward         | -2.73e+04   |\n",
      "|    total_reward_pct     | -54.5       |\n",
      "|    total_trades         | 26041       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019548982 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.316      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0351      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.83e+04   |\n",
      "|    total_cost           | 2.77e+04   |\n",
      "|    total_reward         | -1.71e+03  |\n",
      "|    total_reward_pct     | -3.42      |\n",
      "|    total_trades         | 27202      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 372        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04724799 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.6      |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.306     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.0167     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.04e+04    |\n",
      "|    total_cost           | 1.49e+04    |\n",
      "|    total_reward         | -2.96e+04   |\n",
      "|    total_reward_pct     | -59.2       |\n",
      "|    total_trades         | 26023       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030333653 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0266      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-04-04 to  2019-07-05\n",
      "PPO Sharpe Ratio:  0.2490323903458084\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.77e+04  |\n",
      "|    total_cost       | 196       |\n",
      "|    total_reward     | -3.23e+04 |\n",
      "|    total_reward_pct | -64.7     |\n",
      "|    total_trades     | 15577     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 122       |\n",
      "|    time_elapsed     | 74        |\n",
      "|    total timesteps  | 9088      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.789     |\n",
      "|    critic_loss      | 6.62      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6816      |\n",
      "-----------------------------------\n",
      "day: 2271, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 26277.13\n",
      "total_reward: -23722.87\n",
      "total_cost: 214.96\n",
      "total_trades: 15499\n",
      "Sharpe: 0.180\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.38e+04  |\n",
      "|    total_cost       | 191       |\n",
      "|    total_reward     | -2.62e+04 |\n",
      "|    total_reward_pct | -52.4     |\n",
      "|    total_trades     | 16093     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 110       |\n",
      "|    time_elapsed     | 163       |\n",
      "|    total timesteps  | 18176     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 0.119     |\n",
      "|    critic_loss      | 1.32      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 15904     |\n",
      "-----------------------------------\n",
      "day: 2271, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 23153.19\n",
      "total_reward: -26846.81\n",
      "total_cost: 261.68\n",
      "total_trades: 15184\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.22e+04  |\n",
      "|    total_cost       | 255       |\n",
      "|    total_reward     | -2.78e+04 |\n",
      "|    total_reward_pct | -55.7     |\n",
      "|    total_trades     | 15069     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 107       |\n",
      "|    time_elapsed     | 253       |\n",
      "|    total timesteps  | 27264     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -0.14     |\n",
      "|    critic_loss      | 0.926     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 24992     |\n",
      "-----------------------------------\n",
      "day: 2271, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17861.87\n",
      "total_reward: -32138.13\n",
      "total_cost: 251.91\n",
      "total_trades: 15146\n",
      "Sharpe: 0.106\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3e+04    |\n",
      "|    total_cost       | 287      |\n",
      "|    total_reward     | -2e+04   |\n",
      "|    total_reward_pct | -40.1    |\n",
      "|    total_trades     | 14922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total timesteps  | 36352    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -0.277   |\n",
      "|    critic_loss      | 0.836    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34080    |\n",
      "----------------------------------\n",
      "day: 2271, episode: 110\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24862.48\n",
      "total_reward: -25137.52\n",
      "total_cost: 280.36\n",
      "total_trades: 14384\n",
      "Sharpe: 0.251\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.49e+04  |\n",
      "|    total_cost       | 280       |\n",
      "|    total_reward     | -2.51e+04 |\n",
      "|    total_reward_pct | -50.3     |\n",
      "|    total_trades     | 14384     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 105       |\n",
      "|    time_elapsed     | 432       |\n",
      "|    total timesteps  | 45440     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -0.47     |\n",
      "|    critic_loss      | 0.54      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 43168     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-04-04 to  2019-07-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_189_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.69e+04 |\n",
      "|    total_cost       | 221      |\n",
      "|    total_reward     | 6.93e+03 |\n",
      "|    total_reward_pct | 13.9     |\n",
      "|    total_trades     | 23150    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total timesteps  | 9340     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -73.8    |\n",
      "|    critic_loss      | 164      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7005     |\n",
      "----------------------------------\n",
      "day: 2334, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 39308.70\n",
      "total_reward: -10691.30\n",
      "total_cost: 123.83\n",
      "total_trades: 24241\n",
      "Sharpe: 0.510\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.88e+04 |\n",
      "|    total_cost       | 275      |\n",
      "|    total_reward     | 8.82e+03 |\n",
      "|    total_reward_pct | 17.6     |\n",
      "|    total_trades     | 24605    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total timesteps  | 18680    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -39.2    |\n",
      "|    critic_loss      | 14.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16345    |\n",
      "----------------------------------\n",
      "day: 2334, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 52299.58\n",
      "total_reward: 2299.58\n",
      "total_cost: 186.39\n",
      "total_trades: 25632\n",
      "Sharpe: 0.515\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.08e+04 |\n",
      "|    total_cost       | 98.1     |\n",
      "|    total_reward     | 812      |\n",
      "|    total_reward_pct | 1.62     |\n",
      "|    total_trades     | 26088    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total timesteps  | 28020    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -24.1    |\n",
      "|    critic_loss      | 5.44     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25685    |\n",
      "----------------------------------\n",
      "day: 2334, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 53903.86\n",
      "total_reward: 3903.86\n",
      "total_cost: 145.80\n",
      "total_trades: 26218\n",
      "Sharpe: 0.495\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.94e+04 |\n",
      "|    total_cost       | 96.8     |\n",
      "|    total_reward     | -609     |\n",
      "|    total_reward_pct | -1.22    |\n",
      "|    total_trades     | 26556    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 102      |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total timesteps  | 37360    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -15.5    |\n",
      "|    critic_loss      | 2.29     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35025    |\n",
      "----------------------------------\n",
      "day: 2334, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 51613.75\n",
      "total_reward: 1613.75\n",
      "total_cost: 137.72\n",
      "total_trades: 25785\n",
      "Sharpe: 0.511\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.16e+04 |\n",
      "|    total_cost       | 138      |\n",
      "|    total_reward     | 1.61e+03 |\n",
      "|    total_reward_pct | 3.23     |\n",
      "|    total_trades     | 25785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 458      |\n",
      "|    total timesteps  | 46700    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -10.1    |\n",
      "|    critic_loss      | 1.15     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44365    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-07-05 to  2019-10-02\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2010-01-01 to  2019-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -5.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.67     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.023    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -2.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0475  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.00491  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -1.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 4.36     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0271   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -5.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -4.54    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0409   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5e+04    |\n",
      "|    total_cost         | 6.46e+04 |\n",
      "|    total_reward       | 11       |\n",
      "|    total_reward_pct   | 0.0219   |\n",
      "|    total_trades       | 26667    |\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -39.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0114   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -50.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.625    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00927  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.665   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.538   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00246  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -8.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00722  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 2.91e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -2.63    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00915  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.5e+04  |\n",
      "|    total_cost         | 8.94e+03 |\n",
      "|    total_reward       | -3.5e+04 |\n",
      "|    total_reward_pct   | -70      |\n",
      "|    total_trades       | 22185    |\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.216   |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.000282 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.865    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00101  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -1.82    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.0645   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.000889 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.297   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00668  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -2.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.941    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00377  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.48e+04  |\n",
      "|    total_cost         | 3.36e+03  |\n",
      "|    total_reward       | -5.17e+03 |\n",
      "|    total_reward_pct   | -10.3     |\n",
      "|    total_trades       | 19298     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 1.81      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.00505   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | 0.354    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.976   |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | -0.614   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -1.48    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00381  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | -0.425   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.401   |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.5e+04  |\n",
      "|    total_cost         | 3.15e+03 |\n",
      "|    total_reward       | 3.5e+04  |\n",
      "|    total_reward_pct   | 69.9     |\n",
      "|    total_trades       | 17700    |\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -43.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.52    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.00114  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -315     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0853  |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.000782 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0166  |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 6.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | -0.851   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.856    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.00184  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | 0.187    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -2.96    |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.02     |\n",
      "------------------------------------\n",
      "day: 2334, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 73453.17\n",
      "total_reward: 23453.17\n",
      "total_cost: 4701.07\n",
      "total_trades: 17578\n",
      "Sharpe: 0.394\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.35e+04 |\n",
      "|    total_cost         | 4.7e+03  |\n",
      "|    total_reward       | 2.35e+04 |\n",
      "|    total_reward_pct   | 46.9     |\n",
      "|    total_trades       | 17578    |\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -0.585   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -1.45    |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.00405  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.94     |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.00923  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | 0.689    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.471    |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.000249 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | 0.46     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.00216  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -1.24    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0022   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.23e+04 |\n",
      "|    total_cost         | 4.82e+03 |\n",
      "|    total_reward       | 2.31e+03 |\n",
      "|    total_reward_pct   | 4.62     |\n",
      "|    total_trades       | 18454    |\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | 0.559    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.0968   |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.000171 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | -7.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.084   |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.000455 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | -4.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 1.35     |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.00221  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | -0.734   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -2.24    |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.00694  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.77e+04  |\n",
      "|    total_cost         | 3.75e+03  |\n",
      "|    total_reward       | -2.23e+04 |\n",
      "|    total_reward_pct   | -44.5     |\n",
      "|    total_trades       | 18917     |\n",
      "| time/                 |           |\n",
      "|    fps                | 238       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35       |\n",
      "|    explained_variance | -0.0862   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 0.565     |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 0.000574  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | -5.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.316    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.00105  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | -2.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.343   |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 238       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 0.643     |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 0.00126   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | 0.585    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 3.18     |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0103   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.71e+04  |\n",
      "|    total_cost         | 2.24e+03  |\n",
      "|    total_reward       | -2.94e+03 |\n",
      "|    total_reward_pct   | -5.88     |\n",
      "|    total_trades       | 17939     |\n",
      "| time/                 |           |\n",
      "|    fps                | 238       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.5     |\n",
      "|    explained_variance | -1.06     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 0.233     |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 0.000602  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.851   |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.000639 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.466    |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.000407 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.97     |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.000575 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.9    |\n",
      "|    explained_variance | -0.405   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 3.41     |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.0365   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.06e+04  |\n",
      "|    total_cost         | 1.63e+03  |\n",
      "|    total_reward       | -9.44e+03 |\n",
      "|    total_reward_pct   | -18.9     |\n",
      "|    total_trades       | 16332     |\n",
      "| time/                 |           |\n",
      "|    fps                | 238       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 5.32      |\n",
      "|    std                | 1.81      |\n",
      "|    value_loss         | 0.0328    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 1.79     |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.00249  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | -0.0466  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.0538  |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 0.000342 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | -4.3     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.643    |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.00096  |\n",
      "------------------------------------\n",
      "day: 2334, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 35613.45\n",
      "total_reward: -14386.55\n",
      "total_cost: 2896.03\n",
      "total_trades: 18207\n",
      "Sharpe: 0.161\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.56e+04  |\n",
      "|    total_cost         | 2.9e+03   |\n",
      "|    total_reward       | -1.44e+04 |\n",
      "|    total_reward_pct   | -28.8     |\n",
      "|    total_trades       | 18207     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.6     |\n",
      "|    explained_variance | 0.237     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -0.669    |\n",
      "|    std                | 1.94      |\n",
      "|    value_loss         | 0.000374  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | -1.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.712    |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.000695 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | -16.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.951    |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.00227  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | -7.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.294    |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.000343 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.332    |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 0.000188 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.39e+04  |\n",
      "|    total_cost         | 2.73e+03  |\n",
      "|    total_reward       | -2.61e+04 |\n",
      "|    total_reward_pct   | -52.2     |\n",
      "|    total_trades       | 19023     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -1.11     |\n",
      "|    std                | 2.15      |\n",
      "|    value_loss         | 0.000917  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.553   |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.000258 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.683    |\n",
      "|    std                | 2.24     |\n",
      "|    value_loss         | 0.000347 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.251    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.512   |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 0.000291 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | -37.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    std                | 2.35     |\n",
      "|    value_loss         | 0.0133   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.24e+04  |\n",
      "|    total_cost         | 2.68e+03  |\n",
      "|    total_reward       | -2.76e+04 |\n",
      "|    total_reward_pct   | -55.3     |\n",
      "|    total_trades       | 18310     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 0.00823   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -1.11     |\n",
      "|    std                | 2.38      |\n",
      "|    value_loss         | 0.0135    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -28.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -1.59    |\n",
      "|    std                | 2.42     |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -0.163   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 2.47     |\n",
      "|    value_loss         | 0.00162  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -4.4     |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 0.0112   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.3e+04  |\n",
      "|    total_cost         | 7.97e+03 |\n",
      "|    total_reward       | -2.7e+04 |\n",
      "|    total_reward_pct   | -54.1    |\n",
      "|    total_trades       | 20173    |\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -1.97    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.844    |\n",
      "|    std                | 2.55     |\n",
      "|    value_loss         | 0.000372 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | -2.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -1.27    |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 0.00094  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.695   |\n",
      "|    std                | 2.66     |\n",
      "|    value_loss         | 0.000263 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0.589    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -0.43    |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 9.49e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | -12.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.00179  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.18e+03  |\n",
      "|    total_cost         | 1.06e+04  |\n",
      "|    total_reward       | -4.78e+04 |\n",
      "|    total_reward_pct   | -95.6     |\n",
      "|    total_trades       | 22487     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | -0.246    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 2.25      |\n",
      "|    std                | 2.88      |\n",
      "|    value_loss         | 0.00281   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.857   |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.000529 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0.0645   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -1.86    |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.00224  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.1    |\n",
      "|    explained_variance | -0.0249  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -4.68    |\n",
      "|    std                | 3.05     |\n",
      "|    value_loss         | 0.00948  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.4     |\n",
      "|    explained_variance | -4.77e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -1        |\n",
      "|    std                | 3.09      |\n",
      "|    value_loss         | 0.000558  |\n",
      "-------------------------------------\n",
      "day: 2334, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 23766.96\n",
      "total_reward: -26233.04\n",
      "total_cost: 13517.08\n",
      "total_trades: 22585\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.38e+04  |\n",
      "|    total_cost         | 1.35e+04  |\n",
      "|    total_reward       | -2.62e+04 |\n",
      "|    total_reward_pct   | -52.5     |\n",
      "|    total_trades       | 22585     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 0.718     |\n",
      "|    std                | 3.14      |\n",
      "|    value_loss         | 0.000403  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 3.21     |\n",
      "|    value_loss         | 0.00328  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.958   |\n",
      "|    std                | 3.28     |\n",
      "|    value_loss         | 0.00166  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 0.0784   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 3.32     |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.19e+04  |\n",
      "|    total_cost         | 8.83e+03  |\n",
      "|    total_reward       | -2.81e+04 |\n",
      "|    total_reward_pct   | -56.3     |\n",
      "|    total_trades       | 21972     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50       |\n",
      "|    explained_variance | -3.74     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -0.194    |\n",
      "|    std                | 3.37      |\n",
      "|    value_loss         | 0.000213  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | -0.124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.176   |\n",
      "|    std                | 3.43     |\n",
      "|    value_loss         | 0.000221 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | -92.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 3.52     |\n",
      "|    value_loss         | 0.00678  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 1.53     |\n",
      "|    std                | 3.59     |\n",
      "|    value_loss         | 0.00305  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | -3.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 3.63     |\n",
      "|    value_loss         | 0.00272  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.39e+04  |\n",
      "|    total_cost         | 1.33e+04  |\n",
      "|    total_reward       | -3.61e+04 |\n",
      "|    total_reward_pct   | -72.3     |\n",
      "|    total_trades       | 23447     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.7     |\n",
      "|    explained_variance | -0.078    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -4.19     |\n",
      "|    std                | 3.68      |\n",
      "|    value_loss         | 0.00714   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 2.75     |\n",
      "|    std                | 3.73     |\n",
      "|    value_loss         | 0.00335  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.56     |\n",
      "|    std                | 3.8      |\n",
      "|    value_loss         | 0.000964 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | -0.591   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -2.91    |\n",
      "|    std                | 3.86     |\n",
      "|    value_loss         | 0.00328  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | -2.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.808    |\n",
      "|    std                | 3.93     |\n",
      "|    value_loss         | 0.000588 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.28e+04  |\n",
      "|    total_cost         | 2.2e+04   |\n",
      "|    total_reward       | -2.72e+04 |\n",
      "|    total_reward_pct   | -54.4     |\n",
      "|    total_trades       | 25828     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 0.708     |\n",
      "|    std                | 4.02      |\n",
      "|    value_loss         | 0.000527  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | -0.403   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.355   |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 8.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | -0.347   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 4.23     |\n",
      "|    value_loss         | 0.00109  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.465    |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 0.00018  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.64e+03  |\n",
      "|    total_cost         | 1.72e+04  |\n",
      "|    total_reward       | -4.44e+04 |\n",
      "|    total_reward_pct   | -88.7     |\n",
      "|    total_trades       | 25886     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.4     |\n",
      "|    explained_variance | -0.667    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 0.217     |\n",
      "|    std                | 4.48      |\n",
      "|    value_loss         | 0.000233  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | -0.38    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.342    |\n",
      "|    std                | 4.59     |\n",
      "|    value_loss         | 8.23e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -0.304    |\n",
      "|    std                | 4.71      |\n",
      "|    value_loss         | 0.000111  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | -0.0373  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -2.97    |\n",
      "|    std                | 4.85     |\n",
      "|    value_loss         | 0.00337  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.4    |\n",
      "|    explained_variance | 0.139    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.548   |\n",
      "|    std                | 4.98     |\n",
      "|    value_loss         | 0.000179 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4826.65\n",
      "total_reward: -45173.35\n",
      "total_cost: 20855.09\n",
      "total_trades: 26624\n",
      "Sharpe: -0.324\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.83e+03  |\n",
      "|    total_cost         | 2.09e+04  |\n",
      "|    total_reward       | -4.52e+04 |\n",
      "|    total_reward_pct   | -90.3     |\n",
      "|    total_trades       | 26624     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58       |\n",
      "|    explained_variance | 0.168     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -0.978    |\n",
      "|    std                | 5.12      |\n",
      "|    value_loss         | 0.000449  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -0.174    |\n",
      "|    std                | 5.26      |\n",
      "|    value_loss         | 1.59e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.178   |\n",
      "|    std                | 5.42     |\n",
      "|    value_loss         | 1.23e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.6    |\n",
      "|    explained_variance | -0.0293  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.653   |\n",
      "|    std                | 5.59     |\n",
      "|    value_loss         | 0.000128 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.3    |\n",
      "|    explained_variance | 0.0726   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.123   |\n",
      "|    std                | 5.78     |\n",
      "|    value_loss         | 8.26e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.31e+03  |\n",
      "|    total_cost         | 1.84e+04  |\n",
      "|    total_reward       | -4.67e+04 |\n",
      "|    total_reward_pct   | -93.4     |\n",
      "|    total_trades       | 26833     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 0.271     |\n",
      "|    std                | 6         |\n",
      "|    value_loss         | 6.13e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.7    |\n",
      "|    explained_variance | -1.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.504   |\n",
      "|    std                | 6.22     |\n",
      "|    value_loss         | 0.000305 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.1    |\n",
      "|    explained_variance | 0.0189   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -3.25    |\n",
      "|    std                | 6.38     |\n",
      "|    value_loss         | 0.00517  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.4    |\n",
      "|    explained_variance | -0.565   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 7.94     |\n",
      "|    std                | 6.45     |\n",
      "|    value_loss         | 0.0191   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.18e+04  |\n",
      "|    total_cost         | 3.94e+04  |\n",
      "|    total_reward       | -1.82e+04 |\n",
      "|    total_reward_pct   | -36.3     |\n",
      "|    total_trades       | 27883     |\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.6     |\n",
      "|    explained_variance | -0.632    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 0.83      |\n",
      "|    std                | 6.55      |\n",
      "|    value_loss         | 0.000395  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63      |\n",
      "|    explained_variance | -1.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -0.555   |\n",
      "|    std                | 6.67     |\n",
      "|    value_loss         | 0.000109 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.775    |\n",
      "|    std                | 6.82     |\n",
      "|    value_loss         | 0.000359 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 0.594    |\n",
      "|    std                | 7.01     |\n",
      "|    value_loss         | 0.000183 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.4    |\n",
      "|    explained_variance | 0.148    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.471    |\n",
      "|    std                | 7.2      |\n",
      "|    value_loss         | 8.22e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.24e+03 |\n",
      "|    total_cost         | 2.42e+04  |\n",
      "|    total_reward       | -5.42e+04 |\n",
      "|    total_reward_pct   | -108      |\n",
      "|    total_trades       | 27403     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.9     |\n",
      "|    explained_variance | 0.211     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | -0.201    |\n",
      "|    std                | 7.39      |\n",
      "|    value_loss         | 0.000137  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.222    |\n",
      "|    std                | 7.64     |\n",
      "|    value_loss         | 1.51e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.2    |\n",
      "|    explained_variance | 0.432    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 0.386    |\n",
      "|    std                | 7.91     |\n",
      "|    value_loss         | 3.39e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    std                | 8.17     |\n",
      "|    value_loss         | 0.000581 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.395    |\n",
      "|    std                | 8.46     |\n",
      "|    value_loss         | 6.07e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.36e+03  |\n",
      "|    total_cost         | 1.86e+04  |\n",
      "|    total_reward       | -4.56e+04 |\n",
      "|    total_reward_pct   | -91.3     |\n",
      "|    total_trades       | 26547     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 0.551     |\n",
      "|    std                | 8.73      |\n",
      "|    value_loss         | 7.04e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.341   |\n",
      "|    std                | 9.04     |\n",
      "|    value_loss         | 3.28e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.0962   |\n",
      "|    std                | 9.31     |\n",
      "|    value_loss         | 1.87e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.9    |\n",
      "|    explained_variance | -0.11    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.453   |\n",
      "|    std                | 9.59     |\n",
      "|    value_loss         | 9.28e-05 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -4801.51\n",
      "total_reward: -54801.51\n",
      "total_cost: 24202.80\n",
      "total_trades: 26755\n",
      "Sharpe: 0.383\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.8e+03  |\n",
      "|    total_cost         | 2.42e+04  |\n",
      "|    total_reward       | -5.48e+04 |\n",
      "|    total_reward_pct   | -110      |\n",
      "|    total_trades       | 26755     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | -0.737    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -2.55     |\n",
      "|    std                | 9.84      |\n",
      "|    value_loss         | 0.00143   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.8    |\n",
      "|    explained_variance | 0.236    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.269   |\n",
      "|    std                | 10.1     |\n",
      "|    value_loss         | 7.95e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -1.41    |\n",
      "|    std                | 10.3     |\n",
      "|    value_loss         | 0.000507 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -0.647   |\n",
      "|    std                | 10.5     |\n",
      "|    value_loss         | 9.51e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 0.177    |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 6.82e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.37e+03  |\n",
      "|    total_cost         | 1.94e+04  |\n",
      "|    total_reward       | -4.86e+04 |\n",
      "|    total_reward_pct   | -97.3     |\n",
      "|    total_trades       | 26774     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 257       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | -0.121    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -0.0386   |\n",
      "|    std                | 11.3      |\n",
      "|    value_loss         | 1.51e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.0816   |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 1.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    std                | 12.1     |\n",
      "|    value_loss         | 0.000346 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.7    |\n",
      "|    explained_variance | 0.0411   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 2.41     |\n",
      "|    std                | 12.4     |\n",
      "|    value_loss         | 0.00116  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.34    |\n",
      "|    std                | 12.6     |\n",
      "|    value_loss         | 4.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.96e+03 |\n",
      "|    total_cost         | 3.69e+04 |\n",
      "|    total_reward       | -4.1e+04 |\n",
      "|    total_reward_pct   | -82.1    |\n",
      "|    total_trades       | 27181    |\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -0.0949  |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 8.79e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 0.273     |\n",
      "|    std                | 13.4      |\n",
      "|    value_loss         | 1.78e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 1.34     |\n",
      "|    std                | 13.8     |\n",
      "|    value_loss         | 0.000324 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.3    |\n",
      "|    explained_variance | -1.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    std                | 14.2     |\n",
      "|    value_loss         | 0.000383 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.77e+03  |\n",
      "|    total_cost         | 2.45e+04  |\n",
      "|    total_reward       | -4.72e+04 |\n",
      "|    total_reward_pct   | -94.5     |\n",
      "|    total_trades       | 26882     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 276       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.9     |\n",
      "|    explained_variance | -0.13     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 0.541     |\n",
      "|    std                | 14.7      |\n",
      "|    value_loss         | 7.95e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.6    |\n",
      "|    explained_variance | -0.278   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 0.152    |\n",
      "|    std                | 15.2     |\n",
      "|    value_loss         | 1.06e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.979    |\n",
      "|    std                | 15.8     |\n",
      "|    value_loss         | 0.000342 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.189   |\n",
      "|    std                | 16.3     |\n",
      "|    value_loss         | 1.5e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -0.223   |\n",
      "|    std                | 16.9     |\n",
      "|    value_loss         | 1.33e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.54e+03  |\n",
      "|    total_cost         | 1.76e+04  |\n",
      "|    total_reward       | -4.75e+04 |\n",
      "|    total_reward_pct   | -94.9     |\n",
      "|    total_trades       | 26284     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 287       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 0.308     |\n",
      "|    std                | 17.5      |\n",
      "|    value_loss         | 3.08e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.0454  |\n",
      "|    std                | 18.2     |\n",
      "|    value_loss         | 3.4e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.8    |\n",
      "|    explained_variance | -0.462   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -1.27    |\n",
      "|    std                | 18.9     |\n",
      "|    value_loss         | 0.000283 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -1.62    |\n",
      "|    std                | 19.4     |\n",
      "|    value_loss         | 0.000437 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.6    |\n",
      "|    explained_variance | -0.0366  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 0.214    |\n",
      "|    std                | 19.7     |\n",
      "|    value_loss         | 0.000184 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 12723.90\n",
      "total_reward: -37276.10\n",
      "total_cost: 31646.01\n",
      "total_trades: 26898\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.27e+04  |\n",
      "|    total_cost         | 3.16e+04  |\n",
      "|    total_reward       | -3.73e+04 |\n",
      "|    total_reward_pct   | -74.6     |\n",
      "|    total_trades       | 26898     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 298       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -2.52     |\n",
      "|    std                | 20.2      |\n",
      "|    value_loss         | 0.00107   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.74     |\n",
      "|    std                | 20.8     |\n",
      "|    value_loss         | 9.64e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0.69    |\n",
      "|    std                | 21.5     |\n",
      "|    value_loss         | 0.000278 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 0.0518   |\n",
      "|    std                | 22       |\n",
      "|    value_loss         | 5.11e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+03  |\n",
      "|    total_cost         | 2.94e+04  |\n",
      "|    total_reward       | -4.66e+04 |\n",
      "|    total_reward_pct   | -93.2     |\n",
      "|    total_trades       | 27395     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 306       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86.2     |\n",
      "|    explained_variance | -26.4     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -0.316    |\n",
      "|    std                | 22.6      |\n",
      "|    value_loss         | 5.45e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.7    |\n",
      "|    explained_variance | -1.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.0692   |\n",
      "|    std                | 23.3     |\n",
      "|    value_loss         | 5.07e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.4    |\n",
      "|    explained_variance | -0.0683  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    std                | 24.1     |\n",
      "|    value_loss         | 0.000239 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -1.1     |\n",
      "|    std                | 24.9     |\n",
      "|    value_loss         | 0.000171 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.7    |\n",
      "|    explained_variance | -0.16    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 0.00297  |\n",
      "|    std                | 25.8     |\n",
      "|    value_loss         | 2.98e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.52e+03  |\n",
      "|    total_cost         | 1.48e+04  |\n",
      "|    total_reward       | -4.85e+04 |\n",
      "|    total_reward_pct   | -97       |\n",
      "|    total_trades       | 26219     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 317       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -89.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -1.79     |\n",
      "|    std                | 26.7      |\n",
      "|    value_loss         | 0.000541  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    std                | 27.5     |\n",
      "|    value_loss         | 0.000148 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.4    |\n",
      "|    explained_variance | -0.278   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.019   |\n",
      "|    std                | 28.3     |\n",
      "|    value_loss         | 0.000276 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -90.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -2.49     |\n",
      "|    std                | 29        |\n",
      "|    value_loss         | 0.00111   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 326      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.4    |\n",
      "|    explained_variance | -3.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.161   |\n",
      "|    std                | 29.9     |\n",
      "|    value_loss         | 0.000111 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.32e+03  |\n",
      "|    total_cost         | 3.14e+04  |\n",
      "|    total_reward       | -4.37e+04 |\n",
      "|    total_reward_pct   | -87.4     |\n",
      "|    total_trades       | 27717     |\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 328       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -4.92     |\n",
      "|    std                | 30.5      |\n",
      "|    value_loss         | 0.00331   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 330       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -92.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | -0.179    |\n",
      "|    std                | 30.9      |\n",
      "|    value_loss         | 0.000253  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.5    |\n",
      "|    explained_variance | -0.00111 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    std                | 31.5     |\n",
      "|    value_loss         | 0.000276 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 2.56     |\n",
      "|    std                | 32.3     |\n",
      "|    value_loss         | 0.00109  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.9e+03   |\n",
      "|    total_cost         | 3.73e+04  |\n",
      "|    total_reward       | -4.71e+04 |\n",
      "|    total_reward_pct   | -94.2     |\n",
      "|    total_trades       | 28636     |\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 337       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93.5     |\n",
      "|    explained_variance | -3.51     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | -0.262    |\n",
      "|    std                | 33.2      |\n",
      "|    value_loss         | 2.59e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.1    |\n",
      "|    explained_variance | 0.346    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 0.685    |\n",
      "|    std                | 34.3     |\n",
      "|    value_loss         | 6.15e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    std                | 35.5     |\n",
      "|    value_loss         | 0.000507 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -0.344   |\n",
      "|    std                | 36.6     |\n",
      "|    value_loss         | 1.49e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.194   |\n",
      "|    std                | 37.9     |\n",
      "|    value_loss         | 7.64e-06 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3119.94\n",
      "total_reward: -46880.06\n",
      "total_cost: 19704.70\n",
      "total_trades: 26777\n",
      "Sharpe: 0.282\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.12e+03  |\n",
      "|    total_cost         | 1.97e+04  |\n",
      "|    total_reward       | -4.69e+04 |\n",
      "|    total_reward_pct   | -93.8     |\n",
      "|    total_trades       | 26777     |\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 347       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -96.7     |\n",
      "|    explained_variance | 0.776     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -0.161    |\n",
      "|    std                | 39.4      |\n",
      "|    value_loss         | 3.61e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.179    |\n",
      "|    std                | 40.9     |\n",
      "|    value_loss         | 9.07e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 42.3     |\n",
      "|    value_loss         | 0.000332 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.445    |\n",
      "|    std                | 43.2     |\n",
      "|    value_loss         | 2.79e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99      |\n",
      "|    explained_variance | -40.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 0.879    |\n",
      "|    std                | 44.4     |\n",
      "|    value_loss         | 0.000206 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.69e+03  |\n",
      "|    total_cost         | 2.98e+04  |\n",
      "|    total_reward       | -4.73e+04 |\n",
      "|    total_reward_pct   | -94.6     |\n",
      "|    total_trades       | 27246     |\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 358       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99.4     |\n",
      "|    explained_variance | -0.0537   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 6.66      |\n",
      "|    std                | 45.4      |\n",
      "|    value_loss         | 0.00538   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.529    |\n",
      "|    std                | 46.3     |\n",
      "|    value_loss         | 0.000112 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    std                | 47.5     |\n",
      "|    value_loss         | 0.000458 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 0.0163   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 0.517    |\n",
      "|    std                | 48.9     |\n",
      "|    value_loss         | 0.000105 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.3e+03   |\n",
      "|    total_cost         | 2.77e+04  |\n",
      "|    total_reward       | -4.87e+04 |\n",
      "|    total_reward_pct   | -97.4     |\n",
      "|    total_trades       | 27746     |\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 367       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | -2.23     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 1.8       |\n",
      "|    std                | 50.6      |\n",
      "|    value_loss         | 0.000402  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 0.0896   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.278    |\n",
      "|    std                | 52.5     |\n",
      "|    value_loss         | 1.45e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 371       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -103      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | -1.52     |\n",
      "|    std                | 54.7      |\n",
      "|    value_loss         | 0.000639  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.405    |\n",
      "|    std                | 56.2     |\n",
      "|    value_loss         | 2.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 375      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    std                | 57.8     |\n",
      "|    value_loss         | 0.000522 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.94e+03 |\n",
      "|    total_cost         | 2.26e+04  |\n",
      "|    total_reward       | -5.89e+04 |\n",
      "|    total_reward_pct   | -118      |\n",
      "|    total_trades       | 26962     |\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 377       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | -0.0939   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 0.293     |\n",
      "|    std                | 59.4      |\n",
      "|    value_loss         | 0.000109  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 380       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 0.00742   |\n",
      "|    std                | 61        |\n",
      "|    value_loss         | 6.41e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -106      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | 1.07      |\n",
      "|    std                | 63        |\n",
      "|    value_loss         | 0.000131  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 384      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -0.0596  |\n",
      "|    std                | 65.4     |\n",
      "|    value_loss         | 4.61e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 386      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 0.295    |\n",
      "|    std                | 68.2     |\n",
      "|    value_loss         | 1.95e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -6.63e+03 |\n",
      "|    total_cost         | 1.46e+04  |\n",
      "|    total_reward       | -5.66e+04 |\n",
      "|    total_reward_pct   | -113      |\n",
      "|    total_trades       | 26446     |\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 389       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -108      |\n",
      "|    explained_variance | 0.0725    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 7.06      |\n",
      "|    std                | 69.7      |\n",
      "|    value_loss         | 0.00579   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | -1.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.392   |\n",
      "|    std                | 71.4     |\n",
      "|    value_loss         | 0.000198 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.406   |\n",
      "|    std                | 73.7     |\n",
      "|    value_loss         | 2.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 396      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | -15.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 0.247    |\n",
      "|    std                | 76.5     |\n",
      "|    value_loss         | 8.79e-06 |\n",
      "------------------------------------\n",
      "day: 2334, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 389.14\n",
      "total_reward: -49610.86\n",
      "total_cost: 16994.06\n",
      "total_trades: 26721\n",
      "Sharpe: -1.327\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 389       |\n",
      "|    total_cost         | 1.7e+04   |\n",
      "|    total_reward       | -4.96e+04 |\n",
      "|    total_reward_pct   | -99.2     |\n",
      "|    total_trades       | 26721     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 398       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -110      |\n",
      "|    explained_variance | -1.09     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -0.308    |\n",
      "|    std                | 79.6      |\n",
      "|    value_loss         | 5.08e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 0.19     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -2.71    |\n",
      "|    std                | 81.2     |\n",
      "|    value_loss         | 0.000934 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -1.95    |\n",
      "|    std                | 83.2     |\n",
      "|    value_loss         | 0.000334 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 404       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -112      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -0.261    |\n",
      "|    std                | 85.8      |\n",
      "|    value_loss         | 7.35e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | 0.363    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.0386  |\n",
      "|    std                | 89.1     |\n",
      "|    value_loss         | 3.21e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 970      |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | -4.9e+04 |\n",
      "|    total_reward_pct   | -98.1    |\n",
      "|    total_trades       | 27392    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 409      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -113     |\n",
      "|    explained_variance | -0.0595  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 0.589    |\n",
      "|    std                | 92.7     |\n",
      "|    value_loss         | 3.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 411      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 0.0952   |\n",
      "|    std                | 96.5     |\n",
      "|    value_loss         | 9.86e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 413      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | -0.576   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 100      |\n",
      "|    value_loss         | 0.000154 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 415      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -115     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 0.598    |\n",
      "|    std                | 104      |\n",
      "|    value_loss         | 7.77e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 417      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -116     |\n",
      "|    explained_variance | 0.015    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 0.26     |\n",
      "|    std                | 108      |\n",
      "|    value_loss         | 9.66e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 66.3      |\n",
      "|    total_cost         | 2.01e+04  |\n",
      "|    total_reward       | -4.99e+04 |\n",
      "|    total_reward_pct   | -99.9     |\n",
      "|    total_trades       | 26676     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 420       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -116      |\n",
      "|    explained_variance | -0.000503 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -3.86     |\n",
      "|    std                | 111       |\n",
      "|    value_loss         | 0.00111   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 422       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -117      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 0.206     |\n",
      "|    std                | 113       |\n",
      "|    value_loss         | 9.34e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 424      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -117     |\n",
      "|    explained_variance | 0.765    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 2.73     |\n",
      "|    std                | 117      |\n",
      "|    value_loss         | 0.00053  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -118     |\n",
      "|    explained_variance | 0.347    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 2.07     |\n",
      "|    std                | 120      |\n",
      "|    value_loss         | 0.000308 |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-07-05 to  2019-10-02\n",
      "A2C Sharpe Ratio:  -0.22123178952848455\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 276  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.27e+03   |\n",
      "|    total_cost           | 1.59e+04   |\n",
      "|    total_reward         | -4.87e+04  |\n",
      "|    total_reward_pct     | -97.5      |\n",
      "|    total_trades         | 25979      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01583989 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | -0.77      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.309     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0395     |\n",
      "----------------------------------------\n",
      "day: 2334, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1740.24\n",
      "total_reward: -48259.76\n",
      "total_cost: 13321.16\n",
      "total_trades: 25922\n",
      "Sharpe: -0.315\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.74e+03   |\n",
      "|    total_cost           | 1.33e+04   |\n",
      "|    total_reward         | -4.83e+04  |\n",
      "|    total_reward_pct     | -96.5      |\n",
      "|    total_trades         | 25922      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01588503 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.306     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0202     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.91e+03    |\n",
      "|    total_cost           | 3.75e+04    |\n",
      "|    total_reward         | -4.11e+04   |\n",
      "|    total_reward_pct     | -82.2       |\n",
      "|    total_trades         | 28516       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017831692 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0159      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.47e+03    |\n",
      "|    total_cost           | 3.15e+04    |\n",
      "|    total_reward         | -4.25e+04   |\n",
      "|    total_reward_pct     | -85.1       |\n",
      "|    total_trades         | 27915       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019192588 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0098      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.08e+03    |\n",
      "|    total_cost           | 2.62e+04    |\n",
      "|    total_reward         | -4.19e+04   |\n",
      "|    total_reward_pct     | -83.8       |\n",
      "|    total_trades         | 27630       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012014718 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.331      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00682     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.77e+03    |\n",
      "|    total_cost           | 1.23e+04    |\n",
      "|    total_reward         | -4.72e+04   |\n",
      "|    total_reward_pct     | -94.5       |\n",
      "|    total_trades         | 26049       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015141057 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00751     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2328.59\n",
      "total_reward: -47671.41\n",
      "total_cost: 17032.55\n",
      "total_trades: 26548\n",
      "Sharpe: 0.362\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+03    |\n",
      "|    total_cost           | 1.7e+04     |\n",
      "|    total_reward         | -4.77e+04   |\n",
      "|    total_reward_pct     | -95.3       |\n",
      "|    total_trades         | 26548       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009098965 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00384     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013965267 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00353     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.44e+03    |\n",
      "|    total_cost           | 1.21e+04    |\n",
      "|    total_reward         | -4.66e+04   |\n",
      "|    total_reward_pct     | -93.1       |\n",
      "|    total_trades         | 25962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026510138 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00228     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.92e+03   |\n",
      "|    total_cost           | 1.58e+04   |\n",
      "|    total_reward         | -4.41e+04  |\n",
      "|    total_reward_pct     | -88.2      |\n",
      "|    total_trades         | 26457      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 258        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 87         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02777913 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.76       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.323     |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.00269    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.13e+04    |\n",
      "|    total_cost           | 4.42e+04    |\n",
      "|    total_reward         | -2.87e+04   |\n",
      "|    total_reward_pct     | -57.3       |\n",
      "|    total_trades         | 29159       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037332073 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | -1.19       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.67e+04    |\n",
      "|    total_cost           | 6.03e+04    |\n",
      "|    total_reward         | -1.33e+04   |\n",
      "|    total_reward_pct     | -26.5       |\n",
      "|    total_trades         | 30027       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009801441 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 11933.22\n",
      "total_reward: -38066.78\n",
      "total_cost: 27785.93\n",
      "total_trades: 28119\n",
      "Sharpe: -0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+04    |\n",
      "|    total_cost           | 2.78e+04    |\n",
      "|    total_reward         | -3.81e+04   |\n",
      "|    total_reward_pct     | -76.1       |\n",
      "|    total_trades         | 28119       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012078485 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.315      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+04    |\n",
      "|    total_cost           | 2.71e+04    |\n",
      "|    total_reward         | -3.87e+04   |\n",
      "|    total_reward_pct     | -77.3       |\n",
      "|    total_trades         | 27990       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014172192 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.322      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00571     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.85e+03    |\n",
      "|    total_cost           | 1.96e+04    |\n",
      "|    total_reward         | -4.31e+04   |\n",
      "|    total_reward_pct     | -86.3       |\n",
      "|    total_trades         | 27291       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024460478 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.246      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00922     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029397916 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00489     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.18e+04   |\n",
      "|    total_cost           | 3.43e+04   |\n",
      "|    total_reward         | -2.82e+04  |\n",
      "|    total_reward_pct     | -56.4      |\n",
      "|    total_trades         | 28913      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 258        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02641353 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.5      |\n",
      "|    explained_variance   | 0.156      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.295     |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0122     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.96e+03    |\n",
      "|    total_cost           | 1.43e+04    |\n",
      "|    total_reward         | -4.2e+04    |\n",
      "|    total_reward_pct     | -84.1       |\n",
      "|    total_trades         | 26599       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017498776 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00482     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 14024.65\n",
      "total_reward: -35975.35\n",
      "total_cost: 19965.43\n",
      "total_trades: 26986\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.4e+04    |\n",
      "|    total_cost           | 2e+04      |\n",
      "|    total_reward         | -3.6e+04   |\n",
      "|    total_reward_pct     | -72        |\n",
      "|    total_trades         | 26986      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 258        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 158        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03277744 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.66       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.303     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.00581    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.46e+04    |\n",
      "|    total_cost           | 1.9e+04     |\n",
      "|    total_reward         | -3.54e+04   |\n",
      "|    total_reward_pct     | -70.9       |\n",
      "|    total_trades         | 26722       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022695966 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00569     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.79e+04    |\n",
      "|    total_cost           | 5.69e+04    |\n",
      "|    total_reward         | -2.21e+04   |\n",
      "|    total_reward_pct     | -44.3       |\n",
      "|    total_trades         | 29673       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041676443 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | -1.26       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0267      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.12e+03   |\n",
      "|    total_cost           | 2.07e+04   |\n",
      "|    total_reward         | -4.59e+04  |\n",
      "|    total_reward_pct     | -91.8      |\n",
      "|    total_trades         | 27264      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 258        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02722198 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.308     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.00943    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.3e+04     |\n",
      "|    total_cost           | 3.39e+04    |\n",
      "|    total_reward         | -3.7e+04    |\n",
      "|    total_reward_pct     | -74         |\n",
      "|    total_trades         | 28386       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031118626 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00584     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030165352 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00587     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 31464.22\n",
      "total_reward: -18535.78\n",
      "total_cost: 53516.06\n",
      "total_trades: 29551\n",
      "Sharpe: -0.073\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.15e+04    |\n",
      "|    total_cost           | 5.35e+04    |\n",
      "|    total_reward         | -1.85e+04   |\n",
      "|    total_reward_pct     | -37.1       |\n",
      "|    total_trades         | 29551       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023807041 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0156      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.43e+04   |\n",
      "|    total_cost           | 3.12e+04   |\n",
      "|    total_reward         | -3.57e+04  |\n",
      "|    total_reward_pct     | -71.5      |\n",
      "|    total_trades         | 28330      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 259        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01052927 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.587      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.295     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.00752    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.85e+04    |\n",
      "|    total_cost           | 3.49e+04    |\n",
      "|    total_reward         | -3.15e+04   |\n",
      "|    total_reward_pct     | -62.9       |\n",
      "|    total_trades         | 28719       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027660027 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00583     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+04    |\n",
      "|    total_cost           | 2.22e+04    |\n",
      "|    total_reward         | -3.78e+04   |\n",
      "|    total_reward_pct     | -75.5       |\n",
      "|    total_trades         | 27694       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024140835 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.331      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00472     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.5e+04     |\n",
      "|    total_cost           | 2.49e+04    |\n",
      "|    total_reward         | -3.5e+04    |\n",
      "|    total_reward_pct     | -70         |\n",
      "|    total_trades         | 28042       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027953293 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00411     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -5442.32\n",
      "total_reward: -55442.32\n",
      "total_cost: 11208.34\n",
      "total_trades: 25943\n",
      "Sharpe: 0.206\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -5.44e+03   |\n",
      "|    total_cost           | 1.12e+04    |\n",
      "|    total_reward         | -5.54e+04   |\n",
      "|    total_reward_pct     | -111        |\n",
      "|    total_trades         | 25943       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018008782 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00351     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.23e+04   |\n",
      "|    total_cost           | 1.78e+04   |\n",
      "|    total_reward         | -3.77e+04  |\n",
      "|    total_reward_pct     | -75.3      |\n",
      "|    total_trades         | 27088      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 259        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03154957 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28        |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.289     |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.00273    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026379172 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00241     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.55e+04    |\n",
      "|    total_cost           | 4.64e+04    |\n",
      "|    total_reward         | 5.52e+03    |\n",
      "|    total_reward_pct     | 11          |\n",
      "|    total_trades         | 29577       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038730413 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.42e+03    |\n",
      "|    total_cost           | 1.13e+04    |\n",
      "|    total_reward         | -4.06e+04   |\n",
      "|    total_reward_pct     | -81.2       |\n",
      "|    total_trades         | 26228       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021910764 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00387     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.65e+03    |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -4.73e+04   |\n",
      "|    total_reward_pct     | -94.7       |\n",
      "|    total_trades         | 26610       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022072216 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.319      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00211     |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24874.87\n",
      "total_reward: -25125.13\n",
      "total_cost: 22876.60\n",
      "total_trades: 28039\n",
      "Sharpe: 0.113\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.49e+04    |\n",
      "|    total_cost           | 2.29e+04    |\n",
      "|    total_reward         | -2.51e+04   |\n",
      "|    total_reward_pct     | -50.3       |\n",
      "|    total_trades         | 28039       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051773302 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00626     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4e+04      |\n",
      "|    total_cost           | 3.46e+04   |\n",
      "|    total_reward         | -1e+04     |\n",
      "|    total_reward_pct     | -20        |\n",
      "|    total_trades         | 28857      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 259        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02145851 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.433      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.32      |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.00773    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.62e+04   |\n",
      "|    total_cost           | 1.99e+04   |\n",
      "|    total_reward         | -3.38e+04  |\n",
      "|    total_reward_pct     | -67.7      |\n",
      "|    total_trades         | 27441      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 259        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 307        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03286194 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.5      |\n",
      "|    explained_variance   | 0.652      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.323     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.00681    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.19e+04    |\n",
      "|    total_cost           | 2.48e+04    |\n",
      "|    total_reward         | -1.81e+04   |\n",
      "|    total_reward_pct     | -36.1       |\n",
      "|    total_trades         | 28141       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026410993 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.349      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00432     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036853787 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00761     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.08e+04    |\n",
      "|    total_cost           | 3.95e+04    |\n",
      "|    total_reward         | 1.08e+04    |\n",
      "|    total_reward_pct     | 21.7        |\n",
      "|    total_trades         | 29234       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026707891 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 32033.07\n",
      "total_reward: -17966.93\n",
      "total_cost: 32327.95\n",
      "total_trades: 28835\n",
      "Sharpe: -0.007\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.2e+04     |\n",
      "|    total_cost           | 3.23e+04    |\n",
      "|    total_reward         | -1.8e+04    |\n",
      "|    total_reward_pct     | -35.9       |\n",
      "|    total_trades         | 28835       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027191047 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.44e+04   |\n",
      "|    total_cost           | 1.51e+04   |\n",
      "|    total_reward         | -2.56e+04  |\n",
      "|    total_reward_pct     | -51.2      |\n",
      "|    total_trades         | 26409      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 259        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03094941 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.6      |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.315     |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.00938    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.95e+03    |\n",
      "|    total_cost           | 8.97e+03    |\n",
      "|    total_reward         | -4.51e+04   |\n",
      "|    total_reward_pct     | -90.1       |\n",
      "|    total_trades         | 26066       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017557442 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.327      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00469     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.21e+04    |\n",
      "|    total_cost           | 2.03e+04    |\n",
      "|    total_reward         | -2.79e+04   |\n",
      "|    total_reward_pct     | -55.8       |\n",
      "|    total_trades         | 27682       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036125388 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00386     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.75e+04    |\n",
      "|    total_cost           | 2.06e+04    |\n",
      "|    total_reward         | -2.25e+04   |\n",
      "|    total_reward_pct     | -45.1       |\n",
      "|    total_trades         | 27694       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032585286 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0054      |\n",
      "-----------------------------------------\n",
      "day: 2334, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 16519.78\n",
      "total_reward: -33480.22\n",
      "total_cost: 14847.16\n",
      "total_trades: 27097\n",
      "Sharpe: 0.038\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.65e+04    |\n",
      "|    total_cost           | 1.48e+04    |\n",
      "|    total_reward         | -3.35e+04   |\n",
      "|    total_reward_pct     | -67         |\n",
      "|    total_trades         | 27097       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030911397 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.339      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.00635     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 259        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 386        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02558864 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.9      |\n",
      "|    explained_variance   | 0.828      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.314     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.0032     |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2019-07-05 to  2019-10-02\n",
      "PPO Sharpe Ratio:  -0.18286896973004185\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
      "day: 2334, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 40997.48\n",
      "total_reward: -9002.52\n",
      "total_cost: 158.43\n",
      "total_trades: 20309\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.1e+04  |\n",
      "|    total_cost       | 158      |\n",
      "|    total_reward     | -9e+03   |\n",
      "|    total_reward_pct | -18      |\n",
      "|    total_trades     | 20309    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 120      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total timesteps  | 9340     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -54.6    |\n",
      "|    critic_loss      | 7.96     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7005     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.98e+04  |\n",
      "|    total_cost       | 139       |\n",
      "|    total_reward     | -1.02e+04 |\n",
      "|    total_reward_pct | -20.4     |\n",
      "|    total_trades     | 19628     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 110       |\n",
      "|    time_elapsed     | 169       |\n",
      "|    total timesteps  | 18680     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -34.3     |\n",
      "|    critic_loss      | 2.49      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16345     |\n",
      "-----------------------------------\n",
      "day: 2334, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 69977.19\n",
      "total_reward: 19977.19\n",
      "total_cost: 171.61\n",
      "total_trades: 19451\n",
      "Sharpe: 0.496\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.67e+04 |\n",
      "|    total_cost       | 155      |\n",
      "|    total_reward     | 6.73e+03 |\n",
      "|    total_reward_pct | 13.5     |\n",
      "|    total_trades     | 18339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 106      |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total timesteps  | 28020    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -21.7    |\n",
      "|    critic_loss      | 1.17     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25685    |\n",
      "----------------------------------\n",
      "day: 2334, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 73261.05\n",
      "total_reward: 23261.05\n",
      "total_cost: 158.65\n",
      "total_trades: 18539\n",
      "Sharpe: 0.505\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.24e+04 |\n",
      "|    total_cost       | 162      |\n",
      "|    total_reward     | 1.24e+04 |\n",
      "|    total_reward_pct | 24.7     |\n",
      "|    total_trades     | 18501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total timesteps  | 37360    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -13.8    |\n",
      "|    critic_loss      | 0.751    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35025    |\n",
      "----------------------------------\n",
      "day: 2334, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 47893.09\n",
      "total_reward: -2106.91\n",
      "total_cost: 103.94\n",
      "total_trades: 18478\n",
      "Sharpe: 0.472\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.05e+04 |\n",
      "|    total_cost       | 105      |\n",
      "|    total_reward     | 509      |\n",
      "|    total_reward_pct | 1.02     |\n",
      "|    total_trades     | 18466    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 447      |\n",
      "|    total timesteps  | 46700    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.85    |\n",
      "|    critic_loss      | 0.739    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44365    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-07-05 to  2019-10-02\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-02\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_252_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.54e+04  |\n",
      "|    total_cost       | 113       |\n",
      "|    total_reward     | -4.61e+03 |\n",
      "|    total_reward_pct | -9.23     |\n",
      "|    total_trades     | 24782     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 80        |\n",
      "|    total timesteps  | 9592      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -12.3     |\n",
      "|    critic_loss      | 77.7      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7194      |\n",
      "-----------------------------------\n",
      "day: 2397, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49758.78\n",
      "total_reward: -241.22\n",
      "total_cost: 104.66\n",
      "total_trades: 24116\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.56e+04  |\n",
      "|    total_cost       | 107       |\n",
      "|    total_reward     | -4.41e+03 |\n",
      "|    total_reward_pct | -8.82     |\n",
      "|    total_trades     | 23758     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 108       |\n",
      "|    time_elapsed     | 176       |\n",
      "|    total timesteps  | 19184     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -7.1      |\n",
      "|    critic_loss      | 7.05      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16786     |\n",
      "-----------------------------------\n",
      "day: 2397, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50360.08\n",
      "total_reward: 360.08\n",
      "total_cost: 102.55\n",
      "total_trades: 24636\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.4e+04  |\n",
      "|    total_cost       | 114      |\n",
      "|    total_reward     | 3.99e+03 |\n",
      "|    total_reward_pct | 7.99     |\n",
      "|    total_trades     | 24919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total timesteps  | 28776    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.21    |\n",
      "|    critic_loss      | 2.58     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 26378    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49581.74\n",
      "total_reward: -418.26\n",
      "total_cost: 115.81\n",
      "total_trades: 24626\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.62e+04 |\n",
      "|    total_cost       | 105      |\n",
      "|    total_reward     | -3.8e+03 |\n",
      "|    total_reward_pct | -7.61    |\n",
      "|    total_trades     | 24797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 367      |\n",
      "|    total timesteps  | 38368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -4.02    |\n",
      "|    critic_loss      | 1.29     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35970    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48701.12\n",
      "total_reward: -1298.88\n",
      "total_cost: 104.43\n",
      "total_trades: 24224\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.87e+04 |\n",
      "|    total_cost       | 104      |\n",
      "|    total_reward     | -1.3e+03 |\n",
      "|    total_reward_pct | -2.6     |\n",
      "|    total_trades     | 24224    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 464      |\n",
      "|    total timesteps  | 47960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.03    |\n",
      "|    critic_loss      | 0.775    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45562    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-10-02 to  2020-01-03\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2010-01-01 to  2019-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -3.46    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.563    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.00452  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -1.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.306   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00208  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.906    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00348  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0.0188   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 7.55     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.35e+05 |\n",
      "|    total_cost         | 3.4e+04  |\n",
      "|    total_reward       | 8.52e+04 |\n",
      "|    total_reward_pct   | 170      |\n",
      "|    total_trades       | 28075    |\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -303     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -3.96    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0414   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -63.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.502    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00894  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -49.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -1.44    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00704  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.947   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -18.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -7.7     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0971   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | -1.1e+04 |\n",
      "|    total_cost         | 3.14e+03 |\n",
      "|    total_reward       | -6.1e+04 |\n",
      "|    total_reward_pct   | -122     |\n",
      "|    total_trades       | 24092    |\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -2.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0199   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.000486 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00043  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | -0.342   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.256    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.00337  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | 0.213    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -1.16    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00169  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.145   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.239    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00017  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.22e+04 |\n",
      "|    total_cost         | 3.63e+03 |\n",
      "|    total_reward       | 2.18e+03 |\n",
      "|    total_reward_pct   | 4.36     |\n",
      "|    total_trades       | 23650    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -10.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.532    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.00256  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.631   |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0014   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.00417  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -3.65    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.0167   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | -3.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.0379   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 5.22e+03 |\n",
      "|    total_reward       | 5.04e+04 |\n",
      "|    total_reward_pct   | 101      |\n",
      "|    total_trades       | 23949    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -1.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.481   |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.000574 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.9    |\n",
      "|    explained_variance | -2.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 0.00141  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.0032   |\n",
      "------------------------------------\n",
      "day: 2397, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49818.49\n",
      "total_reward: -181.51\n",
      "total_cost: 5223.36\n",
      "total_trades: 24177\n",
      "Sharpe: 0.284\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.98e+04 |\n",
      "|    total_cost         | 5.22e+03 |\n",
      "|    total_reward       | -182     |\n",
      "|    total_reward_pct   | -0.363   |\n",
      "|    total_trades       | 24177    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | 0.174    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -33.8    |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 4.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | -5.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.403   |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.000792 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.587   |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.0014   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | -0.00022 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 1.23     |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.00181  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 2.86     |\n",
      "|    std                | 1.44     |\n",
      "|    value_loss         | 0.00896  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.98e+04 |\n",
      "|    total_cost         | 2.77e+03 |\n",
      "|    total_reward       | -187     |\n",
      "|    total_reward_pct   | -0.374   |\n",
      "|    total_trades       | 25126    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | -5.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.295   |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.000168 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | -8.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.367    |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.000944 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.0952   |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.000389 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -0.459   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.822    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.00198  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | -78.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -7.25    |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.054    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.88e+04 |\n",
      "|    total_cost         | 5.26e+03 |\n",
      "|    total_reward       | -1.2e+03 |\n",
      "|    total_reward_pct   | -2.4     |\n",
      "|    total_trades       | 24650    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | 0.0132   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.00224  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | 0.331    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.97     |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.0048   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 4.65     |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0266   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | 0.0418   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 6.64     |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.0559   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | -28.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 4.41     |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.48e+04 |\n",
      "|    total_cost         | 7.25e+03 |\n",
      "|    total_reward       | 2.48e+04 |\n",
      "|    total_reward_pct   | 49.5     |\n",
      "|    total_trades       | 25114    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | -3.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -2.03    |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.00419  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.00374  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | 0.177    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.735   |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.000569 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -6.63    |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.0552   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | -18.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 2.66     |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.0195   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.54e+04  |\n",
      "|    total_cost         | 7.64e+03  |\n",
      "|    total_reward       | -4.59e+03 |\n",
      "|    total_reward_pct   | -9.19     |\n",
      "|    total_trades       | 25163     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.8     |\n",
      "|    explained_variance | 0.0823    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 3.74      |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.0127    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.00401  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | -0.0296  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.913    |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.00193  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.6    |\n",
      "|    explained_variance | 0.199    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -3.08    |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "day: 2397, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 57509.39\n",
      "total_reward: 7509.39\n",
      "total_cost: 3524.23\n",
      "total_trades: 23208\n",
      "Sharpe: 0.292\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.75e+04 |\n",
      "|    total_cost         | 3.52e+03 |\n",
      "|    total_reward       | 7.51e+03 |\n",
      "|    total_reward_pct   | 15       |\n",
      "|    total_trades       | 23208    |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | -529     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 2.68     |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.0215   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | -1.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -1.66    |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.00428  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.00107  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 1.35     |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.00279  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | -0.374   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 0.00501  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.68e+04  |\n",
      "|    total_cost         | 2.73e+03  |\n",
      "|    total_reward       | -3.24e+03 |\n",
      "|    total_reward_pct   | -6.48     |\n",
      "|    total_trades       | 23405     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -4.66     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -0.769    |\n",
      "|    std                | 1.99      |\n",
      "|    value_loss         | 0.00166   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.0252   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -1.08    |\n",
      "|    std                | 2.03     |\n",
      "|    value_loss         | 0.000939 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.371   |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.00069  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | 0.0111   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.414    |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.000556 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | -0.399   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.282    |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.000974 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.77e+04  |\n",
      "|    total_cost         | 3.13e+03  |\n",
      "|    total_reward       | -2.23e+04 |\n",
      "|    total_reward_pct   | -44.6     |\n",
      "|    total_trades       | 23606     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | -0.372    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -2.22     |\n",
      "|    std                | 2.16      |\n",
      "|    value_loss         | 0.00397   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.302    |\n",
      "|    std                | 2.19     |\n",
      "|    value_loss         | 8.55e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0.207    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 2.64     |\n",
      "|    std                | 2.23     |\n",
      "|    value_loss         | 0.00638  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.289   |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.000334 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0971   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.00791 |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.000863 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.07e+04  |\n",
      "|    total_cost         | 9.54e+03  |\n",
      "|    total_reward       | -9.27e+03 |\n",
      "|    total_reward_pct   | -18.5     |\n",
      "|    total_trades       | 24905     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -0.119    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -0.0651   |\n",
      "|    std                | 2.33      |\n",
      "|    value_loss         | 1.16e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 9.1       |\n",
      "|    std                | 2.38      |\n",
      "|    value_loss         | 0.0572    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.485    |\n",
      "|    std                | 2.45     |\n",
      "|    value_loss         | 0.000294 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0.000188 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.4e-05  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.488   |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.000189 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.81e+04  |\n",
      "|    total_cost         | 3.79e+03  |\n",
      "|    total_reward       | -3.19e+04 |\n",
      "|    total_reward_pct   | -63.7     |\n",
      "|    total_trades       | 23259     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -0.13     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 2.71      |\n",
      "|    std                | 2.58      |\n",
      "|    value_loss         | 0.00509   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | -0.168   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -2.9     |\n",
      "|    std                | 2.62     |\n",
      "|    value_loss         | 0.00438  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0.498    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -1.97    |\n",
      "|    std                | 2.65     |\n",
      "|    value_loss         | 0.00213  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | -0.00669 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.135   |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.00357  |\n",
      "------------------------------------\n",
      "day: 2397, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 36518.90\n",
      "total_reward: -13481.10\n",
      "total_cost: 8865.06\n",
      "total_trades: 24417\n",
      "Sharpe: 0.068\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.65e+04  |\n",
      "|    total_cost         | 8.87e+03  |\n",
      "|    total_reward       | -1.35e+04 |\n",
      "|    total_reward_pct   | -27       |\n",
      "|    total_trades       | 24417     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -2.71     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 0.693     |\n",
      "|    std                | 2.72      |\n",
      "|    value_loss         | 0.000535  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | -20.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.356    |\n",
      "|    std                | 2.77     |\n",
      "|    value_loss         | 0.000852 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.278    |\n",
      "|    std                | 2.84     |\n",
      "|    value_loss         | 6.64e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | -0.621   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -0.869   |\n",
      "|    std                | 2.92     |\n",
      "|    value_loss         | 0.000432 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 3.82     |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 0.00858  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.17e+04  |\n",
      "|    total_cost         | 6.65e+03  |\n",
      "|    total_reward       | -3.83e+04 |\n",
      "|    total_reward_pct   | -76.6     |\n",
      "|    total_trades       | 23549     |\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.9     |\n",
      "|    explained_variance | -1.12     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 1.32      |\n",
      "|    std                | 3.02      |\n",
      "|    value_loss         | 0.00139   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | -1.82    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.00104  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.7    |\n",
      "|    explained_variance | -1.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.0767   |\n",
      "|    std                | 3.15     |\n",
      "|    value_loss         | 3.74e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | -1.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 0.291    |\n",
      "|    std                | 3.23     |\n",
      "|    value_loss         | 4.8e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | -0.112   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -0.118   |\n",
      "|    std                | 3.32     |\n",
      "|    value_loss         | 2.11e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.22e+03  |\n",
      "|    total_cost         | 8.68e+03  |\n",
      "|    total_reward       | -4.78e+04 |\n",
      "|    total_reward_pct   | -95.6     |\n",
      "|    total_trades       | 24294     |\n",
      "| time/                 |           |\n",
      "|    fps                | 233       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.3     |\n",
      "|    explained_variance | -0.24     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -0.0555   |\n",
      "|    std                | 3.41      |\n",
      "|    value_loss         | 5.5e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.69    |\n",
      "|    std                | 3.51     |\n",
      "|    value_loss         | 0.000321 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 0.318    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    std                | 3.62     |\n",
      "|    value_loss         | 0.000813 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.635   |\n",
      "|    std                | 3.7      |\n",
      "|    value_loss         | 0.000153 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.14     |\n",
      "|    std                | 3.81     |\n",
      "|    value_loss         | 1.21e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.34e+03  |\n",
      "|    total_cost         | 1.48e+04  |\n",
      "|    total_reward       | -4.07e+04 |\n",
      "|    total_reward_pct   | -81.3     |\n",
      "|    total_trades       | 24728     |\n",
      "| time/                 |           |\n",
      "|    fps                | 233       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.9     |\n",
      "|    explained_variance | 1.59e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 0.217     |\n",
      "|    std                | 3.91      |\n",
      "|    value_loss         | 3.04e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.363   |\n",
      "|    std                | 4.02     |\n",
      "|    value_loss         | 8.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | -0.934   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 4.15     |\n",
      "|    value_loss         | 0.000779 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    std                | 4.27     |\n",
      "|    value_loss         | 0.00037  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | -6.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -0.334   |\n",
      "|    std                | 4.4      |\n",
      "|    value_loss         | 0.000251 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.67e+03  |\n",
      "|    total_cost         | 1.03e+04  |\n",
      "|    total_reward       | -4.03e+04 |\n",
      "|    total_reward_pct   | -80.7     |\n",
      "|    total_trades       | 24615     |\n",
      "| time/                 |           |\n",
      "|    fps                | 233       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | -108      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 2.51      |\n",
      "|    std                | 4.55      |\n",
      "|    value_loss         | 0.00271   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -3.02    |\n",
      "|    std                | 4.69     |\n",
      "|    value_loss         | 0.00319  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.8    |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -2.6     |\n",
      "|    std                | 4.81     |\n",
      "|    value_loss         | 0.00238  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | -0.622   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 4.94     |\n",
      "|    value_loss         | 0.000461 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6564.65\n",
      "total_reward: -43435.35\n",
      "total_cost: 17759.26\n",
      "total_trades: 25107\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.56e+03  |\n",
      "|    total_cost         | 1.78e+04  |\n",
      "|    total_reward       | -4.34e+04 |\n",
      "|    total_reward_pct   | -86.9     |\n",
      "|    total_trades       | 25107     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.8     |\n",
      "|    explained_variance | -4.91     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -1.71     |\n",
      "|    std                | 5.07      |\n",
      "|    value_loss         | 0.00399   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.2    |\n",
      "|    explained_variance | 0.000552 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.221   |\n",
      "|    std                | 5.18     |\n",
      "|    value_loss         | 0.000309 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.497   |\n",
      "|    std                | 5.3      |\n",
      "|    value_loss         | 0.000264 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 4.47     |\n",
      "|    std                | 5.42     |\n",
      "|    value_loss         | 0.00559  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.208   |\n",
      "|    std                | 5.53     |\n",
      "|    value_loss         | 0.000135 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.54e+03  |\n",
      "|    total_cost         | 3.04e+04  |\n",
      "|    total_reward       | -4.25e+04 |\n",
      "|    total_reward_pct   | -84.9     |\n",
      "|    total_trades       | 26635     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 216       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.9     |\n",
      "|    explained_variance | -17.3     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -1.2      |\n",
      "|    std                | 5.67      |\n",
      "|    value_loss         | 0.00044   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.4    |\n",
      "|    explained_variance | -0.257   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -0.293   |\n",
      "|    std                | 5.83     |\n",
      "|    value_loss         | 4.28e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61      |\n",
      "|    explained_variance | -1.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 2.25     |\n",
      "|    std                | 6.02     |\n",
      "|    value_loss         | 0.00186  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 0.315    |\n",
      "|    std                | 6.17     |\n",
      "|    value_loss         | 0.000114 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.9    |\n",
      "|    explained_variance | -0.0818  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.229   |\n",
      "|    std                | 6.31     |\n",
      "|    value_loss         | 4.77e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.97e+03 |\n",
      "|    total_cost         | 2.64e+04 |\n",
      "|    total_reward       | -4.2e+04 |\n",
      "|    total_reward_pct   | -84.1    |\n",
      "|    total_trades       | 26537    |\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.4    |\n",
      "|    explained_variance | -0.00389 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.75    |\n",
      "|    std                | 6.45     |\n",
      "|    value_loss         | 0.000793 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -3.05    |\n",
      "|    std                | 6.56     |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.9    |\n",
      "|    explained_variance | 0.137    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -4.64    |\n",
      "|    std                | 6.65     |\n",
      "|    value_loss         | 0.00632  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -1       |\n",
      "|    std                | 6.73     |\n",
      "|    value_loss         | 0.00257  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 3.85     |\n",
      "|    std                | 6.81     |\n",
      "|    value_loss         | 0.00672  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.2e+04  |\n",
      "|    total_cost         | 5.9e+04  |\n",
      "|    total_reward       | -1.8e+04 |\n",
      "|    total_reward_pct   | -36      |\n",
      "|    total_trades       | 28397    |\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.6    |\n",
      "|    explained_variance | 0.589    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 0.325    |\n",
      "|    std                | 6.9      |\n",
      "|    value_loss         | 3.38e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | -0.557   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.851    |\n",
      "|    std                | 7.02     |\n",
      "|    value_loss         | 0.000194 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -0.358   |\n",
      "|    std                | 7.2      |\n",
      "|    value_loss         | 6.35e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.156   |\n",
      "|    std                | 7.4      |\n",
      "|    value_loss         | 1.62e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.461   |\n",
      "|    std                | 7.66     |\n",
      "|    value_loss         | 5.89e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.61e+03  |\n",
      "|    total_cost         | 2.09e+04  |\n",
      "|    total_reward       | -4.74e+04 |\n",
      "|    total_reward_pct   | -94.8     |\n",
      "|    total_trades       | 27306     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.2     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -3.42     |\n",
      "|    std                | 7.92      |\n",
      "|    value_loss         | 0.00319   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 0.0276   |\n",
      "|    std                | 8.16     |\n",
      "|    value_loss         | 9.51e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.182   |\n",
      "|    std                | 8.48     |\n",
      "|    value_loss         | 1.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.3    |\n",
      "|    explained_variance | -0.555   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -0.109   |\n",
      "|    std                | 8.83     |\n",
      "|    value_loss         | 3.64e-06 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 84.20\n",
      "total_reward: -49915.80\n",
      "total_cost: 12602.74\n",
      "total_trades: 26655\n",
      "Sharpe: -0.782\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 84.2      |\n",
      "|    total_cost         | 1.26e+04  |\n",
      "|    total_reward       | -4.99e+04 |\n",
      "|    total_reward_pct   | -99.8     |\n",
      "|    total_trades       | 26655     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 257       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.1     |\n",
      "|    explained_variance | -1.58     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -1.34     |\n",
      "|    std                | 9.22      |\n",
      "|    value_loss         | 0.000482  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.9    |\n",
      "|    explained_variance | -0.00597 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.616   |\n",
      "|    std                | 9.59     |\n",
      "|    value_loss         | 7.39e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.128    |\n",
      "|    std                | 10       |\n",
      "|    value_loss         | 5.66e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.2    |\n",
      "|    explained_variance | -0.0524  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 10.3     |\n",
      "|    value_loss         | 0.00156  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | 1.63      |\n",
      "|    std                | 10.5      |\n",
      "|    value_loss         | 0.000593  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.18e+04  |\n",
      "|    total_cost         | 3.37e+04  |\n",
      "|    total_reward       | -3.82e+04 |\n",
      "|    total_reward_pct   | -76.4     |\n",
      "|    total_trades       | 27924     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 268       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72       |\n",
      "|    explained_variance | -79.6     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 0.756     |\n",
      "|    std                | 10.7      |\n",
      "|    value_loss         | 0.000186  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.6    |\n",
      "|    explained_variance | 0.771    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.568   |\n",
      "|    std                | 11.1     |\n",
      "|    value_loss         | 6.33e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.2    |\n",
      "|    explained_variance | -0.0612  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    std                | 11.4     |\n",
      "|    value_loss         | 0.000325 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.6    |\n",
      "|    explained_variance | -0.102   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.0496   |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 7.62e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | -0.439   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.155    |\n",
      "|    std                | 12       |\n",
      "|    value_loss         | 0.000104 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.64e+03  |\n",
      "|    total_cost         | 2.36e+04  |\n",
      "|    total_reward       | -4.44e+04 |\n",
      "|    total_reward_pct   | -88.7     |\n",
      "|    total_trades       | 27670     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | -14.2     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | 0.344     |\n",
      "|    std                | 12.3      |\n",
      "|    value_loss         | 0.000188  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 1.33     |\n",
      "|    std                | 12.6     |\n",
      "|    value_loss         | 0.000439 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.6    |\n",
      "|    explained_variance | 0.273    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -1.74    |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 0.000774 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.579    |\n",
      "|    std                | 13.4     |\n",
      "|    value_loss         | 0.000214 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 13.8     |\n",
      "|    value_loss         | 0.000235 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.43e+03  |\n",
      "|    total_cost         | 2.58e+04  |\n",
      "|    total_reward       | -4.56e+04 |\n",
      "|    total_reward_pct   | -91.1     |\n",
      "|    total_trades       | 28441     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 290       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.4     |\n",
      "|    explained_variance | -0.0362   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -0.551    |\n",
      "|    std                | 14.3      |\n",
      "|    value_loss         | 5.52e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.1    |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.0718   |\n",
      "|    std                | 14.8     |\n",
      "|    value_loss         | 6.12e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.7    |\n",
      "|    explained_variance | -0.0912  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 0.723    |\n",
      "|    std                | 15.3     |\n",
      "|    value_loss         | 0.000154 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.946   |\n",
      "|    std                | 15.6     |\n",
      "|    value_loss         | 0.000368 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -0.0707  |\n",
      "|    std                | 16.1     |\n",
      "|    value_loss         | 1.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.95e+03 |\n",
      "|    total_cost         | 2.67e+04 |\n",
      "|    total_reward       | -4.5e+04 |\n",
      "|    total_reward_pct   | -90.1    |\n",
      "|    total_trades       | 27976    |\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 0.192    |\n",
      "|    std                | 16.5     |\n",
      "|    value_loss         | 2e-05    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 0.277    |\n",
      "|    std                | 17.1     |\n",
      "|    value_loss         | 1.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | -1.45    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 0.000569 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.0738   |\n",
      "|    std                | 18.4     |\n",
      "|    value_loss         | 1.09e-06 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 211.35\n",
      "total_reward: -49788.65\n",
      "total_cost: 12651.78\n",
      "total_trades: 26705\n",
      "Sharpe: -0.494\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 211       |\n",
      "|    total_cost         | 1.27e+04  |\n",
      "|    total_reward       | -4.98e+04 |\n",
      "|    total_reward_pct   | -99.6     |\n",
      "|    total_trades       | 26705     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.9     |\n",
      "|    explained_variance | -0.914    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -2.16     |\n",
      "|    std                | 19        |\n",
      "|    value_loss         | 0.00112   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.5    |\n",
      "|    explained_variance | -0.821   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.575    |\n",
      "|    std                | 19.7     |\n",
      "|    value_loss         | 7.66e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -3.26    |\n",
      "|    std                | 20.4     |\n",
      "|    value_loss         | 0.00169  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.7    |\n",
      "|    explained_variance | -3.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 1.49     |\n",
      "|    std                | 20.9     |\n",
      "|    value_loss         | 0.000376 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 0.13     |\n",
      "|    std                | 21.5     |\n",
      "|    value_loss         | 6.26e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.03e+03 |\n",
      "|    total_cost         | 2.5e+04  |\n",
      "|    total_reward       | -4.4e+04 |\n",
      "|    total_reward_pct   | -87.9    |\n",
      "|    total_trades       | 28152    |\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.9    |\n",
      "|    explained_variance | -0.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.295   |\n",
      "|    std                | 22.3     |\n",
      "|    value_loss         | 1.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.5    |\n",
      "|    explained_variance | -2.23    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -0.375   |\n",
      "|    std                | 23       |\n",
      "|    value_loss         | 2.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.2    |\n",
      "|    explained_variance | -0.104   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 4.26     |\n",
      "|    std                | 23.9     |\n",
      "|    value_loss         | 0.00308  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 326      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -1.44    |\n",
      "|    std                | 24.5     |\n",
      "|    value_loss         | 0.00027  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 25.3     |\n",
      "|    value_loss         | 0.00019  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.32e+03  |\n",
      "|    total_cost         | 2.17e+04  |\n",
      "|    total_reward       | -4.77e+04 |\n",
      "|    total_reward_pct   | -95.4     |\n",
      "|    total_trades       | 27932     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -89       |\n",
      "|    explained_variance | -0.316    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | 0.46      |\n",
      "|    std                | 26.2      |\n",
      "|    value_loss         | 3.4e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.834   |\n",
      "|    std                | 27.2     |\n",
      "|    value_loss         | 9.11e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.884   |\n",
      "|    std                | 28.2     |\n",
      "|    value_loss         | 0.000138 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    std                | 29       |\n",
      "|    value_loss         | 4.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.5    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -0.53    |\n",
      "|    std                | 29.9     |\n",
      "|    value_loss         | 6.86e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.02e+03 |\n",
      "|    total_cost         | 2.42e+04 |\n",
      "|    total_reward       | -4.3e+04 |\n",
      "|    total_reward_pct   | -86      |\n",
      "|    total_trades       | 28120    |\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 342      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 0.804    |\n",
      "|    std                | 30.9     |\n",
      "|    value_loss         | 9.19e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.26    |\n",
      "|    std                | 32       |\n",
      "|    value_loss         | 9.29e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 346      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -1.65    |\n",
      "|    std                | 33.1     |\n",
      "|    value_loss         | 0.000343 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.8    |\n",
      "|    explained_variance | 0.00803  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -3.2     |\n",
      "|    std                | 33.8     |\n",
      "|    value_loss         | 0.0017   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 0.425    |\n",
      "|    std                | 34.6     |\n",
      "|    value_loss         | 4.28e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.72e+03  |\n",
      "|    total_cost         | 3.44e+04  |\n",
      "|    total_reward       | -4.13e+04 |\n",
      "|    total_reward_pct   | -82.6     |\n",
      "|    total_trades       | 28443     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 352       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -94.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 2.43      |\n",
      "|    std                | 35.5      |\n",
      "|    value_loss         | 0.000815  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -0.255   |\n",
      "|    std                | 36.7     |\n",
      "|    value_loss         | 8.72e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 357       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -95.9     |\n",
      "|    explained_variance | -1.43e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | -5.23     |\n",
      "|    std                | 37.8      |\n",
      "|    value_loss         | 0.00314   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 359      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.709    |\n",
      "|    std                | 38.9     |\n",
      "|    value_loss         | 0.000225 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 716.59\n",
      "total_reward: -49283.41\n",
      "total_cost: 23347.91\n",
      "total_trades: 27984\n",
      "Sharpe: 0.433\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 717       |\n",
      "|    total_cost         | 2.33e+04  |\n",
      "|    total_reward       | -4.93e+04 |\n",
      "|    total_reward_pct   | -98.6     |\n",
      "|    total_trades       | 27984     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 361       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -97       |\n",
      "|    explained_variance | -0.525    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -0.0991   |\n",
      "|    std                | 40        |\n",
      "|    value_loss         | 3.52e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.5    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 1.94     |\n",
      "|    std                | 41.1     |\n",
      "|    value_loss         | 0.000459 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.0983   |\n",
      "|    std                | 42.5     |\n",
      "|    value_loss         | 1.43e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.8    |\n",
      "|    explained_variance | 0.369    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 0.0557   |\n",
      "|    std                | 43.9     |\n",
      "|    value_loss         | 0.000146 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 370      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 0.464    |\n",
      "|    std                | 45.2     |\n",
      "|    value_loss         | 0.000111 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.29e+04 |\n",
      "|    total_cost         | 2.09e+04  |\n",
      "|    total_reward       | -6.29e+04 |\n",
      "|    total_reward_pct   | -126      |\n",
      "|    total_trades       | 27945     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 372       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -99.8     |\n",
      "|    explained_variance | 0.072     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -0.965    |\n",
      "|    std                | 46.4      |\n",
      "|    value_loss         | 0.000127  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | -5.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -0.349   |\n",
      "|    std                | 47.7     |\n",
      "|    value_loss         | 7.29e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | 0.0116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 2.83     |\n",
      "|    std                | 49.2     |\n",
      "|    value_loss         | 0.000931 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | -0.0488  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    std                | 50.7     |\n",
      "|    value_loss         | 0.0166   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.203    |\n",
      "|    std                | 51.8     |\n",
      "|    value_loss         | 2.87e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.39e+03 |\n",
      "|    total_cost         | 2.33e+04  |\n",
      "|    total_reward       | -5.24e+04 |\n",
      "|    total_reward_pct   | -105      |\n",
      "|    total_trades       | 28276     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -102      |\n",
      "|    explained_variance | 0.0481    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 0.583     |\n",
      "|    std                | 53.2      |\n",
      "|    value_loss         | 5.61e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | -0.101   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 2.01     |\n",
      "|    std                | 54.4     |\n",
      "|    value_loss         | 0.000446 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0.203    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    std                | 55.6     |\n",
      "|    value_loss         | 0.000286 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 389      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | -2.77    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -0.223   |\n",
      "|    std                | 57.1     |\n",
      "|    value_loss         | 0.000145 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | -9.56    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 3.24     |\n",
      "|    std                | 58.7     |\n",
      "|    value_loss         | 0.00107  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.83e+03  |\n",
      "|    total_cost         | 3.31e+04  |\n",
      "|    total_reward       | -4.52e+04 |\n",
      "|    total_reward_pct   | -90.3     |\n",
      "|    total_trades       | 29312     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 393       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 7.23      |\n",
      "|    std                | 60.2      |\n",
      "|    value_loss         | 0.00546   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 395       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -0.758    |\n",
      "|    std                | 61.5      |\n",
      "|    value_loss         | 0.000145  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 397       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -106      |\n",
      "|    explained_variance | -0.000345 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -0.807    |\n",
      "|    std                | 63.3      |\n",
      "|    value_loss         | 9.2e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | -0.246   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -3.08    |\n",
      "|    std                | 65.4     |\n",
      "|    value_loss         | 0.000998 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | -34.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -0.336   |\n",
      "|    std                | 67.5     |\n",
      "|    value_loss         | 6.18e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.59e+03  |\n",
      "|    total_cost         | 2.38e+04  |\n",
      "|    total_reward       | -4.74e+04 |\n",
      "|    total_reward_pct   | -94.8     |\n",
      "|    total_trades       | 28664     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 404       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -107      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | 0.55      |\n",
      "|    std                | 69.1      |\n",
      "|    value_loss         | 9.34e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 70.9     |\n",
      "|    value_loss         | 0.000459 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 408      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | -0.898   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -2.31    |\n",
      "|    std                | 72.8     |\n",
      "|    value_loss         | 0.000694 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | -0.622   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 0.526    |\n",
      "|    std                | 75.1     |\n",
      "|    value_loss         | 4.84e-05 |\n",
      "------------------------------------\n",
      "day: 2397, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -7789.76\n",
      "total_reward: -57789.76\n",
      "total_cost: 25010.25\n",
      "total_trades: 28257\n",
      "Sharpe: -0.279\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -7.79e+03 |\n",
      "|    total_cost         | 2.5e+04   |\n",
      "|    total_reward       | -5.78e+04 |\n",
      "|    total_reward_pct   | -116      |\n",
      "|    total_trades       | 28257     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 413       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -110      |\n",
      "|    explained_variance | -3.6      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 0.0148    |\n",
      "|    std                | 77.6      |\n",
      "|    value_loss         | 0.000101  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 415      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | -0.605   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    std                | 80.1     |\n",
      "|    value_loss         | 0.000267 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 417       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -111      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -1.22     |\n",
      "|    std                | 82.9      |\n",
      "|    value_loss         | 0.000341  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 419      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -0.467   |\n",
      "|    std                | 85.1     |\n",
      "|    value_loss         | 0.000706 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 421      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | -0.705   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -4.68    |\n",
      "|    std                | 87.2     |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.57e+03  |\n",
      "|    total_cost         | 2.76e+04  |\n",
      "|    total_reward       | -4.74e+04 |\n",
      "|    total_reward_pct   | -94.9     |\n",
      "|    total_trades       | 28507     |\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 423       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -112      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -0.445    |\n",
      "|    std                | 89.8      |\n",
      "|    value_loss         | 6.05e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 425      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -113     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.569    |\n",
      "|    std                | 92.3     |\n",
      "|    value_loss         | 2.86e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 428      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | -0.875   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 0.2      |\n",
      "|    std                | 95.7     |\n",
      "|    value_loss         | 4.06e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 430      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 0.018    |\n",
      "|    std                | 99.7     |\n",
      "|    value_loss         | 2.69e-07 |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-10-02 to  2020-01-03\n",
      "A2C Sharpe Ratio:  0.37353703063143073\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 271  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.83e+03    |\n",
      "|    total_cost           | 4.52e+04    |\n",
      "|    total_reward         | -4.22e+04   |\n",
      "|    total_reward_pct     | -84.3       |\n",
      "|    total_trades         | 29574       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016856492 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0492      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+03    |\n",
      "|    total_cost           | 2.22e+04    |\n",
      "|    total_reward         | -4.72e+04   |\n",
      "|    total_reward_pct     | -94.4       |\n",
      "|    total_trades         | 27675       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012522804 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.321      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 19453.03\n",
      "total_reward: -30546.97\n",
      "total_cost: 43249.18\n",
      "total_trades: 29494\n",
      "Sharpe: 0.100\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.95e+04    |\n",
      "|    total_cost           | 4.32e+04    |\n",
      "|    total_reward         | -3.05e+04   |\n",
      "|    total_reward_pct     | -61.1       |\n",
      "|    total_trades         | 29494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021773193 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.64e+03    |\n",
      "|    total_cost           | 2.8e+04     |\n",
      "|    total_reward         | -4.34e+04   |\n",
      "|    total_reward_pct     | -86.7       |\n",
      "|    total_trades         | 28410       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016192753 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0126      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.32e+04    |\n",
      "|    total_cost           | 3.83e+04    |\n",
      "|    total_reward         | -3.68e+04   |\n",
      "|    total_reward_pct     | -73.7       |\n",
      "|    total_trades         | 29250       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018337503 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.0675     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.258      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0143      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 257        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01980171 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.1      |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.297     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0235    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0111     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.99e+03    |\n",
      "|    total_cost           | 2.49e+04    |\n",
      "|    total_reward         | -4.5e+04    |\n",
      "|    total_reward_pct     | -90         |\n",
      "|    total_trades         | 28048       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018068146 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00332     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.7e+04     |\n",
      "|    total_cost           | 3.15e+04    |\n",
      "|    total_reward         | -3.3e+04    |\n",
      "|    total_reward_pct     | -66         |\n",
      "|    total_trades         | 28037       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022571864 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0139      |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 25833.87\n",
      "total_reward: -24166.13\n",
      "total_cost: 58606.93\n",
      "total_trades: 30398\n",
      "Sharpe: -0.078\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+04    |\n",
      "|    total_cost           | 5.86e+04    |\n",
      "|    total_reward         | -2.42e+04   |\n",
      "|    total_reward_pct     | -48.3       |\n",
      "|    total_trades         | 30398       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022943866 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -1.84       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.17e+03    |\n",
      "|    total_cost           | 2.54e+04    |\n",
      "|    total_reward         | -4.08e+04   |\n",
      "|    total_reward_pct     | -81.7       |\n",
      "|    total_trades         | 27816       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015129227 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0185      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.93e+03   |\n",
      "|    total_cost           | 2.07e+04   |\n",
      "|    total_reward         | -4.11e+04  |\n",
      "|    total_reward_pct     | -82.1      |\n",
      "|    total_trades         | 27696      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 256        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 95         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02586369 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.277     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.023     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.00859    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.95e+04    |\n",
      "|    total_cost           | 4.81e+04    |\n",
      "|    total_reward         | -2.05e+04   |\n",
      "|    total_reward_pct     | -41.1       |\n",
      "|    total_trades         | 29618       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022297159 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0064      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017461848 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.22e+03   |\n",
      "|    total_cost           | 2.12e+04   |\n",
      "|    total_reward         | -4.38e+04  |\n",
      "|    total_reward_pct     | -87.6      |\n",
      "|    total_trades         | 27431      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 256        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02095037 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.4      |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0239    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.00259    |\n",
      "----------------------------------------\n",
      "day: 2397, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 63925.91\n",
      "total_reward: 13925.91\n",
      "total_cost: 85499.99\n",
      "total_trades: 31157\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.39e+04    |\n",
      "|    total_cost           | 8.55e+04    |\n",
      "|    total_reward         | 1.39e+04    |\n",
      "|    total_reward_pct     | 27.9        |\n",
      "|    total_trades         | 31157       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026778612 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | -0.609      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0556      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -5.96e+03   |\n",
      "|    total_cost           | 2e+04       |\n",
      "|    total_reward         | -5.6e+04    |\n",
      "|    total_reward_pct     | -112        |\n",
      "|    total_trades         | 27439       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021237805 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.89e+04   |\n",
      "|    total_cost           | 4.47e+04   |\n",
      "|    total_reward         | -2.11e+04  |\n",
      "|    total_reward_pct     | -42.2      |\n",
      "|    total_trades         | 29408      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 255        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02673047 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.414      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.307     |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.016      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.15e+04    |\n",
      "|    total_cost           | 2.63e+04    |\n",
      "|    total_reward         | -3.85e+04   |\n",
      "|    total_reward_pct     | -77         |\n",
      "|    total_trades         | 27785       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017525878 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0152      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.64e+04  |\n",
      "|    total_cost           | 3.11e+04  |\n",
      "|    total_reward         | -3.36e+04 |\n",
      "|    total_reward_pct     | -67.2     |\n",
      "|    total_trades         | 28957     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 255       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 160       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0398247 |\n",
      "|    clip_fraction        | 0.236     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.6     |\n",
      "|    explained_variance   | 0.0884    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.305    |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -0.0174   |\n",
      "|    std                  | 1.03      |\n",
      "|    value_loss           | 0.0143    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135647105 |\n",
      "|    clip_fraction        | 0.213        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.6        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.273       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0183      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0103       |\n",
      "------------------------------------------\n",
      "day: 2397, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6267.37\n",
      "total_reward: -43732.63\n",
      "total_cost: 16653.19\n",
      "total_trades: 27744\n",
      "Sharpe: -0.049\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.27e+03    |\n",
      "|    total_cost           | 1.67e+04    |\n",
      "|    total_reward         | -4.37e+04   |\n",
      "|    total_reward_pct     | -87.5       |\n",
      "|    total_trades         | 27744       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026388193 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00282     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+03    |\n",
      "|    total_cost           | 1.4e+04     |\n",
      "|    total_reward         | -4.66e+04   |\n",
      "|    total_reward_pct     | -93.2       |\n",
      "|    total_trades         | 27086       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036648657 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00796     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.45e+03   |\n",
      "|    total_cost           | 2.11e+04   |\n",
      "|    total_reward         | -4.36e+04  |\n",
      "|    total_reward_pct     | -87.1      |\n",
      "|    total_trades         | 28136      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 255        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03365281 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | -0.122     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.299     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.00796    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+04    |\n",
      "|    total_cost           | 2.44e+04    |\n",
      "|    total_reward         | -3.87e+04   |\n",
      "|    total_reward_pct     | -77.5       |\n",
      "|    total_trades         | 28810       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025352377 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00758     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+04    |\n",
      "|    total_cost           | 2.34e+04    |\n",
      "|    total_reward         | -3.71e+04   |\n",
      "|    total_reward_pct     | -74.1       |\n",
      "|    total_trades         | 27952       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026024345 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00606     |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -7088.97\n",
      "total_reward: -57088.97\n",
      "total_cost: 14475.71\n",
      "total_trades: 27162\n",
      "Sharpe: 0.375\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -7.09e+03  |\n",
      "|    total_cost           | 1.45e+04   |\n",
      "|    total_reward         | -5.71e+04  |\n",
      "|    total_reward_pct     | -114       |\n",
      "|    total_trades         | 27162      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 255        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03652689 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.525      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.296     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.00817    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023325676 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00689     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+04    |\n",
      "|    total_cost           | 3.26e+04    |\n",
      "|    total_reward         | -2.86e+04   |\n",
      "|    total_reward_pct     | -57.3       |\n",
      "|    total_trades         | 28791       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011478738 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00812     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.72e+03   |\n",
      "|    total_cost           | 1.82e+04    |\n",
      "|    total_reward         | -5.17e+04   |\n",
      "|    total_reward_pct     | -103        |\n",
      "|    total_trades         | 27594       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024798632 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00466     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.56e+04    |\n",
      "|    total_cost           | 2.48e+04    |\n",
      "|    total_reward         | -2.44e+04   |\n",
      "|    total_reward_pct     | -48.9       |\n",
      "|    total_trades         | 28299       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034643516 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.329      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00946     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -3.27e+03   |\n",
      "|    total_cost           | 1.3e+04     |\n",
      "|    total_reward         | -5.33e+04   |\n",
      "|    total_reward_pct     | -107        |\n",
      "|    total_trades         | 26815       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028707994 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00978     |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5237.99\n",
      "total_reward: -44762.01\n",
      "total_cost: 12406.17\n",
      "total_trades: 26827\n",
      "Sharpe: 0.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.24e+03    |\n",
      "|    total_cost           | 1.24e+04    |\n",
      "|    total_reward         | -4.48e+04   |\n",
      "|    total_reward_pct     | -89.5       |\n",
      "|    total_trades         | 26827       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019489784 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0039      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.53e+04    |\n",
      "|    total_cost           | 2.45e+04    |\n",
      "|    total_reward         | -3.47e+04   |\n",
      "|    total_reward_pct     | -69.5       |\n",
      "|    total_trades         | 28353       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022670656 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.321      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00576     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027111847 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.322      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00632     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.58e+04    |\n",
      "|    total_cost           | 3.33e+04    |\n",
      "|    total_reward         | -3.42e+04   |\n",
      "|    total_reward_pct     | -68.4       |\n",
      "|    total_trades         | 29329       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017146036 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.322      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+04     |\n",
      "|    total_cost           | 3.28e+04    |\n",
      "|    total_reward         | -2.2e+04    |\n",
      "|    total_reward_pct     | -44.1       |\n",
      "|    total_trades         | 29211       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018518053 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.4e+04    |\n",
      "|    total_cost           | 2.31e+04   |\n",
      "|    total_reward         | -2.6e+04   |\n",
      "|    total_reward_pct     | -52        |\n",
      "|    total_trades         | 28536      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 255        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02155488 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.331     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.00717    |\n",
      "----------------------------------------\n",
      "day: 2397, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -2926.62\n",
      "total_reward: -52926.62\n",
      "total_cost: 17749.10\n",
      "total_trades: 27844\n",
      "Sharpe: 0.024\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -2.93e+03   |\n",
      "|    total_cost           | 1.77e+04    |\n",
      "|    total_reward         | -5.29e+04   |\n",
      "|    total_reward_pct     | -106        |\n",
      "|    total_trades         | 27844       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033881333 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0041      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.78e+04    |\n",
      "|    total_cost           | 1.98e+04    |\n",
      "|    total_reward         | -3.22e+04   |\n",
      "|    total_reward_pct     | -64.3       |\n",
      "|    total_trades         | 28069       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028963827 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00339     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.52e+04    |\n",
      "|    total_cost           | 2e+04       |\n",
      "|    total_reward         | -3.48e+04   |\n",
      "|    total_reward_pct     | -69.5       |\n",
      "|    total_trades         | 28195       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037377916 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00398     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035814054 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.00214     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00833     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+04    |\n",
      "|    total_cost           | 2.2e+04     |\n",
      "|    total_reward         | -3.66e+04   |\n",
      "|    total_reward_pct     | -73.2       |\n",
      "|    total_trades         | 28763       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014093785 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00524     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+04    |\n",
      "|    total_cost           | 3.06e+04    |\n",
      "|    total_reward         | -2.01e+04   |\n",
      "|    total_reward_pct     | -40.3       |\n",
      "|    total_trades         | 29070       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025202189 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00712     |\n",
      "-----------------------------------------\n",
      "day: 2397, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8340.95\n",
      "total_reward: -41659.05\n",
      "total_cost: 15729.64\n",
      "total_trades: 27652\n",
      "Sharpe: -0.033\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.34e+03   |\n",
      "|    total_cost           | 1.57e+04   |\n",
      "|    total_reward         | -4.17e+04  |\n",
      "|    total_reward_pct     | -83.3      |\n",
      "|    total_trades         | 27652      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 255        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 360        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02371919 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.8      |\n",
      "|    explained_variance   | 0.647      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.302     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.00613    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.19e+04    |\n",
      "|    total_cost           | 2.74e+04    |\n",
      "|    total_reward         | -8.07e+03   |\n",
      "|    total_reward_pct     | -16.1       |\n",
      "|    total_trades         | 28683       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027384259 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.00275     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.33e+03    |\n",
      "|    total_cost           | 1.5e+04     |\n",
      "|    total_reward         | -4.17e+04   |\n",
      "|    total_reward_pct     | -83.3       |\n",
      "|    total_trades         | 27690       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038208365 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 384         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030000538 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.00274     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.46e+04    |\n",
      "|    total_cost           | 2.13e+04    |\n",
      "|    total_reward         | -3.54e+04   |\n",
      "|    total_reward_pct     | -70.8       |\n",
      "|    total_trades         | 28010       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032197326 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -29         |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-10-02 to  2020-01-03\n",
      "PPO Sharpe Ratio:  0.1955096385487485\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
      "day: 2397, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 86260.73\n",
      "total_reward: 36260.73\n",
      "total_cost: 2678.43\n",
      "total_trades: 21431\n",
      "Sharpe: 0.358\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.3e+04   |\n",
      "|    total_cost       | 151       |\n",
      "|    total_reward     | -7.01e+03 |\n",
      "|    total_reward_pct | -14       |\n",
      "|    total_trades     | 26006     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 117       |\n",
      "|    time_elapsed     | 81        |\n",
      "|    total timesteps  | 9592      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -33.9     |\n",
      "|    critic_loss      | 3.52      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7194      |\n",
      "-----------------------------------\n",
      "day: 2397, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48634.28\n",
      "total_reward: -1365.72\n",
      "total_cost: 124.88\n",
      "total_trades: 26082\n",
      "Sharpe: 0.351\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.75e+04  |\n",
      "|    total_cost       | 123       |\n",
      "|    total_reward     | -2.53e+03 |\n",
      "|    total_reward_pct | -5.06     |\n",
      "|    total_trades     | 25259     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 108       |\n",
      "|    time_elapsed     | 176       |\n",
      "|    total timesteps  | 19184     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -22.8     |\n",
      "|    critic_loss      | 1.48      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16786     |\n",
      "-----------------------------------\n",
      "day: 2397, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 45765.77\n",
      "total_reward: -4234.23\n",
      "total_cost: 144.14\n",
      "total_trades: 21237\n",
      "Sharpe: 0.439\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.44e+04 |\n",
      "|    total_cost       | 123      |\n",
      "|    total_reward     | -5.6e+03 |\n",
      "|    total_reward_pct | -11.2    |\n",
      "|    total_trades     | 21243    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total timesteps  | 28776    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -14      |\n",
      "|    critic_loss      | 0.875    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 26378    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49948.60\n",
      "total_reward: -51.40\n",
      "total_cost: 99.88\n",
      "total_trades: 21476\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+04 |\n",
      "|    total_cost       | 99.9     |\n",
      "|    total_reward     | -51.4    |\n",
      "|    total_reward_pct | -0.103   |\n",
      "|    total_trades     | 21476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total timesteps  | 38368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -8.69    |\n",
      "|    critic_loss      | 0.539    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35970    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.01e+04 |\n",
      "|    total_cost       | 101      |\n",
      "|    total_reward     | 69.7     |\n",
      "|    total_reward_pct | 0.139    |\n",
      "|    total_trades     | 20961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 464      |\n",
      "|    total timesteps  | 47960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -5.49    |\n",
      "|    critic_loss      | 0.443    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 45562    |\n",
      "----------------------------------\n",
      "day: 2397, episode: 105\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48926.27\n",
      "total_reward: -1073.73\n",
      "total_cost: 99.25\n",
      "total_trades: 20918\n",
      "Sharpe: 0.400\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-02 to  2020-01-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_315_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -3.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -7.39    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -10.8     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.177     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | -0.0416  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 15.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.368    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -2       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.559    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0337   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+05 |\n",
      "|    total_cost         | 1.47e+04 |\n",
      "|    total_reward       | 5.62e+04 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 24849    |\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -9.21    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -1.57    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.006    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | -24.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00627  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | -120     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.00299  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | 0.0421   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.509    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00121  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.6    |\n",
      "|    explained_variance | 0.00189  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 5.97     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0462   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.64e+04 |\n",
      "|    total_cost         | 1.08e+04 |\n",
      "|    total_reward       | 6.36e+03 |\n",
      "|    total_reward_pct   | 12.7     |\n",
      "|    total_trades       | 25106    |\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -7.21    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -3.19    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0221   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.9    |\n",
      "|    explained_variance | -0.582   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -6.67    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0609   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -4.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -4.4     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0336   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0.422    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -11      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.611   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 4.41     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.049    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.34e+05 |\n",
      "|    total_cost         | 2.38e+04 |\n",
      "|    total_reward       | 8.39e+04 |\n",
      "|    total_reward_pct   | 168      |\n",
      "|    total_trades       | 26960    |\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.4    |\n",
      "|    explained_variance | -21.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.956   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.8    |\n",
      "|    explained_variance | -138     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -2.46    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.00697  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.862    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.00098  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | -0.0336  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.563   |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.00191  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | -0.0121  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.983   |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0112   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.47e+04 |\n",
      "|    total_cost         | 6.66e+03 |\n",
      "|    total_reward       | 1.47e+04 |\n",
      "|    total_reward_pct   | 29.4     |\n",
      "|    total_trades       | 24035    |\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -2.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.286    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.0032   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.371    |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.000206 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31      |\n",
      "|    explained_variance | -1.69    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -1.38    |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.147   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -5.47    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0609   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | 0.273    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -6.58    |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.0599   |\n",
      "------------------------------------\n",
      "day: 2460, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48609.84\n",
      "total_reward: -1390.16\n",
      "total_cost: 6381.36\n",
      "total_trades: 23202\n",
      "Sharpe: 0.207\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.86e+04  |\n",
      "|    total_cost         | 6.38e+03  |\n",
      "|    total_reward       | -1.39e+03 |\n",
      "|    total_reward_pct   | -2.78     |\n",
      "|    total_trades       | 23202     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.4     |\n",
      "|    explained_variance | -7.04     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -0.361    |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.00209   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | -0.383   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0862  |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 2.78e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | -1.2     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -2.64    |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.0161   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.4    |\n",
      "|    explained_variance | 0.0393   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 11.4     |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | -2.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.76e+04  |\n",
      "|    total_cost         | 3.49e+03  |\n",
      "|    total_reward       | -2.44e+03 |\n",
      "|    total_reward_pct   | -4.89     |\n",
      "|    total_trades       | 22692     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.8     |\n",
      "|    explained_variance | -0.348    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 0.62      |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 0.000429  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | 0.0338   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.738    |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.000585 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -27.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0324  |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.00321  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 8.21     |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.0822   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -2.33    |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 0.00906  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.42e+04 |\n",
      "|    total_cost         | 2.11e+03 |\n",
      "|    total_reward       | 4.19e+03 |\n",
      "|    total_reward_pct   | 8.37     |\n",
      "|    total_trades       | 22747    |\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.8    |\n",
      "|    explained_variance | -5.45    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.00518  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 1.49     |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 0.00193  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | -0.462   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 3.38     |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.0155   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | -3.71    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 4.13     |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.047    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -1.28    |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 0.00216  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.12e+04 |\n",
      "|    total_cost         | 1.29e+03 |\n",
      "|    total_reward       | 2.12e+04 |\n",
      "|    total_reward_pct   | 42.3     |\n",
      "|    total_trades       | 22737    |\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 2.29     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0088   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00273  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.1    |\n",
      "|    explained_variance | -0.82    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 0.00379  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | -0.287   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -7.58    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.0707   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -7.75    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.352    |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.00876  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.14e+04  |\n",
      "|    total_cost         | 1.17e+03  |\n",
      "|    total_reward       | -2.86e+04 |\n",
      "|    total_reward_pct   | -57.2     |\n",
      "|    total_trades       | 21782     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.6     |\n",
      "|    explained_variance | 0.761     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 0.283     |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 7.56e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -2.86    |\n",
      "|    std                | 1.6      |\n",
      "|    value_loss         | 0.00709  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.318   |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.000492 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -8.5     |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.0807   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 0.771     |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 0.000771  |\n",
      "-------------------------------------\n",
      "day: 2460, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 46036.37\n",
      "total_reward: -3963.63\n",
      "total_cost: 623.98\n",
      "total_trades: 21685\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.6e+04   |\n",
      "|    total_cost         | 624       |\n",
      "|    total_reward       | -3.96e+03 |\n",
      "|    total_reward_pct   | -7.93     |\n",
      "|    total_trades       | 21685     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 0.806     |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 0.000549  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.00515  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | -6.75    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -2.29    |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.00697  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -2.65    |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.00889  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 5.62     |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 0.0259   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.28e+04  |\n",
      "|    total_cost         | 968       |\n",
      "|    total_reward       | -1.72e+04 |\n",
      "|    total_reward_pct   | -34.3     |\n",
      "|    total_trades       | 21419     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.6     |\n",
      "|    explained_variance | 1.98e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -1.46     |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 0.00282   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | 0.00418  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 4.19     |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.0117   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | 0.000468 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 5.22     |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.023    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 0.545    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -9.68    |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.0699   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.562    |\n",
      "|    std                | 1.81     |\n",
      "|    value_loss         | 0.00239  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.54e+04 |\n",
      "|    total_cost         | 1.31e+03 |\n",
      "|    total_reward       | 3.54e+04 |\n",
      "|    total_reward_pct   | 70.8     |\n",
      "|    total_trades       | 21359    |\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | -24.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.0997   |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 4.95e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.643   |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | 0.317    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -1.18    |\n",
      "|    std                | 1.91     |\n",
      "|    value_loss         | 0.00116  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.302   |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.00765  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.14e+04  |\n",
      "|    total_cost         | 374       |\n",
      "|    total_reward       | -2.86e+04 |\n",
      "|    total_reward_pct   | -57.3     |\n",
      "|    total_trades       | 21025     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.8     |\n",
      "|    explained_variance | 0.273     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -29.5     |\n",
      "|    std                | 1.97      |\n",
      "|    value_loss         | 2.72      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | -1.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -3.54    |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 0.00785  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -2.58    |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.00481  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.9    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 3.3      |\n",
      "|    std                | 2.08     |\n",
      "|    value_loss         | 0.00794  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 12.6     |\n",
      "|    std                | 2.1      |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.75e+03  |\n",
      "|    total_cost         | 672       |\n",
      "|    total_reward       | -4.23e+04 |\n",
      "|    total_reward_pct   | -84.5     |\n",
      "|    total_trades       | 20598     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 0.0618    |\n",
      "|    std                | 2.12      |\n",
      "|    value_loss         | 0.000117  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -1.92    |\n",
      "|    std                | 2.15     |\n",
      "|    value_loss         | 0.00209  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 0.48     |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 0.000236 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | -0.231   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.581   |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 0.000362 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.264    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -2.99    |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 0.00548  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17405.04\n",
      "total_reward: -32594.96\n",
      "total_cost: 311.96\n",
      "total_trades: 20231\n",
      "Sharpe: 0.133\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.74e+04  |\n",
      "|    total_cost         | 312       |\n",
      "|    total_reward       | -3.26e+04 |\n",
      "|    total_reward_pct   | -65.2     |\n",
      "|    total_trades       | 20231     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -0.00721  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -5.05     |\n",
      "|    std                | 2.33      |\n",
      "|    value_loss         | 0.015     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.00328  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.341   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 4.95     |\n",
      "|    std                | 2.4      |\n",
      "|    value_loss         | 0.0168   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | -0.215   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 2.92     |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.00697  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -9.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -10.7    |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 0.0659   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.28e+04  |\n",
      "|    total_cost         | 1.18e+03  |\n",
      "|    total_reward       | -7.25e+03 |\n",
      "|    total_reward_pct   | -14.5     |\n",
      "|    total_trades       | 21260     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -0.293    |\n",
      "|    std                | 2.47      |\n",
      "|    value_loss         | 8.25e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 0.265     |\n",
      "|    std                | 2.5       |\n",
      "|    value_loss         | 7.88e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -1.67    |\n",
      "|    std                | 2.55     |\n",
      "|    value_loss         | 0.00168  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 8.68      |\n",
      "|    std                | 2.59      |\n",
      "|    value_loss         | 0.0472    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -5.18    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.0124   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.09e+04  |\n",
      "|    total_cost         | 1.28e+03  |\n",
      "|    total_reward       | -1.91e+04 |\n",
      "|    total_reward_pct   | -38.1     |\n",
      "|    total_trades       | 22230     |\n",
      "| time/                 |           |\n",
      "|    fps                | 231       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 181       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 2.49      |\n",
      "|    std                | 2.64      |\n",
      "|    value_loss         | 0.00404   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | -13.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.00107  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | -0.508   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -3.47    |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 0.00664  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | -0.0876  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    std                | 2.76     |\n",
      "|    value_loss         | 0.0953   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0.626    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -5.16    |\n",
      "|    std                | 2.79     |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.45e+04  |\n",
      "|    total_cost         | 1.05e+03  |\n",
      "|    total_reward       | -5.48e+03 |\n",
      "|    total_reward_pct   | -11       |\n",
      "|    total_trades       | 21301     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -1.5      |\n",
      "|    std                | 2.82      |\n",
      "|    value_loss         | 0.00217   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | -5.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    std                | 2.85     |\n",
      "|    value_loss         | 0.00072  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | -0.0244  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -2.83     |\n",
      "|    std                | 2.92      |\n",
      "|    value_loss         | 0.0108    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -0.0382  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -1.84    |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.00966  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.07e+04 |\n",
      "|    total_cost         | 1.26e+03 |\n",
      "|    total_reward       | 728      |\n",
      "|    total_reward_pct   | 1.46     |\n",
      "|    total_trades       | 21270    |\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -1.81    |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 0.00219  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    std                | 3.02     |\n",
      "|    value_loss         | 0.00117  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0.197    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 1.49     |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.00132  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 0.067    |\n",
      "|    std                | 3.12     |\n",
      "|    value_loss         | 0.0056   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 1.7      |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "day: 2460, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 29697.97\n",
      "total_reward: -20302.03\n",
      "total_cost: 2328.95\n",
      "total_trades: 22137\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.97e+04  |\n",
      "|    total_cost         | 2.33e+03  |\n",
      "|    total_reward       | -2.03e+04 |\n",
      "|    total_reward_pct   | -40.6     |\n",
      "|    total_trades       | 22137     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -0.00524  |\n",
      "|    std                | 3.21      |\n",
      "|    value_loss         | 1.28e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 0.125    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -1.37    |\n",
      "|    std                | 3.28     |\n",
      "|    value_loss         | 0.00088  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0.214    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 1.95     |\n",
      "|    std                | 3.35     |\n",
      "|    value_loss         | 0.00254  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -9.2     |\n",
      "|    std                | 3.4      |\n",
      "|    value_loss         | 0.0639   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.4    |\n",
      "|    explained_variance | -12.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 3.12     |\n",
      "|    std                | 3.43     |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.12e+04  |\n",
      "|    total_cost         | 3.26e+03  |\n",
      "|    total_reward       | -8.79e+03 |\n",
      "|    total_reward_pct   | -17.6     |\n",
      "|    total_trades       | 22885     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.6     |\n",
      "|    explained_variance | -2.62e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 0.235     |\n",
      "|    std                | 3.48      |\n",
      "|    value_loss         | 0.000127  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -3.27    |\n",
      "|    std                | 3.53     |\n",
      "|    value_loss         | 0.00426  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | -0.0124  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -7.53    |\n",
      "|    std                | 3.57     |\n",
      "|    value_loss         | 0.0227   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 231       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 11.2      |\n",
      "|    std                | 3.59      |\n",
      "|    value_loss         | 0.0555    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | -0.328   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 9.93     |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.06e+04 |\n",
      "|    total_cost         | 2.81e+03 |\n",
      "|    total_reward       | 4.06e+04 |\n",
      "|    total_reward_pct   | 81.2     |\n",
      "|    total_trades       | 23592    |\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -3.45    |\n",
      "|    std                | 3.65     |\n",
      "|    value_loss         | 0.00486  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.906   |\n",
      "|    std                | 3.71     |\n",
      "|    value_loss         | 0.000384 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 0.8      |\n",
      "|    std                | 3.78     |\n",
      "|    value_loss         | 0.000311 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -1.95    |\n",
      "|    std                | 3.84     |\n",
      "|    value_loss         | 0.00295  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -0.497   |\n",
      "|    std                | 3.89     |\n",
      "|    value_loss         | 0.000383 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.23e+03  |\n",
      "|    total_cost         | 1.41e+03  |\n",
      "|    total_reward       | -4.08e+04 |\n",
      "|    total_reward_pct   | -81.5     |\n",
      "|    total_trades       | 23693     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 4.46      |\n",
      "|    std                | 3.93      |\n",
      "|    value_loss         | 0.0199    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.1    |\n",
      "|    explained_variance | 0.534    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.451   |\n",
      "|    std                | 3.97     |\n",
      "|    value_loss         | 0.000544 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 5.23     |\n",
      "|    std                | 4        |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -0.717   |\n",
      "|    std                | 4.01     |\n",
      "|    value_loss         | 0.0369   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -3.64    |\n",
      "|    std                | 4.04     |\n",
      "|    value_loss         | 0.00545  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+05  |\n",
      "|    total_cost         | 3.27e+03 |\n",
      "|    total_reward       | 6.95e+04 |\n",
      "|    total_reward_pct   | 139      |\n",
      "|    total_trades       | 24853    |\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.7    |\n",
      "|    explained_variance | -0.631   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.0984   |\n",
      "|    std                | 4.09     |\n",
      "|    value_loss         | 0.00166  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -1.88     |\n",
      "|    std                | 4.16      |\n",
      "|    value_loss         | 0.00164   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | -1.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -8.97    |\n",
      "|    std                | 4.21     |\n",
      "|    value_loss         | 0.0327   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -1.04    |\n",
      "|    std                | 4.24     |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 3.43     |\n",
      "|    std                | 4.27     |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "day: 2460, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 36084.28\n",
      "total_reward: -13915.72\n",
      "total_cost: 3046.14\n",
      "total_trades: 25435\n",
      "Sharpe: -0.145\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.61e+04  |\n",
      "|    total_cost         | 3.05e+03  |\n",
      "|    total_reward       | -1.39e+04 |\n",
      "|    total_reward_pct   | -27.8     |\n",
      "|    total_trades       | 25435     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 268       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.8     |\n",
      "|    explained_variance | -4.31     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | 1.81      |\n",
      "|    std                | 4.32      |\n",
      "|    value_loss         | 0.00121   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -2.71    |\n",
      "|    std                | 4.4      |\n",
      "|    value_loss         | 0.00364  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    std                | 4.48     |\n",
      "|    value_loss         | 0.00267  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -5.06    |\n",
      "|    std                | 4.51     |\n",
      "|    value_loss         | 0.0252   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.83e+04  |\n",
      "|    total_cost         | 4.97e+03  |\n",
      "|    total_reward       | -3.17e+04 |\n",
      "|    total_reward_pct   | -63.4     |\n",
      "|    total_trades       | 25356     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 277       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 0.821     |\n",
      "|    std                | 4.55      |\n",
      "|    value_loss         | 0.000243  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | -0.00241 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -3.3     |\n",
      "|    std                | 4.6      |\n",
      "|    value_loss         | 0.00372  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 8.43     |\n",
      "|    std                | 4.66     |\n",
      "|    value_loss         | 0.0387   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 4.18     |\n",
      "|    std                | 4.71     |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -2.33    |\n",
      "|    std                | 4.74     |\n",
      "|    value_loss         | 0.00936  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.97e+04 |\n",
      "|    total_cost         | 4.79e+03 |\n",
      "|    total_reward       | 1.97e+04 |\n",
      "|    total_reward_pct   | 39.5     |\n",
      "|    total_trades       | 24896    |\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | -10.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 2.58     |\n",
      "|    std                | 4.77     |\n",
      "|    value_loss         | 0.00325  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 4.85     |\n",
      "|    value_loss         | 0.000521 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -0.445   |\n",
      "|    std                | 4.96     |\n",
      "|    value_loss         | 6.47e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.7    |\n",
      "|    explained_variance | 0.181    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -1.82    |\n",
      "|    std                | 5.04     |\n",
      "|    value_loss         | 0.00563  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.7    |\n",
      "|    explained_variance | -0.129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -2.54    |\n",
      "|    std                | 5.06     |\n",
      "|    value_loss         | 0.0103   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.5e+04   |\n",
      "|    total_cost         | 8.03e+03  |\n",
      "|    total_reward       | -4.97e+03 |\n",
      "|    total_reward_pct   | -9.93     |\n",
      "|    total_trades       | 26575     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 299       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.9     |\n",
      "|    explained_variance | 0.0465    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 1.43      |\n",
      "|    std                | 5.1       |\n",
      "|    value_loss         | 0.000857  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 301       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 0.172     |\n",
      "|    std                | 5.18      |\n",
      "|    value_loss         | 2.36e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 0.232    |\n",
      "|    std                | 5.28     |\n",
      "|    value_loss         | 8.06e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | 0.456    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -2.22    |\n",
      "|    std                | 5.37     |\n",
      "|    value_loss         | 0.00169  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | -1.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -2.25    |\n",
      "|    std                | 5.45     |\n",
      "|    value_loss         | 0.0027   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.09e+03  |\n",
      "|    total_cost         | 4.62e+03  |\n",
      "|    total_reward       | -4.49e+04 |\n",
      "|    total_reward_pct   | -89.8     |\n",
      "|    total_trades       | 26544     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | 2.46      |\n",
      "|    std                | 5.52      |\n",
      "|    value_loss         | 0.00202   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.7    |\n",
      "|    explained_variance | -14.1    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 0.456    |\n",
      "|    std                | 5.62     |\n",
      "|    value_loss         | 0.000208 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.1    |\n",
      "|    explained_variance | -0.177   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.283    |\n",
      "|    std                | 5.74     |\n",
      "|    value_loss         | 0.000197 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.4    |\n",
      "|    explained_variance | -0.0016  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 3.52     |\n",
      "|    std                | 5.83     |\n",
      "|    value_loss         | 0.00756  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 319       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 0.85      |\n",
      "|    std                | 5.87      |\n",
      "|    value_loss         | 0.0154    |\n",
      "-------------------------------------\n",
      "day: 2460, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -5162.83\n",
      "total_reward: -55162.83\n",
      "total_cost: 9640.67\n",
      "total_trades: 27273\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -5.16e+03 |\n",
      "|    total_cost         | 9.64e+03  |\n",
      "|    total_reward       | -5.52e+04 |\n",
      "|    total_reward_pct   | -110      |\n",
      "|    total_trades       | 27273     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 321       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -0.248    |\n",
      "|    std                | 5.92      |\n",
      "|    value_loss         | 1.74e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61      |\n",
      "|    explained_variance | -40.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.255   |\n",
      "|    std                | 6.02     |\n",
      "|    value_loss         | 0.000216 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 325      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 4.78     |\n",
      "|    std                | 6.15     |\n",
      "|    value_loss         | 0.00658  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 10.1     |\n",
      "|    std                | 6.27     |\n",
      "|    value_loss         | 0.0336   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62      |\n",
      "|    explained_variance | -0.0162  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 5.8      |\n",
      "|    std                | 6.33     |\n",
      "|    value_loss         | 0.00927  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.96e+04  |\n",
      "|    total_cost         | 1.17e+04  |\n",
      "|    total_reward       | -1.04e+04 |\n",
      "|    total_reward_pct   | -20.8     |\n",
      "|    total_trades       | 27217     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 332       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -0.345    |\n",
      "|    std                | 6.4       |\n",
      "|    value_loss         | 3.68e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.661    |\n",
      "|    std                | 6.51     |\n",
      "|    value_loss         | 0.000149 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.9    |\n",
      "|    explained_variance | 0.601    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    std                | 6.64     |\n",
      "|    value_loss         | 0.000437 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.2    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -3.45    |\n",
      "|    std                | 6.76     |\n",
      "|    value_loss         | 0.00407  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -1.32    |\n",
      "|    std                | 6.85     |\n",
      "|    value_loss         | 0.000521 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.37e+03  |\n",
      "|    total_cost         | 1.86e+04  |\n",
      "|    total_reward       | -4.06e+04 |\n",
      "|    total_reward_pct   | -81.3     |\n",
      "|    total_trades       | 27494     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 343       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | 0.702     |\n",
      "|    std                | 6.98      |\n",
      "|    value_loss         | 0.000179  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.3    |\n",
      "|    explained_variance | -0.845   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.246   |\n",
      "|    std                | 7.14     |\n",
      "|    value_loss         | 3.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.8    |\n",
      "|    explained_variance | -1.49    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.314   |\n",
      "|    std                | 7.32     |\n",
      "|    value_loss         | 0.000493 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65      |\n",
      "|    explained_variance | -3.87    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -7.87    |\n",
      "|    std                | 7.43     |\n",
      "|    value_loss         | 0.0217   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -0.971   |\n",
      "|    std                | 7.49     |\n",
      "|    value_loss         | 0.000459 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.16e+04  |\n",
      "|    total_cost         | 2.41e+04  |\n",
      "|    total_reward       | -8.36e+03 |\n",
      "|    total_reward_pct   | -16.7     |\n",
      "|    total_trades       | 28095     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 354       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.4     |\n",
      "|    explained_variance | 0.045     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -1.01     |\n",
      "|    std                | 7.58      |\n",
      "|    value_loss         | 0.000863  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 2.48     |\n",
      "|    std                | 7.68     |\n",
      "|    value_loss         | 0.00165  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66      |\n",
      "|    explained_variance | -0.00016 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 3.57     |\n",
      "|    std                | 7.8      |\n",
      "|    value_loss         | 0.00315  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 360       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | -1.55     |\n",
      "|    std                | 7.91      |\n",
      "|    value_loss         | 0.00319   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 362      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.926    |\n",
      "|    std                | 7.98     |\n",
      "|    value_loss         | 0.000362 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.15e+04  |\n",
      "|    total_cost         | 2.48e+04  |\n",
      "|    total_reward       | -8.46e+03 |\n",
      "|    total_reward_pct   | -16.9     |\n",
      "|    total_trades       | 28404     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 364       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -0.44     |\n",
      "|    std                | 8.09      |\n",
      "|    value_loss         | 5.61e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.1    |\n",
      "|    explained_variance | 0.101    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    std                | 8.26     |\n",
      "|    value_loss         | 0.0406   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.135    |\n",
      "|    std                | 8.48     |\n",
      "|    value_loss         | 2.6e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 371      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    std                | 8.66     |\n",
      "|    value_loss         | 0.00672  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.3    |\n",
      "|    explained_variance | 0.253    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 5.55     |\n",
      "|    std                | 8.8      |\n",
      "|    value_loss         | 0.00739  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 20885.18\n",
      "total_reward: -29114.82\n",
      "total_cost: 28599.61\n",
      "total_trades: 28092\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.09e+04  |\n",
      "|    total_cost         | 2.86e+04  |\n",
      "|    total_reward       | -2.91e+04 |\n",
      "|    total_reward_pct   | -58.2     |\n",
      "|    total_trades       | 28092     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 375       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 0.0608    |\n",
      "|    std                | 8.96      |\n",
      "|    value_loss         | 1.16e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 378       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | 0.822     |\n",
      "|    std                | 9.2       |\n",
      "|    value_loss         | 0.000147  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.6    |\n",
      "|    explained_variance | -0.565   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 0.854    |\n",
      "|    std                | 9.43     |\n",
      "|    value_loss         | 0.00026  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 382      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -1.99    |\n",
      "|    std                | 9.63     |\n",
      "|    value_loss         | 0.00148  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 384      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.483    |\n",
      "|    std                | 9.82     |\n",
      "|    value_loss         | 0.000297 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.21e+04  |\n",
      "|    total_cost         | 2.56e+04  |\n",
      "|    total_reward       | -3.79e+04 |\n",
      "|    total_reward_pct   | -75.8     |\n",
      "|    total_trades       | 27664     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 386       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 0.992     |\n",
      "|    std                | 10.1      |\n",
      "|    value_loss         | 0.000212  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 389      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.4    |\n",
      "|    explained_variance | 0.309    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -1.97    |\n",
      "|    std                | 10.4     |\n",
      "|    value_loss         | 0.000834 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.9    |\n",
      "|    explained_variance | -2.44    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.138    |\n",
      "|    std                | 10.6     |\n",
      "|    value_loss         | 8.57e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -2.11    |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 0.000946 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 395      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.7    |\n",
      "|    explained_variance | -0.19    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -2.49    |\n",
      "|    std                | 11.1     |\n",
      "|    value_loss         | 0.00146  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.27e+04  |\n",
      "|    total_cost         | 2.95e+04  |\n",
      "|    total_reward       | -3.73e+04 |\n",
      "|    total_reward_pct   | -74.6     |\n",
      "|    total_trades       | 28209     |\n",
      "| time/                 |           |\n",
      "|    fps                | 230       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 397       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.2     |\n",
      "|    explained_variance | -3.17     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 0.477     |\n",
      "|    std                | 11.4      |\n",
      "|    value_loss         | 0.000438  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 399      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.0409  |\n",
      "|    std                | 11.8     |\n",
      "|    value_loss         | 9.21e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.103   |\n",
      "|    std                | 12.2     |\n",
      "|    value_loss         | 8.3e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 404      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.2    |\n",
      "|    explained_variance | 0.043    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 0.184    |\n",
      "|    std                | 12.7     |\n",
      "|    value_loss         | 8.54e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    std                | 13.2     |\n",
      "|    value_loss         | 0.000757 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -7.31e+03 |\n",
      "|    total_cost         | 1.23e+04  |\n",
      "|    total_reward       | -5.73e+04 |\n",
      "|    total_reward_pct   | -115      |\n",
      "|    total_trades       | 26871     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 408       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -0.0406   |\n",
      "|    std                | 13.6      |\n",
      "|    value_loss         | 1.98e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.507   |\n",
      "|    std                | 14.1     |\n",
      "|    value_loss         | 5.11e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 413      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    std                | 14.5     |\n",
      "|    value_loss         | 0.0029   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 415       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | -0.279    |\n",
      "|    std                | 14.8      |\n",
      "|    value_loss         | 0.000191  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.42e+04  |\n",
      "|    total_cost         | 3.58e+04  |\n",
      "|    total_reward       | -3.58e+04 |\n",
      "|    total_reward_pct   | -71.7     |\n",
      "|    total_trades       | 28795     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 417       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78.5     |\n",
      "|    explained_variance | -1.09e+04 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 125       |\n",
      "|    std                | 15.1      |\n",
      "|    value_loss         | 3.42      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 419      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -3.47    |\n",
      "|    std                | 15.2     |\n",
      "|    value_loss         | 0.00237  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 421      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 2.76     |\n",
      "|    std                | 15.5     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 424      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    std                | 15.8     |\n",
      "|    value_loss         | 0.000302 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -1.06    |\n",
      "|    std                | 16.1     |\n",
      "|    value_loss         | 0.00106  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 10496.44\n",
      "total_reward: -39503.56\n",
      "total_cost: 50093.43\n",
      "total_trades: 30344\n",
      "Sharpe: -0.429\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.05e+04  |\n",
      "|    total_cost         | 5.01e+04  |\n",
      "|    total_reward       | -3.95e+04 |\n",
      "|    total_reward_pct   | -79       |\n",
      "|    total_trades       | 30344     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 428       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -1.58     |\n",
      "|    std                | 16.4      |\n",
      "|    value_loss         | 0.00059   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 430      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.5    |\n",
      "|    explained_variance | -0.0106  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.696    |\n",
      "|    std                | 16.7     |\n",
      "|    value_loss         | 0.00021  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 432      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    std                | 17.2     |\n",
      "|    value_loss         | 0.000183 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.523   |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 4.47e-05 |\n",
      "------------------------------------\n",
      "======Trading from:  2020-01-03 to  2020-04-06\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2010-01-01 to  2020-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 2.52     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.021    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -0.582   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -3.15    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0221   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.0436   |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.00203  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -1.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -17      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.419    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.57e+05 |\n",
      "|    total_cost         | 1.96e+04 |\n",
      "|    total_reward       | 1.07e+05 |\n",
      "|    total_reward_pct   | 214      |\n",
      "|    total_trades       | 27415    |\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -5.31    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -1.61    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0344   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -9.25    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 4.01     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0303   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -0.161   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -1.68    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00343  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -2.07    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0299  |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00435  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -1.09    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 6.69     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0617   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.33e+04 |\n",
      "|    total_cost         | 1.2e+04  |\n",
      "|    total_reward       | 3.3e+03  |\n",
      "|    total_reward_pct   | 6.61     |\n",
      "|    total_trades       | 26198    |\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -67.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.8    |\n",
      "|    explained_variance | -5.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.268    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.000269 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.27    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.000117 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -7.5     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.812   |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30      |\n",
      "|    explained_variance | -73.7    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00231  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.11e+04  |\n",
      "|    total_cost         | 5.32e+03  |\n",
      "|    total_reward       | -3.89e+04 |\n",
      "|    total_reward_pct   | -77.9     |\n",
      "|    total_trades       | 25370     |\n",
      "| time/                 |           |\n",
      "|    fps                | 227       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | -36       |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -0.67     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.000753  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.0173   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 3.68     |\n",
      "|    std                | 1.22     |\n",
      "|    value_loss         | 0.013    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00132  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | -1.98    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.00393  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | -3.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.00546  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.83e+04  |\n",
      "|    total_cost         | 5.71e+03  |\n",
      "|    total_reward       | -1.17e+04 |\n",
      "|    total_reward_pct   | -23.5     |\n",
      "|    total_trades       | 25477     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32       |\n",
      "|    explained_variance | -1.58     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 0.871     |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.00118   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.2    |\n",
      "|    explained_variance | -6.89    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 5.68     |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.031    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.693    |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.000613 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.161    |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.000678 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 0.00475  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50894.02\n",
      "total_reward: 894.02\n",
      "total_cost: 11388.78\n",
      "total_trades: 25864\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.09e+04 |\n",
      "|    total_cost         | 1.14e+04 |\n",
      "|    total_reward       | 894      |\n",
      "|    total_reward_pct   | 1.79     |\n",
      "|    total_trades       | 25864    |\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.3    |\n",
      "|    explained_variance | -27.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.718    |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 0.000636 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.7    |\n",
      "|    explained_variance | -6.05    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.31     |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.97     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.0029   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.4    |\n",
      "|    explained_variance | 0.0415   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 3.19     |\n",
      "|    std                | 1.48     |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.7    |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 4.87     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.0217   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.17e+04 |\n",
      "|    total_cost         | 8.43e+03 |\n",
      "|    total_reward       | 1.7e+03  |\n",
      "|    total_reward_pct   | 3.39     |\n",
      "|    total_trades       | 25775    |\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.533   |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.00033  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -0.298    |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 8.14e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | -8.76    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 4.71     |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.0261   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | -0.212   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -2.35    |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0043   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.87e+04  |\n",
      "|    total_cost         | 9.54e+03  |\n",
      "|    total_reward       | -2.13e+04 |\n",
      "|    total_reward_pct   | -42.6     |\n",
      "|    total_trades       | 26484     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 0.018     |\n",
      "|    std                | 1.68      |\n",
      "|    value_loss         | 8.96e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | -4.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.267   |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 8.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | -4.01    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.568   |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.0022   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.9    |\n",
      "|    explained_variance | 0.586    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -4.55    |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -3.03    |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.00653  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.05e+04 |\n",
      "|    total_cost         | 9.37e+03 |\n",
      "|    total_reward       | 508      |\n",
      "|    total_reward_pct   | 1.02     |\n",
      "|    total_trades       | 26028    |\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    std                | 1.83     |\n",
      "|    value_loss         | 0.000888 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.419    |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 0.000155 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.2    |\n",
      "|    explained_variance | 0.21     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -4.89    |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.0176   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -1.51    |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.0018   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.7    |\n",
      "|    explained_variance | -0.582   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.00277  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.57e+04  |\n",
      "|    total_cost         | 5.39e+03  |\n",
      "|    total_reward       | -4.28e+03 |\n",
      "|    total_reward_pct   | -8.57     |\n",
      "|    total_trades       | 26119     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 0.364     |\n",
      "|    std                | 1.98      |\n",
      "|    value_loss         | 0.00043   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | -1.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.471   |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.000303 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -2.69    |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.0174   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -0.000969 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -5.78     |\n",
      "|    std                | 2.07      |\n",
      "|    value_loss         | 0.0231    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -4.59    |\n",
      "|    std                | 2.1      |\n",
      "|    value_loss         | 0.0129   |\n",
      "------------------------------------\n",
      "day: 2460, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 57969.70\n",
      "total_reward: 7969.70\n",
      "total_cost: 11653.01\n",
      "total_trades: 27647\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.8e+04  |\n",
      "|    total_cost         | 1.17e+04 |\n",
      "|    total_reward       | 7.97e+03 |\n",
      "|    total_reward_pct   | 15.9     |\n",
      "|    total_trades       | 27647    |\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 0.000626 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -1.1     |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.00079  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | -1.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 1.77     |\n",
      "|    std                | 2.18     |\n",
      "|    value_loss         | 0.00259  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0.104    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.608   |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.000531 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | 0.0936   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 2.94     |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 0.00784  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.751    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.686    |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.000335 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.19e+04 |\n",
      "|    total_cost         | 9.49e+03 |\n",
      "|    total_reward       | 1.91e+03 |\n",
      "|    total_reward_pct   | 3.82     |\n",
      "|    total_trades       | 27718    |\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -25.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 0.00195  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.622   |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.000482 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 2.4      |\n",
      "|    value_loss         | 0.000831 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -0.162   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 0.00124  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | -1.76    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 2.48     |\n",
      "|    value_loss         | 0.00274  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.11e+04  |\n",
      "|    total_cost         | 8.72e+03  |\n",
      "|    total_reward       | -2.89e+04 |\n",
      "|    total_reward_pct   | -57.9     |\n",
      "|    total_trades       | 27399     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 0.226     |\n",
      "|    std                | 2.53      |\n",
      "|    value_loss         | 3.95e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.00941  |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 7.71e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -1.37     |\n",
      "|    std                | 2.66      |\n",
      "|    value_loss         | 0.00125   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | -2.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 1        |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 0.00222  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.38e+03 |\n",
      "|    total_cost         | 1.74e+04  |\n",
      "|    total_reward       | -5.44e+04 |\n",
      "|    total_reward_pct   | -109      |\n",
      "|    total_trades       | 27846     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | 0.313     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -16.9     |\n",
      "|    std                | 2.75      |\n",
      "|    value_loss         | 3.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0.311    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 2.81     |\n",
      "|    value_loss         | 0.000762 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -1.7     |\n",
      "|    std                | 2.88     |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.734   |\n",
      "|    std                | 2.95     |\n",
      "|    value_loss         | 0.000937 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 2.99     |\n",
      "|    value_loss         | 0.000973 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.75e+04  |\n",
      "|    total_cost         | 2.79e+04  |\n",
      "|    total_reward       | -2.52e+03 |\n",
      "|    total_reward_pct   | -5.03     |\n",
      "|    total_trades       | 28657     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48       |\n",
      "|    explained_variance | -1.39     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 7.52      |\n",
      "|    std                | 3.02      |\n",
      "|    value_loss         | 0.0249    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.897   |\n",
      "|    std                | 3.08     |\n",
      "|    value_loss         | 0.000428 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | -0.457   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 0.571    |\n",
      "|    std                | 3.15     |\n",
      "|    value_loss         | 0.000307 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.513   |\n",
      "|    std                | 3.24     |\n",
      "|    value_loss         | 0.000192 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -0.479    |\n",
      "|    std                | 3.36      |\n",
      "|    value_loss         | 0.000125  |\n",
      "-------------------------------------\n",
      "day: 2460, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2853.62\n",
      "total_reward: -47146.38\n",
      "total_cost: 11823.01\n",
      "total_trades: 27750\n",
      "Sharpe: -0.386\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.85e+03  |\n",
      "|    total_cost         | 1.18e+04  |\n",
      "|    total_reward       | -4.71e+04 |\n",
      "|    total_reward_pct   | -94.3     |\n",
      "|    total_trades       | 27750     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.6     |\n",
      "|    explained_variance | -0.0605   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 0.415     |\n",
      "|    std                | 3.47      |\n",
      "|    value_loss         | 0.000834  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | -0.43    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 2.45     |\n",
      "|    std                | 3.55     |\n",
      "|    value_loss         | 0.00437  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.104    |\n",
      "|    std                | 3.62     |\n",
      "|    value_loss         | 0.000195 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.36     |\n",
      "|    std                | 3.7      |\n",
      "|    value_loss         | 6.75e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | -0.0595  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.388    |\n",
      "|    std                | 3.78     |\n",
      "|    value_loss         | 0.00013  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.61e+03  |\n",
      "|    total_cost         | 3.08e+04  |\n",
      "|    total_reward       | -4.44e+04 |\n",
      "|    total_reward_pct   | -88.8     |\n",
      "|    total_trades       | 29988     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.6     |\n",
      "|    explained_variance | 0.39      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -0.335    |\n",
      "|    std                | 3.86      |\n",
      "|    value_loss         | 0.000535  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.8    |\n",
      "|    explained_variance | 0.546    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.246   |\n",
      "|    std                | 3.9      |\n",
      "|    value_loss         | 0.000145 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | -0.231   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -4.81    |\n",
      "|    std                | 3.95     |\n",
      "|    value_loss         | 0.00929  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -1.96     |\n",
      "|    std                | 3.99      |\n",
      "|    value_loss         | 0.00138   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 0.261    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.787   |\n",
      "|    std                | 4.05     |\n",
      "|    value_loss         | 0.000397 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.88e+04  |\n",
      "|    total_cost         | 6.24e+04  |\n",
      "|    total_reward       | -3.12e+04 |\n",
      "|    total_reward_pct   | -62.4     |\n",
      "|    total_trades       | 31656     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -0.211    |\n",
      "|    std                | 4.12      |\n",
      "|    value_loss         | 2.27e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | -5.76    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.983   |\n",
      "|    std                | 4.23     |\n",
      "|    value_loss         | 0.000474 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.8    |\n",
      "|    explained_variance | -0.36    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.0955  |\n",
      "|    std                | 4.34     |\n",
      "|    value_loss         | 5.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.3    |\n",
      "|    explained_variance | -0.483   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -0.229   |\n",
      "|    std                | 4.45     |\n",
      "|    value_loss         | 5.37e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    std                | 4.59     |\n",
      "|    value_loss         | 6.34e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.56e+03  |\n",
      "|    total_cost         | 1.96e+04  |\n",
      "|    total_reward       | -4.44e+04 |\n",
      "|    total_reward_pct   | -88.9     |\n",
      "|    total_trades       | 28794     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.4     |\n",
      "|    explained_variance | 0.0883    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -0.446    |\n",
      "|    std                | 4.73      |\n",
      "|    value_loss         | 0.000136  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.9    |\n",
      "|    explained_variance | -34.8    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -1.94    |\n",
      "|    std                | 4.84     |\n",
      "|    value_loss         | 0.00144  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.4    |\n",
      "|    explained_variance | 0.0213   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -0.67    |\n",
      "|    std                | 4.96     |\n",
      "|    value_loss         | 0.00383  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -1.84    |\n",
      "|    std                | 5.04     |\n",
      "|    value_loss         | 0.00303  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58      |\n",
      "|    explained_variance | 0.304    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 5.13     |\n",
      "|    value_loss         | 0.00164  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.1e+04  |\n",
      "|    total_cost         | 3.97e+04 |\n",
      "|    total_reward       | -2.9e+04 |\n",
      "|    total_reward_pct   | -58      |\n",
      "|    total_trades       | 30122    |\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -0.186   |\n",
      "|    std                | 5.21     |\n",
      "|    value_loss         | 0.000172 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.7    |\n",
      "|    explained_variance | 0.727    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.918    |\n",
      "|    std                | 5.32     |\n",
      "|    value_loss         | 0.000411 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.1     |\n",
      "|    explained_variance | -0.000455 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -0.255    |\n",
      "|    std                | 5.45      |\n",
      "|    value_loss         | 0.000524  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.6    |\n",
      "|    explained_variance | 0.00347  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.962   |\n",
      "|    std                | 5.59     |\n",
      "|    value_loss         | 0.000326 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.1    |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.662   |\n",
      "|    std                | 5.74     |\n",
      "|    value_loss         | 0.000289 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6552.37\n",
      "total_reward: -43447.63\n",
      "total_cost: 25166.15\n",
      "total_trades: 29734\n",
      "Sharpe: -0.197\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.55e+03  |\n",
      "|    total_cost         | 2.52e+04  |\n",
      "|    total_reward       | -4.34e+04 |\n",
      "|    total_reward_pct   | -86.9     |\n",
      "|    total_trades       | 29734     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 216       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.6     |\n",
      "|    explained_variance | -0.0217   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -3.05     |\n",
      "|    std                | 5.88      |\n",
      "|    value_loss         | 0.00314   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61      |\n",
      "|    explained_variance | 0.672    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -2.46    |\n",
      "|    std                | 6.02     |\n",
      "|    value_loss         | 0.00163  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | -0.551   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    std                | 6.18     |\n",
      "|    value_loss         | 0.000563 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -1.5     |\n",
      "|    std                | 6.32     |\n",
      "|    value_loss         | 0.00103  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.278   |\n",
      "|    std                | 6.47     |\n",
      "|    value_loss         | 3.51e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.75e+03  |\n",
      "|    total_cost         | 3.05e+04  |\n",
      "|    total_reward       | -4.13e+04 |\n",
      "|    total_reward_pct   | -82.5     |\n",
      "|    total_trades       | 29746     |\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.8     |\n",
      "|    explained_variance | 0.235     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 1.1       |\n",
      "|    std                | 6.62      |\n",
      "|    value_loss         | 0.000447  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 6.77     |\n",
      "|    value_loss         | 0.0003   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.7    |\n",
      "|    explained_variance | -0.522   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.351   |\n",
      "|    std                | 6.94     |\n",
      "|    value_loss         | 5.95e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.3    |\n",
      "|    explained_variance | -0.227   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.3      |\n",
      "|    std                | 7.14     |\n",
      "|    value_loss         | 8.38e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.931   |\n",
      "|    std                | 7.34     |\n",
      "|    value_loss         | 0.000195 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.49e+03  |\n",
      "|    total_cost         | 2.32e+04  |\n",
      "|    total_reward       | -4.85e+04 |\n",
      "|    total_reward_pct   | -97       |\n",
      "|    total_trades       | 29309     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.3     |\n",
      "|    explained_variance | -0.453    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -3.8      |\n",
      "|    std                | 7.55      |\n",
      "|    value_loss         | 0.00395   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -1.9     |\n",
      "|    std                | 7.75     |\n",
      "|    value_loss         | 0.00104  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -0.603   |\n",
      "|    std                | 7.93     |\n",
      "|    value_loss         | 0.000421 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.6    |\n",
      "|    explained_variance | 0.0188   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -0.817   |\n",
      "|    std                | 8.08     |\n",
      "|    value_loss         | 0.000293 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67      |\n",
      "|    explained_variance | 0.0632   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -1.44    |\n",
      "|    std                | 8.25     |\n",
      "|    value_loss         | 0.000568 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.41e+04  |\n",
      "|    total_cost         | 3.39e+04  |\n",
      "|    total_reward       | -3.59e+04 |\n",
      "|    total_reward_pct   | -71.7     |\n",
      "|    total_trades       | 30268     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.4     |\n",
      "|    explained_variance | -7.15e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 0.614     |\n",
      "|    std                | 8.44      |\n",
      "|    value_loss         | 9.78e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.208   |\n",
      "|    std                | 8.7      |\n",
      "|    value_loss         | 1.08e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 253       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 0.0995    |\n",
      "|    std                | 8.93      |\n",
      "|    value_loss         | 0.0004    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 255       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | 1.26      |\n",
      "|    std                | 9.14      |\n",
      "|    value_loss         | 0.000463  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.936   |\n",
      "|    std                | 9.35     |\n",
      "|    value_loss         | 0.000204 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.04e+04  |\n",
      "|    total_cost         | 2.98e+04  |\n",
      "|    total_reward       | -3.96e+04 |\n",
      "|    total_reward_pct   | -79.1     |\n",
      "|    total_trades       | 29424     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 0.802     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -0.72     |\n",
      "|    std                | 9.56      |\n",
      "|    value_loss         | 0.000144  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 0.155    |\n",
      "|    std                | 9.84     |\n",
      "|    value_loss         | 5.95e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.9    |\n",
      "|    explained_variance | -0.0428  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.228   |\n",
      "|    std                | 10.1     |\n",
      "|    value_loss         | 0.000183 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 10.4     |\n",
      "|    value_loss         | 0.000363 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.9    |\n",
      "|    explained_variance | 0.0292   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -0.369   |\n",
      "|    std                | 10.7     |\n",
      "|    value_loss         | 4.55e-05 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4555.19\n",
      "total_reward: -45444.81\n",
      "total_cost: 23328.35\n",
      "total_trades: 29255\n",
      "Sharpe: 0.133\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.56e+03  |\n",
      "|    total_cost         | 2.33e+04  |\n",
      "|    total_reward       | -4.54e+04 |\n",
      "|    total_reward_pct   | -90.9     |\n",
      "|    total_trades       | 29255     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -0.0712   |\n",
      "|    std                | 11.1      |\n",
      "|    value_loss         | 3.57e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.746    |\n",
      "|    std                | 11.5     |\n",
      "|    value_loss         | 0.00047  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.8    |\n",
      "|    explained_variance | 0.0793   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 2.85     |\n",
      "|    std                | 11.8     |\n",
      "|    value_loss         | 0.00372  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -0.0929  |\n",
      "|    std                | 12.1     |\n",
      "|    value_loss         | 1.71e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.34e+03  |\n",
      "|    total_cost         | 2.41e+04  |\n",
      "|    total_reward       | -4.37e+04 |\n",
      "|    total_reward_pct   | -87.3     |\n",
      "|    total_trades       | 29073     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | -0.275    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -0.485    |\n",
      "|    std                | 12.4      |\n",
      "|    value_loss         | 5.15e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.3    |\n",
      "|    explained_variance | 0.146    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -1.61    |\n",
      "|    std                | 12.8     |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 0.35     |\n",
      "|    std                | 13.3     |\n",
      "|    value_loss         | 3.2e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.896   |\n",
      "|    std                | 13.7     |\n",
      "|    value_loss         | 0.000166 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 0.187    |\n",
      "|    std                | 14       |\n",
      "|    value_loss         | 4.38e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.16e+03  |\n",
      "|    total_cost         | 2.36e+04  |\n",
      "|    total_reward       | -4.28e+04 |\n",
      "|    total_reward_pct   | -85.7     |\n",
      "|    total_trades       | 29109     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 290       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -77.6     |\n",
      "|    explained_variance | 0.000831  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | 0.702     |\n",
      "|    std                | 14.4      |\n",
      "|    value_loss         | 0.000162  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.2    |\n",
      "|    explained_variance | -0.0313  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -1.33    |\n",
      "|    std                | 14.9     |\n",
      "|    value_loss         | 0.000348 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 0.568    |\n",
      "|    std                | 15.4     |\n",
      "|    value_loss         | 6.94e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.5    |\n",
      "|    explained_variance | -0.234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.778   |\n",
      "|    std                | 15.9     |\n",
      "|    value_loss         | 0.000142 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.0765  |\n",
      "|    std                | 16.4     |\n",
      "|    value_loss         | 3.14e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -9.18e+03 |\n",
      "|    total_cost         | 2.41e+04  |\n",
      "|    total_reward       | -5.92e+04 |\n",
      "|    total_reward_pct   | -118      |\n",
      "|    total_trades       | 28937     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 301       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -80.5     |\n",
      "|    explained_variance | -0.0678   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 3.21      |\n",
      "|    std                | 16.8      |\n",
      "|    value_loss         | 0.00279   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 0.423    |\n",
      "|    std                | 17.2     |\n",
      "|    value_loss         | 3.94e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.872   |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 0.000264 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 308       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 1.48      |\n",
      "|    std                | 18.1      |\n",
      "|    value_loss         | 0.000461  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.0602   |\n",
      "|    std                | 18.6     |\n",
      "|    value_loss         | 0.000126 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -6.74e+03 |\n",
      "|    total_cost         | 3.52e+04  |\n",
      "|    total_reward       | -5.67e+04 |\n",
      "|    total_reward_pct   | -113      |\n",
      "|    total_trades       | 29941     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 312       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.9     |\n",
      "|    explained_variance | -7.86     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | 1.01      |\n",
      "|    std                | 19        |\n",
      "|    value_loss         | 0.000787  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.4    |\n",
      "|    explained_variance | -3.81    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.229   |\n",
      "|    std                | 19.6     |\n",
      "|    value_loss         | 6.3e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84      |\n",
      "|    explained_variance | 0.641    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -0.153   |\n",
      "|    std                | 20.2     |\n",
      "|    value_loss         | 1.03e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.194    |\n",
      "|    std                | 21       |\n",
      "|    value_loss         | 7.05e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -0.0606  |\n",
      "|    std                | 21.9     |\n",
      "|    value_loss         | 6.39e-07 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -102.51\n",
      "total_reward: -50102.51\n",
      "total_cost: 9225.79\n",
      "total_trades: 27113\n",
      "Sharpe: -0.129\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -103      |\n",
      "|    total_cost         | 9.23e+03  |\n",
      "|    total_reward       | -5.01e+04 |\n",
      "|    total_reward_pct   | -100      |\n",
      "|    total_trades       | 27113     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 323       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86.4     |\n",
      "|    explained_variance | 0.0813    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -0.128    |\n",
      "|    std                | 22.9      |\n",
      "|    value_loss         | 2.39e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 325      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.9    |\n",
      "|    explained_variance | -0.557   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 0.0481   |\n",
      "|    std                | 23.6     |\n",
      "|    value_loss         | 1.12e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.5    |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 0.572    |\n",
      "|    std                | 24.3     |\n",
      "|    value_loss         | 6.16e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    std                | 25.2     |\n",
      "|    value_loss         | 0.000326 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.221   |\n",
      "|    std                | 26.1     |\n",
      "|    value_loss         | 1.09e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.93e+03 |\n",
      "|    total_cost         | 1.82e+04  |\n",
      "|    total_reward       | -5.89e+04 |\n",
      "|    total_reward_pct   | -118      |\n",
      "|    total_trades       | 28436     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 334       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -89.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 1.95      |\n",
      "|    std                | 26.7      |\n",
      "|    value_loss         | 0.000694  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.943    |\n",
      "|    std                | 27.2     |\n",
      "|    value_loss         | 0.000139 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90      |\n",
      "|    explained_variance | -0.0413  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 27.8     |\n",
      "|    value_loss         | 0.00061  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 0.332    |\n",
      "|    std                | 28.4     |\n",
      "|    value_loss         | 8.04e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91      |\n",
      "|    explained_variance | -0.605   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 0.0696   |\n",
      "|    std                | 29.2     |\n",
      "|    value_loss         | 1.62e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.57e+03  |\n",
      "|    total_cost         | 3.54e+04  |\n",
      "|    total_reward       | -4.54e+04 |\n",
      "|    total_reward_pct   | -90.9     |\n",
      "|    total_trades       | 30222     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 345       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | -0.0174   |\n",
      "|    std                | 30.2      |\n",
      "|    value_loss         | 5.83e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.0835  |\n",
      "|    std                | 31.4     |\n",
      "|    value_loss         | 2.18e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 349       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | -0.506    |\n",
      "|    std                | 32.5      |\n",
      "|    value_loss         | 0.000889  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.5    |\n",
      "|    explained_variance | -0.00196 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 33.4     |\n",
      "|    value_loss         | 0.000273 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    std                | 34.3     |\n",
      "|    value_loss         | 0.000211 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.15e+03  |\n",
      "|    total_cost         | 2.59e+04  |\n",
      "|    total_reward       | -4.18e+04 |\n",
      "|    total_reward_pct   | -83.7     |\n",
      "|    total_trades       | 28735     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 356       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -94.5     |\n",
      "|    explained_variance | 0.0347    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -0.64     |\n",
      "|    std                | 35.1      |\n",
      "|    value_loss         | 5.25e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    std                | 36.1     |\n",
      "|    value_loss         | 0.000606 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.3      |\n",
      "|    std                | 37.3     |\n",
      "|    value_loss         | 1.55e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.122    |\n",
      "|    std                | 38.8     |\n",
      "|    value_loss         | 3.1e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.2    |\n",
      "|    explained_variance | -17.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.282    |\n",
      "|    std                | 40.5     |\n",
      "|    value_loss         | 1.57e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 618       |\n",
      "|    total_cost         | 1.36e+04  |\n",
      "|    total_reward       | -4.94e+04 |\n",
      "|    total_reward_pct   | -98.8     |\n",
      "|    total_trades       | 27948     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 367       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -97.9     |\n",
      "|    explained_variance | -2.44     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -0.195    |\n",
      "|    std                | 42        |\n",
      "|    value_loss         | 6.1e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.4    |\n",
      "|    explained_variance | -0.245   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -0.246   |\n",
      "|    std                | 43.2     |\n",
      "|    value_loss         | 9.67e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 371      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.71    |\n",
      "|    std                | 44.6     |\n",
      "|    value_loss         | 6.15e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    std                | 46.4     |\n",
      "|    value_loss         | 6.63e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | 0.285    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -3.22    |\n",
      "|    std                | 48.2     |\n",
      "|    value_loss         | 0.00156  |\n",
      "------------------------------------\n",
      "day: 2460, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -13802.10\n",
      "total_reward: -63802.10\n",
      "total_cost: 17896.82\n",
      "total_trades: 28330\n",
      "Sharpe: 0.056\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.38e+04 |\n",
      "|    total_cost         | 1.79e+04  |\n",
      "|    total_reward       | -6.38e+04 |\n",
      "|    total_reward_pct   | -128      |\n",
      "|    total_trades       | 28330     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 378       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | -0.169    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 0.0654    |\n",
      "|    std                | 49.5      |\n",
      "|    value_loss         | 6.96e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | -0.0128  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -0.428   |\n",
      "|    std                | 51       |\n",
      "|    value_loss         | 3.35e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -102      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 0.0444    |\n",
      "|    std                | 52.9      |\n",
      "|    value_loss         | 6.8e-07   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | -0.0942  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.0354   |\n",
      "|    std                | 54.9     |\n",
      "|    value_loss         | 1.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -4.66    |\n",
      "|    std                | 56.8     |\n",
      "|    value_loss         | 0.0028   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.15e+03 |\n",
      "|    total_cost         | 1.95e+04  |\n",
      "|    total_reward       | -5.82e+04 |\n",
      "|    total_reward_pct   | -116      |\n",
      "|    total_trades       | 28423     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 389       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -104      |\n",
      "|    explained_variance | -0.231    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 4.49      |\n",
      "|    std                | 58.2      |\n",
      "|    value_loss         | 0.00208   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.519    |\n",
      "|    std                | 59.8     |\n",
      "|    value_loss         | 3.59e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.045    |\n",
      "|    std                | 61.9     |\n",
      "|    value_loss         | 0.000133 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 396      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 0.0754   |\n",
      "|    std                | 64.3     |\n",
      "|    value_loss         | 5.46e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 398      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | -1.21    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    std                | 67.1     |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.04e+03 |\n",
      "|    total_cost         | 1.29e+04  |\n",
      "|    total_reward       | -5.8e+04  |\n",
      "|    total_reward_pct   | -116      |\n",
      "|    total_trades       | 27397     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 400       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -107      |\n",
      "|    explained_variance | 0.155     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 0.613     |\n",
      "|    std                | 68.7      |\n",
      "|    value_loss         | 0.000742  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 402       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -108      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -0.619    |\n",
      "|    std                | 70.3      |\n",
      "|    value_loss         | 5.39e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 404      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | 0.00771  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.644   |\n",
      "|    std                | 72.2     |\n",
      "|    value_loss         | 6.28e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 407      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | -24      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -0.135   |\n",
      "|    std                | 74.4     |\n",
      "|    value_loss         | 7.4e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 409      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 4.17     |\n",
      "|    std                | 76.8     |\n",
      "|    value_loss         | 0.00227  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.02e+03 |\n",
      "|    total_cost         | 2.86e+04  |\n",
      "|    total_reward       | -5.8e+04  |\n",
      "|    total_reward_pct   | -116      |\n",
      "|    total_trades       | 29681     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 411       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -110      |\n",
      "|    explained_variance | -0.443    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | 4.07      |\n",
      "|    std                | 77.7      |\n",
      "|    value_loss         | 0.00202   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 413      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -5.03    |\n",
      "|    std                | 78.7     |\n",
      "|    value_loss         | 0.00267  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 415      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 6.79     |\n",
      "|    std                | 79.8     |\n",
      "|    value_loss         | 0.0039   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 418      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 0.553    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -1.67    |\n",
      "|    std                | 81.1     |\n",
      "|    value_loss         | 0.000244 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.01e+03 |\n",
      "|    total_cost         | 7.39e+04 |\n",
      "|    total_reward       | -4.4e+04 |\n",
      "|    total_reward_pct   | -88      |\n",
      "|    total_trades       | 31667    |\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | -0.153   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 6.62     |\n",
      "|    std                | 82.9     |\n",
      "|    value_loss         | 0.00366  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 422      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | -0.0678  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -8.18    |\n",
      "|    std                | 84.1     |\n",
      "|    value_loss         | 0.0053   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 424      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | -0.676   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 4.16     |\n",
      "|    std                | 85.4     |\n",
      "|    value_loss         | 0.00175  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -0.224   |\n",
      "|    std                | 87.2     |\n",
      "|    value_loss         | 6.25e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.406   |\n",
      "|    std                | 89.4     |\n",
      "|    value_loss         | 5.55e-05 |\n",
      "------------------------------------\n",
      "day: 2460, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -4553.43\n",
      "total_reward: -54553.43\n",
      "total_cost: 45378.59\n",
      "total_trades: 30657\n",
      "Sharpe: -0.395\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.55e+03 |\n",
      "|    total_cost         | 4.54e+04  |\n",
      "|    total_reward       | -5.46e+04 |\n",
      "|    total_reward_pct   | -109      |\n",
      "|    total_trades       | 30657     |\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 431       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -113      |\n",
      "|    explained_variance | -0.193    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    std                | 91.9      |\n",
      "|    value_loss         | 0.0128    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 433      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -113     |\n",
      "|    explained_variance | -0.33    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 2.29     |\n",
      "|    std                | 93.5     |\n",
      "|    value_loss         | 0.000666 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 435      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -113     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 0.172    |\n",
      "|    std                | 95.4     |\n",
      "|    value_loss         | 1.54e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 437       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -114      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -0.245    |\n",
      "|    std                | 97.8      |\n",
      "|    value_loss         | 4.98e-06  |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-01-03 to  2020-04-06\n",
      "A2C Sharpe Ratio:  -0.25108296944479613\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 261  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.11e+03    |\n",
      "|    total_cost           | 2.52e+04    |\n",
      "|    total_reward         | -4.69e+04   |\n",
      "|    total_reward_pct     | -93.8       |\n",
      "|    total_trades         | 28815       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010744771 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.531      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0476      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.1e+03     |\n",
      "|    total_cost           | 4.16e+04    |\n",
      "|    total_reward         | -4.79e+04   |\n",
      "|    total_reward_pct     | -95.8       |\n",
      "|    total_trades         | 29939       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011288613 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0209      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.22e+03    |\n",
      "|    total_cost           | 4.52e+04    |\n",
      "|    total_reward         | -4.58e+04   |\n",
      "|    total_reward_pct     | -91.6       |\n",
      "|    total_trades         | 30380       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005302122 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4137.91\n",
      "total_reward: -45862.09\n",
      "total_cost: 20073.01\n",
      "total_trades: 27866\n",
      "Sharpe: -0.333\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.14e+03    |\n",
      "|    total_cost           | 2.01e+04    |\n",
      "|    total_reward         | -4.59e+04   |\n",
      "|    total_reward_pct     | -91.7       |\n",
      "|    total_trades         | 27866       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010857934 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.296      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019794717 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.337      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.7e+04    |\n",
      "|    total_cost           | 6.53e+04   |\n",
      "|    total_reward         | -3.3e+04   |\n",
      "|    total_reward_pct     | -66        |\n",
      "|    total_trades         | 31498      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 250        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01867472 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | 0.266      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.318     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.011      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.91e+04    |\n",
      "|    total_cost           | 5.29e+04    |\n",
      "|    total_reward         | -3.09e+04   |\n",
      "|    total_reward_pct     | -61.7       |\n",
      "|    total_trades         | 30619       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020505901 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.316      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0101      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.3e+03     |\n",
      "|    total_cost           | 2.63e+04    |\n",
      "|    total_reward         | -4.07e+04   |\n",
      "|    total_reward_pct     | -81.4       |\n",
      "|    total_trades         | 28542       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017247597 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0159      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+04     |\n",
      "|    total_cost           | 3.43e+04    |\n",
      "|    total_reward         | -3.8e+04    |\n",
      "|    total_reward_pct     | -76.1       |\n",
      "|    total_trades         | 29396       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021628886 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 9392.78\n",
      "total_reward: -40607.22\n",
      "total_cost: 23663.27\n",
      "total_trades: 28892\n",
      "Sharpe: -0.070\n",
      "=================================\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 9.39e+03  |\n",
      "|    total_cost           | 2.37e+04  |\n",
      "|    total_reward         | -4.06e+04 |\n",
      "|    total_reward_pct     | -81.2     |\n",
      "|    total_trades         | 28892     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0218147 |\n",
      "|    clip_fraction        | 0.183     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.3     |\n",
      "|    explained_variance   | 0.418     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.274    |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.0237   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 0.00863   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015517858 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00538     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.33e+03    |\n",
      "|    total_cost           | 2.54e+04    |\n",
      "|    total_reward         | -4.07e+04   |\n",
      "|    total_reward_pct     | -81.3       |\n",
      "|    total_trades         | 28863       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024303727 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00457     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.54e+03    |\n",
      "|    total_cost           | 2.75e+04    |\n",
      "|    total_reward         | -4.15e+04   |\n",
      "|    total_reward_pct     | -82.9       |\n",
      "|    total_trades         | 28950       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027413428 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | -0.877      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0143      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.55e+03    |\n",
      "|    total_cost           | 3.03e+04    |\n",
      "|    total_reward         | -4.34e+04   |\n",
      "|    total_reward_pct     | -86.9       |\n",
      "|    total_trades         | 29515       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007671736 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00905     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.86e+04    |\n",
      "|    total_cost           | 4.05e+04    |\n",
      "|    total_reward         | -3.14e+04   |\n",
      "|    total_reward_pct     | -62.9       |\n",
      "|    total_trades         | 29714       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025516324 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0067      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 13817.36\n",
      "total_reward: -36182.64\n",
      "total_cost: 32993.50\n",
      "total_trades: 29322\n",
      "Sharpe: 0.143\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.38e+04   |\n",
      "|    total_cost           | 3.3e+04    |\n",
      "|    total_reward         | -3.62e+04  |\n",
      "|    total_reward_pct     | -72.4      |\n",
      "|    total_trades         | 29322      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 250        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02965812 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.422      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.277     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.00906    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019616375 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.22e+03   |\n",
      "|    total_cost           | 1.03e+04   |\n",
      "|    total_reward         | -4.78e+04  |\n",
      "|    total_reward_pct     | -95.6      |\n",
      "|    total_trades         | 26834      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02378429 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.28      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.00124    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.82e+03    |\n",
      "|    total_cost           | 1.47e+04    |\n",
      "|    total_reward         | -4.22e+04   |\n",
      "|    total_reward_pct     | -84.4       |\n",
      "|    total_trades         | 27667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023168296 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00353     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.43e+04    |\n",
      "|    total_cost           | 2.61e+04    |\n",
      "|    total_reward         | -3.57e+04   |\n",
      "|    total_reward_pct     | -71.5       |\n",
      "|    total_trades         | 29007       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024457857 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | -1.19       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.322      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00943     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.68e+04    |\n",
      "|    total_cost           | 5e+04       |\n",
      "|    total_reward         | 6.81e+03    |\n",
      "|    total_reward_pct     | 13.6        |\n",
      "|    total_trades         | 30664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019081047 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 28070.52\n",
      "total_reward: -21929.48\n",
      "total_cost: 26760.63\n",
      "total_trades: 28934\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.81e+04   |\n",
      "|    total_cost           | 2.68e+04   |\n",
      "|    total_reward         | -2.19e+04  |\n",
      "|    total_reward_pct     | -43.9      |\n",
      "|    total_trades         | 28934      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02331162 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.8      |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.276     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00939   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0222     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020564508 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.257      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.89e+03    |\n",
      "|    total_cost           | 1.14e+04    |\n",
      "|    total_reward         | -4.21e+04   |\n",
      "|    total_reward_pct     | -84.2       |\n",
      "|    total_trades         | 27224       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025355943 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00215     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -9.04e+03  |\n",
      "|    total_cost           | 1.54e+04   |\n",
      "|    total_reward         | -5.9e+04   |\n",
      "|    total_reward_pct     | -118       |\n",
      "|    total_trades         | 28073      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 250        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 212        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02375412 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.29      |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.00366    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.72e+03    |\n",
      "|    total_cost           | 1.44e+04    |\n",
      "|    total_reward         | -4.33e+04   |\n",
      "|    total_reward_pct     | -86.6       |\n",
      "|    total_trades         | 27539       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021951105 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00761     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.88e+03    |\n",
      "|    total_cost           | 1.52e+04    |\n",
      "|    total_reward         | -4.71e+04   |\n",
      "|    total_reward_pct     | -94.2       |\n",
      "|    total_trades         | 27743       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020011608 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.323      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00334     |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 43527.16\n",
      "total_reward: -6472.84\n",
      "total_cost: 39025.13\n",
      "total_trades: 29801\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.35e+04    |\n",
      "|    total_cost           | 3.9e+04     |\n",
      "|    total_reward         | -6.47e+03   |\n",
      "|    total_reward_pct     | -12.9       |\n",
      "|    total_trades         | 29801       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033129375 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | -1.38       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0142      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029966392 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.56e+04   |\n",
      "|    total_cost           | 2.26e+04   |\n",
      "|    total_reward         | -3.44e+04  |\n",
      "|    total_reward_pct     | -68.8      |\n",
      "|    total_trades         | 28421      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04151173 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.242      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.313     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.00937    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.91e+04   |\n",
      "|    total_cost           | 3.05e+04   |\n",
      "|    total_reward         | -2.09e+04  |\n",
      "|    total_reward_pct     | -41.9      |\n",
      "|    total_trades         | 29170      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 260        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02199094 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.27      |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0101     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.53e+04    |\n",
      "|    total_cost           | 3.07e+04    |\n",
      "|    total_reward         | -2.47e+04   |\n",
      "|    total_reward_pct     | -49.5       |\n",
      "|    total_trades         | 29370       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020011682 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.329      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+04    |\n",
      "|    total_cost           | 1.28e+04    |\n",
      "|    total_reward         | -3.97e+04   |\n",
      "|    total_reward_pct     | -79.3       |\n",
      "|    total_trades         | 27326       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022300955 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0142      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 13360.65\n",
      "total_reward: -36639.35\n",
      "total_cost: 15055.43\n",
      "total_trades: 27769\n",
      "Sharpe: 0.331\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+04    |\n",
      "|    total_cost           | 1.51e+04    |\n",
      "|    total_reward         | -3.66e+04   |\n",
      "|    total_reward_pct     | -73.3       |\n",
      "|    total_trades         | 27769       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028986584 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00467     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018148515 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.272      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0069      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.87e+03   |\n",
      "|    total_cost           | 1.4e+04    |\n",
      "|    total_reward         | -4.01e+04  |\n",
      "|    total_reward_pct     | -80.3      |\n",
      "|    total_trades         | 27884      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 301        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01710049 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.502      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.316     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.00324    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.3e+04     |\n",
      "|    total_cost           | 4.74e+04    |\n",
      "|    total_reward         | 3.01e+03    |\n",
      "|    total_reward_pct     | 6.02        |\n",
      "|    total_trades         | 30709       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029905057 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | -0.897      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.03        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 2.08e+04  |\n",
      "|    total_cost           | 3.22e+04  |\n",
      "|    total_reward         | -2.92e+04 |\n",
      "|    total_reward_pct     | -58.3     |\n",
      "|    total_trades         | 29754     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 317       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0226184 |\n",
      "|    clip_fraction        | 0.246     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0.167     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.296    |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -0.0175   |\n",
      "|    std                  | 1.08      |\n",
      "|    value_loss           | 0.0225    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.74e+04    |\n",
      "|    total_cost           | 4.35e+04    |\n",
      "|    total_reward         | -2.59e+03   |\n",
      "|    total_reward_pct     | -5.17       |\n",
      "|    total_trades         | 29868       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031380292 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0156      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 15625.13\n",
      "total_reward: -34374.87\n",
      "total_cost: 28598.05\n",
      "total_trades: 28683\n",
      "Sharpe: 0.082\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.56e+04    |\n",
      "|    total_cost           | 2.86e+04    |\n",
      "|    total_reward         | -3.44e+04   |\n",
      "|    total_reward_pct     | -68.7       |\n",
      "|    total_trades         | 28683       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029577184 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.311      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0272      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041088127 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0163      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -438        |\n",
      "|    total_cost           | 1.63e+04    |\n",
      "|    total_reward         | -5.04e+04   |\n",
      "|    total_reward_pct     | -101        |\n",
      "|    total_trades         | 27566       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036799893 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00262     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.25e+04    |\n",
      "|    total_cost           | 2.9e+04     |\n",
      "|    total_reward         | -2.75e+04   |\n",
      "|    total_reward_pct     | -54.9       |\n",
      "|    total_trades         | 28713       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036369123 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | -0.123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0512      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -4.6e+03    |\n",
      "|    total_cost           | 1.78e+04    |\n",
      "|    total_reward         | -5.46e+04   |\n",
      "|    total_reward_pct     | -109        |\n",
      "|    total_trades         | 27886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032946613 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.57e+03    |\n",
      "|    total_cost           | 7.03e+03    |\n",
      "|    total_reward         | -4.84e+04   |\n",
      "|    total_reward_pct     | -96.9       |\n",
      "|    total_trades         | 26108       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023415305 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0075      |\n",
      "-----------------------------------------\n",
      "day: 2460, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17339.92\n",
      "total_reward: -32660.08\n",
      "total_cost: 25727.23\n",
      "total_trades: 28743\n",
      "Sharpe: -0.023\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.73e+04   |\n",
      "|    total_cost           | 2.57e+04   |\n",
      "|    total_reward         | -3.27e+04  |\n",
      "|    total_reward_pct     | -65.3      |\n",
      "|    total_trades         | 28743      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 381        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03034278 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.9      |\n",
      "|    explained_variance   | 0.0525     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.3       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.00852    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021338303 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -3.69e+03   |\n",
      "|    total_cost           | 1.35e+04    |\n",
      "|    total_reward         | -5.37e+04   |\n",
      "|    total_reward_pct     | -107        |\n",
      "|    total_trades         | 27537       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028696574 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -29         |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0168      |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-01-03 to  2020-04-06\n",
      "PPO Sharpe Ratio:  -0.3924168000984557\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
      "day: 2460, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103507.03\n",
      "total_reward: 53507.03\n",
      "total_cost: 506.92\n",
      "total_trades: 19878\n",
      "Sharpe: 0.426\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 3.44e+04  |\n",
      "|    total_cost       | 158       |\n",
      "|    total_reward     | -1.56e+04 |\n",
      "|    total_reward_pct | -31.2     |\n",
      "|    total_trades     | 20561     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 119       |\n",
      "|    time_elapsed     | 82        |\n",
      "|    total timesteps  | 9844      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -3.62     |\n",
      "|    critic_loss      | 34.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7383      |\n",
      "-----------------------------------\n",
      "day: 2460, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 49876.23\n",
      "total_reward: -123.77\n",
      "total_cost: 370.95\n",
      "total_trades: 20722\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.99e+04 |\n",
      "|    total_cost       | 371      |\n",
      "|    total_reward     | -124     |\n",
      "|    total_reward_pct | -0.248   |\n",
      "|    total_trades     | 20722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total timesteps  | 19688    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.74    |\n",
      "|    critic_loss      | 4.57     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17227    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.38e+04 |\n",
      "|    total_cost       | 349      |\n",
      "|    total_reward     | 3.38e+04 |\n",
      "|    total_reward_pct | 67.7     |\n",
      "|    total_trades     | 20698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 106      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total timesteps  | 29532    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.09    |\n",
      "|    critic_loss      | 2.32     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27071    |\n",
      "----------------------------------\n",
      "day: 2460, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 69975.55\n",
      "total_reward: 19975.55\n",
      "total_cost: 439.98\n",
      "total_trades: 20762\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.44e+04 |\n",
      "|    total_cost       | 101      |\n",
      "|    total_reward     | 1.44e+04 |\n",
      "|    total_reward_pct | 28.7     |\n",
      "|    total_trades     | 20809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 375      |\n",
      "|    total timesteps  | 39376    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.75    |\n",
      "|    critic_loss      | 1.21     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 36915    |\n",
      "----------------------------------\n",
      "day: 2460, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50871.33\n",
      "total_reward: 871.33\n",
      "total_cost: 101.45\n",
      "total_trades: 20843\n",
      "Sharpe: 0.366\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.81e+05 |\n",
      "|    total_cost       | 210      |\n",
      "|    total_reward     | 1.31e+05 |\n",
      "|    total_reward_pct | 261      |\n",
      "|    total_trades     | 20849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 474      |\n",
      "|    total timesteps  | 49220    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.53    |\n",
      "|    critic_loss      | 0.984    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46759    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-01-03 to  2020-04-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-06\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ensemble_378_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.16e+04 |\n",
      "|    total_cost       | 130      |\n",
      "|    total_reward     | 1.61e+03 |\n",
      "|    total_reward_pct | 3.21     |\n",
      "|    total_trades     | 28059    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 118      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total timesteps  | 10096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -52.5    |\n",
      "|    critic_loss      | 59.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7572     |\n",
      "----------------------------------\n",
      "day: 2523, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 53038.56\n",
      "total_reward: 3038.56\n",
      "total_cost: 118.49\n",
      "total_trades: 28017\n",
      "Sharpe: 0.404\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.89e+04  |\n",
      "|    total_cost       | 117       |\n",
      "|    total_reward     | -1.15e+03 |\n",
      "|    total_reward_pct | -2.29     |\n",
      "|    total_trades     | 28406     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 108       |\n",
      "|    time_elapsed     | 185       |\n",
      "|    total timesteps  | 20192     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -31.2     |\n",
      "|    critic_loss      | 5.55      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17668     |\n",
      "-----------------------------------\n",
      "day: 2523, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 50918.11\n",
      "total_reward: 918.11\n",
      "total_cost: 139.45\n",
      "total_trades: 28764\n",
      "Sharpe: 0.398\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.09e+04 |\n",
      "|    total_cost       | 132      |\n",
      "|    total_reward     | 889      |\n",
      "|    total_reward_pct | 1.78     |\n",
      "|    total_trades     | 29069    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total timesteps  | 30288    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -19.1    |\n",
      "|    critic_loss      | 1.91     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27764    |\n",
      "----------------------------------\n",
      "day: 2523, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 54862.76\n",
      "total_reward: 4862.76\n",
      "total_cost: 123.22\n",
      "total_trades: 28963\n",
      "Sharpe: 0.434\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.82e+04 |\n",
      "|    total_cost       | 109      |\n",
      "|    total_reward     | 1.82e+04 |\n",
      "|    total_reward_pct | 36.4     |\n",
      "|    total_trades     | 28850    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 388      |\n",
      "|    total timesteps  | 40384    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -11.9    |\n",
      "|    critic_loss      | 0.876    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37860    |\n",
      "----------------------------------\n",
      "day: 2523, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 65260.27\n",
      "total_reward: 15260.27\n",
      "total_cost: 118.07\n",
      "total_trades: 28434\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.53e+04 |\n",
      "|    total_cost       | 118      |\n",
      "|    total_reward     | 1.53e+04 |\n",
      "|    total_reward_pct | 30.5     |\n",
      "|    total_trades     | 28434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 490      |\n",
      "|    total timesteps  | 50480    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -7.48    |\n",
      "|    critic_loss      | 0.48     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47956    |\n",
      "----------------------------------\n",
      "======Trading from:  2020-04-06 to  2020-07-09\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2010-01-01 to  2020-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | 0.272    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.869   |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -3.29    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.68    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.002    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -8.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.419   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -3.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.078    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00502  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -4.51    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0431   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.3e+04  |\n",
      "|    total_cost         | 2.08e+04 |\n",
      "|    total_reward       | -3.7e+04 |\n",
      "|    total_reward_pct   | -74      |\n",
      "|    total_trades       | 26684    |\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | -0.129   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.33     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00613  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -0.441   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -8.36    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0914   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.236   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.69     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.008    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | 0.0124   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 2.48     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00925  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00337  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.07e+04  |\n",
      "|    total_cost         | 1.32e+04  |\n",
      "|    total_reward       | -1.93e+04 |\n",
      "|    total_reward_pct   | -38.6     |\n",
      "|    total_trades       | 27565     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | -9.02     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -1.6      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.00468   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 2.08     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.00586  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 0.465     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.000268  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.1    |\n",
      "|    explained_variance | -7.59    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -2.85    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00217  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.58e+03  |\n",
      "|    total_cost         | 9.33e+03  |\n",
      "|    total_reward       | -4.84e+04 |\n",
      "|    total_reward_pct   | -96.8     |\n",
      "|    total_trades       | 26711     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.6     |\n",
      "|    explained_variance | -38.5     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -6.11     |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.0602    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.627   |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.000567 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.2    |\n",
      "|    explained_variance | -8.58    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 1.89     |\n",
      "|    std                | 1.25     |\n",
      "|    value_loss         | 0.00947  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0.357    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.276    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 3.16     |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 0.0148   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.62e+04 |\n",
      "|    total_cost         | 2.27e+04 |\n",
      "|    total_reward       | 2.62e+04 |\n",
      "|    total_reward_pct   | 52.4     |\n",
      "|    total_trades       | 29714    |\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | -4.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 5.06     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.0246   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.569    |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.000951 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | -1.8     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 3.85     |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.0246   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.6    |\n",
      "|    explained_variance | 0.374    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.0698   |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.00023  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.9    |\n",
      "|    explained_variance | 0.0578   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -3.7     |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.0143   |\n",
      "------------------------------------\n",
      "day: 2523, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 29214.15\n",
      "total_reward: -20785.85\n",
      "total_cost: 16283.28\n",
      "total_trades: 29978\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.92e+04  |\n",
      "|    total_cost         | 1.63e+04  |\n",
      "|    total_reward       | -2.08e+04 |\n",
      "|    total_reward_pct   | -41.6     |\n",
      "|    total_trades       | 29978     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.1     |\n",
      "|    explained_variance | 0.307     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -0.0493   |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.000105  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0377  |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 1.49e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 0.356     |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 0.000227  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0.00124  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 1.71     |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.00303  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.447    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.000653 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.81e+04  |\n",
      "|    total_cost         | 6.51e+03  |\n",
      "|    total_reward       | -3.19e+04 |\n",
      "|    total_reward_pct   | -63.8     |\n",
      "|    total_trades       | 27659     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.5     |\n",
      "|    explained_variance | -3.69     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -1.14     |\n",
      "|    std                | 1.49      |\n",
      "|    value_loss         | 0.00125   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.9    |\n",
      "|    explained_variance | -0.651   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00145  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.949    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.000819 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.5    |\n",
      "|    explained_variance | -0.345   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 2.01     |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 0.00429  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -2.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 2        |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.00408  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.42e+04  |\n",
      "|    total_cost         | 3.86e+03  |\n",
      "|    total_reward       | -1.58e+04 |\n",
      "|    total_reward_pct   | -31.5     |\n",
      "|    total_trades       | 25790     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36       |\n",
      "|    explained_variance | -0.00218  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 1.16      |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 0.00198   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | 0.245    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 1.92     |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.00338  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | -0.163   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.856   |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.00115  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | 0.0587   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.34     |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.00166  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -7.68     |\n",
      "|    std                | 1.69      |\n",
      "|    value_loss         | 0.0537    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.18e+04 |\n",
      "|    total_cost         | 8.18e+03 |\n",
      "|    total_reward       | 1.83e+03 |\n",
      "|    total_reward_pct   | 3.67     |\n",
      "|    total_trades       | 27317    |\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.1    |\n",
      "|    explained_variance | -9.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 0.00421  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -1.35    |\n",
      "|    std                | 1.74     |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.322   |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 0.000137 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 0.00275  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.3    |\n",
      "|    explained_variance | -0.0205  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.502    |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.0036   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.91e+04 |\n",
      "|    total_cost         | 1.74e+04 |\n",
      "|    total_reward       | -906     |\n",
      "|    total_reward_pct   | -1.81    |\n",
      "|    total_trades       | 28348    |\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 2.15     |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 0.00355  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.404    |\n",
      "|    std                | 1.87     |\n",
      "|    value_loss         | 0.000444 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -0.433    |\n",
      "|    std                | 1.9       |\n",
      "|    value_loss         | 0.000579  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | -0.167   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.804   |\n",
      "|    std                | 1.93     |\n",
      "|    value_loss         | 0.0052   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | -8.98    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 4        |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "day: 2523, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21222.59\n",
      "total_reward: -28777.41\n",
      "total_cost: 15236.99\n",
      "total_trades: 29444\n",
      "Sharpe: 0.039\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.12e+04  |\n",
      "|    total_cost         | 1.52e+04  |\n",
      "|    total_reward       | -2.88e+04 |\n",
      "|    total_reward_pct   | -57.6     |\n",
      "|    total_trades       | 29444     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 0.314     |\n",
      "|    std                | 1.97      |\n",
      "|    value_loss         | 0.000281  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.725   |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 0.00047  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -2.42    |\n",
      "|    std                | 2.05     |\n",
      "|    value_loss         | 0.00797  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -7.53    |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 0.0996   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 2.01     |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -4.93e+03 |\n",
      "|    total_cost         | 7.5e+03   |\n",
      "|    total_reward       | -5.49e+04 |\n",
      "|    total_reward_pct   | -110      |\n",
      "|    total_trades       | 26710     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0.146     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -0.258    |\n",
      "|    std                | 2.11      |\n",
      "|    value_loss         | 9.54e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.905    |\n",
      "|    std                | 2.15     |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 0.635     |\n",
      "|    std                | 2.18      |\n",
      "|    value_loss         | 0.000408  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 3.98     |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0.445    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -4.1     |\n",
      "|    std                | 2.24     |\n",
      "|    value_loss         | 0.0121   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.53e+03  |\n",
      "|    total_cost         | 6.14e+03  |\n",
      "|    total_reward       | -4.65e+04 |\n",
      "|    total_reward_pct   | -92.9     |\n",
      "|    total_trades       | 26191     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -1.35     |\n",
      "|    std                | 2.26      |\n",
      "|    value_loss         | 0.000982  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 3.16     |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 0.00639  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0575  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 1.3      |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 0.0018   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -4.62    |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    std                | 2.38     |\n",
      "|    value_loss         | 0.00352  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.09e+04 |\n",
      "|    total_cost         | 5.81e+03  |\n",
      "|    total_reward       | -6.09e+04 |\n",
      "|    total_reward_pct   | -122      |\n",
      "|    total_trades       | 26015     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -4.01     |\n",
      "|    std                | 2.4       |\n",
      "|    value_loss         | 0.00834   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.129   |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 1.56e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0.00794 |\n",
      "|    std                | 2.49     |\n",
      "|    value_loss         | 0.000132 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 5.64     |\n",
      "|    std                | 2.52     |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 17.7     |\n",
      "|    std                | 2.53     |\n",
      "|    value_loss         | 0.188    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3e+04    |\n",
      "|    total_cost         | 4.47e+03 |\n",
      "|    total_reward       | -2e+04   |\n",
      "|    total_reward_pct   | -40      |\n",
      "|    total_trades       | 25535    |\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0.0527   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 2.36     |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.00354  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | -3.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -2.67    |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.00393  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -4.42    |\n",
      "|    std                | 2.64     |\n",
      "|    value_loss         | 0.0133   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 7.78      |\n",
      "|    std                | 2.68      |\n",
      "|    value_loss         | 0.0591    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -7.77    |\n",
      "|    std                | 2.69     |\n",
      "|    value_loss         | 0.0375   |\n",
      "------------------------------------\n",
      "day: 2523, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4067.94\n",
      "total_reward: -45932.06\n",
      "total_cost: 2811.65\n",
      "total_trades: 25598\n",
      "Sharpe: -0.192\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.07e+03  |\n",
      "|    total_cost         | 2.81e+03  |\n",
      "|    total_reward       | -4.59e+04 |\n",
      "|    total_reward_pct   | -91.9     |\n",
      "|    total_trades       | 25598     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | -150      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 1.16      |\n",
      "|    std                | 2.71      |\n",
      "|    value_loss         | 0.00175   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | -0.254   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -0.258   |\n",
      "|    std                | 2.76     |\n",
      "|    value_loss         | 0.000134 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0.741    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.313   |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 0.00622  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | -0.279   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 2.87     |\n",
      "|    value_loss         | 0.00186  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 3.43     |\n",
      "|    std                | 2.9      |\n",
      "|    value_loss         | 0.0058   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.12e+04  |\n",
      "|    total_cost         | 2.89e+03  |\n",
      "|    total_reward       | -2.88e+04 |\n",
      "|    total_reward_pct   | -57.6     |\n",
      "|    total_trades       | 25644     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -3.22     |\n",
      "|    std                | 2.93      |\n",
      "|    value_loss         | 0.0047    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.0567   |\n",
      "|    std                | 2.98     |\n",
      "|    value_loss         | 8.16e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0.123    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 2.76     |\n",
      "|    std                | 3.03     |\n",
      "|    value_loss         | 0.00411  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -0.672    |\n",
      "|    std                | 3.08      |\n",
      "|    value_loss         | 0.000531  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.6    |\n",
      "|    explained_variance | 0.218    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.467   |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 0.000203 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.44e+03  |\n",
      "|    total_cost         | 2.09e+03  |\n",
      "|    total_reward       | -4.06e+04 |\n",
      "|    total_reward_pct   | -81.1     |\n",
      "|    total_trades       | 24971     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.9     |\n",
      "|    explained_variance | -0.0513   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 2.81      |\n",
      "|    std                | 3.18      |\n",
      "|    value_loss         | 0.00606   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -1.18    |\n",
      "|    std                | 3.23     |\n",
      "|    value_loss         | 0.00162  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -6.8     |\n",
      "|    std                | 3.28     |\n",
      "|    value_loss         | 0.0218   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 2.41      |\n",
      "|    std                | 3.31      |\n",
      "|    value_loss         | 0.0027    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0.772    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 6.26     |\n",
      "|    std                | 3.35     |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -7.88e+03 |\n",
      "|    total_cost         | 3.37e+03  |\n",
      "|    total_reward       | -5.79e+04 |\n",
      "|    total_reward_pct   | -116      |\n",
      "|    total_trades       | 25683     |\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.1     |\n",
      "|    explained_variance | -8.71     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -1.17     |\n",
      "|    std                | 3.39      |\n",
      "|    value_loss         | 0.00109   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 0.861     |\n",
      "|    std                | 3.44      |\n",
      "|    value_loss         | 0.000341  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.8     |\n",
      "|    explained_variance | -0.000128 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 12.9      |\n",
      "|    std                | 3.51      |\n",
      "|    value_loss         | 0.302     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 225      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 2.43     |\n",
      "|    std                | 3.57     |\n",
      "|    value_loss         | 0.00308  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.0708  |\n",
      "|    std                | 3.64     |\n",
      "|    value_loss         | 1.56e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.12e+04  |\n",
      "|    total_cost         | 2.06e+03  |\n",
      "|    total_reward       | -3.88e+04 |\n",
      "|    total_reward_pct   | -77.5     |\n",
      "|    total_trades       | 26187     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 213       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.8     |\n",
      "|    explained_variance | -0.426    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -1.19     |\n",
      "|    std                | 3.71      |\n",
      "|    value_loss         | 0.000598  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.854   |\n",
      "|    std                | 3.78     |\n",
      "|    value_loss         | 0.000324 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -3.03    |\n",
      "|    std                | 3.86     |\n",
      "|    value_loss         | 0.00352  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -1.23    |\n",
      "|    std                | 3.93     |\n",
      "|    value_loss         | 0.000959 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.2    |\n",
      "|    explained_variance | -2.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.565    |\n",
      "|    std                | 3.99     |\n",
      "|    value_loss         | 0.00124  |\n",
      "------------------------------------\n",
      "day: 2523, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -423.18\n",
      "total_reward: -50423.18\n",
      "total_cost: 2209.04\n",
      "total_trades: 26094\n",
      "Sharpe: -0.032\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -423      |\n",
      "|    total_cost         | 2.21e+03  |\n",
      "|    total_reward       | -5.04e+04 |\n",
      "|    total_reward_pct   | -101      |\n",
      "|    total_trades       | 26094     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 224       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.5     |\n",
      "|    explained_variance | -1        |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 1.72      |\n",
      "|    std                | 4.05      |\n",
      "|    value_loss         | 0.00131   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 1.5      |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 0.000854 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 1.39     |\n",
      "|    std                | 4.21     |\n",
      "|    value_loss         | 0.000863 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    std                | 4.29     |\n",
      "|    value_loss         | 0.00101  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | -3.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.631   |\n",
      "|    std                | 4.38     |\n",
      "|    value_loss         | 0.000287 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 235       |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -6.81     |\n",
      "|    std                | 4.47      |\n",
      "|    value_loss         | 0.0257    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -3.93e+03 |\n",
      "|    total_cost         | 2.6e+03   |\n",
      "|    total_reward       | -5.39e+04 |\n",
      "|    total_reward_pct   | -108      |\n",
      "|    total_trades       | 26553     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 1.1       |\n",
      "|    std                | 4.56      |\n",
      "|    value_loss         | 0.00059   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -1.41    |\n",
      "|    std                | 4.67     |\n",
      "|    value_loss         | 0.00137  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -0.0704   |\n",
      "|    std                | 4.76      |\n",
      "|    value_loss         | 0.000157  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.8    |\n",
      "|    explained_variance | -0.386   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 2.67     |\n",
      "|    std                | 4.81     |\n",
      "|    value_loss         | 0.00968  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 3.98     |\n",
      "|    std                | 4.87     |\n",
      "|    value_loss         | 0.0112   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -7.49e+03 |\n",
      "|    total_cost         | 8.57e+03  |\n",
      "|    total_reward       | -5.75e+04 |\n",
      "|    total_reward_pct   | -115      |\n",
      "|    total_trades       | 27649     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 0.34      |\n",
      "|    std                | 4.96      |\n",
      "|    value_loss         | 4.33e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -0.454   |\n",
      "|    std                | 5.07     |\n",
      "|    value_loss         | 6.69e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.2    |\n",
      "|    explained_variance | 0.0393   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -7.28    |\n",
      "|    std                | 5.19     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -8.59    |\n",
      "|    std                | 5.23     |\n",
      "|    value_loss         | 0.026    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 5.27     |\n",
      "|    value_loss         | 0.0627   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.08e+04 |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -6.08e+04 |\n",
      "|    total_reward_pct   | -122      |\n",
      "|    total_trades       | 27781     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -1.32     |\n",
      "|    std                | 5.33      |\n",
      "|    value_loss         | 0.000679  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 4.37     |\n",
      "|    std                | 5.41     |\n",
      "|    value_loss         | 0.00784  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 264       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.3     |\n",
      "|    explained_variance | -0.000398 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 0.767     |\n",
      "|    std                | 5.49      |\n",
      "|    value_loss         | 0.000625  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.6    |\n",
      "|    explained_variance | 0.355    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -2.9     |\n",
      "|    std                | 5.57     |\n",
      "|    value_loss         | 0.00283  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.7    |\n",
      "|    explained_variance | -0.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -4.11    |\n",
      "|    std                | 5.62     |\n",
      "|    value_loss         | 0.00545  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.91e+04 |\n",
      "|    total_cost         | 8.35e+03  |\n",
      "|    total_reward       | -6.91e+04 |\n",
      "|    total_reward_pct   | -138      |\n",
      "|    total_trades       | 27109     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 271       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -2.46     |\n",
      "|    std                | 5.67      |\n",
      "|    value_loss         | 0.00746   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 4.24     |\n",
      "|    std                | 5.74     |\n",
      "|    value_loss         | 0.005    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.835    |\n",
      "|    std                | 5.78     |\n",
      "|    value_loss         | 0.00377  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -55      |\n",
      "|    std                | 5.81     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 5.85     |\n",
      "|    value_loss         | 0.0731   |\n",
      "------------------------------------\n",
      "day: 2523, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 41276.80\n",
      "total_reward: -8723.20\n",
      "total_cost: 12852.50\n",
      "total_trades: 27909\n",
      "Sharpe: 0.203\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.13e+04  |\n",
      "|    total_cost         | 1.29e+04  |\n",
      "|    total_reward       | -8.72e+03 |\n",
      "|    total_reward_pct   | -17.4     |\n",
      "|    total_trades       | 27909     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 282       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -0.646    |\n",
      "|    std                | 5.91      |\n",
      "|    value_loss         | 0.000236  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61      |\n",
      "|    explained_variance | 0.433    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.481    |\n",
      "|    std                | 6        |\n",
      "|    value_loss         | 8.93e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 4.99     |\n",
      "|    std                | 6.1      |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 0.451    |\n",
      "|    std                | 6.17     |\n",
      "|    value_loss         | 0.000402 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.0884  |\n",
      "|    std                | 6.22     |\n",
      "|    value_loss         | 0.000291 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.2e+04  |\n",
      "|    total_cost         | 1.12e+04 |\n",
      "|    total_reward       | -3.8e+04 |\n",
      "|    total_reward_pct   | -76      |\n",
      "|    total_trades       | 27479    |\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.9    |\n",
      "|    explained_variance | 0.359    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 2.43     |\n",
      "|    std                | 6.31     |\n",
      "|    value_loss         | 0.00165  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 296       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | -0.472    |\n",
      "|    std                | 6.43      |\n",
      "|    value_loss         | 6.45e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.7    |\n",
      "|    explained_variance | 3.99e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -4.04    |\n",
      "|    std                | 6.58     |\n",
      "|    value_loss         | 0.00435  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -3.53    |\n",
      "|    std                | 6.71     |\n",
      "|    value_loss         | 0.00397  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -1.34    |\n",
      "|    std                | 6.8      |\n",
      "|    value_loss         | 0.000601 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.06e+04  |\n",
      "|    total_cost         | 3.67e+04  |\n",
      "|    total_reward       | -2.94e+04 |\n",
      "|    total_reward_pct   | -58.9     |\n",
      "|    total_trades       | 29392     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 304       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.7     |\n",
      "|    explained_variance | 0.0917    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -0.0129   |\n",
      "|    std                | 6.91      |\n",
      "|    value_loss         | 9.83e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 307       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -0.388    |\n",
      "|    std                | 7.08      |\n",
      "|    value_loss         | 7.27e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 0.581    |\n",
      "|    std                | 7.26     |\n",
      "|    value_loss         | 0.000172 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65      |\n",
      "|    explained_variance | 0.0298   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 7.41     |\n",
      "|    value_loss         | 0.000517 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.517   |\n",
      "|    std                | 7.54     |\n",
      "|    value_loss         | 9.59e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.28e+04  |\n",
      "|    total_cost         | 3.54e+04  |\n",
      "|    total_reward       | -3.72e+04 |\n",
      "|    total_reward_pct   | -74.5     |\n",
      "|    total_trades       | 30094     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 316       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | -0.626    |\n",
      "|    std                | 7.68      |\n",
      "|    value_loss         | 0.000374  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66      |\n",
      "|    explained_variance | 0.834    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.652    |\n",
      "|    std                | 7.82     |\n",
      "|    value_loss         | 0.000125 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.4    |\n",
      "|    explained_variance | -1.52    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 0.239    |\n",
      "|    std                | 7.98     |\n",
      "|    value_loss         | 0.000623 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 31.1     |\n",
      "|    std                | 8.06     |\n",
      "|    value_loss         | 0.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 5.43     |\n",
      "|    std                | 8.11     |\n",
      "|    value_loss         | 0.0152   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.55e+04  |\n",
      "|    total_cost         | 3.44e+04  |\n",
      "|    total_reward       | -1.45e+04 |\n",
      "|    total_reward_pct   | -28.9     |\n",
      "|    total_trades       | 30624     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 327       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.9     |\n",
      "|    explained_variance | -0.61     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 0.636     |\n",
      "|    std                | 8.2       |\n",
      "|    value_loss         | 0.000114  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 0.392    |\n",
      "|    std                | 8.35     |\n",
      "|    value_loss         | 3.69e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    std                | 8.51     |\n",
      "|    value_loss         | 0.000454 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -3.28    |\n",
      "|    std                | 8.7      |\n",
      "|    value_loss         | 0.00239  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | -1.75    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 2.1      |\n",
      "|    std                | 8.89     |\n",
      "|    value_loss         | 0.00195  |\n",
      "------------------------------------\n",
      "day: 2523, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 7117.05\n",
      "total_reward: -42882.95\n",
      "total_cost: 31088.31\n",
      "total_trades: 30232\n",
      "Sharpe: -0.245\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.12e+03  |\n",
      "|    total_cost         | 3.11e+04  |\n",
      "|    total_reward       | -4.29e+04 |\n",
      "|    total_reward_pct   | -85.8     |\n",
      "|    total_trades       | 30232     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 338       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -0.695    |\n",
      "|    std                | 9.1       |\n",
      "|    value_loss         | 0.00012   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -0.714   |\n",
      "|    std                | 9.37     |\n",
      "|    value_loss         | 0.000109 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 342      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.816    |\n",
      "|    std                | 9.68     |\n",
      "|    value_loss         | 0.000212 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -2.97    |\n",
      "|    std                | 9.9      |\n",
      "|    value_loss         | 0.0026   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 0.162    |\n",
      "|    std                | 10.2     |\n",
      "|    value_loss         | 7.76e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.48e+03  |\n",
      "|    total_cost         | 2.71e+04  |\n",
      "|    total_reward       | -4.75e+04 |\n",
      "|    total_reward_pct   | -95       |\n",
      "|    total_trades       | 29776     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 349       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.5     |\n",
      "|    explained_variance | -1.34     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -1.39     |\n",
      "|    std                | 10.4      |\n",
      "|    value_loss         | 0.00057   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.1    |\n",
      "|    explained_variance | -0.342   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.218    |\n",
      "|    std                | 10.8     |\n",
      "|    value_loss         | 2.3e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 353      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.849   |\n",
      "|    std                | 11.1     |\n",
      "|    value_loss         | 0.000196 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.968   |\n",
      "|    std                | 11.5     |\n",
      "|    value_loss         | 0.000185 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.347   |\n",
      "|    std                | 12       |\n",
      "|    value_loss         | 2.31e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 784       |\n",
      "|    total_cost         | 1.19e+04  |\n",
      "|    total_reward       | -4.92e+04 |\n",
      "|    total_reward_pct   | -98.4     |\n",
      "|    total_trades       | 28669     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 360       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75       |\n",
      "|    explained_variance | -0.837    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 0.994     |\n",
      "|    std                | 12.5      |\n",
      "|    value_loss         | 0.000202  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 362      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.735   |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 0.000129 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 364      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 0.667    |\n",
      "|    std                | 13.4     |\n",
      "|    value_loss         | 9.78e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.000741 |\n",
      "|    std                | 13.8     |\n",
      "|    value_loss         | 5.08e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.6    |\n",
      "|    explained_variance | -4.76    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.0165   |\n",
      "|    std                | 14.4     |\n",
      "|    value_loss         | 1.43e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 633       |\n",
      "|    total_cost         | 1.41e+04  |\n",
      "|    total_reward       | -4.94e+04 |\n",
      "|    total_reward_pct   | -98.7     |\n",
      "|    total_trades       | 28867     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 371       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -78.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -0.0319   |\n",
      "|    std                | 15        |\n",
      "|    value_loss         | 1.48e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -0.539   |\n",
      "|    std                | 15.6     |\n",
      "|    value_loss         | 6.25e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.7    |\n",
      "|    explained_variance | 2.09e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.614    |\n",
      "|    std                | 16.1     |\n",
      "|    value_loss         | 7.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -2.39    |\n",
      "|    std                | 16.4     |\n",
      "|    value_loss         | 0.00136  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.5    |\n",
      "|    explained_variance | -0.404   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.0701  |\n",
      "|    std                | 16.8     |\n",
      "|    value_loss         | 2.23e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.7e+03   |\n",
      "|    total_cost         | 3.17e+04  |\n",
      "|    total_reward       | -4.03e+04 |\n",
      "|    total_reward_pct   | -80.6     |\n",
      "|    total_trades       | 30067     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 383       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -0.107    |\n",
      "|    std                | 17.2      |\n",
      "|    value_loss         | 3.02e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 0.56     |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 5.14e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.2    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 2.33     |\n",
      "|    std                | 18.3     |\n",
      "|    value_loss         | 0.000912 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 389       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 1.9       |\n",
      "|    std                | 18.7      |\n",
      "|    value_loss         | 0.000597  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 392      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.621   |\n",
      "|    std                | 19.1     |\n",
      "|    value_loss         | 0.00104  |\n",
      "------------------------------------\n",
      "day: 2523, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 9011.32\n",
      "total_reward: -40988.68\n",
      "total_cost: 32367.33\n",
      "total_trades: 29873\n",
      "Sharpe: 0.288\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.01e+03 |\n",
      "|    total_cost         | 3.24e+04 |\n",
      "|    total_reward       | -4.1e+04 |\n",
      "|    total_reward_pct   | -82      |\n",
      "|    total_trades       | 29873    |\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 394      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.459    |\n",
      "|    std                | 19.5     |\n",
      "|    value_loss         | 3.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 396      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.8    |\n",
      "|    explained_variance | -0.00589 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 0.0704   |\n",
      "|    std                | 20       |\n",
      "|    value_loss         | 1.08e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 398       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.4     |\n",
      "|    explained_variance | -0.000463 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 1.01      |\n",
      "|    std                | 20.6      |\n",
      "|    value_loss         | 0.000342  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 401       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | 0.273     |\n",
      "|    std                | 21.2      |\n",
      "|    value_loss         | 0.000271  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -1.81    |\n",
      "|    std                | 21.6     |\n",
      "|    value_loss         | 0.000497 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.69e+03  |\n",
      "|    total_cost         | 3.07e+04  |\n",
      "|    total_reward       | -4.33e+04 |\n",
      "|    total_reward_pct   | -86.6     |\n",
      "|    total_trades       | 29735     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 405       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 0.161     |\n",
      "|    std                | 22.2      |\n",
      "|    value_loss         | 4.09e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 407      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.126    |\n",
      "|    std                | 22.8     |\n",
      "|    value_loss         | 2.43e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 2.43     |\n",
      "|    std                | 23.6     |\n",
      "|    value_loss         | 0.00084  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 412      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.668   |\n",
      "|    std                | 24.2     |\n",
      "|    value_loss         | 7.52e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 414      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -0.386   |\n",
      "|    std                | 24.9     |\n",
      "|    value_loss         | 3.6e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.49e+03  |\n",
      "|    total_cost         | 2.86e+04  |\n",
      "|    total_reward       | -4.85e+04 |\n",
      "|    total_reward_pct   | -97       |\n",
      "|    total_trades       | 29969     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 416       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.6     |\n",
      "|    explained_variance | 0.0805    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 1.24      |\n",
      "|    std                | 25.6      |\n",
      "|    value_loss         | 0.000507  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 418      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89      |\n",
      "|    explained_variance | -8.14    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 1.37     |\n",
      "|    std                | 26.2     |\n",
      "|    value_loss         | 0.000835 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 421      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    std                | 27       |\n",
      "|    value_loss         | 0.000463 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 423       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -90.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 0.173     |\n",
      "|    std                | 27.8      |\n",
      "|    value_loss         | 7.35e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 425      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.7    |\n",
      "|    explained_variance | -14.6    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -1.41    |\n",
      "|    std                | 28.8     |\n",
      "|    value_loss         | 0.000309 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.37e+03  |\n",
      "|    total_cost         | 1.65e+04  |\n",
      "|    total_reward       | -4.86e+04 |\n",
      "|    total_reward_pct   | -97.3     |\n",
      "|    total_trades       | 29114     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 427       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91.5     |\n",
      "|    explained_variance | -0.0404   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | -2.37     |\n",
      "|    std                | 29.9      |\n",
      "|    value_loss         | 0.00131   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 430      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.1    |\n",
      "|    explained_variance | 0.478    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.833   |\n",
      "|    std                | 30.9     |\n",
      "|    value_loss         | 0.000118 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 432      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.6    |\n",
      "|    explained_variance | -7.96    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 0.146    |\n",
      "|    std                | 31.8     |\n",
      "|    value_loss         | 0.000151 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 434       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 0.934     |\n",
      "|    std                | 32.7      |\n",
      "|    value_loss         | 0.000186  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 436      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.8    |\n",
      "|    explained_variance | -1.5     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.777   |\n",
      "|    std                | 33.9     |\n",
      "|    value_loss         | 0.000107 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.05e+04 |\n",
      "|    total_cost         | 2.21e+04  |\n",
      "|    total_reward       | -6.05e+04 |\n",
      "|    total_reward_pct   | -121      |\n",
      "|    total_trades       | 29531     |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 438       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -94.4     |\n",
      "|    explained_variance | -13.9     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 23.7      |\n",
      "|    std                | 34.9      |\n",
      "|    value_loss         | 0.13      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 441      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.7    |\n",
      "|    explained_variance | -0.287   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.522    |\n",
      "|    std                | 35.5     |\n",
      "|    value_loss         | 0.000931 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 443      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -2.09    |\n",
      "|    std                | 36.2     |\n",
      "|    value_loss         | 0.000733 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 445       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -95.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | 0.774     |\n",
      "|    std                | 37.1      |\n",
      "|    value_loss         | 8.11e-05  |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-04-06 to  2020-07-09\n",
      "A2C Sharpe Ratio:  0.2094302321622131\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 255  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.03e+03   |\n",
      "|    total_cost           | 3.08e+04   |\n",
      "|    total_reward         | -4.7e+04   |\n",
      "|    total_reward_pct     | -93.9      |\n",
      "|    total_trades         | 29935      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 250        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01728417 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27        |\n",
      "|    explained_variance   | 0.171      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.287     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.52e+03    |\n",
      "|    total_cost           | 3.12e+04    |\n",
      "|    total_reward         | -4.45e+04   |\n",
      "|    total_reward_pct     | -89         |\n",
      "|    total_trades         | 30200       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011006067 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0238      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.09e+03    |\n",
      "|    total_cost           | 1.98e+04    |\n",
      "|    total_reward         | -4.69e+04   |\n",
      "|    total_reward_pct     | -93.8       |\n",
      "|    total_trades         | 28925       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015957614 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.39e+03    |\n",
      "|    total_cost           | 2.77e+04    |\n",
      "|    total_reward         | -4.76e+04   |\n",
      "|    total_reward_pct     | -95.2       |\n",
      "|    total_trades         | 29685       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020953488 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00758     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018758109 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00805     |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2450.36\n",
      "total_reward: -47549.64\n",
      "total_cost: 16438.45\n",
      "total_trades: 28312\n",
      "Sharpe: -0.307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.45e+03    |\n",
      "|    total_cost           | 1.64e+04    |\n",
      "|    total_reward         | -4.75e+04   |\n",
      "|    total_reward_pct     | -95.1       |\n",
      "|    total_trades         | 28312       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018300295 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00328     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.61e+03    |\n",
      "|    total_cost           | 2.53e+04    |\n",
      "|    total_reward         | -4.44e+04   |\n",
      "|    total_reward_pct     | -88.8       |\n",
      "|    total_trades         | 29171       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023546122 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.009       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.22e+03    |\n",
      "|    total_cost           | 1.89e+04    |\n",
      "|    total_reward         | -4.58e+04   |\n",
      "|    total_reward_pct     | -91.6       |\n",
      "|    total_trades         | 29186       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017502796 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00856     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.06e+03    |\n",
      "|    total_cost           | 2.9e+04     |\n",
      "|    total_reward         | -4.09e+04   |\n",
      "|    total_reward_pct     | -81.9       |\n",
      "|    total_trades         | 30356       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016533798 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00463     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025263812 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | -0.517      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.06e+03    |\n",
      "|    total_cost           | 3.85e+04    |\n",
      "|    total_reward         | -4.09e+04   |\n",
      "|    total_reward_pct     | -81.9       |\n",
      "|    total_trades         | 30730       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021788508 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00829     |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1895.34\n",
      "total_reward: -48104.66\n",
      "total_cost: 17823.79\n",
      "total_trades: 28931\n",
      "Sharpe: -0.489\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.9e+03     |\n",
      "|    total_cost           | 1.78e+04    |\n",
      "|    total_reward         | -4.81e+04   |\n",
      "|    total_reward_pct     | -96.2       |\n",
      "|    total_trades         | 28931       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022436485 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00688     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.11e+03    |\n",
      "|    total_cost           | 1.83e+04    |\n",
      "|    total_reward         | -4.59e+04   |\n",
      "|    total_reward_pct     | -91.8       |\n",
      "|    total_trades         | 28588       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021449357 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00662     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -3.03e+03   |\n",
      "|    total_cost           | 2.1e+04     |\n",
      "|    total_reward         | -5.3e+04    |\n",
      "|    total_reward_pct     | -106        |\n",
      "|    total_trades         | 28696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020881033 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00386     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013416849 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00681     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.67e+03    |\n",
      "|    total_cost           | 1.84e+04    |\n",
      "|    total_reward         | -4.43e+04   |\n",
      "|    total_reward_pct     | -88.7       |\n",
      "|    total_trades         | 28973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020682275 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00188     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+04    |\n",
      "|    total_cost           | 4.66e+04    |\n",
      "|    total_reward         | -3.06e+04   |\n",
      "|    total_reward_pct     | -61.2       |\n",
      "|    total_trades         | 31206       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018827595 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 103098.46\n",
      "total_reward: 53098.46\n",
      "total_cost: 74089.24\n",
      "total_trades: 33000\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 7.41e+04    |\n",
      "|    total_reward         | 5.31e+04    |\n",
      "|    total_reward_pct     | 106         |\n",
      "|    total_trades         | 33000       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020088453 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.063       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0347      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.05e+03    |\n",
      "|    total_cost           | 1.99e+04    |\n",
      "|    total_reward         | -4.1e+04    |\n",
      "|    total_reward_pct     | -81.9       |\n",
      "|    total_trades         | 29069       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020714864 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0664      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 7.13e+04    |\n",
      "|    total_reward         | 5.16e+04    |\n",
      "|    total_reward_pct     | 103         |\n",
      "|    total_trades         | 32866       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026582021 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0217      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026557267 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.081       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.43e+04    |\n",
      "|    total_cost           | 4.82e+04    |\n",
      "|    total_reward         | 3.43e+04    |\n",
      "|    total_reward_pct     | 68.5        |\n",
      "|    total_trades         | 31685       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019765615 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.96e+04    |\n",
      "|    total_cost           | 2.97e+04    |\n",
      "|    total_reward         | -2.04e+04   |\n",
      "|    total_reward_pct     | -40.7       |\n",
      "|    total_trades         | 30315       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019469239 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.269      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.047       |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21452.47\n",
      "total_reward: -28547.53\n",
      "total_cost: 24315.62\n",
      "total_trades: 30223\n",
      "Sharpe: 0.297\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.15e+04    |\n",
      "|    total_cost           | 2.43e+04    |\n",
      "|    total_reward         | -2.85e+04   |\n",
      "|    total_reward_pct     | -57.1       |\n",
      "|    total_trades         | 30223       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018075258 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.283      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.88e+04    |\n",
      "|    total_cost           | 2.91e+04    |\n",
      "|    total_reward         | -2.12e+04   |\n",
      "|    total_reward_pct     | -42.5       |\n",
      "|    total_trades         | 30623       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021937666 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | -0.22       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.321      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0226      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03481315 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.1      |\n",
      "|    explained_variance   | 0.51       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.31      |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0126     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.06e+04   |\n",
      "|    total_cost           | 2.72e+04   |\n",
      "|    total_reward         | 1.06e+04   |\n",
      "|    total_reward_pct     | 21.1       |\n",
      "|    total_trades         | 30342      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03519093 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.33      |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0193     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.98e+04    |\n",
      "|    total_cost           | 2.51e+04    |\n",
      "|    total_reward         | -2.02e+04   |\n",
      "|    total_reward_pct     | -40.3       |\n",
      "|    total_trades         | 29572       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020045932 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0276      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.5e+04     |\n",
      "|    total_cost           | 3.68e+04    |\n",
      "|    total_reward         | -5e+03      |\n",
      "|    total_reward_pct     | -10         |\n",
      "|    total_trades         | 31097       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036102653 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | -0.203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0448      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 48576.00\n",
      "total_reward: -1424.00\n",
      "total_cost: 21352.51\n",
      "total_trades: 29773\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.86e+04    |\n",
      "|    total_cost           | 2.14e+04    |\n",
      "|    total_reward         | -1.42e+03   |\n",
      "|    total_reward_pct     | -2.85       |\n",
      "|    total_trades         | 29773       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030668685 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0265      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029487602 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.259      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0304      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.88e+04    |\n",
      "|    total_cost           | 1.98e+04    |\n",
      "|    total_reward         | -1.2e+03    |\n",
      "|    total_reward_pct     | -2.41       |\n",
      "|    total_trades         | 29365       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023563968 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0146      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.13e+04   |\n",
      "|    total_cost           | 1.81e+04    |\n",
      "|    total_reward         | -6.13e+04   |\n",
      "|    total_reward_pct     | -123        |\n",
      "|    total_trades         | 29064       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023396704 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0142      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.29e+04    |\n",
      "|    total_cost           | 2.88e+04    |\n",
      "|    total_reward         | 2.87e+03    |\n",
      "|    total_reward_pct     | 5.75        |\n",
      "|    total_trades         | 30171       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030770948 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0303      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.87e+04    |\n",
      "|    total_cost           | 3.32e+04    |\n",
      "|    total_reward         | 3.87e+04    |\n",
      "|    total_reward_pct     | 77.3        |\n",
      "|    total_trades         | 30720       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013594376 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0373      |\n",
      "-----------------------------------------\n",
      "day: 2523, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24257.40\n",
      "total_reward: -25742.60\n",
      "total_cost: 15596.00\n",
      "total_trades: 28493\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+04    |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -2.57e+04   |\n",
      "|    total_reward_pct     | -51.5       |\n",
      "|    total_trades         | 28493       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030644597 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0628      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027895126 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0149      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.13e+04   |\n",
      "|    total_cost           | 1.61e+04   |\n",
      "|    total_reward         | -3.87e+04  |\n",
      "|    total_reward_pct     | -77.4      |\n",
      "|    total_trades         | 28997      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02609189 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.6      |\n",
      "|    explained_variance   | 0.742      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.281     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0092    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.00391    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.54e+04    |\n",
      "|    total_cost           | 2.05e+04    |\n",
      "|    total_reward         | -3.46e+04   |\n",
      "|    total_reward_pct     | -69.2       |\n",
      "|    total_trades         | 29229       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026038121 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00911     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -7.92e+03   |\n",
      "|    total_cost           | 1.81e+04    |\n",
      "|    total_reward         | -5.79e+04   |\n",
      "|    total_reward_pct     | -116        |\n",
      "|    total_trades         | 29419       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021454848 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.331      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00906     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.8e+04     |\n",
      "|    total_cost           | 1.65e+04    |\n",
      "|    total_reward         | -2.2e+04    |\n",
      "|    total_reward_pct     | -44         |\n",
      "|    total_trades         | 29266       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013695425 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.316      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00625     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 356        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02713922 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.8      |\n",
      "|    explained_variance   | 0.628      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.321     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 0.0123     |\n",
      "----------------------------------------\n",
      "day: 2523, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 52246.89\n",
      "total_reward: 2246.89\n",
      "total_cost: 20610.54\n",
      "total_trades: 29505\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.22e+04    |\n",
      "|    total_cost           | 2.06e+04    |\n",
      "|    total_reward         | 2.25e+03    |\n",
      "|    total_reward_pct     | 4.49        |\n",
      "|    total_trades         | 29505       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025693897 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0245      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.67e+04    |\n",
      "|    total_cost           | 2.11e+04    |\n",
      "|    total_reward         | -1.33e+04   |\n",
      "|    total_reward_pct     | -26.7       |\n",
      "|    total_trades         | 29375       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014848293 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0269      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.37e+04    |\n",
      "|    total_cost           | 2e+04       |\n",
      "|    total_reward         | -2.63e+04   |\n",
      "|    total_reward_pct     | -52.6       |\n",
      "|    total_trades         | 29458       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031977978 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.36e+04    |\n",
      "|    total_cost           | 1.75e+04    |\n",
      "|    total_reward         | 3.59e+03    |\n",
      "|    total_reward_pct     | 7.18        |\n",
      "|    total_trades         | 29023       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029922312 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027804308 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.9       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0368      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 769        |\n",
      "|    total_cost           | 1.85e+04   |\n",
      "|    total_reward         | -4.92e+04  |\n",
      "|    total_reward_pct     | -98.5      |\n",
      "|    total_trades         | 29296      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 406        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03201084 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -29        |\n",
      "|    explained_variance   | 0.812      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.317     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.00621    |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2020-04-06 to  2020-07-09\n",
      "PPO Sharpe Ratio:  0.05082339923345235\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 8.92e+04 |\n",
      "|    total_cost       | 228      |\n",
      "|    total_reward     | 3.92e+04 |\n",
      "|    total_reward_pct | 78.3     |\n",
      "|    total_trades     | 23141    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total timesteps  | 10096    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 49.9     |\n",
      "|    critic_loss      | 11.6     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7572     |\n",
      "----------------------------------\n",
      "day: 2523, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 41598.84\n",
      "total_reward: -8401.16\n",
      "total_cost: 158.18\n",
      "total_trades: 23586\n",
      "Sharpe: 0.415\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.06e+04 |\n",
      "|    total_cost       | 321      |\n",
      "|    total_reward     | 4.06e+04 |\n",
      "|    total_reward_pct | 81.3     |\n",
      "|    total_trades     | 24218    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 107      |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total timesteps  | 20192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 29.6     |\n",
      "|    critic_loss      | 2.76     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17668    |\n",
      "----------------------------------\n",
      "day: 2523, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 92049.20\n",
      "total_reward: 42049.20\n",
      "total_cost: 279.54\n",
      "total_trades: 24808\n",
      "Sharpe: 0.420\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 5.35e+04 |\n",
      "|    total_cost       | 177      |\n",
      "|    total_reward     | 3.52e+03 |\n",
      "|    total_reward_pct | 7.04     |\n",
      "|    total_trades     | 24707    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total timesteps  | 30288    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 17.4     |\n",
      "|    critic_loss      | 1.2      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 27764    |\n",
      "----------------------------------\n",
      "day: 2523, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 74437.09\n",
      "total_reward: 24437.09\n",
      "total_cost: 287.30\n",
      "total_trades: 24709\n",
      "Sharpe: 0.457\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.7e+04  |\n",
      "|    total_cost       | 141      |\n",
      "|    total_reward     | -2.3e+04 |\n",
      "|    total_reward_pct | -46.1    |\n",
      "|    total_trades     | 24482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 391      |\n",
      "|    total timesteps  | 40384    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 10       |\n",
      "|    critic_loss      | 0.856    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 37860    |\n",
      "----------------------------------\n",
      "day: 2523, episode: 100\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 77815.15\n",
      "total_reward: 27815.15\n",
      "total_cost: 325.64\n",
      "total_trades: 24438\n",
      "Sharpe: 0.442\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 7.78e+04 |\n",
      "|    total_cost       | 326      |\n",
      "|    total_reward     | 2.78e+04 |\n",
      "|    total_reward_pct | 55.6     |\n",
      "|    total_trades     | 24438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 495      |\n",
      "|    total timesteps  | 50480    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 5.62     |\n",
      "|    critic_loss      | 0.699    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 47956    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-04-06 to  2020-07-09\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-09\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/ensemble_441_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | 5.36e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -1.65    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0213   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | 0.239    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.3    |\n",
      "|    explained_variance | -0.0621  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 12.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.271    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.4    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.72     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0166   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -27.2     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.04      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.17e+04 |\n",
      "|    total_cost         | 2.95e+04 |\n",
      "|    total_reward       | 4.17e+04 |\n",
      "|    total_reward_pct   | 83.3     |\n",
      "|    total_trades       | 27435    |\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | -4.91    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00264  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -4.87    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.0673  |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.000296 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -11.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.782    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00596  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -23.9    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -2.49    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -0.264   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.95     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.00492  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+04  |\n",
      "|    total_cost         | 3.33e+04 |\n",
      "|    total_reward       | -1.9e+04 |\n",
      "|    total_reward_pct   | -37.9    |\n",
      "|    total_trades       | 26572    |\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -0.668   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -1.38    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.00385  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | -4.62    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -1.73    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00536  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -0.319   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -1.18    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00189  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.481   |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00513  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -0.662   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.734    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00299  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.03e+04  |\n",
      "|    total_cost         | 3.51e+04  |\n",
      "|    total_reward       | -2.97e+04 |\n",
      "|    total_reward_pct   | -59.4     |\n",
      "|    total_trades       | 29185     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | -3.07     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -0.288    |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.000416  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.0538  |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 5.36e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.9    |\n",
      "|    explained_variance | -0.417   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.0151   |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 1.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | 0.539    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -3.23    |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00866  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.309   |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 0.000116 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.7e+03   |\n",
      "|    total_cost         | 1.69e+04  |\n",
      "|    total_reward       | -4.53e+04 |\n",
      "|    total_reward_pct   | -90.6     |\n",
      "|    total_trades       | 28168     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32       |\n",
      "|    explained_variance | -56.6     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 0.349     |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.00347   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.3    |\n",
      "|    explained_variance | -0.594   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 2.68     |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.00684  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | -12.3    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 0.00465  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.0881   |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.000941 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 3.45     |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "day: 2586, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 31835.04\n",
      "total_reward: -18164.96\n",
      "total_cost: 21046.72\n",
      "total_trades: 28405\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.18e+04  |\n",
      "|    total_cost         | 2.1e+04   |\n",
      "|    total_reward       | -1.82e+04 |\n",
      "|    total_reward_pct   | -36.3     |\n",
      "|    total_trades       | 28405     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.8     |\n",
      "|    explained_variance | 0.495     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 0.345     |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 0.000143  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | -9.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.591    |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 0.000397 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 27.8     |\n",
      "|    std                | 1.5      |\n",
      "|    value_loss         | 0.832    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | -0.457   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 2.04     |\n",
      "|    std                | 1.53     |\n",
      "|    value_loss         | 0.0037   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | -18.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.00356  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.7    |\n",
      "|    explained_variance | -1.42    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 5.36     |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.0297   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.45e+04  |\n",
      "|    total_cost         | 2.54e+04  |\n",
      "|    total_reward       | -2.55e+04 |\n",
      "|    total_reward_pct   | -51.1     |\n",
      "|    total_trades       | 27529     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.1     |\n",
      "|    explained_variance | -243      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 0.206     |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 0.000384  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.42    |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 0.000135 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37      |\n",
      "|    explained_variance | -0.0481  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -2.04    |\n",
      "|    std                | 1.7      |\n",
      "|    value_loss         | 0.00397  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | -0.596   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.272    |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 0.00173  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -1.06     |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.000859  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.25e+04  |\n",
      "|    total_cost         | 2.31e+04  |\n",
      "|    total_reward       | -3.75e+04 |\n",
      "|    total_reward_pct   | -75.1     |\n",
      "|    total_trades       | 25660     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38.1     |\n",
      "|    explained_variance | -61.3     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -2.11     |\n",
      "|    std                | 1.79      |\n",
      "|    value_loss         | 0.0165    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.4    |\n",
      "|    explained_variance | -53.2    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -1.36    |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.004    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | -0.0174  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -4.6     |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.0178   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -4.79    |\n",
      "|    std                | 1.88     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.1    |\n",
      "|    explained_variance | -0.0678  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.9      |\n",
      "|    std                | 1.9      |\n",
      "|    value_loss         | 0.00284  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.4e+04  |\n",
      "|    total_cost         | 3.31e+04 |\n",
      "|    total_reward       | -1.6e+04 |\n",
      "|    total_reward_pct   | -31.9    |\n",
      "|    total_trades       | 28190    |\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.4    |\n",
      "|    explained_variance | -5.85    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.0436  |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 8.79e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.8    |\n",
      "|    explained_variance | -1.24    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.508    |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 0.0002   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.0605  |\n",
      "|    std                | 2.02     |\n",
      "|    value_loss         | 0.00011  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.595   |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 0.000309 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | -41.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.386   |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.000923 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.56e+03 |\n",
      "|    total_cost         | 2.14e+04  |\n",
      "|    total_reward       | -5.86e+04 |\n",
      "|    total_reward_pct   | -117      |\n",
      "|    total_trades       | 27406     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -1.92     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 1.12      |\n",
      "|    std                | 2.17      |\n",
      "|    value_loss         | 0.00123   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | -1.79e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 0.332     |\n",
      "|    std                | 2.22      |\n",
      "|    value_loss         | 0.000104  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.0405   |\n",
      "|    std                | 2.28     |\n",
      "|    value_loss         | 3.4e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -0.892    |\n",
      "|    std                | 2.34      |\n",
      "|    value_loss         | 0.00119   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0.138    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 3.98     |\n",
      "|    std                | 2.39     |\n",
      "|    value_loss         | 0.00939  |\n",
      "------------------------------------\n",
      "day: 2586, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4340.70\n",
      "total_reward: -45659.30\n",
      "total_cost: 17083.19\n",
      "total_trades: 27982\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.34e+03  |\n",
      "|    total_cost         | 1.71e+04  |\n",
      "|    total_reward       | -4.57e+04 |\n",
      "|    total_reward_pct   | -91.3     |\n",
      "|    total_trades       | 27982     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -0.202    |\n",
      "|    std                | 2.43      |\n",
      "|    value_loss         | 2.33e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.0264   |\n",
      "|    std                | 2.48     |\n",
      "|    value_loss         | 2.73e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -0.304   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    std                | 2.55     |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 3.67     |\n",
      "|    std                | 2.61     |\n",
      "|    value_loss         | 0.00786  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -4.33e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -0.175    |\n",
      "|    std                | 2.65      |\n",
      "|    value_loss         | 0.000155  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.24e+04  |\n",
      "|    total_cost         | 2.53e+04  |\n",
      "|    total_reward       | -2.76e+04 |\n",
      "|    total_reward_pct   | -55.3     |\n",
      "|    total_trades       | 29451     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | 0.575     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -0.105    |\n",
      "|    std                | 2.69      |\n",
      "|    value_loss         | 0.000138  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | -1.74    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.895   |\n",
      "|    std                | 2.73     |\n",
      "|    value_loss         | 0.000436 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.248   |\n",
      "|    std                | 2.79     |\n",
      "|    value_loss         | 0.000125 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | -0.386   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    std                | 2.84     |\n",
      "|    value_loss         | 0.00439  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | -0.615   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 7.3      |\n",
      "|    std                | 2.87     |\n",
      "|    value_loss         | 0.0259   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0.302    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -2.31    |\n",
      "|    std                | 2.9      |\n",
      "|    value_loss         | 0.0043   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.59e+04 |\n",
      "|    total_cost         | 2.6e+04  |\n",
      "|    total_reward       | 1.59e+04 |\n",
      "|    total_reward_pct   | 31.9     |\n",
      "|    total_trades       | 30504    |\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -15.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 1.32     |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.00111  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | -7.88    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.528    |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 0.000209 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.3    |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0.0616  |\n",
      "|    std                | 3.07     |\n",
      "|    value_loss         | 0.00104  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | 0.0502   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 0.00193  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 1.04     |\n",
      "|    std                | 3.16     |\n",
      "|    value_loss         | 0.000817 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.93e+04  |\n",
      "|    total_cost         | 2.41e+04  |\n",
      "|    total_reward       | -2.07e+04 |\n",
      "|    total_reward_pct   | -41.5     |\n",
      "|    total_trades       | 30080     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.1     |\n",
      "|    explained_variance | 0.0158    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -1.81     |\n",
      "|    std                | 3.2       |\n",
      "|    value_loss         | 0.00368   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -0.797    |\n",
      "|    std                | 3.26      |\n",
      "|    value_loss         | 0.000564  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.7    |\n",
      "|    explained_variance | -1.47    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -3.19    |\n",
      "|    std                | 3.31     |\n",
      "|    value_loss         | 0.00562  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -1.38    |\n",
      "|    std                | 3.36     |\n",
      "|    value_loss         | 0.000882 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.2    |\n",
      "|    explained_variance | 0.0013   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -4.69    |\n",
      "|    std                | 3.41     |\n",
      "|    value_loss         | 0.0113   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.1e+04  |\n",
      "|    total_cost         | 3.75e+04 |\n",
      "|    total_reward       | -1.9e+04 |\n",
      "|    total_reward_pct   | -38      |\n",
      "|    total_trades       | 32011    |\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.5    |\n",
      "|    explained_variance | -0.463   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.93    |\n",
      "|    std                | 3.46     |\n",
      "|    value_loss         | 0.00034  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.206    |\n",
      "|    std                | 3.55     |\n",
      "|    value_loss         | 3.22e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.214    |\n",
      "|    std                | 3.63     |\n",
      "|    value_loss         | 6.61e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | -0.286   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.0707   |\n",
      "|    std                | 3.72     |\n",
      "|    value_loss         | 0.000507 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    std                | 3.79     |\n",
      "|    value_loss         | 0.000962 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 19075.53\n",
      "total_reward: -30924.47\n",
      "total_cost: 19464.87\n",
      "total_trades: 30169\n",
      "Sharpe: -0.406\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.91e+04  |\n",
      "|    total_cost         | 1.95e+04  |\n",
      "|    total_reward       | -3.09e+04 |\n",
      "|    total_reward_pct   | -61.8     |\n",
      "|    total_trades       | 30169     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.7     |\n",
      "|    explained_variance | 0.257     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 1.34      |\n",
      "|    std                | 3.87      |\n",
      "|    value_loss         | 0.000674  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.1    |\n",
      "|    explained_variance | 0.666    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.582    |\n",
      "|    std                | 3.96     |\n",
      "|    value_loss         | 0.00013  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.6    |\n",
      "|    explained_variance | 0.0257   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.43    |\n",
      "|    std                | 4.07     |\n",
      "|    value_loss         | 0.000549 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | -0.702   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 3.65     |\n",
      "|    std                | 4.16     |\n",
      "|    value_loss         | 0.00527  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.4    |\n",
      "|    explained_variance | -0.732   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 1.36     |\n",
      "|    std                | 4.25     |\n",
      "|    value_loss         | 0.00125  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.98e+04  |\n",
      "|    total_cost         | 1.94e+04  |\n",
      "|    total_reward       | -3.02e+04 |\n",
      "|    total_reward_pct   | -60.5     |\n",
      "|    total_trades       | 29899     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.8     |\n",
      "|    explained_variance | -0.00207  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -1.06     |\n",
      "|    std                | 4.32      |\n",
      "|    value_loss         | 0.00169   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | -10.4    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 4.4      |\n",
      "|    value_loss         | 0.000974 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 0.0179   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.000254 |\n",
      "|    std                | 4.47     |\n",
      "|    value_loss         | 0.000129 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.45     |\n",
      "|    std                | 4.55     |\n",
      "|    value_loss         | 0.000211 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | -0.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -1.45    |\n",
      "|    std                | 4.63     |\n",
      "|    value_loss         | 0.000834 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.21e+04  |\n",
      "|    total_cost         | 2.89e+04  |\n",
      "|    total_reward       | -2.79e+04 |\n",
      "|    total_reward_pct   | -55.9     |\n",
      "|    total_trades       | 30302     |\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 198       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.4     |\n",
      "|    explained_variance | -20.3     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 1.4       |\n",
      "|    std                | 4.71      |\n",
      "|    value_loss         | 0.00101   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.7    |\n",
      "|    explained_variance | -4.41    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    std                | 4.8      |\n",
      "|    value_loss         | 0.00045  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | -2.9     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 4.92     |\n",
      "|    value_loss         | 0.000453 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.6    |\n",
      "|    explained_variance | -0.0466  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 3.79     |\n",
      "|    std                | 5.02     |\n",
      "|    value_loss         | 0.00599  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 0.0662   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 0.128    |\n",
      "|    std                | 5.09     |\n",
      "|    value_loss         | 0.00149  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | 0.00453  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    std                | 5.15     |\n",
      "|    value_loss         | 0.0693   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.52e+04 |\n",
      "|    total_cost         | 3.18e+04 |\n",
      "|    total_reward       | 5.18e+03 |\n",
      "|    total_reward_pct   | 10.4     |\n",
      "|    total_trades       | 29074    |\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.3    |\n",
      "|    explained_variance | -0.621   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    std                | 5.21     |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.6    |\n",
      "|    explained_variance | 0.0642   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 1.89     |\n",
      "|    std                | 5.3      |\n",
      "|    value_loss         | 0.00215  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -3.57    |\n",
      "|    std                | 5.38     |\n",
      "|    value_loss         | 0.00471  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | 1.09e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    std                | 5.45     |\n",
      "|    value_loss         | 0.000712 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -1.28    |\n",
      "|    std                | 5.52     |\n",
      "|    value_loss         | 0.000879 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.36e+04  |\n",
      "|    total_cost         | 3.36e+04  |\n",
      "|    total_reward       | -6.43e+03 |\n",
      "|    total_reward_pct   | -12.9     |\n",
      "|    total_trades       | 29386     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.6     |\n",
      "|    explained_variance | 0.0517    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -0.569    |\n",
      "|    std                | 5.59      |\n",
      "|    value_loss         | 0.000152  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.336   |\n",
      "|    std                | 5.69     |\n",
      "|    value_loss         | 0.000344 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 1.8      |\n",
      "|    std                | 5.79     |\n",
      "|    value_loss         | 0.00125  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 1.71     |\n",
      "|    std                | 5.88     |\n",
      "|    value_loss         | 0.00149  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 232       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -4        |\n",
      "|    std                | 5.98      |\n",
      "|    value_loss         | 0.00486   |\n",
      "-------------------------------------\n",
      "day: 2586, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 11877.22\n",
      "total_reward: -38122.78\n",
      "total_cost: 22800.59\n",
      "total_trades: 29429\n",
      "Sharpe: -0.194\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.19e+04  |\n",
      "|    total_cost         | 2.28e+04  |\n",
      "|    total_reward       | -3.81e+04 |\n",
      "|    total_reward_pct   | -76.2     |\n",
      "|    total_trades       | 29429     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.2     |\n",
      "|    explained_variance | -19.8     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 0.371     |\n",
      "|    std                | 6.08      |\n",
      "|    value_loss         | 6.88e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.204   |\n",
      "|    std                | 6.23     |\n",
      "|    value_loss         | 1.18e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -2.05    |\n",
      "|    std                | 6.42     |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.6    |\n",
      "|    explained_variance | -0.115   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 1.76     |\n",
      "|    std                | 6.54     |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63      |\n",
      "|    explained_variance | 0.0536   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.664   |\n",
      "|    std                | 6.68     |\n",
      "|    value_loss         | 0.000328 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.14e+04  |\n",
      "|    total_cost         | 2.47e+04  |\n",
      "|    total_reward       | -1.86e+04 |\n",
      "|    total_reward_pct   | -37.3     |\n",
      "|    total_trades       | 29711     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | 0.406     |\n",
      "|    std                | 6.79      |\n",
      "|    value_loss         | 6.86e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.8    |\n",
      "|    explained_variance | 0.424    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.409   |\n",
      "|    std                | 6.94     |\n",
      "|    value_loss         | 4.22e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 6.51     |\n",
      "|    std                | 7.14     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.6    |\n",
      "|    explained_variance | -0.0532  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.0962   |\n",
      "|    std                | 7.28     |\n",
      "|    value_loss         | 0.000565 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 3.14     |\n",
      "|    std                | 7.44     |\n",
      "|    value_loss         | 0.00255  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.22e+04  |\n",
      "|    total_cost         | 2.9e+04   |\n",
      "|    total_reward       | -3.78e+04 |\n",
      "|    total_reward_pct   | -75.7     |\n",
      "|    total_trades       | 30607     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 257       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.6     |\n",
      "|    explained_variance | -0.947    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -1.09     |\n",
      "|    std                | 7.65      |\n",
      "|    value_loss         | 0.000358  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 0.734     |\n",
      "|    std                | 7.87      |\n",
      "|    value_loss         | 0.000297  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.7    |\n",
      "|    explained_variance | -3.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 8.1      |\n",
      "|    value_loss         | 0.00035  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.2    |\n",
      "|    explained_variance | -0.0445  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -0.807   |\n",
      "|    std                | 8.34     |\n",
      "|    value_loss         | 0.000233 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.8    |\n",
      "|    explained_variance | -0.277   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    std                | 8.6      |\n",
      "|    value_loss         | 0.000389 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | 0.377    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 3.73     |\n",
      "|    std                | 8.85     |\n",
      "|    value_loss         | 0.00351  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.38e+04 |\n",
      "|    total_cost         | 1.97e+04  |\n",
      "|    total_reward       | -6.38e+04 |\n",
      "|    total_reward_pct   | -128      |\n",
      "|    total_trades       | 30757     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.9     |\n",
      "|    explained_variance | 0.139     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | 1.02      |\n",
      "|    std                | 9.08      |\n",
      "|    value_loss         | 0.000309  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.314   |\n",
      "|    std                | 9.36     |\n",
      "|    value_loss         | 2.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.618    |\n",
      "|    std                | 9.61     |\n",
      "|    value_loss         | 0.000232 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.421    |\n",
      "|    std                | 9.83     |\n",
      "|    value_loss         | 0.000462 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -1.11    |\n",
      "|    std                | 10.1     |\n",
      "|    value_loss         | 0.000543 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.11e+03  |\n",
      "|    total_cost         | 2.78e+04  |\n",
      "|    total_reward       | -4.09e+04 |\n",
      "|    total_reward_pct   | -81.8     |\n",
      "|    total_trades       | 31068     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 282       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -0.0373   |\n",
      "|    std                | 10.3      |\n",
      "|    value_loss         | 3.33e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.133   |\n",
      "|    std                | 10.7     |\n",
      "|    value_loss         | 1.16e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.5    |\n",
      "|    explained_variance | -0.12    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 0.606    |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 9.11e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73      |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -0.464   |\n",
      "|    std                | 11.3     |\n",
      "|    value_loss         | 5.9e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.0893  |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 2.11e-05 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8769.20\n",
      "total_reward: -41230.80\n",
      "total_cost: 26039.87\n",
      "total_trades: 30708\n",
      "Sharpe: 0.374\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.77e+03  |\n",
      "|    total_cost         | 2.6e+04   |\n",
      "|    total_reward       | -4.12e+04 |\n",
      "|    total_reward_pct   | -82.5     |\n",
      "|    total_trades       | 30708     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 293       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | -0.0291   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -1.18     |\n",
      "|    std                | 11.9      |\n",
      "|    value_loss         | 0.000599  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.111   |\n",
      "|    std                | 12.1     |\n",
      "|    value_loss         | 0.000204 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.367   |\n",
      "|    std                | 12.4     |\n",
      "|    value_loss         | 4.18e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.154    |\n",
      "|    std                | 12.7     |\n",
      "|    value_loss         | 5.02e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.9    |\n",
      "|    explained_variance | -1.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.309   |\n",
      "|    std                | 13.1     |\n",
      "|    value_loss         | 3.29e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.53e+03  |\n",
      "|    total_cost         | 2.44e+04  |\n",
      "|    total_reward       | -4.75e+04 |\n",
      "|    total_reward_pct   | -94.9     |\n",
      "|    total_trades       | 31434     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 304       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.5     |\n",
      "|    explained_variance | -0.85     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 0.738     |\n",
      "|    std                | 13.6      |\n",
      "|    value_loss         | 0.000187  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.0528  |\n",
      "|    std                | 14.1     |\n",
      "|    value_loss         | 5.49e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.9    |\n",
      "|    explained_variance | 0.00101  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 4.79     |\n",
      "|    std                | 14.6     |\n",
      "|    value_loss         | 0.00445  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -4.98    |\n",
      "|    std                | 14.9     |\n",
      "|    value_loss         | 0.00419  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.8    |\n",
      "|    explained_variance | 1.25e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 15.3     |\n",
      "|    value_loss         | 0.000262 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.13e+03  |\n",
      "|    total_cost         | 3.59e+04  |\n",
      "|    total_reward       | -4.29e+04 |\n",
      "|    total_reward_pct   | -85.7     |\n",
      "|    total_trades       | 31409     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 316       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -79.2     |\n",
      "|    explained_variance | 0.00752   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 4.52      |\n",
      "|    std                | 15.7      |\n",
      "|    value_loss         | 0.00347   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.6    |\n",
      "|    explained_variance | -0.654   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 16       |\n",
      "|    value_loss         | 0.000234 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.263    |\n",
      "|    std                | 16.4     |\n",
      "|    value_loss         | 6.75e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.65     |\n",
      "|    std                | 16.8     |\n",
      "|    value_loss         | 7.06e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 325      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.2    |\n",
      "|    explained_variance | -0.499   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.527   |\n",
      "|    std                | 17.4     |\n",
      "|    value_loss         | 5.15e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.17e+03  |\n",
      "|    total_cost         | 2.18e+04  |\n",
      "|    total_reward       | -4.88e+04 |\n",
      "|    total_reward_pct   | -97.7     |\n",
      "|    total_trades       | 31194     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 327       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -81.9     |\n",
      "|    explained_variance | -5.95     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 0.198     |\n",
      "|    std                | 18.1      |\n",
      "|    value_loss         | 0.000142  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -82.7    |\n",
      "|    explained_variance | -0.395   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.093    |\n",
      "|    std                | 18.8     |\n",
      "|    value_loss         | 4.27e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 93.2     |\n",
      "|    std                | 19.6     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84      |\n",
      "|    explained_variance | -0.038   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 0.0688   |\n",
      "|    std                | 20.2     |\n",
      "|    value_loss         | 0.0001   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.6    |\n",
      "|    explained_variance | 0.0444   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.871   |\n",
      "|    std                | 20.8     |\n",
      "|    value_loss         | 0.000124 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.2    |\n",
      "|    explained_variance | 0.313    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -2.56    |\n",
      "|    std                | 21.5     |\n",
      "|    value_loss         | 0.000951 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.14e+03 |\n",
      "|    total_cost         | 2.8e+04   |\n",
      "|    total_reward       | -5.21e+04 |\n",
      "|    total_reward_pct   | -104      |\n",
      "|    total_trades       | 30456     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -0.18     |\n",
      "|    std                | 22        |\n",
      "|    value_loss         | 3.96e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 343       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -86.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -0.672    |\n",
      "|    std                | 22.6      |\n",
      "|    value_loss         | 9.57e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 346      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 0.325    |\n",
      "|    std                | 23.2     |\n",
      "|    value_loss         | 2.33e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.168    |\n",
      "|    std                | 24       |\n",
      "|    value_loss         | 4.67e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    std                | 24.9     |\n",
      "|    value_loss         | 0.00344  |\n",
      "------------------------------------\n",
      "day: 2586, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -13582.77\n",
      "total_reward: -63582.77\n",
      "total_cost: 21808.71\n",
      "total_trades: 30864\n",
      "Sharpe: -0.150\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.36e+04 |\n",
      "|    total_cost         | 2.18e+04  |\n",
      "|    total_reward       | -6.36e+04 |\n",
      "|    total_reward_pct   | -127      |\n",
      "|    total_trades       | 30864     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 352       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 0.237     |\n",
      "|    std                | 25.4      |\n",
      "|    value_loss         | 1.51e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 355       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | 0.00614   |\n",
      "|    std                | 26.1      |\n",
      "|    value_loss         | 1.76e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 357      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.5    |\n",
      "|    explained_variance | -0.921   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.459    |\n",
      "|    std                | 26.9     |\n",
      "|    value_loss         | 0.000131 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 359      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 0.839    |\n",
      "|    std                | 27.8     |\n",
      "|    value_loss         | 0.000158 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 362      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.7    |\n",
      "|    explained_variance | 0.0317   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 4.55     |\n",
      "|    std                | 28.7     |\n",
      "|    value_loss         | 0.00257  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.09e+04 |\n",
      "|    total_cost         | 1.99e+04  |\n",
      "|    total_reward       | -7.09e+04 |\n",
      "|    total_reward_pct   | -142      |\n",
      "|    total_trades       | 30528     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 364       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91       |\n",
      "|    explained_variance | -1.23     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 0.217     |\n",
      "|    std                | 29.2      |\n",
      "|    value_loss         | 4.91e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 366      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 0.23     |\n",
      "|    std                | 29.9     |\n",
      "|    value_loss         | 5.88e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 368      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.851   |\n",
      "|    std                | 30.7     |\n",
      "|    value_loss         | 0.000139 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 371      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.5    |\n",
      "|    explained_variance | 0.154    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 0.277    |\n",
      "|    std                | 31.6     |\n",
      "|    value_loss         | 1.43e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.2    |\n",
      "|    explained_variance | -236     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 2.3      |\n",
      "|    std                | 32.7     |\n",
      "|    value_loss         | 0.000662 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -3.53e+03 |\n",
      "|    total_cost         | 2.46e+04  |\n",
      "|    total_reward       | -5.35e+04 |\n",
      "|    total_reward_pct   | -107      |\n",
      "|    total_trades       | 31008     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 375       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93.7     |\n",
      "|    explained_variance | 0.139     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 2.75      |\n",
      "|    std                | 33.6      |\n",
      "|    value_loss         | 0.000899  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    std                | 34.3     |\n",
      "|    value_loss         | 0.000375 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.6    |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 2.96     |\n",
      "|    std                | 35.3     |\n",
      "|    value_loss         | 0.00109  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 382      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -0.803   |\n",
      "|    std                | 36.4     |\n",
      "|    value_loss         | 0.00016  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 384      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.382    |\n",
      "|    std                | 37.6     |\n",
      "|    value_loss         | 4.48e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | -1.3e+04 |\n",
      "|    total_cost         | 2.68e+04 |\n",
      "|    total_reward       | -6.3e+04 |\n",
      "|    total_reward_pct   | -126     |\n",
      "|    total_trades       | 31404    |\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.3    |\n",
      "|    explained_variance | -0.276   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 1.54     |\n",
      "|    std                | 38.5     |\n",
      "|    value_loss         | 0.000898 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 389      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.6    |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.169   |\n",
      "|    std                | 39.1     |\n",
      "|    value_loss         | 5.53e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 3.87     |\n",
      "|    std                | 39.9     |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 394      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.4    |\n",
      "|    explained_variance | -0.00497 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.764    |\n",
      "|    std                | 40.8     |\n",
      "|    value_loss         | 9.63e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 396      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.9    |\n",
      "|    explained_variance | -2.48    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.0574  |\n",
      "|    std                | 42       |\n",
      "|    value_loss         | 0.000108 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.15e+03  |\n",
      "|    total_cost         | 3.1e+04   |\n",
      "|    total_reward       | -4.68e+04 |\n",
      "|    total_reward_pct   | -93.7     |\n",
      "|    total_trades       | 31568     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 398       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -98.6     |\n",
      "|    explained_variance | -10.3     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 0.543     |\n",
      "|    std                | 43.5      |\n",
      "|    value_loss         | 6.23e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.2    |\n",
      "|    explained_variance | -0.0715  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -0.331   |\n",
      "|    std                | 45       |\n",
      "|    value_loss         | 2.16e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -0.141   |\n",
      "|    std                | 46.9     |\n",
      "|    value_loss         | 3.24e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 405      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | -0.00237 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 48.4     |\n",
      "|    value_loss         | 0.000551 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 407      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -101     |\n",
      "|    explained_variance | -2.04    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.497    |\n",
      "|    std                | 49.8     |\n",
      "|    value_loss         | 9.84e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 409      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | -3.64    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    std                | 51.5     |\n",
      "|    value_loss         | 0.000259 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2709.04\n",
      "total_reward: -47290.96\n",
      "total_cost: 24595.02\n",
      "total_trades: 30225\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.71e+03  |\n",
      "|    total_cost         | 2.46e+04  |\n",
      "|    total_reward       | -4.73e+04 |\n",
      "|    total_reward_pct   | -94.6     |\n",
      "|    total_trades       | 30225     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 412       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -102      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 1.13      |\n",
      "|    std                | 52.8      |\n",
      "|    value_loss         | 0.000155  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 414      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -103     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 1.54     |\n",
      "|    std                | 53.9     |\n",
      "|    value_loss         | 0.000487 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 416       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -103      |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -0.147    |\n",
      "|    std                | 55.3      |\n",
      "|    value_loss         | 6.15e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 419      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | -1.37    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.266   |\n",
      "|    std                | 57.1     |\n",
      "|    value_loss         | 2.17e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 421      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 0.163    |\n",
      "|    std                | 59.3     |\n",
      "|    value_loss         | 4.4e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.18e+03  |\n",
      "|    total_cost         | 2.31e+04  |\n",
      "|    total_reward       | -4.88e+04 |\n",
      "|    total_reward_pct   | -97.6     |\n",
      "|    total_trades       | 30671     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 424       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -105      |\n",
      "|    explained_variance | -0.138    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -4.95     |\n",
      "|    std                | 61.2      |\n",
      "|    value_loss         | 0.00313   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | 0.275    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 2.12     |\n",
      "|    std                | 62.6     |\n",
      "|    value_loss         | 0.000519 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 428      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | 0.041    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.621   |\n",
      "|    std                | 64.2     |\n",
      "|    value_loss         | 6.92e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 431      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 2.75     |\n",
      "|    std                | 66       |\n",
      "|    value_loss         | 0.000935 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 433       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -107      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 0.312     |\n",
      "|    std                | 67.8      |\n",
      "|    value_loss         | 0.000137  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.28e+04 |\n",
      "|    total_cost         | 3.53e+04  |\n",
      "|    total_reward       | -6.28e+04 |\n",
      "|    total_reward_pct   | -126      |\n",
      "|    total_trades       | 31852     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 435       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -107      |\n",
      "|    explained_variance | -0.763    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | -0.133    |\n",
      "|    std                | 69.2      |\n",
      "|    value_loss         | 1.46e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 437      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.789   |\n",
      "|    std                | 71.1     |\n",
      "|    value_loss         | 6.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 440      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | -0.148   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -1.92    |\n",
      "|    std                | 73.4     |\n",
      "|    value_loss         | 0.00069  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 442      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    std                | 75.4     |\n",
      "|    value_loss         | 0.000472 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 444      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | -0.623   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.579   |\n",
      "|    std                | 77.6     |\n",
      "|    value_loss         | 6.05e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -6.84e+03 |\n",
      "|    total_cost         | 3.03e+04  |\n",
      "|    total_reward       | -5.68e+04 |\n",
      "|    total_reward_pct   | -114      |\n",
      "|    total_trades       | 30749     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 447       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -110      |\n",
      "|    explained_variance | -9.1      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 0.101     |\n",
      "|    std                | 79.6      |\n",
      "|    value_loss         | 2.69e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 449      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.664    |\n",
      "|    std                | 81.9     |\n",
      "|    value_loss         | 4.22e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 451      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -6.69    |\n",
      "|    std                | 84.7     |\n",
      "|    value_loss         | 0.00526  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 453      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -112     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 1.34     |\n",
      "|    std                | 87.2     |\n",
      "|    value_loss         | 0.0002   |\n",
      "------------------------------------\n",
      "======Trading from:  2020-07-09 to  2020-10-06\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  716.429312034568\n",
      "======Model training from:  2010-01-01 to  2020-07-09\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -5.95    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -8.03    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -72.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 2.25     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.2    |\n",
      "|    explained_variance | -2.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.53     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0043   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.5    |\n",
      "|    explained_variance | -5.06    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.68    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.00222  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0.197    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -5.36    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.048    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.81e+04 |\n",
      "|    total_cost         | 4.67e+04 |\n",
      "|    total_reward       | 8.05e+03 |\n",
      "|    total_reward_pct   | 16.1     |\n",
      "|    total_trades       | 31044    |\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -4.79    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00556  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | -0.00737 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.463   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00096  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | -5.58    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.278   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00435  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.7    |\n",
      "|    explained_variance | -4.63    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -1.6     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.00498  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.298    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.000322 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.3e+04  |\n",
      "|    total_cost         | 7.28e+03 |\n",
      "|    total_reward       | -2.7e+04 |\n",
      "|    total_reward_pct   | -54.1    |\n",
      "|    total_trades       | 26178    |\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.3    |\n",
      "|    explained_variance | -2.85    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 9.92e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.6    |\n",
      "|    explained_variance | -54.5    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -8.23    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0863   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.00215  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.2    |\n",
      "|    explained_variance | -0.0832  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.883    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.00136  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -323     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 0.00967  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.65e+04  |\n",
      "|    total_cost         | 3.01e+03  |\n",
      "|    total_reward       | -3.35e+04 |\n",
      "|    total_reward_pct   | -67.1     |\n",
      "|    total_trades       | 26490     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.9     |\n",
      "|    explained_variance | -9.03     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -0.166    |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 7e-05     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.9      |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.00099  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 3.56     |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.0228  |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 0.000692 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.402   |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 0.000379 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.43e+03 |\n",
      "|    total_cost         | 1.3e+03   |\n",
      "|    total_reward       | -5.24e+04 |\n",
      "|    total_reward_pct   | -105      |\n",
      "|    total_trades       | 26375     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.8     |\n",
      "|    explained_variance | -36.2     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 0.0274    |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 0.000657  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | 0.211    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.458    |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 0.000272 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.5    |\n",
      "|    explained_variance | 0.25     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.00546  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 1.17      |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 0.00162   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.2    |\n",
      "|    explained_variance | -1.57    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.418    |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 0.000879 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -8174.00\n",
      "total_reward: -58174.00\n",
      "total_cost: 2089.68\n",
      "total_trades: 26954\n",
      "Sharpe: -0.345\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -8.17e+03 |\n",
      "|    total_cost         | 2.09e+03  |\n",
      "|    total_reward       | -5.82e+04 |\n",
      "|    total_reward_pct   | -116      |\n",
      "|    total_trades       | 26954     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.5     |\n",
      "|    explained_variance | -0.119    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 1.38      |\n",
      "|    std                | 1.49      |\n",
      "|    value_loss         | 0.00196   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35      |\n",
      "|    explained_variance | 0.368    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.542    |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.000839 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | -0.32    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.269    |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 0.000724 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | -0.0227  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 8.37     |\n",
      "|    std                | 1.56     |\n",
      "|    value_loss         | 0.0631   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.6    |\n",
      "|    explained_variance | -0.875   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -3.14    |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 0.0143   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.8    |\n",
      "|    explained_variance | -0.0235  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 1.73     |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 0.0178   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.97e+04  |\n",
      "|    total_cost         | 9.5e+03   |\n",
      "|    total_reward       | -1.03e+04 |\n",
      "|    total_reward_pct   | -20.5     |\n",
      "|    total_trades       | 27619     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.9     |\n",
      "|    explained_variance | -1.05     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 0.0236    |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 0.00252   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -4.98    |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.0406   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.3    |\n",
      "|    explained_variance | -2.98    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 3.16     |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 0.00921  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -0.706    |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 0.000685  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.7    |\n",
      "|    explained_variance | -0.272   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.0864   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.1e+04  |\n",
      "|    total_cost         | 5.07e+03 |\n",
      "|    total_reward       | -3.9e+04 |\n",
      "|    total_reward_pct   | -78.1    |\n",
      "|    total_trades       | 25231    |\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.9    |\n",
      "|    explained_variance | 0.406    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.00239  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.2    |\n",
      "|    explained_variance | -4.08    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.157    |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.000378 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.6    |\n",
      "|    explained_variance | 0.0236   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.968   |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 0.00166  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -1.28     |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.00368   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 3.3      |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 0.0105   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -7.29e+03 |\n",
      "|    total_cost         | 4.87e+03  |\n",
      "|    total_reward       | -5.73e+04 |\n",
      "|    total_reward_pct   | -115      |\n",
      "|    total_trades       | 25037     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38.3     |\n",
      "|    explained_variance | 0.226     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -0.104    |\n",
      "|    std                | 1.82      |\n",
      "|    value_loss         | 4.61e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.7    |\n",
      "|    explained_variance | -0.0732  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 1.85     |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39      |\n",
      "|    explained_variance | -1.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.802    |\n",
      "|    std                | 1.89     |\n",
      "|    value_loss         | 0.000656 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.3    |\n",
      "|    explained_variance | -0.0909  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.544    |\n",
      "|    std                | 1.92     |\n",
      "|    value_loss         | 0.00106  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | -0.116   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -3.5     |\n",
      "|    std                | 1.94     |\n",
      "|    value_loss         | 0.0277   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.45e+04  |\n",
      "|    total_cost         | 7.03e+03  |\n",
      "|    total_reward       | -3.55e+04 |\n",
      "|    total_reward_pct   | -71       |\n",
      "|    total_trades       | 24798     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 0.735     |\n",
      "|    std                | 1.97      |\n",
      "|    value_loss         | 0.000419  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.285   |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 7.82e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.7    |\n",
      "|    explained_variance | -0.303   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    std                | 2.06     |\n",
      "|    value_loss         | 0.00158  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | -0.844   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.536   |\n",
      "|    std                | 2.1      |\n",
      "|    value_loss         | 0.00068  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0.393    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    std                | 2.14     |\n",
      "|    value_loss         | 0.000967 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 18782.32\n",
      "total_reward: -31217.68\n",
      "total_cost: 3262.83\n",
      "total_trades: 25206\n",
      "Sharpe: 0.274\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.88e+04  |\n",
      "|    total_cost         | 3.26e+03  |\n",
      "|    total_reward       | -3.12e+04 |\n",
      "|    total_reward_pct   | -62.4     |\n",
      "|    total_trades       | 25206     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -3.02     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -0.236    |\n",
      "|    std                | 2.17      |\n",
      "|    value_loss         | 0.000139  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | -0.442   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.724    |\n",
      "|    std                | 2.22     |\n",
      "|    value_loss         | 0.000649 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.194   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.148    |\n",
      "|    std                | 2.26     |\n",
      "|    value_loss         | 0.00246  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0315   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.844   |\n",
      "|    std                | 2.31     |\n",
      "|    value_loss         | 0.000575 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0.025    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -1.22    |\n",
      "|    std                | 2.36     |\n",
      "|    value_loss         | 0.000977 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.13e+04  |\n",
      "|    total_cost         | 3.08e+03  |\n",
      "|    total_reward       | -3.87e+04 |\n",
      "|    total_reward_pct   | -77.3     |\n",
      "|    total_trades       | 24672     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -3.11     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 0.375     |\n",
      "|    std                | 2.41      |\n",
      "|    value_loss         | 0.000462  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | -1.92    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 0.484    |\n",
      "|    std                | 2.46     |\n",
      "|    value_loss         | 0.000207 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.668   |\n",
      "|    std                | 2.51     |\n",
      "|    value_loss         | 0.000291 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | -3.4     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -1.09    |\n",
      "|    std                | 2.56     |\n",
      "|    value_loss         | 0.000924 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0.362    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.236   |\n",
      "|    std                | 2.62     |\n",
      "|    value_loss         | 5.96e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.556   |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 0.000815 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.58e+03  |\n",
      "|    total_cost         | 1.35e+04  |\n",
      "|    total_reward       | -4.54e+04 |\n",
      "|    total_reward_pct   | -90.8     |\n",
      "|    total_trades       | 26321     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | -433      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -3.7      |\n",
      "|    std                | 2.74      |\n",
      "|    value_loss         | 0.0081    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | -3.02    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -0.0081  |\n",
      "|    std                | 2.82     |\n",
      "|    value_loss         | 4.43e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 0.00135  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | -0.838   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -2.26    |\n",
      "|    std                | 2.94     |\n",
      "|    value_loss         | 0.00263  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 2.67     |\n",
      "|    std                | 2.99     |\n",
      "|    value_loss         | 0.00587  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.53e+04  |\n",
      "|    total_cost         | 1.69e+04  |\n",
      "|    total_reward       | -2.47e+04 |\n",
      "|    total_reward_pct   | -49.3     |\n",
      "|    total_trades       | 26869     |\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.1     |\n",
      "|    explained_variance | 0.0455    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -0.0835   |\n",
      "|    std                | 3.05      |\n",
      "|    value_loss         | 4.66e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 0.0519   |\n",
      "|    std                | 3.13     |\n",
      "|    value_loss         | 3.63e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | -0.251   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -4.56    |\n",
      "|    std                | 3.22     |\n",
      "|    value_loss         | 0.00949  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.801   |\n",
      "|    std                | 3.29     |\n",
      "|    value_loss         | 0.000255 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -1.99    |\n",
      "|    std                | 3.35     |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.4e+03   |\n",
      "|    total_cost         | 2.97e+04  |\n",
      "|    total_reward       | -4.16e+04 |\n",
      "|    total_reward_pct   | -83.2     |\n",
      "|    total_trades       | 27718     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.3     |\n",
      "|    explained_variance | 0.0319    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -1.87     |\n",
      "|    std                | 3.41      |\n",
      "|    value_loss         | 0.00143   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -50.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0.956   |\n",
      "|    std                | 3.49     |\n",
      "|    value_loss         | 0.000438 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.3    |\n",
      "|    explained_variance | 0.0283   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.706    |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 0.00048  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.651   |\n",
      "|    std                | 3.72     |\n",
      "|    value_loss         | 0.000271 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.6    |\n",
      "|    explained_variance | -1.46    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.808    |\n",
      "|    std                | 3.86     |\n",
      "|    value_loss         | 0.0005   |\n",
      "------------------------------------\n",
      "day: 2586, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -15363.16\n",
      "total_reward: -65363.16\n",
      "total_cost: 14896.98\n",
      "total_trades: 27469\n",
      "Sharpe: -0.189\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.54e+04 |\n",
      "|    total_cost         | 1.49e+04  |\n",
      "|    total_reward       | -6.54e+04 |\n",
      "|    total_reward_pct   | -131      |\n",
      "|    total_trades       | 27469     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53       |\n",
      "|    explained_variance | -4.49     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 0.468     |\n",
      "|    std                | 3.93      |\n",
      "|    value_loss         | 0.000114  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.135    |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 2.14e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54      |\n",
      "|    explained_variance | -0.0128  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -2.78    |\n",
      "|    std                | 4.15     |\n",
      "|    value_loss         | 0.0045   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -54.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 2.12     |\n",
      "|    std                | 4.27     |\n",
      "|    value_loss         | 0.00177  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55      |\n",
      "|    explained_variance | -2.41    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 1.83     |\n",
      "|    std                | 4.37     |\n",
      "|    value_loss         | 0.00483  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.56e+04  |\n",
      "|    total_cost         | 1.37e+04  |\n",
      "|    total_reward       | -2.44e+04 |\n",
      "|    total_reward_pct   | -48.9     |\n",
      "|    total_trades       | 28030     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.3     |\n",
      "|    explained_variance | 0.026     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -0.357    |\n",
      "|    std                | 4.45      |\n",
      "|    value_loss         | 0.000173  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.7    |\n",
      "|    explained_variance | -0.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 4.54     |\n",
      "|    value_loss         | 0.000687 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.872   |\n",
      "|    std                | 4.61     |\n",
      "|    value_loss         | 0.000463 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -1.24    |\n",
      "|    std                | 4.7      |\n",
      "|    value_loss         | 0.000604 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.7    |\n",
      "|    explained_variance | 0.159    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -2.4     |\n",
      "|    std                | 4.78     |\n",
      "|    value_loss         | 0.0022   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.71e+04  |\n",
      "|    total_cost         | 2.09e+04  |\n",
      "|    total_reward       | -3.29e+04 |\n",
      "|    total_reward_pct   | -65.9     |\n",
      "|    total_trades       | 28716     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.1     |\n",
      "|    explained_variance | 0.424     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -1.06     |\n",
      "|    std                | 4.88      |\n",
      "|    value_loss         | 0.000342  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.5    |\n",
      "|    explained_variance | -0.191   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -0.286   |\n",
      "|    std                | 5        |\n",
      "|    value_loss         | 4.5e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.373    |\n",
      "|    std                | 5.16     |\n",
      "|    value_loss         | 0.000115 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 1.24     |\n",
      "|    std                | 5.31     |\n",
      "|    value_loss         | 0.000549 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.65     |\n",
      "|    std                | 5.43     |\n",
      "|    value_loss         | 0.00109  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.5    |\n",
      "|    explained_variance | -0.0189  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 8.02     |\n",
      "|    std                | 5.54     |\n",
      "|    value_loss         | 0.0248   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.03e+04  |\n",
      "|    total_cost         | 1.96e+04  |\n",
      "|    total_reward       | -2.97e+04 |\n",
      "|    total_reward_pct   | -59.3     |\n",
      "|    total_trades       | 28428     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.8     |\n",
      "|    explained_variance | -0.0865   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 17        |\n",
      "|    std                | 5.65      |\n",
      "|    value_loss         | 0.0938    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -0.415    |\n",
      "|    std                | 5.77      |\n",
      "|    value_loss         | 6.03e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -0.709    |\n",
      "|    std                | 5.92      |\n",
      "|    value_loss         | 0.000199  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.3    |\n",
      "|    explained_variance | -1.35    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.561   |\n",
      "|    std                | 6.09     |\n",
      "|    value_loss         | 0.000227 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 6.25     |\n",
      "|    value_loss         | 0.000425 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.38e+03  |\n",
      "|    total_cost         | 1.61e+04  |\n",
      "|    total_reward       | -4.06e+04 |\n",
      "|    total_reward_pct   | -81.2     |\n",
      "|    total_trades       | 28608     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 224       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.2     |\n",
      "|    explained_variance | -0.754    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -0.548    |\n",
      "|    std                | 6.4       |\n",
      "|    value_loss         | 0.000125  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.7    |\n",
      "|    explained_variance | -3.73    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.206   |\n",
      "|    std                | 6.58     |\n",
      "|    value_loss         | 0.000199 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.3    |\n",
      "|    explained_variance | -0.326   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 0.16     |\n",
      "|    std                | 6.77     |\n",
      "|    value_loss         | 1.96e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.843    |\n",
      "|    std                | 6.99     |\n",
      "|    value_loss         | 0.000169 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.386   |\n",
      "|    std                | 7.24     |\n",
      "|    value_loss         | 5e-05    |\n",
      "------------------------------------\n",
      "day: 2586, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 3305.84\n",
      "total_reward: -46694.16\n",
      "total_cost: 17190.36\n",
      "total_trades: 29204\n",
      "Sharpe: -0.213\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.31e+03  |\n",
      "|    total_cost         | 1.72e+04  |\n",
      "|    total_reward       | -4.67e+04 |\n",
      "|    total_reward_pct   | -93.4     |\n",
      "|    total_trades       | 29204     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 235       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.2     |\n",
      "|    explained_variance | 0.299     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 0.378     |\n",
      "|    std                | 7.48      |\n",
      "|    value_loss         | 5.25e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.0376   |\n",
      "|    std                | 7.74     |\n",
      "|    value_loss         | 7.98e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 0.329    |\n",
      "|    std                | 7.99     |\n",
      "|    value_loss         | 7.99e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.0346   |\n",
      "|    std                | 8.24     |\n",
      "|    value_loss         | 8.41e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.6    |\n",
      "|    explained_variance | -1.03    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.237   |\n",
      "|    std                | 8.5      |\n",
      "|    value_loss         | 2.31e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.58e+03  |\n",
      "|    total_cost         | 1.99e+04  |\n",
      "|    total_reward       | -4.44e+04 |\n",
      "|    total_reward_pct   | -88.8     |\n",
      "|    total_trades       | 28707     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 246       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | 0.00176   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | 0.153     |\n",
      "|    std                | 8.75      |\n",
      "|    value_loss         | 6.55e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 0.431    |\n",
      "|    std                | 8.94     |\n",
      "|    value_loss         | 0.00015  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.9    |\n",
      "|    explained_variance | 0.0453   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 9.11     |\n",
      "|    value_loss         | 0.00154  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.3    |\n",
      "|    explained_variance | -0.17    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -0.488   |\n",
      "|    std                | 9.3      |\n",
      "|    value_loss         | 0.000171 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.7    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 3.59     |\n",
      "|    std                | 9.5      |\n",
      "|    value_loss         | 0.00268  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.2e+03   |\n",
      "|    total_cost         | 3.02e+04  |\n",
      "|    total_reward       | -4.18e+04 |\n",
      "|    total_reward_pct   | -83.6     |\n",
      "|    total_trades       | 29867     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 258       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | -0.911    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -0.543    |\n",
      "|    std                | 9.69      |\n",
      "|    value_loss         | 0.000163  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.5    |\n",
      "|    explained_variance | 0.00255  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    std                | 9.92     |\n",
      "|    value_loss         | 0.00299  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71      |\n",
      "|    explained_variance | -0.0108  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.633   |\n",
      "|    std                | 10.2     |\n",
      "|    value_loss         | 0.000115 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.5    |\n",
      "|    explained_variance | -0.973   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -0.173   |\n",
      "|    std                | 10.4     |\n",
      "|    value_loss         | 3.92e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.171   |\n",
      "|    std                | 10.7     |\n",
      "|    value_loss         | 7.84e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.5    |\n",
      "|    explained_variance | 0.000414 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.57     |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 0.000161 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.44e+03  |\n",
      "|    total_cost         | 2.44e+04  |\n",
      "|    total_reward       | -4.16e+04 |\n",
      "|    total_reward_pct   | -83.1     |\n",
      "|    total_trades       | 29339     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 271       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | 0.818     |\n",
      "|    std                | 11.3      |\n",
      "|    value_loss         | 0.000328  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.362   |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 2.59e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 1.16     |\n",
      "|    std                | 12.1     |\n",
      "|    value_loss         | 0.00036  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.7    |\n",
      "|    explained_variance | -0.0454  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.0858   |\n",
      "|    std                | 12.4     |\n",
      "|    value_loss         | 0.000122 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -0.345   |\n",
      "|    std                | 12.7     |\n",
      "|    value_loss         | 4.53e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.05e+03 |\n",
      "|    total_cost         | 2.75e+04 |\n",
      "|    total_reward       | -4.4e+04 |\n",
      "|    total_reward_pct   | -87.9    |\n",
      "|    total_trades       | 29624    |\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.7    |\n",
      "|    explained_variance | -4.18    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.548   |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 9.59e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.117    |\n",
      "|    std                | 13.5     |\n",
      "|    value_loss         | 6.34e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -0.0286  |\n",
      "|    std                | 14       |\n",
      "|    value_loss         | 7.51e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -77.8    |\n",
      "|    explained_variance | -0.0781  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    std                | 14.6     |\n",
      "|    value_loss         | 0.000356 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -78.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.0138  |\n",
      "|    std                | 15.1     |\n",
      "|    value_loss         | 3.54e-05 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: -2627.23\n",
      "total_reward: -52627.23\n",
      "total_cost: 14235.86\n",
      "total_trades: 29052\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -2.63e+03 |\n",
      "|    total_cost         | 1.42e+04  |\n",
      "|    total_reward       | -5.26e+04 |\n",
      "|    total_reward_pct   | -105      |\n",
      "|    total_trades       | 29052     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 294       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -79.1     |\n",
      "|    explained_variance | -0.255    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -0.133    |\n",
      "|    std                | 15.6      |\n",
      "|    value_loss         | 5.75e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -79.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 6.51     |\n",
      "|    std                | 16.2     |\n",
      "|    value_loss         | 0.00672  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -80.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.216   |\n",
      "|    std                | 16.8     |\n",
      "|    value_loss         | 3.61e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81      |\n",
      "|    explained_variance | 0.0394   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -0.0333  |\n",
      "|    std                | 17.2     |\n",
      "|    value_loss         | 0.000116 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -81.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 0.702    |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 0.000106 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.58e+03  |\n",
      "|    total_cost         | 2.49e+04  |\n",
      "|    total_reward       | -4.64e+04 |\n",
      "|    total_reward_pct   | -92.8     |\n",
      "|    total_trades       | 29987     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 305       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -1.03     |\n",
      "|    std                | 18.3      |\n",
      "|    value_loss         | 0.000176  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 308       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -82.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 0.151     |\n",
      "|    std                | 18.9      |\n",
      "|    value_loss         | 3.89e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -83.5    |\n",
      "|    explained_variance | -0.146   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 2.61     |\n",
      "|    std                | 19.6     |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.219   |\n",
      "|    std                | 20.2     |\n",
      "|    value_loss         | 2.18e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -84.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -0.665   |\n",
      "|    std                | 20.8     |\n",
      "|    value_loss         | 6.82e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.21e+03  |\n",
      "|    total_cost         | 2.15e+04  |\n",
      "|    total_reward       | -4.78e+04 |\n",
      "|    total_reward_pct   | -95.6     |\n",
      "|    total_trades       | 29952     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 317       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -85.3     |\n",
      "|    explained_variance | 0.00838   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 0.677     |\n",
      "|    std                | 21.5      |\n",
      "|    value_loss         | 6.85e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -85.9    |\n",
      "|    explained_variance | -1.93    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.408   |\n",
      "|    std                | 22.2     |\n",
      "|    value_loss         | 3.56e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -86.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 0.432    |\n",
      "|    std                | 23       |\n",
      "|    value_loss         | 4.03e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.602    |\n",
      "|    std                | 23.9     |\n",
      "|    value_loss         | 6.3e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 326      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -87.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.424   |\n",
      "|    std                | 24.6     |\n",
      "|    value_loss         | 2.79e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -1.14e+04 |\n",
      "|    total_cost         | 2.31e+04  |\n",
      "|    total_reward       | -6.14e+04 |\n",
      "|    total_reward_pct   | -123      |\n",
      "|    total_trades       | 30514     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 328       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -88.3     |\n",
      "|    explained_variance | -2.91     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 0.154     |\n",
      "|    std                | 25.2      |\n",
      "|    value_loss         | 0.000108  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -88.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.513   |\n",
      "|    std                | 25.8     |\n",
      "|    value_loss         | 4.99e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 26.5     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -89.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 3.5      |\n",
      "|    std                | 27.2     |\n",
      "|    value_loss         | 0.0017   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.2    |\n",
      "|    explained_variance | -0.288   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 27.9     |\n",
      "|    value_loss         | 0.000312 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -90.7    |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 0.936    |\n",
      "|    std                | 28.7     |\n",
      "|    value_loss         | 0.00058  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.67e+03  |\n",
      "|    total_cost         | 3.35e+04  |\n",
      "|    total_reward       | -4.23e+04 |\n",
      "|    total_reward_pct   | -84.7     |\n",
      "|    total_trades       | 30977     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 342       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -0.322    |\n",
      "|    std                | 29.1      |\n",
      "|    value_loss         | 0.000965  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -91.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.542    |\n",
      "|    std                | 29.6     |\n",
      "|    value_loss         | 0.000103 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 346       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -91.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 0.915     |\n",
      "|    std                | 30.3      |\n",
      "|    value_loss         | 0.000121  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.2    |\n",
      "|    explained_variance | 0.218    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.14    |\n",
      "|    std                | 31.1     |\n",
      "|    value_loss         | 1.07e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -92.9    |\n",
      "|    explained_variance | -8.61    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 0.155    |\n",
      "|    std                | 32.2     |\n",
      "|    value_loss         | 1.11e-05 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 1724.95\n",
      "total_reward: -48275.05\n",
      "total_cost: 29451.77\n",
      "total_trades: 31743\n",
      "Sharpe: -0.685\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.72e+03  |\n",
      "|    total_cost         | 2.95e+04  |\n",
      "|    total_reward       | -4.83e+04 |\n",
      "|    total_reward_pct   | -96.6     |\n",
      "|    total_trades       | 31743     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 353       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -93.4     |\n",
      "|    explained_variance | -0.147    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | -0.481    |\n",
      "|    std                | 33.1      |\n",
      "|    value_loss         | 8.95e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -93.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 0.416    |\n",
      "|    std                | 33.9     |\n",
      "|    value_loss         | 2.55e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.4    |\n",
      "|    explained_variance | -0.0728  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -1.79    |\n",
      "|    std                | 34.8     |\n",
      "|    value_loss         | 0.000559 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -94.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    std                | 35.6     |\n",
      "|    value_loss         | 0.00016  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 362      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -95.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 0.199    |\n",
      "|    std                | 36.6     |\n",
      "|    value_loss         | 8.33e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | -3.22e+03 |\n",
      "|    total_cost         | 4.23e+04  |\n",
      "|    total_reward       | -5.32e+04 |\n",
      "|    total_reward_pct   | -106      |\n",
      "|    total_trades       | 31758     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 365       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -95.7     |\n",
      "|    explained_variance | 1.07e-06  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 0.984     |\n",
      "|    std                | 37.4      |\n",
      "|    value_loss         | 0.000115  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 367       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -96.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 0.56      |\n",
      "|    std                | 38.3      |\n",
      "|    value_loss         | 4.2e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -96.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 0.0557   |\n",
      "|    std                | 39.5     |\n",
      "|    value_loss         | 7.35e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 371      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -97.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -0.118   |\n",
      "|    std                | 41       |\n",
      "|    value_loss         | 6.1e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -98.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.341    |\n",
      "|    std                | 42.7     |\n",
      "|    value_loss         | 1.34e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | -968     |\n",
      "|    total_cost         | 1.48e+04 |\n",
      "|    total_reward       | -5.1e+04 |\n",
      "|    total_reward_pct   | -102     |\n",
      "|    total_trades       | 29591    |\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 2.27     |\n",
      "|    std                | 44.4     |\n",
      "|    value_loss         | 0.000574 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -99.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.395    |\n",
      "|    std                | 46       |\n",
      "|    value_loss         | 3.45e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -100     |\n",
      "|    explained_variance | 0.214    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 0.907    |\n",
      "|    std                | 47.7     |\n",
      "|    value_loss         | 9.7e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 383       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | -0.26     |\n",
      "|    std                | 49.7      |\n",
      "|    value_loss         | 7.63e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -102     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.113    |\n",
      "|    std                | 52       |\n",
      "|    value_loss         | 6.62e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 493       |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -4.95e+04 |\n",
      "|    total_reward_pct   | -99       |\n",
      "|    total_trades       | 29248     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 387       |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -103      |\n",
      "|    explained_variance | -0.921    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | 0.283     |\n",
      "|    std                | 54.4      |\n",
      "|    value_loss         | 1.42e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 390      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 0.0445   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.266   |\n",
      "|    std                | 56.7     |\n",
      "|    value_loss         | 9.35e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 392      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -104     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 2.68     |\n",
      "|    std                | 59       |\n",
      "|    value_loss         | 0.00121  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 394      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    std                | 60.4     |\n",
      "|    value_loss         | 0.000386 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 396      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -105     |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 0.829    |\n",
      "|    std                | 61.7     |\n",
      "|    value_loss         | 0.000232 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.7e+03   |\n",
      "|    total_cost         | 3.68e+04  |\n",
      "|    total_reward       | -4.63e+04 |\n",
      "|    total_reward_pct   | -92.6     |\n",
      "|    total_trades       | 30654     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 399       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -106      |\n",
      "|    explained_variance | -2.78     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 0.505     |\n",
      "|    std                | 63.2      |\n",
      "|    value_loss         | 3.89e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 401      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -106     |\n",
      "|    explained_variance | -1.73    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    std                | 65.2     |\n",
      "|    value_loss         | 8.58e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -0.257   |\n",
      "|    std                | 67.5     |\n",
      "|    value_loss         | 1.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -107     |\n",
      "|    explained_variance | -0.771   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -0.454   |\n",
      "|    std                | 69.4     |\n",
      "|    value_loss         | 0.000371 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 408      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -108     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.9      |\n",
      "|    std                | 71.3     |\n",
      "|    value_loss         | 0.000104 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -109     |\n",
      "|    explained_variance | -7.2     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 2.64     |\n",
      "|    std                | 73.7     |\n",
      "|    value_loss         | 0.000763 |\n",
      "------------------------------------\n",
      "day: 2586, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4688.08\n",
      "total_reward: -45311.92\n",
      "total_cost: 27697.60\n",
      "total_trades: 30242\n",
      "Sharpe: 0.372\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.69e+03  |\n",
      "|    total_cost         | 2.77e+04  |\n",
      "|    total_reward       | -4.53e+04 |\n",
      "|    total_reward_pct   | -90.6     |\n",
      "|    total_trades       | 30242     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 412       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -109      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 0.338     |\n",
      "|    std                | 76        |\n",
      "|    value_loss         | 1.95e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 415      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -110     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.79     |\n",
      "|    std                | 78.6     |\n",
      "|    value_loss         | 7.25e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 417      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.246   |\n",
      "|    std                | 81.7     |\n",
      "|    value_loss         | 2.5e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 419      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -111     |\n",
      "|    explained_variance | -2.66    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.113   |\n",
      "|    std                | 85.2     |\n",
      "|    value_loss         | 5.79e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 422       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -112      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | 0.136     |\n",
      "|    std                | 89        |\n",
      "|    value_loss         | 1.98e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 689       |\n",
      "|    total_cost         | 1.43e+04  |\n",
      "|    total_reward       | -4.93e+04 |\n",
      "|    total_reward_pct   | -98.6     |\n",
      "|    total_trades       | 29530     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 424       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -113      |\n",
      "|    explained_variance | -33.6     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 0.268     |\n",
      "|    std                | 93        |\n",
      "|    value_loss         | 1.15e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -0.0491  |\n",
      "|    std                | 96.7     |\n",
      "|    value_loss         | 1.92e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 428      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -114     |\n",
      "|    explained_variance | 0.667    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -3.45    |\n",
      "|    std                | 100      |\n",
      "|    value_loss         | 0.000983 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 431      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -115     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 0.769    |\n",
      "|    std                | 103      |\n",
      "|    value_loss         | 6.39e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 433      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -115     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.388   |\n",
      "|    std                | 106      |\n",
      "|    value_loss         | 1.28e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.46e+03  |\n",
      "|    total_cost         | 2.91e+04  |\n",
      "|    total_reward       | -4.65e+04 |\n",
      "|    total_reward_pct   | -93.1     |\n",
      "|    total_trades       | 30355     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 435       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -116      |\n",
      "|    explained_variance | -0.68     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | -0.578    |\n",
      "|    std                | 109       |\n",
      "|    value_loss         | 4.42e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 437      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -117     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.506   |\n",
      "|    std                | 114      |\n",
      "|    value_loss         | 2.22e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 440       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -118      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -1.18     |\n",
      "|    std                | 118       |\n",
      "|    value_loss         | 0.000168  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 442      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -118     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -2.75    |\n",
      "|    std                | 122      |\n",
      "|    value_loss         | 0.000722 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 444      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -119     |\n",
      "|    explained_variance | 0.144    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 1.83     |\n",
      "|    std                | 126      |\n",
      "|    value_loss         | 0.000247 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.27e+03  |\n",
      "|    total_cost         | 2.36e+04  |\n",
      "|    total_reward       | -4.67e+04 |\n",
      "|    total_reward_pct   | -93.5     |\n",
      "|    total_trades       | 29764     |\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 447       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -119      |\n",
      "|    explained_variance | -1.17e+03 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -0.787    |\n",
      "|    std                | 130       |\n",
      "|    value_loss         | 0.000109  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 449      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -120     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    std                | 135      |\n",
      "|    value_loss         | 0.000156 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 451      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -121     |\n",
      "|    explained_variance | -0.0624  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -8.8     |\n",
      "|    std                | 140      |\n",
      "|    value_loss         | 0.00741  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 453      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -121     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 1.94     |\n",
      "|    std                | 144      |\n",
      "|    value_loss         | 0.000338 |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-07-09 to  2020-10-06\n",
      "A2C Sharpe Ratio:  -0.05463901976501978\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 246  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2586, episode: 40\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 8861.36\n",
      "total_reward: -41138.64\n",
      "total_cost: 33649.20\n",
      "total_trades: 31173\n",
      "Sharpe: 0.014\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.86e+03    |\n",
      "|    total_cost           | 3.36e+04    |\n",
      "|    total_reward         | -4.11e+04   |\n",
      "|    total_reward_pct     | -82.3       |\n",
      "|    total_trades         | 31173       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016149733 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.937      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0358      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.03e+03    |\n",
      "|    total_cost           | 1.68e+04    |\n",
      "|    total_reward         | -4.2e+04    |\n",
      "|    total_reward_pct     | -83.9       |\n",
      "|    total_trades         | 29192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015699923 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.0587     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0189      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2e+03       |\n",
      "|    total_cost           | 1.31e+04    |\n",
      "|    total_reward         | -4.8e+04    |\n",
      "|    total_reward_pct     | -96         |\n",
      "|    total_trades         | 28761       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013373974 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021931298 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | -0.65       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00891     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.75e+03    |\n",
      "|    total_cost           | 3.3e+04     |\n",
      "|    total_reward         | -4.42e+04   |\n",
      "|    total_reward_pct     | -88.5       |\n",
      "|    total_trades         | 31277       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015637677 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00644     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.05e+03    |\n",
      "|    total_cost           | 2.24e+04    |\n",
      "|    total_reward         | -4.79e+04   |\n",
      "|    total_reward_pct     | -95.9       |\n",
      "|    total_trades         | 29839       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014619529 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.339      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00684     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 45\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 17664.91\n",
      "total_reward: -32335.09\n",
      "total_cost: 67652.72\n",
      "total_trades: 32981\n",
      "Sharpe: -0.293\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+04    |\n",
      "|    total_cost           | 6.77e+04    |\n",
      "|    total_reward         | -3.23e+04   |\n",
      "|    total_reward_pct     | -64.7       |\n",
      "|    total_trades         | 32981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019667488 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | -0.622      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0181      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+04    |\n",
      "|    total_cost           | 3.44e+04    |\n",
      "|    total_reward         | -2.84e+04   |\n",
      "|    total_reward_pct     | -56.9       |\n",
      "|    total_trades         | 31024       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009752719 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03018568 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.2      |\n",
      "|    explained_variance   | -0.389     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0255    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0138     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.76e+04    |\n",
      "|    total_cost           | 5.11e+04    |\n",
      "|    total_reward         | -3.24e+04   |\n",
      "|    total_reward_pct     | -64.8       |\n",
      "|    total_trades         | 32573       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020658333 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.306      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.86e+03    |\n",
      "|    total_cost           | 1.91e+04    |\n",
      "|    total_reward         | -4.11e+04   |\n",
      "|    total_reward_pct     | -82.3       |\n",
      "|    total_trades         | 29118       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019879336 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.12e+04    |\n",
      "|    total_cost           | 6.81e+04    |\n",
      "|    total_reward         | -1.88e+04   |\n",
      "|    total_reward_pct     | -37.6       |\n",
      "|    total_trades         | 33295       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022296783 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | -0.556      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0143      |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 50\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2155.13\n",
      "total_reward: -47844.87\n",
      "total_cost: 16734.73\n",
      "total_trades: 29273\n",
      "Sharpe: -0.601\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.16e+03    |\n",
      "|    total_cost           | 1.67e+04    |\n",
      "|    total_reward         | -4.78e+04   |\n",
      "|    total_reward_pct     | -95.7       |\n",
      "|    total_trades         | 29273       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017855572 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074342852 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.5        |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.309       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0204      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00432      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 872         |\n",
      "|    total_cost           | 1.01e+04    |\n",
      "|    total_reward         | -4.91e+04   |\n",
      "|    total_reward_pct     | -98.3       |\n",
      "|    total_trades         | 28117       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016266262 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0014      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+04    |\n",
      "|    total_cost           | 2.38e+04    |\n",
      "|    total_reward         | -3.87e+04   |\n",
      "|    total_reward_pct     | -77.4       |\n",
      "|    total_trades         | 30118       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027460823 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00834     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.23e+04    |\n",
      "|    total_cost           | 2.65e+04    |\n",
      "|    total_reward         | -3.77e+04   |\n",
      "|    total_reward_pct     | -75.4       |\n",
      "|    total_trades         | 30525       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027558126 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.281      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0068      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.4e+03     |\n",
      "|    total_cost           | 2.1e+04     |\n",
      "|    total_reward         | -4.06e+04   |\n",
      "|    total_reward_pct     | -81.2       |\n",
      "|    total_trades         | 30124       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028196117 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00439     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021936614 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00337     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 55\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 15957.95\n",
      "total_reward: -34042.05\n",
      "total_cost: 22815.85\n",
      "total_trades: 30211\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.6e+04     |\n",
      "|    total_cost           | 2.28e+04    |\n",
      "|    total_reward         | -3.4e+04    |\n",
      "|    total_reward_pct     | -68.1       |\n",
      "|    total_trades         | 30211       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030730572 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00637     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.58e+04    |\n",
      "|    total_cost           | 3.07e+04    |\n",
      "|    total_reward         | -3.42e+04   |\n",
      "|    total_reward_pct     | -68.4       |\n",
      "|    total_trades         | 31131       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027019251 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00619     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.61e+04   |\n",
      "|    total_cost           | 2.04e+04   |\n",
      "|    total_reward         | -3.39e+04  |\n",
      "|    total_reward_pct     | -67.8      |\n",
      "|    total_trades         | 29677      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 194        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03200479 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.293     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.00667    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018460311 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+04    |\n",
      "|    total_cost           | 1.91e+04    |\n",
      "|    total_reward         | -3.82e+04   |\n",
      "|    total_reward_pct     | -76.3       |\n",
      "|    total_trades         | 29392       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033151515 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00941     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.96e+04    |\n",
      "|    total_cost           | 2.84e+04    |\n",
      "|    total_reward         | -3.04e+04   |\n",
      "|    total_reward_pct     | -60.7       |\n",
      "|    total_trades         | 30552       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039341018 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | -0.667      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 60\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 5847.49\n",
      "total_reward: -44152.51\n",
      "total_cost: 16150.77\n",
      "total_trades: 29408\n",
      "Sharpe: -0.124\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.85e+03    |\n",
      "|    total_cost           | 1.62e+04    |\n",
      "|    total_reward         | -4.42e+04   |\n",
      "|    total_reward_pct     | -88.3       |\n",
      "|    total_trades         | 29408       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028112387 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.307      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00576     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.45e+04    |\n",
      "|    total_cost           | 2.7e+04     |\n",
      "|    total_reward         | -1.55e+04   |\n",
      "|    total_reward_pct     | -31         |\n",
      "|    total_trades         | 30823       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020979606 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00435     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022429494 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.295      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.46e+04    |\n",
      "|    total_cost           | 2.11e+04    |\n",
      "|    total_reward         | -3.54e+04   |\n",
      "|    total_reward_pct     | -70.9       |\n",
      "|    total_trades         | 29683       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018290443 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00746     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.21e+04    |\n",
      "|    total_cost           | 2.79e+04    |\n",
      "|    total_reward         | -3.79e+04   |\n",
      "|    total_reward_pct     | -75.8       |\n",
      "|    total_trades         | 30891       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028507106 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00642     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.14e+04    |\n",
      "|    total_cost           | 4.6e+04     |\n",
      "|    total_reward         | -8.56e+03   |\n",
      "|    total_reward_pct     | -17.1       |\n",
      "|    total_trades         | 32029       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028489802 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 65\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 55057.25\n",
      "total_reward: 5057.25\n",
      "total_cost: 49141.30\n",
      "total_trades: 31976\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.51e+04    |\n",
      "|    total_cost           | 4.91e+04    |\n",
      "|    total_reward         | 5.06e+03    |\n",
      "|    total_reward_pct     | 10.1        |\n",
      "|    total_trades         | 31976       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015493365 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.268      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0221      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027378509 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0365      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.07e+05    |\n",
      "|    total_cost           | 6.64e+04    |\n",
      "|    total_reward         | 5.73e+04    |\n",
      "|    total_reward_pct     | 115         |\n",
      "|    total_trades         | 33008       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026252482 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.275      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0466      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.55e+04    |\n",
      "|    total_cost           | 2.57e+04    |\n",
      "|    total_reward         | -3.45e+04   |\n",
      "|    total_reward_pct     | -69         |\n",
      "|    total_trades         | 30151       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015266754 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.274      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0386      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.42e+03    |\n",
      "|    total_cost           | 2.01e+04    |\n",
      "|    total_reward         | -4.16e+04   |\n",
      "|    total_reward_pct     | -83.2       |\n",
      "|    total_trades         | 29775       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023301588 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0059      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.71e+03   |\n",
      "|    total_cost           | 1.17e+04   |\n",
      "|    total_reward         | -4.83e+04  |\n",
      "|    total_reward_pct     | -96.6      |\n",
      "|    total_trades         | 28617      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03452523 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.3      |\n",
      "|    explained_variance   | 0.725      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.341     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.00399    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029497614 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.323      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00256     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 70\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 24078.94\n",
      "total_reward: -25921.06\n",
      "total_cost: 34746.51\n",
      "total_trades: 31124\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.41e+04    |\n",
      "|    total_cost           | 3.47e+04    |\n",
      "|    total_reward         | -2.59e+04   |\n",
      "|    total_reward_pct     | -51.8       |\n",
      "|    total_trades         | 31124       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041769274 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00869     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.76e+04    |\n",
      "|    total_cost           | 3.85e+04    |\n",
      "|    total_reward         | -3.24e+04   |\n",
      "|    total_reward_pct     | -64.9       |\n",
      "|    total_trades         | 30742       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030460697 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.5e+03     |\n",
      "|    total_cost           | 1.78e+04    |\n",
      "|    total_reward         | -4.05e+04   |\n",
      "|    total_reward_pct     | -81         |\n",
      "|    total_trades         | 29604       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032626837 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.319      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00424     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.97e+03    |\n",
      "|    total_cost           | 2.18e+04    |\n",
      "|    total_reward         | -4.4e+04    |\n",
      "|    total_reward_pct     | -88.1       |\n",
      "|    total_trades         | 29612       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034248266 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00318     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034512978 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00366     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+04    |\n",
      "|    total_cost           | 4.18e+04    |\n",
      "|    total_reward         | -3.84e+04   |\n",
      "|    total_reward_pct     | -76.9       |\n",
      "|    total_trades         | 31172       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030730052 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00649     |\n",
      "-----------------------------------------\n",
      "day: 2586, episode: 75\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 16719.27\n",
      "total_reward: -33280.73\n",
      "total_cost: 28963.98\n",
      "total_trades: 30319\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.67e+04    |\n",
      "|    total_cost           | 2.9e+04     |\n",
      "|    total_reward         | -3.33e+04   |\n",
      "|    total_reward_pct     | -66.6       |\n",
      "|    total_trades         | 30319       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030650476 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+04    |\n",
      "|    total_cost           | 3.43e+04    |\n",
      "|    total_reward         | -2.45e+04   |\n",
      "|    total_reward_pct     | -49         |\n",
      "|    total_trades         | 31122       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033097707 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.334      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00726     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028354863 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.7       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00806     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.67e+04    |\n",
      "|    total_cost           | 2.78e+04    |\n",
      "|    total_reward         | -3.33e+04   |\n",
      "|    total_reward_pct     | -66.5       |\n",
      "|    total_trades         | 30509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028413974 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.8       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.303      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00831     |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-07-09 to  2020-10-06\n",
      "PPO Sharpe Ratio:  0.05365990664187649\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_1\n",
      "day: 2586, episode: 80\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 66994.23\n",
      "total_reward: 16994.23\n",
      "total_cost: 181.01\n",
      "total_trades: 25174\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.44e+04  |\n",
      "|    total_cost       | 105       |\n",
      "|    total_reward     | -5.62e+03 |\n",
      "|    total_reward_pct | -11.2     |\n",
      "|    total_trades     | 25993     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 116       |\n",
      "|    time_elapsed     | 88        |\n",
      "|    total timesteps  | 10348     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -19.3     |\n",
      "|    critic_loss      | 5.85      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7761      |\n",
      "-----------------------------------\n",
      "day: 2586, episode: 85\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 21589.89\n",
      "total_reward: -28410.11\n",
      "total_cost: 134.48\n",
      "total_trades: 26521\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 4.87e+04 |\n",
      "|    total_cost       | 97.3     |\n",
      "|    total_reward     | -1.3e+03 |\n",
      "|    total_reward_pct | -2.6     |\n",
      "|    total_trades     | 26374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 106      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total timesteps  | 20696    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -11.9    |\n",
      "|    critic_loss      | 1.4      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18109    |\n",
      "----------------------------------\n",
      "day: 2586, episode: 90\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 68677.94\n",
      "total_reward: 18677.94\n",
      "total_cost: 265.64\n",
      "total_trades: 26000\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 6.87e+04 |\n",
      "|    total_cost       | 266      |\n",
      "|    total_reward     | 1.87e+04 |\n",
      "|    total_reward_pct | 37.4     |\n",
      "|    total_trades     | 26000    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total timesteps  | 31044    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -7.41    |\n",
      "|    critic_loss      | 0.833    |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28457    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 2.96e+04  |\n",
      "|    total_cost       | 130       |\n",
      "|    total_reward     | -2.04e+04 |\n",
      "|    total_reward_pct | -40.8     |\n",
      "|    total_trades     | 25845     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 101       |\n",
      "|    time_elapsed     | 406       |\n",
      "|    total timesteps  | 41392     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -4.72     |\n",
      "|    critic_loss      | 0.612     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 38805     |\n",
      "-----------------------------------\n",
      "day: 2586, episode: 95\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 70688.37\n",
      "total_reward: 20688.37\n",
      "total_cost: 201.17\n",
      "total_trades: 26042\n",
      "Sharpe: 0.338\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 4.79e+04  |\n",
      "|    total_cost       | 98.7      |\n",
      "|    total_reward     | -2.14e+03 |\n",
      "|    total_reward_pct | -4.27     |\n",
      "|    total_trades     | 26577     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 100       |\n",
      "|    time_elapsed     | 512       |\n",
      "|    total timesteps  | 51740     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -3.17     |\n",
      "|    critic_loss      | 0.627     |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 49153     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2020-07-09 to  2020-10-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-10-06\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ensemble_504_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 247  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.76e+04    |\n",
      "|    total_cost           | 9.16e+04    |\n",
      "|    total_reward         | -3.24e+04   |\n",
      "|    total_reward_pct     | -64.8       |\n",
      "|    total_trades         | 34803       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011603667 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | -0.232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.259      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0886      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.09e+03    |\n",
      "|    total_cost           | 4.01e+04    |\n",
      "|    total_reward         | -4.29e+04   |\n",
      "|    total_reward_pct     | -85.8       |\n",
      "|    total_trades         | 32102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014256141 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0306      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+04    |\n",
      "|    total_cost           | 4.12e+04    |\n",
      "|    total_reward         | -3.83e+04   |\n",
      "|    total_reward_pct     | -76.7       |\n",
      "|    total_trades         | 32252       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019894738 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.297      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016650928 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.288      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0133      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+03       |\n",
      "|    total_cost           | 1.51e+04    |\n",
      "|    total_reward         | -4.9e+04    |\n",
      "|    total_reward_pct     | -98         |\n",
      "|    total_trades         | 29719       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012083923 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0059      |\n",
      "-----------------------------------------\n",
      "day: 2649, episode: 5\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 4944.30\n",
      "total_reward: -45055.70\n",
      "total_cost: 25895.98\n",
      "total_trades: 31456\n",
      "Sharpe: -0.344\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.94e+03    |\n",
      "|    total_cost           | 2.59e+04    |\n",
      "|    total_reward         | -4.51e+04   |\n",
      "|    total_reward_pct     | -90.1       |\n",
      "|    total_trades         | 31456       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196643 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.31       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+03    |\n",
      "|    total_cost           | 1.66e+04    |\n",
      "|    total_reward         | -4.75e+04   |\n",
      "|    total_reward_pct     | -95         |\n",
      "|    total_trades         | 29765       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019575268 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.316      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0078      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055226507 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -27.2        |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.284       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00513      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.35e+04    |\n",
      "|    total_cost           | 2.12e+04    |\n",
      "|    total_reward         | -3.65e+04   |\n",
      "|    total_reward_pct     | -73.1       |\n",
      "|    total_trades         | 28327       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014281204 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00945     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -6.2e+03    |\n",
      "|    total_cost           | 1.52e+04    |\n",
      "|    total_reward         | -5.62e+04   |\n",
      "|    total_reward_pct     | -112        |\n",
      "|    total_trades         | 29192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019089945 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00889     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -7.18e+03  |\n",
      "|    total_cost           | 2.34e+04   |\n",
      "|    total_reward         | -5.72e+04  |\n",
      "|    total_reward_pct     | -114       |\n",
      "|    total_trades         | 30874      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02380848 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.302     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0244    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.00593    |\n",
      "----------------------------------------\n",
      "day: 2649, episode: 10\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 6264.28\n",
      "total_reward: -43735.72\n",
      "total_cost: 11668.01\n",
      "total_trades: 29297\n",
      "Sharpe: -0.048\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.26e+03    |\n",
      "|    total_cost           | 1.17e+04    |\n",
      "|    total_reward         | -4.37e+04   |\n",
      "|    total_reward_pct     | -87.5       |\n",
      "|    total_trades         | 29297       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015564818 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00452     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017660625 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00261     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.69e+03    |\n",
      "|    total_cost           | 1.62e+04    |\n",
      "|    total_reward         | -4.23e+04   |\n",
      "|    total_reward_pct     | -84.6       |\n",
      "|    total_trades         | 27844       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013449207 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00563     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+04    |\n",
      "|    total_cost           | 1.62e+04    |\n",
      "|    total_reward         | -3.87e+04   |\n",
      "|    total_reward_pct     | -77.5       |\n",
      "|    total_trades         | 28086       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026008721 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00627     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.5e+04     |\n",
      "|    total_cost           | 4.48e+04    |\n",
      "|    total_reward         | -3.5e+04    |\n",
      "|    total_reward_pct     | -70.1       |\n",
      "|    total_trades         | 33136       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033407636 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | -2.99       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0175      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02361482 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.6      |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.306     |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0102     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.39e+03    |\n",
      "|    total_cost           | 2e+04       |\n",
      "|    total_reward         | -4.56e+04   |\n",
      "|    total_reward_pct     | -91.2       |\n",
      "|    total_trades         | 30834       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026604917 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "day: 2649, episode: 15\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 2864.16\n",
      "total_reward: -47135.84\n",
      "total_cost: 18459.66\n",
      "total_trades: 30836\n",
      "Sharpe: 0.027\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.86e+03   |\n",
      "|    total_cost           | 1.85e+04   |\n",
      "|    total_reward         | -4.71e+04  |\n",
      "|    total_reward_pct     | -94.3      |\n",
      "|    total_trades         | 30836      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 172        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02703591 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.7      |\n",
      "|    explained_variance   | 0.679      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.261     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.00309    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+04    |\n",
      "|    total_cost           | 2.25e+04    |\n",
      "|    total_reward         | -3.75e+04   |\n",
      "|    total_reward_pct     | -75         |\n",
      "|    total_trades         | 29394       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034548666 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.7       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.318      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00691     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.12e+04    |\n",
      "|    total_cost           | 2.07e+04    |\n",
      "|    total_reward         | -3.88e+04   |\n",
      "|    total_reward_pct     | -77.6       |\n",
      "|    total_trades         | 31347       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018601997 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00323     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030098163 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00283     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.38e+03    |\n",
      "|    total_cost           | 1.36e+04    |\n",
      "|    total_reward         | -4.06e+04   |\n",
      "|    total_reward_pct     | -81.2       |\n",
      "|    total_trades         | 30403       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031175911 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.81e+03    |\n",
      "|    total_cost           | 1.7e+04     |\n",
      "|    total_reward         | -4.22e+04   |\n",
      "|    total_reward_pct     | -84.4       |\n",
      "|    total_trades         | 30934       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027468372 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00253     |\n",
      "-----------------------------------------\n",
      "day: 2649, episode: 20\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 12200.05\n",
      "total_reward: -37799.95\n",
      "total_cost: 15555.16\n",
      "total_trades: 29300\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+04    |\n",
      "|    total_cost           | 1.56e+04    |\n",
      "|    total_reward         | -3.78e+04   |\n",
      "|    total_reward_pct     | -75.6       |\n",
      "|    total_trades         | 29300       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025640637 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00151     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 233        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04048816 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | -0.828     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.301     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0208     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.15e+04    |\n",
      "|    total_cost           | 5.55e+04    |\n",
      "|    total_reward         | 1.15e+04    |\n",
      "|    total_reward_pct     | 23          |\n",
      "|    total_trades         | 33945       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030895319 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0253      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.02e+04    |\n",
      "|    total_cost           | 7.47e+04    |\n",
      "|    total_reward         | 4.02e+04    |\n",
      "|    total_reward_pct     | 80.5        |\n",
      "|    total_trades         | 34489       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017456982 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0678      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.72e+04   |\n",
      "|    total_cost           | 2.26e+04   |\n",
      "|    total_reward         | -3.28e+04  |\n",
      "|    total_reward_pct     | -65.7      |\n",
      "|    total_trades         | 31644      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 260        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01911233 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.261     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0826     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017782198 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.66e+04    |\n",
      "|    total_cost           | 3.37e+04    |\n",
      "|    total_reward         | -3.45e+03   |\n",
      "|    total_reward_pct     | -6.9        |\n",
      "|    total_trades         | 29850       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033590745 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0453      |\n",
      "-----------------------------------------\n",
      "day: 2649, episode: 25\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 41805.15\n",
      "total_reward: -8194.85\n",
      "total_cost: 27844.77\n",
      "total_trades: 29428\n",
      "Sharpe: 0.308\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.18e+04    |\n",
      "|    total_cost           | 2.78e+04    |\n",
      "|    total_reward         | -8.19e+03   |\n",
      "|    total_reward_pct     | -16.4       |\n",
      "|    total_trades         | 29428       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036881577 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.58e+03    |\n",
      "|    total_cost           | 1.73e+04    |\n",
      "|    total_reward         | -4.74e+04   |\n",
      "|    total_reward_pct     | -94.8       |\n",
      "|    total_trades         | 30839       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028769894 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.3        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.97e+03    |\n",
      "|    total_cost           | 1.94e+04    |\n",
      "|    total_reward         | -4e+04      |\n",
      "|    total_reward_pct     | -80.1       |\n",
      "|    total_trades         | 29272       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015920805 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.317      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00575     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021833964 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.57e+04   |\n",
      "|    total_cost           | 1.43e+04   |\n",
      "|    total_reward         | -3.43e+04  |\n",
      "|    total_reward_pct     | -68.7      |\n",
      "|    total_trades         | 28600      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03469359 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.2      |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.273     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.00584    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+04    |\n",
      "|    total_cost           | 1.87e+04    |\n",
      "|    total_reward         | -3.71e+04   |\n",
      "|    total_reward_pct     | -74.2       |\n",
      "|    total_trades         | 31143       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027342815 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00672     |\n",
      "-----------------------------------------\n",
      "day: 2649, episode: 30\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 60025.02\n",
      "total_reward: 10025.02\n",
      "total_cost: 39520.79\n",
      "total_trades: 33301\n",
      "Sharpe: 0.213\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6e+04       |\n",
      "|    total_cost           | 3.95e+04    |\n",
      "|    total_reward         | 1e+04       |\n",
      "|    total_reward_pct     | 20.1        |\n",
      "|    total_trades         | 33301       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026426082 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019555112 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.257      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0332      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.96e+04    |\n",
      "|    total_cost           | 1.63e+04    |\n",
      "|    total_reward         | -2.04e+04   |\n",
      "|    total_reward_pct     | -40.8       |\n",
      "|    total_trades         | 30661       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035133794 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.005       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.35e+04    |\n",
      "|    total_cost           | 2.07e+04    |\n",
      "|    total_reward         | -2.65e+04   |\n",
      "|    total_reward_pct     | -52.9       |\n",
      "|    total_trades         | 31311       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018405795 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.319      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00692     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.19e+03   |\n",
      "|    total_cost           | 1.78e+04   |\n",
      "|    total_reward         | -4.78e+04  |\n",
      "|    total_reward_pct     | -95.6      |\n",
      "|    total_trades         | 31084      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 372        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02614949 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.684      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.311     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.00602    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.16e+04   |\n",
      "|    total_cost           | 1.39e+04    |\n",
      "|    total_reward         | -6.16e+04   |\n",
      "|    total_reward_pct     | -123        |\n",
      "|    total_trades         | 30725       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025572672 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.315      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00371     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026578233 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00661     |\n",
      "-----------------------------------------\n",
      "day: 2649, episode: 35\n",
      "begin_total_asset: 50000.00\n",
      "end_total_asset: 35987.39\n",
      "total_reward: -14012.61\n",
      "total_cost: 27086.40\n",
      "total_trades: 31956\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.6e+04     |\n",
      "|    total_cost           | 2.71e+04    |\n",
      "|    total_reward         | -1.4e+04    |\n",
      "|    total_reward_pct     | -28         |\n",
      "|    total_trades         | 31956       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028512442 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.259      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00875     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.37e+04   |\n",
      "|    total_cost           | 2.5e+04    |\n",
      "|    total_reward         | -6.31e+03  |\n",
      "|    total_reward_pct     | -12.6      |\n",
      "|    total_trades         | 31549      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 407        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03793861 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.5      |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.318     |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.00875    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.42e+04   |\n",
      "|    total_cost           | 2.37e+04   |\n",
      "|    total_reward         | -1.58e+04  |\n",
      "|    total_reward_pct     | -31.6      |\n",
      "|    total_trades         | 32232      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 416        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03278944 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.6      |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.296     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.0261     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034099136 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.6       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0123      |\n",
      "-----------------------------------------\n",
      "======Trading from:  2020-10-06 to  2021-01-06\n",
      "Ensemble Strategy took:  211.7364906946818  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.0617986</td>\n",
       "      <td>0.237839</td>\n",
       "      <td>0.302988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.225373</td>\n",
       "      <td>0.249032</td>\n",
       "      <td>0.617601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.221232</td>\n",
       "      <td>-0.182869</td>\n",
       "      <td>-0.178115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.373537</td>\n",
       "      <td>0.19551</td>\n",
       "      <td>0.250524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.251083</td>\n",
       "      <td>-0.392417</td>\n",
       "      <td>-0.0786158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.20943</td>\n",
       "      <td>0.0508234</td>\n",
       "      <td>0.166593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.054639</td>\n",
       "      <td>0.0536599</td>\n",
       "      <td>-0.266323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126  2019-01-03  2019-04-04       DDPG  0.0617986   0.237839    0.302988\n",
       "1  189  2019-04-04  2019-07-05       DDPG  -0.225373   0.249032    0.617601\n",
       "2  252  2019-07-05  2019-10-02       DDPG  -0.221232  -0.182869   -0.178115\n",
       "3  315  2019-10-02  2020-01-03        A2C   0.373537    0.19551    0.250524\n",
       "4  378  2020-01-03  2020-04-06       DDPG  -0.251083  -0.392417  -0.0786158\n",
       "5  441  2020-04-06  2020-07-09        A2C    0.20943  0.0508234    0.166593\n",
       "6  504  2020-07-09  2020-10-06        PPO  -0.054639  0.0536599   -0.266323"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.36301273156440733\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50182.734417</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>2019-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50223.428631</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>2019-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50968.613780</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>2019-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51195.990131</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>2019-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   50000.000000  2019-04-04           NaN  2019-04-04\n",
       "1   50182.734417  2019-04-05      0.003655  2019-04-05\n",
       "2   50223.428631  2019-04-08      0.000811  2019-04-08\n",
       "3   50968.613780  2019-04-09      0.014837  2019-04-09\n",
       "4   51195.990131  2019-04-10      0.004461  2019-04-10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.058940\n",
      "Cumulative returns     0.105413\n",
      "Annual volatility      0.232840\n",
      "Sharpe ratio           0.363013\n",
      "Calmar ratio           0.201724\n",
      "Stability              0.075538\n",
      "Max drawdown          -0.292180\n",
      "Omega ratio            1.066048\n",
      "Sortino ratio          0.509017\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.040224\n",
      "Daily value at risk   -0.029000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to IHSG===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (425, 8)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4fe69935546d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^JKSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n\u001b[0m",
      "\u001b[0;32m/home/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mbacktest_plot\u001b[0;34m(account_value, baseline_start, baseline_end, baseline_ticker, value_col_name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         pyfolio.create_full_tear_sheet(\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mreturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[0;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mturnover_denom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturnover_denom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mheader_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         set_context=set_context)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     create_interesting_times_tear_sheet(returns,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[0;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbenchmark_rets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_returns_to_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     plotting.show_perf_stats(returns, benchmark_rets,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyfolio/utils.py\u001b[0m in \u001b[0;36mclip_returns_to_benchmark\u001b[0;34m(rets, benchmark_rets)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mclipped_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     raise KeyError(\n\u001b[0;32m-> 1316\u001b[0;31m                         \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m                         \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                         \u001b[0;34mf\"The following labels were missing: {not_found}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2019-05-09 00:00:00+00:00', '2019-06-12 00:00:00+00:00',\\n               '2019-11-04 00:00:00+00:00', '2020-01-02 00:00:00+00:00',\\n               '2020-01-07 00:00:00+00:00',\\n               ...\\n               '2020-05-11 00:00:00+00:00', '2020-06-12 00:00:00+00:00',\\n               '2020-06-24 00:00:00+00:00', '2020-07-01 00:00:00+00:00',\\n               '2020-11-04 00:00:00+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=12, freq=None). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to IHSG===========\")\n",
    "%matplotlib inline\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^JKSE', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_perf_stats=backtest_stats('^JKSE',\n",
    "                                  baseline_start = df_account_value.loc[0,'date'],\n",
    "                                  baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_multiple_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
